[2023-11-21 19:49:02,072][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/hubert_with_llama', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1400000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train-clean-360', 'valid_subset': 'dev-other,dev-clean', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 5, 'validate_interval_updates': 10000, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1400000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 100000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [32], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 25000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'LLaMAhubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.1, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'llama_path': '/mntcephfs/lab_data/maduo/model_hub/OPT-LLM/lit-llama/7b/7B/lit-llama.pth', 'hubert_path': '/mntcephfs/lab_data/maduo/model_hub/librispeech/hubert_base_librispeech_offical_no_finetune//hubert_base_ls960.pt', 'n_layer': 32, 'n_head': 32, 'n_embd': 4096, 'multiple_of': 256, 'first_layer': 31, 'n_layers': 32, 'llama_post_norm': False}, 'task': {'_name': 'hubert_pretraining', 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech', 'fine_tuning': False, 'labels': ['km'], 'label_dir': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/feat_dir/9layer_feat_from_offical_hubert_base_model/label_dir/', 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}, 'criterion': {'_name': 'hubert', 'pred_masked_weight': 1.0, 'pred_nomask_weight': 0.0, 'loss_weights': [10.0], 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005], 'amsgrad': False}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 100000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': '/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/hubert_with_llama/pretrain.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2023-11-21 19:49:02,075][fairseq.tasks.hubert_pretraining][INFO] - current directory is /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/hubert_with_llama
[2023-11-21 19:49:02,075][fairseq.tasks.hubert_pretraining][INFO] - HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech', 'fine_tuning': False, 'labels': ['km'], 'label_dir': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/feat_dir/9layer_feat_from_offical_hubert_base_model/label_dir/', 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
[2023-11-21 19:49:02,084][fairseq.models.hubert.hubert_with_llama][INFO] - HubertModel Config: {'_name': 'LLaMAhubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.1, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'llama_path': '/mntcephfs/lab_data/maduo/model_hub/OPT-LLM/lit-llama/7b/7B/lit-llama.pth', 'hubert_path': '/mntcephfs/lab_data/maduo/model_hub/librispeech/hubert_base_librispeech_offical_no_finetune//hubert_base_ls960.pt', 'n_layer': 32, 'n_head': 32, 'n_embd': 4096, 'multiple_of': 256, 'first_layer': 31, 'n_layers': 32, 'llama_post_norm': False}
[2023-11-21 19:49:04,227][fairseq_cli.train][INFO] - Loading LLaMA checkpoints
[2023-11-21 19:49:04,568][fairseq_cli.train][INFO] - Loaded in 0.34 seconds
[2023-11-21 19:49:04,568][fairseq_cli.train][INFO] - Loading offical base Hubert checkpoints
[2023-11-21 19:49:04,709][fairseq_cli.train][INFO] - Loaded in 0.14 seconds
[2023-11-21 19:49:04,711][fairseq_cli.train][INFO] - LLaMAHubertModel(
  (feature_extractor): ConvFeatureExtractionModel(
    (conv_layers): ModuleList(
      (0): Sequential(
        (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
        (1): Dropout(p=0.0, inplace=False)
        (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
        (3): GELU(approximate='none')
      )
      (1-4): 4 x Sequential(
        (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
        (1): Dropout(p=0.0, inplace=False)
        (2): GELU(approximate='none')
      )
      (5-6): 2 x Sequential(
        (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
        (1): Dropout(p=0.0, inplace=False)
        (2): GELU(approximate='none')
      )
    )
  )
  (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.1, inplace=False)
  (dropout_features): Dropout(p=0.1, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (llama): LLaMATransformer(
    (layers): ModuleList(
      (0): Block(
        (rms_1): LitRMSNorm()
        (attn): Attention(
          (c_attn): Linear(in_features=4096, out_features=12288, bias=False)
          (c_proj): Linear(in_features=4096, out_features=4096, bias=False)
        )
        (rms_2): LitRMSNorm()
        (mlp): MLP(
          (c_fc1): Linear(in_features=4096, out_features=11008, bias=False)
          (c_fc2): Linear(in_features=4096, out_features=11008, bias=False)
          (c_proj): Linear(in_features=11008, out_features=4096, bias=False)
        )
      )
    )
    (norm): LitRMSNorm()
  )
  (llama_dim_mapper1): Linear(in_features=768, out_features=4096, bias=False)
  (llama_dim_mapper2): Linear(in_features=4096, out_features=768, bias=False)
  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (final_proj): Linear(in_features=768, out_features=256, bias=True)
)
[2023-11-21 19:49:04,712][fairseq_cli.train][INFO] - task: HubertPretrainingTask
[2023-11-21 19:49:04,712][fairseq_cli.train][INFO] - model: LLaMAHubertModel
[2023-11-21 19:49:04,712][fairseq_cli.train][INFO] - criterion: HubertCriterion
[2023-11-21 19:49:04,713][fairseq_cli.train][INFO] - num. shared model params: 303,376,512 (num. trained: 100,989,056)
[2023-11-21 19:49:04,714][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-11-21 19:49:04,734][fairseq.data.audio.hubert_dataset][INFO] - max_keep=None, min_keep=32000, loaded 2808, skipped 56 short and 0 long, longest-loaded=562480, shortest-loaded=32000
[2023-11-21 19:49:04,773][fairseq.data.audio.hubert_dataset][INFO] - pad_audio=False, random_crop=True, normalize=False, max_sample_size=250000
[2023-11-21 19:49:04,775][fairseq.data.audio.hubert_dataset][INFO] - max_keep=None, min_keep=32000, loaded 2666, skipped 37 short and 0 long, longest-loaded=522320, shortest-loaded=32000
[2023-11-21 19:49:04,814][fairseq.data.audio.hubert_dataset][INFO] - pad_audio=False, random_crop=True, normalize=False, max_sample_size=250000
[2023-11-21 19:49:05,331][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- feature_extractor.conv_layers.1.0.bias
[2023-11-21 19:49:05,331][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- feature_extractor.conv_layers.2.0.bias
[2023-11-21 19:49:05,331][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- feature_extractor.conv_layers.3.0.bias
[2023-11-21 19:49:05,331][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- feature_extractor.conv_layers.4.0.bias
[2023-11-21 19:49:05,331][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- feature_extractor.conv_layers.5.0.bias
[2023-11-21 19:49:05,331][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- feature_extractor.conv_layers.6.0.bias
[2023-11-21 19:49:05,331][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- llama.layers.0.attn.c_attn.bias
[2023-11-21 19:49:05,331][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- llama.layers.0.attn.c_proj.bias
[2023-11-21 19:49:05,331][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- llama.layers.0.mlp.c_fc1.bias
[2023-11-21 19:49:05,331][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- llama.layers.0.mlp.c_fc2.bias
[2023-11-21 19:49:05,331][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- llama.layers.0.mlp.c_proj.bias
[2023-11-21 19:49:05,332][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- llama_dim_mapper1.bias
[2023-11-21 19:49:05,332][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- llama_dim_mapper2.bias
[2023-11-21 19:49:05,332][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-11-21 19:49:05,332][fairseq.utils][INFO] - rank   0: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A800-SXM4-80GB                   
[2023-11-21 19:49:05,332][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-11-21 19:49:05,332][fairseq_cli.train][INFO] - training on 1 devices (GPUs/TPUs)
[2023-11-21 19:49:05,332][fairseq_cli.train][INFO] - max tokens per device = 1400000 and max sentences per device = None
[2023-11-21 19:49:05,333][fairseq.trainer][INFO] - Preparing to load checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-21 19:49:05,333][fairseq.trainer][INFO] - No existing checkpoint found /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-21 19:49:05,333][fairseq.trainer][INFO] - loading train data for epoch 1
[2023-11-21 19:49:05,376][fairseq.data.audio.hubert_dataset][INFO] - max_keep=None, min_keep=32000, loaded 103798, skipped 216 short and 0 long, longest-loaded=475760, shortest-loaded=32000
[2023-11-21 19:49:07,247][fairseq.data.audio.hubert_dataset][INFO] - pad_audio=False, random_crop=True, normalize=False, max_sample_size=250000
[2023-11-21 19:49:07,248][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-21 19:49:07,249][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2023-11-21 19:49:07,249][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = False
[2023-11-21 19:49:07,249][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2023-11-21 19:51:05,686][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/hubert_with_llama', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1400000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train-clean-360', 'valid_subset': 'dev-other,dev-clean', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 5, 'validate_interval_updates': 10000, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1400000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 100000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [32], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 25000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'LLaMAhubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.1, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'llama_path': '/mntcephfs/lab_data/maduo/model_hub/OPT-LLM/lit-llama/7b/7B/lit-llama.pth', 'hubert_path': '/mntcephfs/lab_data/maduo/model_hub/librispeech/hubert_base_librispeech_offical_no_finetune//hubert_base_ls960.pt', 'n_layer': 32, 'n_head': 32, 'n_embd': 4096, 'multiple_of': 256, 'first_layer': 31, 'n_layers': 32, 'llama_post_norm': False}, 'task': {'_name': 'hubert_pretraining', 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech', 'fine_tuning': False, 'labels': ['km'], 'label_dir': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/feat_dir/9layer_feat_from_offical_hubert_base_model/label_dir/', 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}, 'criterion': {'_name': 'hubert', 'pred_masked_weight': 1.0, 'pred_nomask_weight': 0.0, 'loss_weights': [10.0], 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005], 'amsgrad': False}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 100000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': '/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/hubert_with_llama/pretrain.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2023-11-21 19:51:05,689][fairseq.tasks.hubert_pretraining][INFO] - current directory is /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/hubert_with_llama
[2023-11-21 19:51:05,689][fairseq.tasks.hubert_pretraining][INFO] - HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech', 'fine_tuning': False, 'labels': ['km'], 'label_dir': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/feat_dir/9layer_feat_from_offical_hubert_base_model/label_dir/', 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
[2023-11-21 19:51:05,696][fairseq.models.hubert.hubert_with_llama][INFO] - HubertModel Config: {'_name': 'LLaMAhubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.1, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'llama_path': '/mntcephfs/lab_data/maduo/model_hub/OPT-LLM/lit-llama/7b/7B/lit-llama.pth', 'hubert_path': '/mntcephfs/lab_data/maduo/model_hub/librispeech/hubert_base_librispeech_offical_no_finetune//hubert_base_ls960.pt', 'n_layer': 32, 'n_head': 32, 'n_embd': 4096, 'multiple_of': 256, 'first_layer': 31, 'n_layers': 32, 'llama_post_norm': False}
[2023-11-21 19:51:07,809][fairseq_cli.train][INFO] - Loading LLaMA checkpoints
[2023-11-21 19:51:07,998][fairseq_cli.train][INFO] - Loaded in 0.19 seconds
[2023-11-21 19:51:07,999][fairseq_cli.train][INFO] - Loading offical base Hubert checkpoints
[2023-11-21 19:51:08,134][fairseq_cli.train][INFO] - Loaded in 0.14 seconds
[2023-11-21 19:51:08,135][fairseq_cli.train][INFO] - LLaMAHubertModel(
  (feature_extractor): ConvFeatureExtractionModel(
    (conv_layers): ModuleList(
      (0): Sequential(
        (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
        (1): Dropout(p=0.0, inplace=False)
        (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
        (3): GELU(approximate='none')
      )
      (1-4): 4 x Sequential(
        (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
        (1): Dropout(p=0.0, inplace=False)
        (2): GELU(approximate='none')
      )
      (5-6): 2 x Sequential(
        (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
        (1): Dropout(p=0.0, inplace=False)
        (2): GELU(approximate='none')
      )
    )
  )
  (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.1, inplace=False)
  (dropout_features): Dropout(p=0.1, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (llama): LLaMATransformer(
    (layers): ModuleList(
      (0): Block(
        (rms_1): LitRMSNorm()
        (attn): Attention(
          (c_attn): Linear(in_features=4096, out_features=12288, bias=False)
          (c_proj): Linear(in_features=4096, out_features=4096, bias=False)
        )
        (rms_2): LitRMSNorm()
        (mlp): MLP(
          (c_fc1): Linear(in_features=4096, out_features=11008, bias=False)
          (c_fc2): Linear(in_features=4096, out_features=11008, bias=False)
          (c_proj): Linear(in_features=11008, out_features=4096, bias=False)
        )
      )
    )
    (norm): LitRMSNorm()
  )
  (llama_dim_mapper1): Linear(in_features=768, out_features=4096, bias=False)
  (llama_dim_mapper2): Linear(in_features=4096, out_features=768, bias=False)
  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (final_proj): Linear(in_features=768, out_features=256, bias=True)
)
[2023-11-21 19:51:08,137][fairseq_cli.train][INFO] - task: HubertPretrainingTask
[2023-11-21 19:51:08,137][fairseq_cli.train][INFO] - model: LLaMAHubertModel
[2023-11-21 19:51:08,137][fairseq_cli.train][INFO] - criterion: HubertCriterion
[2023-11-21 19:51:08,138][fairseq_cli.train][INFO] - num. shared model params: 303,376,512 (num. trained: 100,989,056)
[2023-11-21 19:51:08,138][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-11-21 19:51:08,142][fairseq.data.audio.hubert_dataset][INFO] - max_keep=None, min_keep=32000, loaded 2808, skipped 56 short and 0 long, longest-loaded=562480, shortest-loaded=32000
[2023-11-21 19:51:08,167][fairseq.data.audio.hubert_dataset][INFO] - pad_audio=False, random_crop=True, normalize=False, max_sample_size=250000
[2023-11-21 19:51:08,169][fairseq.data.audio.hubert_dataset][INFO] - max_keep=None, min_keep=32000, loaded 2666, skipped 37 short and 0 long, longest-loaded=522320, shortest-loaded=32000
[2023-11-21 19:51:08,195][fairseq.data.audio.hubert_dataset][INFO] - pad_audio=False, random_crop=True, normalize=False, max_sample_size=250000
[2023-11-21 19:51:08,725][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- feature_extractor.conv_layers.1.0.bias
[2023-11-21 19:51:08,725][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- feature_extractor.conv_layers.2.0.bias
[2023-11-21 19:51:08,725][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- feature_extractor.conv_layers.3.0.bias
[2023-11-21 19:51:08,725][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- feature_extractor.conv_layers.4.0.bias
[2023-11-21 19:51:08,726][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- feature_extractor.conv_layers.5.0.bias
[2023-11-21 19:51:08,726][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- feature_extractor.conv_layers.6.0.bias
[2023-11-21 19:51:08,726][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- llama.layers.0.attn.c_attn.bias
[2023-11-21 19:51:08,726][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- llama.layers.0.attn.c_proj.bias
[2023-11-21 19:51:08,726][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- llama.layers.0.mlp.c_fc1.bias
[2023-11-21 19:51:08,726][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- llama.layers.0.mlp.c_fc2.bias
[2023-11-21 19:51:08,726][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- llama.layers.0.mlp.c_proj.bias
[2023-11-21 19:51:08,726][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- llama_dim_mapper1.bias
[2023-11-21 19:51:08,726][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- llama_dim_mapper2.bias
[2023-11-21 19:51:08,726][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-11-21 19:51:08,726][fairseq.utils][INFO] - rank   0: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A800-SXM4-80GB                   
[2023-11-21 19:51:08,726][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-11-21 19:51:08,726][fairseq_cli.train][INFO] - training on 1 devices (GPUs/TPUs)
[2023-11-21 19:51:08,726][fairseq_cli.train][INFO] - max tokens per device = 1400000 and max sentences per device = None
[2023-11-21 19:51:08,727][fairseq.trainer][INFO] - Preparing to load checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-21 19:51:08,727][fairseq.trainer][INFO] - No existing checkpoint found /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-21 19:51:08,727][fairseq.trainer][INFO] - loading train data for epoch 1
[2023-11-21 19:51:08,770][fairseq.data.audio.hubert_dataset][INFO] - max_keep=None, min_keep=32000, loaded 103798, skipped 216 short and 0 long, longest-loaded=475760, shortest-loaded=32000
[2023-11-21 19:51:10,444][fairseq.data.audio.hubert_dataset][INFO] - pad_audio=False, random_crop=True, normalize=False, max_sample_size=250000
[2023-11-21 19:51:10,445][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-21 19:51:10,445][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2023-11-21 19:51:10,445][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = False
[2023-11-21 19:51:10,445][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2023-11-21 19:51:10,681][fairseq_cli.train][INFO] - begin dry-run validation on "dev-other" subset
[2023-11-21 19:51:10,681][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-21 19:51:10,682][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2023-11-21 19:51:10,682][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = False
[2023-11-21 19:51:10,682][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2023-11-21 19:51:14,315][fairseq_cli.train][INFO] - begin dry-run validation on "dev-clean" subset
[2023-11-21 19:51:14,315][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-21 19:51:14,316][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2023-11-21 19:51:14,316][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = False
[2023-11-21 19:51:14,316][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2023-11-21 19:51:17,323][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-21 19:51:17,325][fairseq.trainer][INFO] - begin training epoch 1
[2023-11-21 19:51:17,325][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-21 19:51:31,167][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2023-11-21 19:51:43,670][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2023-11-21 20:12:21,616][train_inner][INFO] - {"epoch": 1, "update": 0.385, "loss": "11.52", "count_m_0": "65969.8", "count_u_0": "58136.8", "loss_m_0": "8.944", "loss_u_0": "7.899", "loss_features_pen": "2.575", "correct_m_0": "0.00592875", "correct_u_0": "0.00466884", "ppl": "2936.26", "wps": "10697.1", "ups": "0.16", "wpb": "65969.8", "bsz": "196.8", "num_updates": "200", "lr": "3.125e-06", "gnorm": "1.478", "clip": "0", "loss_scale": "32", "train_wall": "1232", "gb_free": "65.4", "wall": "1273"}
[2023-11-21 20:33:23,651][train_inner][INFO] - {"epoch": 1, "update": 0.767, "loss": "9.172", "count_m_0": "66063", "count_u_0": "58338.4", "loss_m_0": "8.879", "loss_u_0": "7.869", "loss_features_pen": "0.293", "correct_m_0": "0.00992731", "correct_u_0": "0.00681066", "ppl": "576.78", "wps": "10469.4", "ups": "0.16", "wpb": "66063", "bsz": "198.8", "num_updates": "400", "lr": "6.25e-06", "gnorm": "0.338", "clip": "0", "loss_scale": "32", "train_wall": "1228", "gb_free": "65.7", "wall": "2535"}
[2023-11-21 20:46:17,312][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 522 updates
[2023-11-21 20:46:17,313][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-21 20:46:21,049][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-21 20:46:21,057][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 1 @ 522 updates, score None) (writing took 3.7447420889511704 seconds)
[2023-11-21 20:46:21,057][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2023-11-21 20:46:21,075][train][INFO] - {"epoch": 1, "train_loss": "9.983", "train_count_m_0": "65949.3", "train_count_u_0": "58213.7", "train_loss_m_0": "8.868", "train_loss_u_0": "7.867", "train_loss_features_pen": "1.114", "train_correct_m_0": "0.0102547", "train_correct_u_0": "0.00725198", "train_ppl": "1011.81", "train_wps": "10518.1", "train_ups": "0.16", "train_wpb": "65949.3", "train_bsz": "198.1", "train_num_updates": "522", "train_lr": "8.15625e-06", "train_gnorm": "0.805", "train_clip": "0", "train_loss_scale": "64", "train_train_wall": "3213", "train_gb_free": "65.4", "train_wall": "3312"}
[2023-11-21 20:46:21,076][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-21 20:46:21,144][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-21 20:46:21,147][fairseq.trainer][INFO] - begin training epoch 2
[2023-11-21 20:46:21,147][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-21 20:54:35,131][train_inner][INFO] - {"epoch": 2, "update": 1.149, "loss": "8.747", "count_m_0": "65854.2", "count_u_0": "58158.8", "loss_m_0": "8.694", "loss_u_0": "7.788", "loss_features_pen": "0.053", "correct_m_0": "0.0200765", "correct_u_0": "0.0130107", "ppl": "429.57", "wps": "10358.8", "ups": "0.16", "wpb": "65854.2", "bsz": "197.7", "num_updates": "600", "lr": "9.375e-06", "gnorm": "0.452", "clip": "0", "loss_scale": "64", "train_wall": "1238", "gb_free": "65.9", "wall": "3806"}
[2023-11-21 21:15:49,706][train_inner][INFO] - {"epoch": 2, "update": 1.531, "loss": "8.594", "count_m_0": "65963.1", "count_u_0": "58256.2", "loss_m_0": "8.574", "loss_u_0": "7.752", "loss_features_pen": "0.02", "correct_m_0": "0.0303311", "correct_u_0": "0.0182502", "ppl": "386.4", "wps": "10350.7", "ups": "0.16", "wpb": "65963.1", "bsz": "198.4", "num_updates": "800", "lr": "1.25e-05", "gnorm": "0.502", "clip": "0", "loss_scale": "64", "train_wall": "1249", "gb_free": "65.4", "wall": "5081"}
[2023-11-21 21:36:56,228][train_inner][INFO] - {"epoch": 2, "update": 1.912, "loss": "8.492", "count_m_0": "65814.7", "count_u_0": "58202.4", "loss_m_0": "8.48", "loss_u_0": "7.738", "loss_features_pen": "0.012", "correct_m_0": "0.0377643", "correct_u_0": "0.020659", "ppl": "360.04", "wps": "10393.1", "ups": "0.16", "wpb": "65814.7", "bsz": "198.9", "num_updates": "1000", "lr": "1.5625e-05", "gnorm": "0.549", "clip": "0", "loss_scale": "64", "train_wall": "1238", "gb_free": "65.7", "wall": "6347"}
[2023-11-21 21:40:37,718][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2023-11-21 21:41:47,084][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 1045 updates
[2023-11-21 21:41:47,084][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-21 21:41:54,373][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-21 21:41:54,381][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 2 @ 1045 updates, score None) (writing took 7.297344050952233 seconds)
[2023-11-21 21:41:54,381][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2023-11-21 21:41:54,397][train][INFO] - {"epoch": 2, "train_loss": "8.554", "train_count_m_0": "65934.3", "train_count_u_0": "58222.4", "train_loss_m_0": "8.536", "train_loss_u_0": "7.739", "train_loss_features_pen": "0.018", "train_correct_m_0": "0.0331397", "train_correct_u_0": "0.0189427", "train_ppl": "375.76", "train_wps": "10345.2", "train_ups": "0.16", "train_wpb": "65934.3", "train_bsz": "198.1", "train_num_updates": "1045", "train_lr": "1.63281e-05", "train_gnorm": "0.516", "train_clip": "0", "train_loss_scale": "64", "train_train_wall": "3254", "train_gb_free": "65.4", "train_wall": "6646"}
[2023-11-21 21:41:54,398][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-21 21:41:54,465][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-21 21:41:54,467][fairseq.trainer][INFO] - begin training epoch 3
[2023-11-21 21:41:54,468][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-21 21:58:06,269][train_inner][INFO] - {"epoch": 3, "update": 2.296, "loss": "8.388", "count_m_0": "65992.1", "count_u_0": "58234.5", "loss_m_0": "8.378", "loss_u_0": "7.663", "loss_features_pen": "0.01", "correct_m_0": "0.044825", "correct_u_0": "0.0240939", "ppl": "334.9", "wps": "10392.3", "ups": "0.16", "wpb": "65992.1", "bsz": "198.1", "num_updates": "1200", "lr": "1.875e-05", "gnorm": "0.612", "clip": "0", "loss_scale": "64", "train_wall": "1237", "gb_free": "65.5", "wall": "7618"}
[2023-11-21 22:05:50,574][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2023-11-21 22:19:10,104][train_inner][INFO] - {"epoch": 3, "update": 2.679, "loss": "8.28", "count_m_0": "65908.6", "count_u_0": "58281.8", "loss_m_0": "8.271", "loss_u_0": "7.625", "loss_features_pen": "0.009", "correct_m_0": "0.0526645", "correct_u_0": "0.0285431", "ppl": "310.94", "wps": "10430.1", "ups": "0.16", "wpb": "65908.6", "bsz": "198.1", "num_updates": "1400", "lr": "2.1875e-05", "gnorm": "0.64", "clip": "0", "loss_scale": "32", "train_wall": "1241", "gb_free": "65.5", "wall": "8881"}
[2023-11-21 22:21:59,127][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2023-11-21 22:36:53,433][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 1567 updates
[2023-11-21 22:36:53,434][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-21 22:36:58,089][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-21 22:36:58,099][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 3 @ 1567 updates, score None) (writing took 4.665453447960317 seconds)
[2023-11-21 22:36:58,099][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)
[2023-11-21 22:36:58,113][train][INFO] - {"epoch": 3, "train_loss": "8.279", "train_count_m_0": "65911.4", "train_count_u_0": "58240.5", "train_loss_m_0": "8.27", "train_loss_u_0": "7.621", "train_loss_features_pen": "0.009", "train_correct_m_0": "0.0528496", "train_correct_u_0": "0.0286588", "train_ppl": "310.72", "train_wps": "10414.3", "train_ups": "0.16", "train_wpb": "65911.4", "train_bsz": "198.1", "train_num_updates": "1567", "train_lr": "2.44844e-05", "train_gnorm": "0.646", "train_clip": "0", "train_loss_scale": "16", "train_train_wall": "3239", "train_gb_free": "65.5", "train_wall": "9949"}
[2023-11-21 22:36:58,114][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-21 22:36:58,187][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-21 22:36:58,191][fairseq.trainer][INFO] - begin training epoch 4
[2023-11-21 22:36:58,191][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-21 22:40:25,861][train_inner][INFO] - {"epoch": 4, "update": 3.063, "loss": "8.181", "count_m_0": "65830.4", "count_u_0": "58169.2", "loss_m_0": "8.172", "loss_u_0": "7.576", "loss_features_pen": "0.009", "correct_m_0": "0.0603695", "correct_u_0": "0.0330419", "ppl": "290.14", "wps": "10320.4", "ups": "0.16", "wpb": "65830.4", "bsz": "197.8", "num_updates": "1600", "lr": "2.5e-05", "gnorm": "0.688", "clip": "0", "loss_scale": "16", "train_wall": "1247", "gb_free": "65.3", "wall": "10157"}
[2023-11-21 23:01:36,847][train_inner][INFO] - {"epoch": 4, "update": 3.445, "loss": "8.084", "count_m_0": "65931.9", "count_u_0": "58177.4", "loss_m_0": "8.076", "loss_u_0": "7.495", "loss_features_pen": "0.008", "correct_m_0": "0.0683394", "correct_u_0": "0.040886", "ppl": "271.34", "wps": "10375", "ups": "0.16", "wpb": "65931.9", "bsz": "199.3", "num_updates": "1800", "lr": "2.8125e-05", "gnorm": "0.66", "clip": "0", "loss_scale": "16", "train_wall": "1248", "gb_free": "65.6", "wall": "11428"}
[2023-11-21 23:20:11,333][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2023-11-21 23:22:56,604][train_inner][INFO] - {"epoch": 4, "update": 3.828, "loss": "7.98", "count_m_0": "66032", "count_u_0": "58159.6", "loss_m_0": "7.972", "loss_u_0": "7.399", "loss_features_pen": "0.008", "correct_m_0": "0.077821", "correct_u_0": "0.0521705", "ppl": "252.44", "wps": "10319.6", "ups": "0.16", "wpb": "66032", "bsz": "196.8", "num_updates": "2000", "lr": "3.125e-05", "gnorm": "0.625", "clip": "0", "loss_scale": "16", "train_wall": "1257", "gb_free": "65.3", "wall": "12708"}
[2023-11-21 23:32:29,205][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 2090 updates
[2023-11-21 23:32:29,206][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-21 23:32:40,024][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-21 23:32:40,031][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 4 @ 2090 updates, score None) (writing took 10.826289504999295 seconds)
[2023-11-21 23:32:40,032][fairseq_cli.train][INFO] - end of epoch 4 (average epoch stats below)
[2023-11-21 23:32:40,047][train][INFO] - {"epoch": 4, "train_loss": "8.016", "train_count_m_0": "65977.3", "train_count_u_0": "58182", "train_loss_m_0": "8.008", "train_loss_u_0": "7.435", "train_loss_features_pen": "0.008", "train_correct_m_0": "0.0745447", "train_correct_u_0": "0.0484092", "train_ppl": "258.9", "train_wps": "10325.2", "train_ups": "0.16", "train_wpb": "65977.3", "train_bsz": "198", "train_num_updates": "2090", "train_lr": "3.26562e-05", "train_gnorm": "0.656", "train_clip": "0", "train_loss_scale": "16", "train_train_wall": "3270", "train_gb_free": "65.6", "train_wall": "13291"}
[2023-11-21 23:32:40,048][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-21 23:32:40,120][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-21 23:32:40,123][fairseq.trainer][INFO] - begin training epoch 5
[2023-11-21 23:32:40,123][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-21 23:43:14,767][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2023-11-21 23:44:24,616][train_inner][INFO] - {"epoch": 5, "update": 4.212, "loss": "7.876", "count_m_0": "66075.4", "count_u_0": "58255.2", "loss_m_0": "7.868", "loss_u_0": "7.313", "loss_features_pen": "0.008", "correct_m_0": "0.0872611", "correct_u_0": "0.0644677", "ppl": "234.92", "wps": "10260.2", "ups": "0.16", "wpb": "66075.4", "bsz": "197.3", "num_updates": "2200", "lr": "3.4375e-05", "gnorm": "0.666", "clip": "0", "loss_scale": "8", "train_wall": "1254", "gb_free": "65.5", "wall": "13996"}
[2023-11-22 00:05:33,344][train_inner][INFO] - {"epoch": 5, "update": 4.594, "loss": "7.772", "count_m_0": "65917.9", "count_u_0": "58201", "loss_m_0": "7.765", "loss_u_0": "7.22", "loss_features_pen": "0.007", "correct_m_0": "0.0960581", "correct_u_0": "0.0774593", "ppl": "218.6", "wps": "10391.3", "ups": "0.16", "wpb": "65917.9", "bsz": "198.6", "num_updates": "2400", "lr": "3.75e-05", "gnorm": "0.656", "clip": "0", "loss_scale": "8", "train_wall": "1246", "gb_free": "65.5", "wall": "15265"}
[2023-11-22 00:26:48,108][train_inner][INFO] - {"epoch": 5, "update": 4.975, "loss": "7.675", "count_m_0": "65958.7", "count_u_0": "58199.6", "loss_m_0": "7.668", "loss_u_0": "7.094", "loss_features_pen": "0.007", "correct_m_0": "0.103138", "correct_u_0": "0.0905378", "ppl": "204.43", "wps": "10348.5", "ups": "0.16", "wpb": "65958.7", "bsz": "198.7", "num_updates": "2600", "lr": "4.0625e-05", "gnorm": "0.662", "clip": "0", "loss_scale": "8", "train_wall": "1252", "gb_free": "65.5", "wall": "16539"}
[2023-11-22 00:28:11,131][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-22 00:28:11,132][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 00:28:33,762][dev-other][INFO] - {"epoch": 5, "dev-other_loss": "7.552", "dev-other_count_m_0": "1720.42", "dev-other_count_u_0": "1676.24", "dev-other_loss_m_0": "7.532", "dev-other_loss_u_0": "7.913", "dev-other_loss_features_pen": "0.007", "dev-other_correct_m_0": "0.116173", "dev-other_correct_u_0": "0.0911536", "dev-other_ppl": "187.72", "dev-other_wps": "19924.8", "dev-other_wpb": "1720.4", "dev-other_bsz": "10.8", "dev-other_num_updates": "2613"}
[2023-11-22 00:28:33,763][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-22 00:28:33,763][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 00:28:56,049][dev-clean][INFO] - {"epoch": 5, "dev-clean_loss": "7.566", "dev-clean_count_m_0": "1779.75", "dev-clean_count_u_0": "1695.98", "dev-clean_loss_m_0": "7.543", "dev-clean_loss_u_0": "7.73", "dev-clean_loss_features_pen": "0.007", "dev-clean_correct_m_0": "0.116251", "dev-clean_correct_u_0": "0.0911197", "dev-clean_ppl": "189.47", "dev-clean_wps": "21405.2", "dev-clean_wpb": "1779.7", "dev-clean_bsz": "10", "dev-clean_num_updates": "2613"}
[2023-11-22 00:28:56,050][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 2613 updates
[2023-11-22 00:28:56,050][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-22 00:29:00,241][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-22 00:29:06,003][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt (epoch 5 @ 2613 updates, score 7.552) (writing took 9.953514404012822 seconds)
[2023-11-22 00:29:06,004][fairseq_cli.train][INFO] - end of epoch 5 (average epoch stats below)
[2023-11-22 00:29:06,019][train][INFO] - {"epoch": 5, "train_loss": "7.749", "train_count_m_0": "65954", "train_count_u_0": "58202.2", "train_loss_m_0": "7.741", "train_loss_u_0": "7.183", "train_loss_features_pen": "0.007", "train_correct_m_0": "0.097556", "train_correct_u_0": "0.0807227", "train_ppl": "215.09", "train_wps": "10187.4", "train_ups": "0.15", "train_wpb": "65954", "train_bsz": "198.1", "train_num_updates": "2613", "train_lr": "4.08281e-05", "train_gnorm": "0.657", "train_clip": "0", "train_loss_scale": "8", "train_train_wall": "3271", "train_gb_free": "65.5", "train_wall": "16677"}
[2023-11-22 00:29:06,020][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 00:29:06,088][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 00:29:06,089][fairseq.trainer][INFO] - begin training epoch 6
[2023-11-22 00:29:06,090][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 00:40:28,522][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2023-11-22 00:49:03,377][train_inner][INFO] - {"epoch": 6, "update": 5.359, "loss": "7.578", "count_m_0": "65888.2", "count_u_0": "58149.4", "loss_m_0": "7.571", "loss_u_0": "6.981", "loss_features_pen": "0.007", "correct_m_0": "0.110046", "correct_u_0": "0.10235", "ppl": "191.08", "wps": "9869", "ups": "0.15", "wpb": "65888.2", "bsz": "198.4", "num_updates": "2800", "lr": "4.375e-05", "gnorm": "0.648", "clip": "0", "loss_scale": "8", "train_wall": "1257", "gb_free": "65.3", "wall": "17875"}
[2023-11-22 01:10:21,489][train_inner][INFO] - {"epoch": 6, "update": 5.74, "loss": "7.479", "count_m_0": "65968.6", "count_u_0": "58325.5", "loss_m_0": "7.472", "loss_u_0": "6.883", "loss_features_pen": "0.007", "correct_m_0": "0.116666", "correct_u_0": "0.113369", "ppl": "178.41", "wps": "10323", "ups": "0.16", "wpb": "65968.6", "bsz": "197.9", "num_updates": "3000", "lr": "4.6875e-05", "gnorm": "0.638", "clip": "0", "loss_scale": "8", "train_wall": "1254", "gb_free": "65.6", "wall": "19153"}
[2023-11-22 01:17:21,597][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2023-11-22 01:24:43,047][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 3135 updates
[2023-11-22 01:24:43,048][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 01:24:47,664][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 01:24:47,674][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 6 @ 3135 updates, score None) (writing took 4.627213839092292 seconds)
[2023-11-22 01:24:47,674][fairseq_cli.train][INFO] - end of epoch 6 (average epoch stats below)
[2023-11-22 01:24:47,693][train][INFO] - {"epoch": 6, "train_loss": "7.494", "train_count_m_0": "65918.3", "train_count_u_0": "58235.6", "train_loss_m_0": "7.487", "train_loss_u_0": "6.893", "train_loss_features_pen": "0.007", "train_correct_m_0": "0.115528", "train_correct_u_0": "0.111586", "train_ppl": "180.21", "train_wps": "10297.1", "train_ups": "0.16", "train_wpb": "65918.3", "train_bsz": "198.1", "train_num_updates": "3135", "train_lr": "4.89844e-05", "train_gnorm": "0.645", "train_clip": "0", "train_loss_scale": "4", "train_train_wall": "3275", "train_gb_free": "66.1", "train_wall": "20019"}
[2023-11-22 01:24:47,693][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 01:24:47,765][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 01:24:47,768][fairseq.trainer][INFO] - begin training epoch 7
[2023-11-22 01:24:47,768][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 01:31:37,667][train_inner][INFO] - {"epoch": 7, "update": 6.124, "loss": "7.388", "count_m_0": "65892.4", "count_u_0": "58206.2", "loss_m_0": "7.381", "loss_u_0": "6.774", "loss_features_pen": "0.006", "correct_m_0": "0.121892", "correct_u_0": "0.122923", "ppl": "167.5", "wps": "10326.6", "ups": "0.16", "wpb": "65892.4", "bsz": "198", "num_updates": "3200", "lr": "5e-05", "gnorm": "0.67", "clip": "0", "loss_scale": "4", "train_wall": "1248", "gb_free": "65.8", "wall": "20429"}
[2023-11-22 01:52:41,376][train_inner][INFO] - {"epoch": 7, "update": 6.506, "loss": "7.29", "count_m_0": "65930.3", "count_u_0": "58146.3", "loss_m_0": "7.284", "loss_u_0": "6.666", "loss_features_pen": "0.006", "correct_m_0": "0.127442", "correct_u_0": "0.131407", "ppl": "156.55", "wps": "10434.5", "ups": "0.16", "wpb": "65930.3", "bsz": "196.7", "num_updates": "3400", "lr": "5.3125e-05", "gnorm": "0.66", "clip": "0", "loss_scale": "4", "train_wall": "1240", "gb_free": "65.5", "wall": "21693"}
[2023-11-22 02:13:50,068][train_inner][INFO] - {"epoch": 7, "update": 6.887, "loss": "7.191", "count_m_0": "65967.1", "count_u_0": "58274", "loss_m_0": "7.185", "loss_u_0": "6.579", "loss_features_pen": "0.006", "correct_m_0": "0.133415", "correct_u_0": "0.139772", "ppl": "146.13", "wps": "10399.4", "ups": "0.16", "wpb": "65967.1", "bsz": "199.5", "num_updates": "3600", "lr": "5.625e-05", "gnorm": "0.654", "clip": "0", "loss_scale": "8", "train_wall": "1245", "gb_free": "65.7", "wall": "22961"}
[2023-11-22 02:20:03,118][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 3659 updates
[2023-11-22 02:20:03,119][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 02:20:14,147][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 02:20:14,155][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 7 @ 3659 updates, score None) (writing took 11.036709184991196 seconds)
[2023-11-22 02:20:14,155][fairseq_cli.train][INFO] - end of epoch 7 (average epoch stats below)
[2023-11-22 02:20:14,210][train][INFO] - {"epoch": 7, "train_loss": "7.243", "train_count_m_0": "65954", "train_count_u_0": "58205", "train_loss_m_0": "7.237", "train_loss_u_0": "6.621", "train_loss_features_pen": "0.006", "train_correct_m_0": "0.130239", "train_correct_u_0": "0.135577", "train_ppl": "151.52", "train_wps": "10389.4", "train_ups": "0.16", "train_wpb": "65954", "train_bsz": "198.1", "train_num_updates": "3659", "train_lr": "5.71719e-05", "train_gnorm": "0.663", "train_clip": "0", "train_loss_scale": "8", "train_train_wall": "3254", "train_gb_free": "65.6", "train_wall": "23345"}
[2023-11-22 02:20:14,211][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 02:20:14,282][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 02:20:14,285][fairseq.trainer][INFO] - begin training epoch 8
[2023-11-22 02:20:14,285][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 02:22:25,778][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2023-11-22 02:35:12,333][train_inner][INFO] - {"epoch": 8, "update": 7.271, "loss": "7.098", "count_m_0": "65989", "count_u_0": "58175.7", "loss_m_0": "7.091", "loss_u_0": "6.463", "loss_features_pen": "0.006", "correct_m_0": "0.138406", "correct_u_0": "0.147542", "ppl": "136.96", "wps": "10292.7", "ups": "0.16", "wpb": "65989", "bsz": "197.2", "num_updates": "3800", "lr": "5.9375e-05", "gnorm": "0.657", "clip": "0", "loss_scale": "4", "train_wall": "1247", "gb_free": "65.6", "wall": "24244"}
[2023-11-22 02:56:29,390][train_inner][INFO] - {"epoch": 8, "update": 7.653, "loss": "6.996", "count_m_0": "65972.8", "count_u_0": "58208.9", "loss_m_0": "6.99", "loss_u_0": "6.373", "loss_features_pen": "0.006", "correct_m_0": "0.143984", "correct_u_0": "0.155733", "ppl": "127.64", "wps": "10332.1", "ups": "0.16", "wpb": "65972.8", "bsz": "198.6", "num_updates": "4000", "lr": "6.25e-05", "gnorm": "0.636", "clip": "0", "loss_scale": "4", "train_wall": "1254", "gb_free": "65.5", "wall": "25521"}
[2023-11-22 03:15:49,150][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 4182 updates
[2023-11-22 03:15:49,151][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 03:15:59,813][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 03:15:59,821][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 8 @ 4182 updates, score None) (writing took 10.671111910021864 seconds)
[2023-11-22 03:15:59,821][fairseq_cli.train][INFO] - end of epoch 8 (average epoch stats below)
[2023-11-22 03:15:59,836][train][INFO] - {"epoch": 8, "train_loss": "6.986", "train_count_m_0": "65966.6", "train_count_u_0": "58198", "train_loss_m_0": "6.979", "train_loss_u_0": "6.361", "train_loss_features_pen": "0.006", "train_correct_m_0": "0.14455", "train_correct_u_0": "0.1567", "train_ppl": "126.74", "train_wps": "10312.2", "train_ups": "0.16", "train_wpb": "65966.6", "train_bsz": "198.1", "train_num_updates": "4182", "train_lr": "6.53438e-05", "train_gnorm": "0.645", "train_clip": "0", "train_loss_scale": "4", "train_train_wall": "3275", "train_gb_free": "65.5", "train_wall": "26691"}
[2023-11-22 03:15:59,837][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 03:15:59,903][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 03:15:59,906][fairseq.trainer][INFO] - begin training epoch 9
[2023-11-22 03:15:59,906][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 03:17:54,149][train_inner][INFO] - {"epoch": 9, "update": 8.034, "loss": "6.894", "count_m_0": "65954.7", "count_u_0": "58226.9", "loss_m_0": "6.888", "loss_u_0": "6.272", "loss_features_pen": "0.006", "correct_m_0": "0.149604", "correct_u_0": "0.164696", "ppl": "118.97", "wps": "10267.4", "ups": "0.16", "wpb": "65954.7", "bsz": "198.1", "num_updates": "4200", "lr": "6.5625e-05", "gnorm": "0.643", "clip": "0", "loss_scale": "8", "train_wall": "1251", "gb_free": "65.5", "wall": "26805"}
[2023-11-22 03:20:25,998][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2023-11-22 03:30:02,719][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-22 03:39:13,795][train_inner][INFO] - {"epoch": 9, "update": 8.42, "loss": "6.797", "count_m_0": "66034.7", "count_u_0": "58267.4", "loss_m_0": "6.791", "loss_u_0": "6.163", "loss_features_pen": "0.006", "correct_m_0": "0.154865", "correct_u_0": "0.173497", "ppl": "111.22", "wps": "10320.9", "ups": "0.16", "wpb": "66034.7", "bsz": "198.7", "num_updates": "4400", "lr": "6.875e-05", "gnorm": "0.649", "clip": "0", "loss_scale": "2", "train_wall": "1256", "gb_free": "65.4", "wall": "28085"}
[2023-11-22 04:00:22,333][train_inner][INFO] - {"epoch": 9, "update": 8.802, "loss": "6.697", "count_m_0": "65848.8", "count_u_0": "58076", "loss_m_0": "6.691", "loss_u_0": "6.041", "loss_features_pen": "0.006", "correct_m_0": "0.160435", "correct_u_0": "0.181927", "ppl": "103.76", "wps": "10382", "ups": "0.16", "wpb": "65848.8", "bsz": "198", "num_updates": "4600", "lr": "7.1875e-05", "gnorm": "0.649", "clip": "0", "loss_scale": "2", "train_wall": "1246", "gb_free": "65.4", "wall": "29354"}
[2023-11-22 04:11:19,516][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 9 @ 4704 updates
[2023-11-22 04:11:19,517][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 04:11:36,189][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 04:11:36,197][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 9 @ 4704 updates, score None) (writing took 16.680978457909077 seconds)
[2023-11-22 04:11:36,198][fairseq_cli.train][INFO] - end of epoch 9 (average epoch stats below)
[2023-11-22 04:11:36,211][train][INFO] - {"epoch": 9, "train_loss": "6.725", "train_count_m_0": "65945", "train_count_u_0": "58204.5", "train_loss_m_0": "6.718", "train_loss_u_0": "6.079", "train_loss_features_pen": "0.006", "train_correct_m_0": "0.158918", "train_correct_u_0": "0.17965", "train_ppl": "105.79", "train_wps": "10317.6", "train_ups": "0.16", "train_wpb": "65945", "train_bsz": "198.1", "train_num_updates": "4704", "train_lr": "7.35e-05", "train_gnorm": "0.647", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3260", "train_gb_free": "65.6", "train_wall": "30027"}
[2023-11-22 04:11:36,212][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 04:11:36,279][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 04:11:36,282][fairseq.trainer][INFO] - begin training epoch 10
[2023-11-22 04:11:36,282][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 04:21:42,216][train_inner][INFO] - {"epoch": 10, "update": 9.183, "loss": "6.598", "count_m_0": "65954", "count_u_0": "58273.2", "loss_m_0": "6.591", "loss_u_0": "5.934", "loss_features_pen": "0.006", "correct_m_0": "0.165856", "correct_u_0": "0.191653", "ppl": "96.87", "wps": "10306.4", "ups": "0.16", "wpb": "65954", "bsz": "197.1", "num_updates": "4800", "lr": "7.5e-05", "gnorm": "0.644", "clip": "0", "loss_scale": "2", "train_wall": "1241", "gb_free": "65.5", "wall": "30633"}
[2023-11-22 04:42:48,646][train_inner][INFO] - {"epoch": 10, "update": 9.565, "loss": "6.497", "count_m_0": "66004.2", "count_u_0": "58346.1", "loss_m_0": "6.49", "loss_u_0": "5.791", "loss_features_pen": "0.007", "correct_m_0": "0.171566", "correct_u_0": "0.203735", "ppl": "90.34", "wps": "10423.8", "ups": "0.16", "wpb": "66004.2", "bsz": "199.2", "num_updates": "5000", "lr": "7.8125e-05", "gnorm": "0.64", "clip": "0", "loss_scale": "4", "train_wall": "1244", "gb_free": "65.4", "wall": "31900"}
[2023-11-22 05:03:54,704][train_inner][INFO] - {"epoch": 10, "update": 9.947, "loss": "6.408", "count_m_0": "65775.5", "count_u_0": "58111.2", "loss_m_0": "6.401", "loss_u_0": "5.651", "loss_features_pen": "0.007", "correct_m_0": "0.176116", "correct_u_0": "0.216262", "ppl": "84.9", "wps": "10390.7", "ups": "0.16", "wpb": "65775.5", "bsz": "197.8", "num_updates": "5200", "lr": "8.125e-05", "gnorm": "0.639", "clip": "0", "loss_scale": "4", "train_wall": "1243", "gb_free": "65.6", "wall": "33166"}
[2023-11-22 05:06:50,479][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-22 05:06:50,480][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 05:07:12,770][dev-other][INFO] - {"epoch": 10, "dev-other_loss": "6.311", "dev-other_count_m_0": "1718.26", "dev-other_count_u_0": "1678.28", "dev-other_loss_m_0": "6.282", "dev-other_loss_u_0": "6.31", "dev-other_loss_features_pen": "0.006", "dev-other_correct_m_0": "0.181792", "dev-other_correct_u_0": "0.20344", "dev-other_ppl": "79.37", "dev-other_wps": "20175.5", "dev-other_wpb": "1718.3", "dev-other_bsz": "10.8", "dev-other_num_updates": "5228", "dev-other_best_loss": "6.311"}
[2023-11-22 05:07:12,771][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-22 05:07:12,771][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 05:07:35,385][dev-clean][INFO] - {"epoch": 10, "dev-clean_loss": "6.214", "dev-clean_count_m_0": "1784.54", "dev-clean_count_u_0": "1691.26", "dev-clean_loss_m_0": "6.179", "dev-clean_loss_u_0": "6.03", "dev-clean_loss_features_pen": "0.007", "dev-clean_correct_m_0": "0.19794", "dev-clean_correct_u_0": "0.224186", "dev-clean_ppl": "74.22", "dev-clean_wps": "21145", "dev-clean_wpb": "1784.5", "dev-clean_bsz": "10", "dev-clean_num_updates": "5228"}
[2023-11-22 05:07:35,386][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 10 @ 5228 updates
[2023-11-22 05:07:35,387][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-22 05:07:44,421][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-22 05:07:50,156][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt (epoch 10 @ 5228 updates, score 6.311) (writing took 14.769968081032857 seconds)
[2023-11-22 05:07:50,157][fairseq_cli.train][INFO] - end of epoch 10 (average epoch stats below)
[2023-11-22 05:07:50,170][train][INFO] - {"epoch": 10, "train_loss": "6.47", "train_count_m_0": "65923.3", "train_count_u_0": "58235.7", "train_loss_m_0": "6.463", "train_loss_u_0": "5.745", "train_loss_features_pen": "0.007", "train_correct_m_0": "0.172897", "train_correct_u_0": "0.20796", "train_ppl": "88.63", "train_wps": "10238.4", "train_ups": "0.16", "train_wpb": "65923.3", "train_bsz": "198.1", "train_num_updates": "5228", "train_lr": "8.16875e-05", "train_gnorm": "0.643", "train_clip": "0", "train_loss_scale": "4", "train_train_wall": "3255", "train_gb_free": "65.5", "train_wall": "33401"}
[2023-11-22 05:07:50,171][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 05:07:50,245][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 05:07:50,247][fairseq.trainer][INFO] - begin training epoch 11
[2023-11-22 05:07:50,247][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 05:20:29,695][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2023-11-22 05:26:11,896][train_inner][INFO] - {"epoch": 11, "update": 10.33, "loss": "6.313", "count_m_0": "65892", "count_u_0": "58178.5", "loss_m_0": "6.306", "loss_u_0": "5.494", "loss_features_pen": "0.007", "correct_m_0": "0.18142", "correct_u_0": "0.230618", "ppl": "79.51", "wps": "9855.4", "ups": "0.15", "wpb": "65892", "bsz": "198.8", "num_updates": "5400", "lr": "8.4375e-05", "gnorm": "0.631", "clip": "0", "loss_scale": "4", "train_wall": "1254", "gb_free": "65.7", "wall": "34503"}
[2023-11-22 05:47:19,711][train_inner][INFO] - {"epoch": 11, "update": 10.712, "loss": "6.219", "count_m_0": "65967.2", "count_u_0": "58283.8", "loss_m_0": "6.212", "loss_u_0": "5.314", "loss_features_pen": "0.007", "correct_m_0": "0.186968", "correct_u_0": "0.246192", "ppl": "74.47", "wps": "10406.6", "ups": "0.16", "wpb": "65967.2", "bsz": "197.4", "num_updates": "5600", "lr": "8.75e-05", "gnorm": "0.639", "clip": "0", "loss_scale": "4", "train_wall": "1245", "gb_free": "65.7", "wall": "35771"}
[2023-11-22 06:03:17,392][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 11 @ 5751 updates
[2023-11-22 06:03:17,393][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 06:03:23,699][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 06:03:23,708][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 11 @ 5751 updates, score None) (writing took 6.315611736034043 seconds)
[2023-11-22 06:03:23,708][fairseq_cli.train][INFO] - end of epoch 11 (average epoch stats below)
[2023-11-22 06:03:23,723][train][INFO] - {"epoch": 11, "train_loss": "6.226", "train_count_m_0": "65917.9", "train_count_u_0": "58240.9", "train_loss_m_0": "6.219", "train_loss_u_0": "5.33", "train_loss_features_pen": "0.007", "train_correct_m_0": "0.186463", "train_correct_u_0": "0.245185", "train_ppl": "74.84", "train_wps": "10341.9", "train_ups": "0.16", "train_wpb": "65917.9", "train_bsz": "198.1", "train_num_updates": "5751", "train_lr": "8.98594e-05", "train_gnorm": "0.636", "train_clip": "0", "train_loss_scale": "4", "train_train_wall": "3266", "train_gb_free": "65.6", "train_wall": "36735"}
[2023-11-22 06:03:23,724][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 06:03:23,791][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 06:03:23,796][fairseq.trainer][INFO] - begin training epoch 12
[2023-11-22 06:03:23,796][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 06:08:33,971][train_inner][INFO] - {"epoch": 12, "update": 11.094, "loss": "6.133", "count_m_0": "66070", "count_u_0": "58330.9", "loss_m_0": "6.126", "loss_u_0": "5.147", "loss_features_pen": "0.007", "correct_m_0": "0.191719", "correct_u_0": "0.261203", "ppl": "70.16", "wps": "10370.1", "ups": "0.16", "wpb": "66070", "bsz": "196.9", "num_updates": "5800", "lr": "9.0625e-05", "gnorm": "0.644", "clip": "0", "loss_scale": "4", "train_wall": "1244", "gb_free": "65.8", "wall": "37045"}
[2023-11-22 06:15:30,703][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2023-11-22 06:29:48,603][train_inner][INFO] - {"epoch": 12, "update": 11.477, "loss": "6.039", "count_m_0": "65855.7", "count_u_0": "58130.1", "loss_m_0": "6.031", "loss_u_0": "4.955", "loss_features_pen": "0.007", "correct_m_0": "0.197392", "correct_u_0": "0.279905", "ppl": "65.74", "wps": "10333.4", "ups": "0.16", "wpb": "65855.7", "bsz": "198.3", "num_updates": "6000", "lr": "9.375e-05", "gnorm": "0.636", "clip": "0", "loss_scale": "4", "train_wall": "1252", "gb_free": "65.6", "wall": "38320"}
[2023-11-22 06:51:09,573][train_inner][INFO] - {"epoch": 12, "update": 11.859, "loss": "5.95", "count_m_0": "65874.3", "count_u_0": "58179.4", "loss_m_0": "5.942", "loss_u_0": "4.771", "loss_features_pen": "0.007", "correct_m_0": "0.202908", "correct_u_0": "0.297084", "ppl": "61.8", "wps": "10285.2", "ups": "0.16", "wpb": "65874.3", "bsz": "198", "num_updates": "6200", "lr": "9.6875e-05", "gnorm": "0.635", "clip": "0", "loss_scale": "4", "train_wall": "1258", "gb_free": "66", "wall": "39601"}
[2023-11-22 06:59:02,185][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 12 @ 6274 updates
[2023-11-22 06:59:02,186][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 06:59:06,323][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 06:59:06,332][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 12 @ 6274 updates, score None) (writing took 4.14735700096935 seconds)
[2023-11-22 06:59:06,333][fairseq_cli.train][INFO] - end of epoch 12 (average epoch stats below)
[2023-11-22 06:59:06,348][train][INFO] - {"epoch": 12, "train_loss": "5.991", "train_count_m_0": "65958.8", "train_count_u_0": "58192", "train_loss_m_0": "5.983", "train_loss_u_0": "4.845", "train_loss_features_pen": "0.007", "train_correct_m_0": "0.200314", "train_correct_u_0": "0.289542", "train_ppl": "63.58", "train_wps": "10320.2", "train_ups": "0.16", "train_wpb": "65958.8", "train_bsz": "198.1", "train_num_updates": "6274", "train_lr": "9.80313e-05", "train_gnorm": "0.638", "train_clip": "0", "train_loss_scale": "4", "train_train_wall": "3278", "train_gb_free": "65.4", "train_wall": "40078"}
[2023-11-22 06:59:06,348][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 06:59:06,420][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 06:59:06,423][fairseq.trainer][INFO] - begin training epoch 13
[2023-11-22 06:59:06,423][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 07:12:29,167][train_inner][INFO] - {"epoch": 13, "update": 12.24, "loss": "5.867", "count_m_0": "66104.3", "count_u_0": "58225.6", "loss_m_0": "5.86", "loss_u_0": "4.552", "loss_features_pen": "0.007", "correct_m_0": "0.207768", "correct_u_0": "0.316644", "ppl": "58.38", "wps": "10332.2", "ups": "0.16", "wpb": "66104.3", "bsz": "198.5", "num_updates": "6400", "lr": "0.0001", "gnorm": "0.632", "clip": "0", "loss_scale": "8", "train_wall": "1252", "gb_free": "65.1", "wall": "40880"}
[2023-11-22 07:14:55,925][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2023-11-22 07:33:50,601][train_inner][INFO] - {"epoch": 13, "update": 12.624, "loss": "5.773", "count_m_0": "65947", "count_u_0": "58260.5", "loss_m_0": "5.765", "loss_u_0": "4.395", "loss_features_pen": "0.007", "correct_m_0": "0.214131", "correct_u_0": "0.335055", "ppl": "54.69", "wps": "10292.8", "ups": "0.16", "wpb": "65947", "bsz": "198.1", "num_updates": "6600", "lr": "0.000103125", "gnorm": "0.626", "clip": "0", "loss_scale": "4", "train_wall": "1258", "gb_free": "65.6", "wall": "42162"}
[2023-11-22 07:54:49,244][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 13 @ 6797 updates
[2023-11-22 07:54:49,245][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 07:54:53,422][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 07:54:53,433][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 13 @ 6797 updates, score None) (writing took 4.189073862973601 seconds)
[2023-11-22 07:54:53,433][fairseq_cli.train][INFO] - end of epoch 13 (average epoch stats below)
[2023-11-22 07:54:53,449][train][INFO] - {"epoch": 13, "train_loss": "5.762", "train_count_m_0": "65937.2", "train_count_u_0": "58219.2", "train_loss_m_0": "5.754", "train_loss_u_0": "4.356", "train_loss_features_pen": "0.007", "train_correct_m_0": "0.214849", "train_correct_u_0": "0.338842", "train_ppl": "54.27", "train_wps": "10303", "train_ups": "0.16", "train_wpb": "65937.2", "train_bsz": "198.1", "train_num_updates": "6797", "train_lr": "0.000106203", "train_gnorm": "0.625", "train_clip": "0", "train_loss_scale": "4", "train_train_wall": "3281", "train_gb_free": "65.6", "train_wall": "43425"}
[2023-11-22 07:54:53,450][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 07:54:53,517][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 07:54:53,520][fairseq.trainer][INFO] - begin training epoch 14
[2023-11-22 07:54:53,520][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 07:55:12,611][train_inner][INFO] - {"epoch": 14, "update": 13.006, "loss": "5.694", "count_m_0": "65833.2", "count_u_0": "58161.4", "loss_m_0": "5.687", "loss_u_0": "4.211", "loss_features_pen": "0.008", "correct_m_0": "0.219399", "correct_u_0": "0.354501", "ppl": "51.78", "wps": "10270.4", "ups": "0.16", "wpb": "65833.2", "bsz": "198.1", "num_updates": "6800", "lr": "0.00010625", "gnorm": "0.624", "clip": "0", "loss_scale": "4", "train_wall": "1254", "gb_free": "65.7", "wall": "43444"}
[2023-11-22 08:12:40,944][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2023-11-22 08:16:29,773][train_inner][INFO] - {"epoch": 14, "update": 13.389, "loss": "5.616", "count_m_0": "65964", "count_u_0": "58231.7", "loss_m_0": "5.608", "loss_u_0": "4.014", "loss_features_pen": "0.008", "correct_m_0": "0.224664", "correct_u_0": "0.375439", "ppl": "49.04", "wps": "10329.9", "ups": "0.16", "wpb": "65964", "bsz": "196.5", "num_updates": "7000", "lr": "0.000109375", "gnorm": "0.623", "clip": "0", "loss_scale": "4", "train_wall": "1254", "gb_free": "65.5", "wall": "44721"}
[2023-11-22 08:37:37,336][train_inner][INFO] - {"epoch": 14, "update": 13.771, "loss": "5.54", "count_m_0": "65894.6", "count_u_0": "58214.6", "loss_m_0": "5.532", "loss_u_0": "3.856", "loss_features_pen": "0.008", "correct_m_0": "0.229886", "correct_u_0": "0.390996", "ppl": "46.54", "wps": "10397.2", "ups": "0.16", "wpb": "65894.6", "bsz": "199", "num_updates": "7200", "lr": "0.0001125", "gnorm": "0.622", "clip": "0", "loss_scale": "4", "train_wall": "1245", "gb_free": "65.6", "wall": "45989"}
[2023-11-22 08:46:09,623][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-22 08:50:17,906][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 14 @ 7319 updates
[2023-11-22 08:50:17,907][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 08:50:22,121][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 08:50:22,130][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 14 @ 7319 updates, score None) (writing took 4.224156431038864 seconds)
[2023-11-22 08:50:22,131][fairseq_cli.train][INFO] - end of epoch 14 (average epoch stats below)
[2023-11-22 08:50:22,148][train][INFO] - {"epoch": 14, "train_loss": "5.557", "train_count_m_0": "65936.4", "train_count_u_0": "58228.7", "train_loss_m_0": "5.549", "train_loss_u_0": "3.889", "train_loss_features_pen": "0.008", "train_correct_m_0": "0.228759", "train_correct_u_0": "0.387817", "train_ppl": "47.09", "train_wps": "10340.1", "train_ups": "0.16", "train_wpb": "65936.4", "train_bsz": "198", "train_num_updates": "7319", "train_lr": "0.000114359", "train_gnorm": "0.624", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3264", "train_gb_free": "65.8", "train_wall": "46753"}
[2023-11-22 08:50:22,149][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 08:50:22,219][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 08:50:22,221][fairseq.trainer][INFO] - begin training epoch 15
[2023-11-22 08:50:22,221][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 08:58:53,322][train_inner][INFO] - {"epoch": 15, "update": 14.155, "loss": "5.469", "count_m_0": "65989.3", "count_u_0": "58195.6", "loss_m_0": "5.461", "loss_u_0": "3.698", "loss_features_pen": "0.008", "correct_m_0": "0.235145", "correct_u_0": "0.407209", "ppl": "44.3", "wps": "10343.4", "ups": "0.16", "wpb": "65989.3", "bsz": "198.6", "num_updates": "7400", "lr": "0.000115625", "gnorm": "0.622", "clip": "0", "loss_scale": "2", "train_wall": "1248", "gb_free": "65.5", "wall": "47265"}
[2023-11-22 09:20:03,056][train_inner][INFO] - {"epoch": 15, "update": 14.536, "loss": "5.395", "count_m_0": "65900.1", "count_u_0": "58211.5", "loss_m_0": "5.386", "loss_u_0": "3.566", "loss_features_pen": "0.008", "correct_m_0": "0.240326", "correct_u_0": "0.421817", "ppl": "42.07", "wps": "10380.3", "ups": "0.16", "wpb": "65900.1", "bsz": "198.3", "num_updates": "7600", "lr": "0.00011875", "gnorm": "0.61", "clip": "0", "loss_scale": "2", "train_wall": "1247", "gb_free": "65.4", "wall": "48534"}
[2023-11-22 09:41:15,584][train_inner][INFO] - {"epoch": 15, "update": 14.918, "loss": "5.322", "count_m_0": "65947.9", "count_u_0": "58323.8", "loss_m_0": "5.313", "loss_u_0": "3.422", "loss_features_pen": "0.008", "correct_m_0": "0.245837", "correct_u_0": "0.438269", "ppl": "40.01", "wps": "10365", "ups": "0.16", "wpb": "65947.9", "bsz": "198.4", "num_updates": "7800", "lr": "0.000121875", "gnorm": "0.602", "clip": "0", "loss_scale": "4", "train_wall": "1249", "gb_free": "65.3", "wall": "49807"}
[2023-11-22 09:45:46,884][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-22 09:45:46,885][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 09:46:09,531][dev-other][INFO] - {"epoch": 15, "dev-other_loss": "5.33", "dev-other_count_m_0": "1720.25", "dev-other_count_u_0": "1675.91", "dev-other_loss_m_0": "5.292", "dev-other_loss_u_0": "4.114", "dev-other_loss_features_pen": "0.008", "dev-other_correct_m_0": "0.240771", "dev-other_correct_u_0": "0.378555", "dev-other_ppl": "40.22", "dev-other_wps": "19903.7", "dev-other_wpb": "1720.3", "dev-other_bsz": "10.8", "dev-other_num_updates": "7843", "dev-other_best_loss": "5.33"}
[2023-11-22 09:46:09,532][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-22 09:46:09,532][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 09:46:31,857][dev-clean][INFO] - {"epoch": 15, "dev-clean_loss": "5.053", "dev-clean_count_m_0": "1777.9", "dev-clean_count_u_0": "1697.93", "dev-clean_loss_m_0": "5.014", "dev-clean_loss_u_0": "3.656", "dev-clean_loss_features_pen": "0.008", "dev-clean_correct_m_0": "0.275447", "dev-clean_correct_u_0": "0.443792", "dev-clean_ppl": "33.2", "dev-clean_wps": "21345", "dev-clean_wpb": "1777.9", "dev-clean_bsz": "10", "dev-clean_num_updates": "7843"}
[2023-11-22 09:46:31,859][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 15 @ 7843 updates
[2023-11-22 09:46:31,859][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-22 09:46:36,278][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-22 09:46:42,378][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt (epoch 15 @ 7843 updates, score 5.33) (writing took 10.519174156943336 seconds)
[2023-11-22 09:46:42,379][fairseq_cli.train][INFO] - end of epoch 15 (average epoch stats below)
[2023-11-22 09:46:42,394][train][INFO] - {"epoch": 15, "train_loss": "5.367", "train_count_m_0": "65936.6", "train_count_u_0": "58222.6", "train_loss_m_0": "5.358", "train_loss_u_0": "3.507", "train_loss_features_pen": "0.008", "train_correct_m_0": "0.242443", "train_correct_u_0": "0.428413", "train_ppl": "41.27", "train_wps": "10221.4", "train_ups": "0.16", "train_wpb": "65936.6", "train_bsz": "198.1", "train_num_updates": "7843", "train_lr": "0.000122547", "train_gnorm": "0.607", "train_clip": "0", "train_loss_scale": "4", "train_train_wall": "3264", "train_gb_free": "65.4", "train_wall": "50134"}
[2023-11-22 09:46:42,395][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 09:46:42,462][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 09:46:42,464][fairseq.trainer][INFO] - begin training epoch 16
[2023-11-22 09:46:42,464][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 10:03:21,102][train_inner][INFO] - {"epoch": 16, "update": 15.3, "loss": "5.255", "count_m_0": "65841.6", "count_u_0": "58141.6", "loss_m_0": "5.246", "loss_u_0": "3.303", "loss_features_pen": "0.008", "correct_m_0": "0.250798", "correct_u_0": "0.450945", "ppl": "38.19", "wps": "9934.6", "ups": "0.15", "wpb": "65841.6", "bsz": "197.9", "num_updates": "8000", "lr": "0.000125", "gnorm": "0.601", "clip": "0", "loss_scale": "4", "train_wall": "1247", "gb_free": "65.4", "wall": "51132"}
[2023-11-22 10:24:25,718][train_inner][INFO] - {"epoch": 16, "update": 15.681, "loss": "5.198", "count_m_0": "65918", "count_u_0": "58185.3", "loss_m_0": "5.189", "loss_u_0": "3.187", "loss_features_pen": "0.009", "correct_m_0": "0.254639", "correct_u_0": "0.4637", "ppl": "36.71", "wps": "10425.1", "ups": "0.16", "wpb": "65918", "bsz": "198.2", "num_updates": "8200", "lr": "0.000128125", "gnorm": "0.599", "clip": "0", "loss_scale": "4", "train_wall": "1242", "gb_free": "65.3", "wall": "52397"}
[2023-11-22 10:37:39,826][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2023-11-22 10:42:08,623][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 16 @ 8366 updates
[2023-11-22 10:42:08,624][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 10:42:16,324][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 10:42:16,334][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 16 @ 8366 updates, score None) (writing took 7.710609351983294 seconds)
[2023-11-22 10:42:16,334][fairseq_cli.train][INFO] - end of epoch 16 (average epoch stats below)
[2023-11-22 10:42:16,348][train][INFO] - {"epoch": 16, "train_loss": "5.19", "train_count_m_0": "65939", "train_count_u_0": "58221.8", "train_loss_m_0": "5.181", "train_loss_u_0": "3.187", "train_loss_features_pen": "0.009", "train_correct_m_0": "0.255625", "train_correct_u_0": "0.463852", "train_ppl": "36.51", "train_wps": "10343.9", "train_ups": "0.16", "train_wpb": "65939", "train_bsz": "198", "train_num_updates": "8366", "train_lr": "0.000130719", "train_gnorm": "0.601", "train_clip": "0", "train_loss_scale": "4", "train_train_wall": "3265", "train_gb_free": "65.3", "train_wall": "53468"}
[2023-11-22 10:42:16,349][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 10:42:16,417][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 10:42:16,420][fairseq.trainer][INFO] - begin training epoch 17
[2023-11-22 10:42:16,420][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 10:45:51,835][train_inner][INFO] - {"epoch": 17, "update": 16.065, "loss": "5.125", "count_m_0": "66026.8", "count_u_0": "58277.9", "loss_m_0": "5.115", "loss_u_0": "3.078", "loss_features_pen": "0.009", "correct_m_0": "0.260897", "correct_u_0": "0.476128", "ppl": "34.89", "wps": "10267.8", "ups": "0.16", "wpb": "66026.8", "bsz": "197.8", "num_updates": "8400", "lr": "0.00013125", "gnorm": "0.599", "clip": "0", "loss_scale": "4", "train_wall": "1254", "gb_free": "65.4", "wall": "53683"}
[2023-11-22 11:07:05,736][train_inner][INFO] - {"epoch": 17, "update": 16.447, "loss": "5.074", "count_m_0": "65964.2", "count_u_0": "58200.2", "loss_m_0": "5.065", "loss_u_0": "2.961", "loss_features_pen": "0.009", "correct_m_0": "0.264737", "correct_u_0": "0.488752", "ppl": "33.68", "wps": "10356.4", "ups": "0.16", "wpb": "65964.2", "bsz": "197.7", "num_updates": "8600", "lr": "0.000134375", "gnorm": "0.596", "clip": "0", "loss_scale": "4", "train_wall": "1251", "gb_free": "65.6", "wall": "54957"}
[2023-11-22 11:19:44,713][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-22 11:28:30,119][train_inner][INFO] - {"epoch": 17, "update": 16.83, "loss": "5.012", "count_m_0": "65982.4", "count_u_0": "58263.4", "loss_m_0": "5.003", "loss_u_0": "2.873", "loss_features_pen": "0.009", "correct_m_0": "0.269785", "correct_u_0": "0.4987", "ppl": "32.27", "wps": "10274.7", "ups": "0.16", "wpb": "65982.4", "bsz": "198.4", "num_updates": "8800", "lr": "0.0001375", "gnorm": "0.592", "clip": "0", "loss_scale": "2", "train_wall": "1261", "gb_free": "65.6", "wall": "56241"}
[2023-11-22 11:37:58,081][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 17 @ 8889 updates
[2023-11-22 11:37:58,082][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 11:38:04,325][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 11:38:04,333][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 17 @ 8889 updates, score None) (writing took 6.251340023940429 seconds)
[2023-11-22 11:38:04,333][fairseq_cli.train][INFO] - end of epoch 17 (average epoch stats below)
[2023-11-22 11:38:04,347][train][INFO] - {"epoch": 17, "train_loss": "5.035", "train_count_m_0": "65934.6", "train_count_u_0": "58219.2", "train_loss_m_0": "5.025", "train_loss_u_0": "2.906", "train_loss_features_pen": "0.009", "train_correct_m_0": "0.267916", "train_correct_u_0": "0.495135", "train_ppl": "32.78", "train_wps": "10299.9", "train_ups": "0.16", "train_wpb": "65934.6", "train_bsz": "198.1", "train_num_updates": "8889", "train_lr": "0.000138891", "train_gnorm": "0.593", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3282", "train_gb_free": "65.7", "train_wall": "56816"}
[2023-11-22 11:38:04,348][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 11:38:04,418][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 11:38:04,421][fairseq.trainer][INFO] - begin training epoch 18
[2023-11-22 11:38:04,421][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 11:49:49,731][train_inner][INFO] - {"epoch": 18, "update": 17.212, "loss": "4.95", "count_m_0": "65987.5", "count_u_0": "58327.2", "loss_m_0": "4.94", "loss_u_0": "2.781", "loss_features_pen": "0.009", "correct_m_0": "0.274845", "correct_u_0": "0.509449", "ppl": "30.9", "wps": "10313.8", "ups": "0.16", "wpb": "65987.5", "bsz": "197.2", "num_updates": "9000", "lr": "0.000140625", "gnorm": "0.598", "clip": "0", "loss_scale": "2", "train_wall": "1251", "gb_free": "65", "wall": "57521"}
[2023-11-22 12:11:02,653][train_inner][INFO] - {"epoch": 18, "update": 17.594, "loss": "4.907", "count_m_0": "65944", "count_u_0": "58108.7", "loss_m_0": "4.897", "loss_u_0": "2.688", "loss_features_pen": "0.009", "correct_m_0": "0.278323", "correct_u_0": "0.51912", "ppl": "30", "wps": "10361.2", "ups": "0.16", "wpb": "65944", "bsz": "196.8", "num_updates": "9200", "lr": "0.00014375", "gnorm": "0.585", "clip": "0", "loss_scale": "2", "train_wall": "1250", "gb_free": "65.5", "wall": "58794"}
[2023-11-22 12:16:20,361][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-22 12:32:18,107][train_inner][INFO] - {"epoch": 18, "update": 17.977, "loss": "4.844", "count_m_0": "65817.7", "count_u_0": "58235.6", "loss_m_0": "4.834", "loss_u_0": "2.63", "loss_features_pen": "0.009", "correct_m_0": "0.283981", "correct_u_0": "0.526654", "ppl": "28.73", "wps": "10320.9", "ups": "0.16", "wpb": "65817.7", "bsz": "200", "num_updates": "9400", "lr": "0.000146875", "gnorm": "0.587", "clip": "0", "loss_scale": "2", "train_wall": "1252", "gb_free": "65.6", "wall": "60069"}
[2023-11-22 12:33:34,211][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 18 @ 9412 updates
[2023-11-22 12:33:34,212][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 12:33:44,427][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 12:33:44,436][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 18 @ 9412 updates, score None) (writing took 10.225811242009513 seconds)
[2023-11-22 12:33:44,437][fairseq_cli.train][INFO] - end of epoch 18 (average epoch stats below)
[2023-11-22 12:33:44,452][train][INFO] - {"epoch": 18, "train_loss": "4.886", "train_count_m_0": "65931.7", "train_count_u_0": "58230", "train_loss_m_0": "4.876", "train_loss_u_0": "2.678", "train_loss_features_pen": "0.009", "train_correct_m_0": "0.280305", "train_correct_u_0": "0.520866", "train_ppl": "29.57", "train_wps": "10323.8", "train_ups": "0.16", "train_wpb": "65931.7", "train_bsz": "198.1", "train_num_updates": "9412", "train_lr": "0.000147063", "train_gnorm": "0.59", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3269", "train_gb_free": "65.2", "train_wall": "60156"}
[2023-11-22 12:33:44,453][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 12:33:44,521][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 12:33:44,523][fairseq.trainer][INFO] - begin training epoch 19
[2023-11-22 12:33:44,524][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 12:53:32,192][train_inner][INFO] - {"epoch": 19, "update": 18.359, "loss": "4.804", "count_m_0": "65982.2", "count_u_0": "58213.7", "loss_m_0": "4.794", "loss_u_0": "2.542", "loss_features_pen": "0.01", "correct_m_0": "0.287291", "correct_u_0": "0.536693", "ppl": "27.94", "wps": "10357.7", "ups": "0.16", "wpb": "65982.2", "bsz": "197.7", "num_updates": "9600", "lr": "0.00015", "gnorm": "0.589", "clip": "0", "loss_scale": "2", "train_wall": "1241", "gb_free": "65.5", "wall": "61343"}
[2023-11-22 13:14:41,175][train_inner][INFO] - {"epoch": 19, "update": 18.74, "loss": "4.745", "count_m_0": "65926.2", "count_u_0": "58305.4", "loss_m_0": "4.735", "loss_u_0": "2.488", "loss_features_pen": "0.01", "correct_m_0": "0.292927", "correct_u_0": "0.543376", "ppl": "26.82", "wps": "10390.6", "ups": "0.16", "wpb": "65926.2", "bsz": "198.6", "num_updates": "9800", "lr": "0.000153125", "gnorm": "0.585", "clip": "0", "loss_scale": "4", "train_wall": "1246", "gb_free": "65.6", "wall": "62612"}
[2023-11-22 13:23:01,740][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-22 13:29:00,647][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 19 @ 9935 updates
[2023-11-22 13:29:00,648][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 13:29:11,080][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 13:29:11,089][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 19 @ 9935 updates, score None) (writing took 10.442099209991284 seconds)
[2023-11-22 13:29:11,089][fairseq_cli.train][INFO] - end of epoch 19 (average epoch stats below)
[2023-11-22 13:29:11,109][train][INFO] - {"epoch": 19, "train_loss": "4.756", "train_count_m_0": "65922.1", "train_count_u_0": "58237.6", "train_loss_m_0": "4.746", "train_loss_u_0": "2.493", "train_loss_features_pen": "0.01", "train_correct_m_0": "0.291871", "train_correct_u_0": "0.542743", "train_ppl": "27.02", "train_wps": "10364", "train_ups": "0.16", "train_wpb": "65922.1", "train_bsz": "198.1", "train_num_updates": "9935", "train_lr": "0.000155234", "train_gnorm": "0.586", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3256", "train_gb_free": "65.6", "train_wall": "63482"}
[2023-11-22 13:29:11,109][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 13:29:11,180][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 13:29:11,183][fairseq.trainer][INFO] - begin training epoch 20
[2023-11-22 13:29:11,183][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 13:36:00,172][train_inner][INFO] - {"epoch": 20, "update": 19.124, "loss": "4.698", "count_m_0": "65776.6", "count_u_0": "58170.9", "loss_m_0": "4.688", "loss_u_0": "2.431", "loss_features_pen": "0.01", "correct_m_0": "0.297136", "correct_u_0": "0.550577", "ppl": "25.96", "wps": "10285.8", "ups": "0.16", "wpb": "65776.6", "bsz": "198.1", "num_updates": "10000", "lr": "0.00015625", "gnorm": "0.583", "clip": "0", "loss_scale": "2", "train_wall": "1246", "gb_free": "65.9", "wall": "63891"}
[2023-11-22 13:36:00,173][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-22 13:36:00,173][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 13:36:22,696][dev-other][INFO] - {"epoch": 20, "dev-other_loss": "4.803", "dev-other_count_m_0": "1714.63", "dev-other_count_u_0": "1681.92", "dev-other_loss_m_0": "4.748", "dev-other_loss_u_0": "3.244", "dev-other_loss_features_pen": "0.01", "dev-other_correct_m_0": "0.282899", "dev-other_correct_u_0": "0.45937", "dev-other_ppl": "27.92", "dev-other_wps": "19944.2", "dev-other_wpb": "1714.6", "dev-other_bsz": "10.8", "dev-other_num_updates": "10000", "dev-other_best_loss": "4.803"}
[2023-11-22 13:36:22,697][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-22 13:36:22,697][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 13:36:44,799][dev-clean][INFO] - {"epoch": 20, "dev-clean_loss": "4.429", "dev-clean_count_m_0": "1775.83", "dev-clean_count_u_0": "1699.83", "dev-clean_loss_m_0": "4.375", "dev-clean_loss_u_0": "2.664", "dev-clean_loss_features_pen": "0.01", "dev-clean_correct_m_0": "0.329225", "dev-clean_correct_u_0": "0.542591", "dev-clean_ppl": "21.54", "dev-clean_wps": "21534", "dev-clean_wpb": "1775.8", "dev-clean_bsz": "10", "dev-clean_num_updates": "10000"}
[2023-11-22 13:57:50,712][train_inner][INFO] - {"epoch": 20, "update": 19.506, "loss": "4.656", "count_m_0": "65966.8", "count_u_0": "58320.1", "loss_m_0": "4.646", "loss_u_0": "2.37", "loss_features_pen": "0.01", "correct_m_0": "0.300898", "correct_u_0": "0.557041", "ppl": "25.21", "wps": "10067.2", "ups": "0.15", "wpb": "65966.8", "bsz": "199.4", "num_updates": "10200", "lr": "0.000159375", "gnorm": "0.587", "clip": "0", "loss_scale": "2", "train_wall": "1243", "gb_free": "65.3", "wall": "65202"}
[2023-11-22 14:06:59,461][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2023-11-22 14:18:57,604][train_inner][INFO] - {"epoch": 20, "update": 19.889, "loss": "4.62", "count_m_0": "65952.2", "count_u_0": "58161.1", "loss_m_0": "4.61", "loss_u_0": "2.308", "loss_features_pen": "0.01", "correct_m_0": "0.303924", "correct_u_0": "0.564059", "ppl": "24.59", "wps": "10411.8", "ups": "0.16", "wpb": "65952.2", "bsz": "197.2", "num_updates": "10400", "lr": "0.0001625", "gnorm": "0.575", "clip": "0", "loss_scale": "1", "train_wall": "1244", "gb_free": "65.8", "wall": "66469"}
[2023-11-22 14:25:02,058][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-22 14:25:02,059][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 14:25:24,118][dev-other][INFO] - {"epoch": 20, "dev-other_loss": "4.738", "dev-other_count_m_0": "1717.97", "dev-other_count_u_0": "1678.95", "dev-other_loss_m_0": "4.699", "dev-other_loss_u_0": "3.144", "dev-other_loss_features_pen": "0.01", "dev-other_correct_m_0": "0.289009", "dev-other_correct_u_0": "0.468955", "dev-other_ppl": "26.69", "dev-other_wps": "20397.8", "dev-other_wpb": "1718", "dev-other_bsz": "10.8", "dev-other_num_updates": "10458", "dev-other_best_loss": "4.738"}
[2023-11-22 14:25:24,119][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-22 14:25:24,119][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 14:25:46,579][dev-clean][INFO] - {"epoch": 20, "dev-clean_loss": "4.312", "dev-clean_count_m_0": "1775.28", "dev-clean_count_u_0": "1700.6", "dev-clean_loss_m_0": "4.253", "dev-clean_loss_u_0": "2.58", "dev-clean_loss_features_pen": "0.01", "dev-clean_correct_m_0": "0.341745", "dev-clean_correct_u_0": "0.55208", "dev-clean_ppl": "19.86", "dev-clean_wps": "21168.9", "dev-clean_wpb": "1775.3", "dev-clean_bsz": "10", "dev-clean_num_updates": "10458"}
[2023-11-22 14:25:46,580][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 20 @ 10458 updates
[2023-11-22 14:25:46,580][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-22 14:25:50,910][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-22 14:25:56,562][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt (epoch 20 @ 10458 updates, score 4.738) (writing took 9.981564974994399 seconds)
[2023-11-22 14:25:56,562][fairseq_cli.train][INFO] - end of epoch 20 (average epoch stats below)
[2023-11-22 14:25:56,615][train][INFO] - {"epoch": 20, "train_loss": "4.638", "train_count_m_0": "65926.4", "train_count_u_0": "58231.2", "train_loss_m_0": "4.628", "train_loss_u_0": "2.342", "train_loss_features_pen": "0.01", "train_correct_m_0": "0.30242", "train_correct_u_0": "0.560292", "train_ppl": "24.9", "train_wps": "10124.8", "train_ups": "0.15", "train_wpb": "65926.4", "train_bsz": "198.1", "train_num_updates": "10458", "train_lr": "0.000163406", "train_gnorm": "0.579", "train_clip": "0", "train_loss_scale": "1", "train_train_wall": "3247", "train_gb_free": "65.5", "train_wall": "66888"}
[2023-11-22 14:25:56,616][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 14:25:56,708][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 14:25:56,710][fairseq.trainer][INFO] - begin training epoch 21
[2023-11-22 14:25:56,710][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 14:40:52,701][train_inner][INFO] - {"epoch": 21, "update": 20.271, "loss": "4.573", "count_m_0": "66010.9", "count_u_0": "58231.6", "loss_m_0": "4.563", "loss_u_0": "2.253", "loss_features_pen": "0.01", "correct_m_0": "0.308477", "correct_u_0": "0.570452", "ppl": "23.81", "wps": "10039.1", "ups": "0.15", "wpb": "66010.9", "bsz": "194.9", "num_updates": "10600", "lr": "0.000165625", "gnorm": "0.573", "clip": "0", "loss_scale": "1", "train_wall": "1237", "gb_free": "65.8", "wall": "67784"}
[2023-11-22 15:02:00,360][train_inner][INFO] - {"epoch": 21, "update": 20.653, "loss": "4.524", "count_m_0": "65880.7", "count_u_0": "58251.6", "loss_m_0": "4.513", "loss_u_0": "2.217", "loss_features_pen": "0.01", "correct_m_0": "0.313204", "correct_u_0": "0.575438", "ppl": "23", "wps": "10394.2", "ups": "0.16", "wpb": "65880.7", "bsz": "199.5", "num_updates": "10800", "lr": "0.00016875", "gnorm": "0.579", "clip": "0", "loss_scale": "2", "train_wall": "1245", "gb_free": "65.4", "wall": "69052"}
[2023-11-22 15:21:10,976][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 21 @ 10982 updates
[2023-11-22 15:21:10,977][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 15:21:19,445][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 15:21:19,453][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 21 @ 10982 updates, score None) (writing took 8.477274047094397 seconds)
[2023-11-22 15:21:19,453][fairseq_cli.train][INFO] - end of epoch 21 (average epoch stats below)
[2023-11-22 15:21:19,468][train][INFO] - {"epoch": 21, "train_loss": "4.525", "train_count_m_0": "65938.1", "train_count_u_0": "58220.8", "train_loss_m_0": "4.514", "train_loss_u_0": "2.206", "train_loss_features_pen": "0.01", "train_correct_m_0": "0.313088", "train_correct_u_0": "0.576434", "train_ppl": "23.02", "train_wps": "10398.2", "train_ups": "0.16", "train_wpb": "65938.1", "train_bsz": "198.1", "train_num_updates": "10982", "train_lr": "0.000171594", "train_gnorm": "0.575", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3254", "train_gb_free": "65.6", "train_wall": "70211"}
[2023-11-22 15:21:19,469][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 15:21:19,537][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 15:21:19,540][fairseq.trainer][INFO] - begin training epoch 22
[2023-11-22 15:21:19,540][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 15:23:12,650][train_inner][INFO] - {"epoch": 22, "update": 21.034, "loss": "4.491", "count_m_0": "65893", "count_u_0": "58162.5", "loss_m_0": "4.48", "loss_u_0": "2.163", "loss_features_pen": "0.01", "correct_m_0": "0.316407", "correct_u_0": "0.581549", "ppl": "22.49", "wps": "10358.3", "ups": "0.16", "wpb": "65893", "bsz": "199.5", "num_updates": "11000", "lr": "0.000171875", "gnorm": "0.569", "clip": "0", "loss_scale": "2", "train_wall": "1241", "gb_free": "65.6", "wall": "70324"}
[2023-11-22 15:44:14,539][train_inner][INFO] - {"epoch": 22, "update": 21.416, "loss": "4.444", "count_m_0": "65974.6", "count_u_0": "58311", "loss_m_0": "4.433", "loss_u_0": "2.128", "loss_features_pen": "0.011", "correct_m_0": "0.321321", "correct_u_0": "0.58677", "ppl": "21.76", "wps": "10456.6", "ups": "0.16", "wpb": "65974.6", "bsz": "198.5", "num_updates": "11200", "lr": "0.000175", "gnorm": "0.566", "clip": "0", "loss_scale": "2", "train_wall": "1239", "gb_free": "65.7", "wall": "71586"}
[2023-11-22 15:58:08,894][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-22 16:05:25,656][train_inner][INFO] - {"epoch": 22, "update": 21.8, "loss": "4.416", "count_m_0": "65878.7", "count_u_0": "58218.9", "loss_m_0": "4.405", "loss_u_0": "2.097", "loss_features_pen": "0.011", "correct_m_0": "0.323743", "correct_u_0": "0.590302", "ppl": "21.35", "wps": "10365.6", "ups": "0.16", "wpb": "65878.7", "bsz": "197.1", "num_updates": "11400", "lr": "0.000178125", "gnorm": "0.569", "clip": "0", "loss_scale": "2", "train_wall": "1248", "gb_free": "65.6", "wall": "72857"}
[2023-11-22 16:16:32,640][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 22 @ 11505 updates
[2023-11-22 16:16:32,641][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 16:16:40,120][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 16:16:40,128][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 22 @ 11505 updates, score None) (writing took 7.488021244062111 seconds)
[2023-11-22 16:16:40,128][fairseq_cli.train][INFO] - end of epoch 22 (average epoch stats below)
[2023-11-22 16:16:40,143][train][INFO] - {"epoch": 22, "train_loss": "4.424", "train_count_m_0": "65920.5", "train_count_u_0": "58248.5", "train_loss_m_0": "4.413", "train_loss_u_0": "2.104", "train_loss_features_pen": "0.011", "train_correct_m_0": "0.323039", "train_correct_u_0": "0.589422", "train_ppl": "21.47", "train_wps": "10382.4", "train_ups": "0.16", "train_wpb": "65920.5", "train_bsz": "198.1", "train_num_updates": "11505", "train_lr": "0.000179766", "train_gnorm": "0.567", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3254", "train_gb_free": "65.4", "train_wall": "73531"}
[2023-11-22 16:16:40,144][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 16:16:40,210][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 16:16:40,214][fairseq.trainer][INFO] - begin training epoch 23
[2023-11-22 16:16:40,214][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 16:26:40,920][train_inner][INFO] - {"epoch": 23, "update": 22.181, "loss": "4.386", "count_m_0": "66089.7", "count_u_0": "58262.6", "loss_m_0": "4.375", "loss_u_0": "2.055", "loss_features_pen": "0.011", "correct_m_0": "0.326435", "correct_u_0": "0.594637", "ppl": "20.91", "wps": "10365", "ups": "0.16", "wpb": "66089.7", "bsz": "198", "num_updates": "11600", "lr": "0.00018125", "gnorm": "0.57", "clip": "0", "loss_scale": "2", "train_wall": "1245", "gb_free": "65.6", "wall": "74132"}
[2023-11-22 16:47:51,202][train_inner][INFO] - {"epoch": 23, "update": 22.563, "loss": "4.339", "count_m_0": "65748.6", "count_u_0": "58191.6", "loss_m_0": "4.328", "loss_u_0": "2.037", "loss_features_pen": "0.011", "correct_m_0": "0.331551", "correct_u_0": "0.597953", "ppl": "20.24", "wps": "10351.9", "ups": "0.16", "wpb": "65748.6", "bsz": "198.2", "num_updates": "11800", "lr": "0.000184375", "gnorm": "0.56", "clip": "0", "loss_scale": "2", "train_wall": "1247", "gb_free": "65.4", "wall": "75402"}
[2023-11-22 16:53:03,825][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-22 17:09:11,394][train_inner][INFO] - {"epoch": 23, "update": 22.947, "loss": "4.32", "count_m_0": "65923.9", "count_u_0": "58192", "loss_m_0": "4.309", "loss_u_0": "1.996", "loss_features_pen": "0.011", "correct_m_0": "0.333138", "correct_u_0": "0.602444", "ppl": "19.98", "wps": "10299.2", "ups": "0.16", "wpb": "65923.9", "bsz": "198.5", "num_updates": "12000", "lr": "0.0001875", "gnorm": "0.563", "clip": "0", "loss_scale": "2", "train_wall": "1257", "gb_free": "65.1", "wall": "76683"}
[2023-11-22 17:12:09,599][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 23 @ 12028 updates
[2023-11-22 17:12:09,600][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 17:12:20,046][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 17:12:20,054][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 23 @ 12028 updates, score None) (writing took 10.455207151942886 seconds)
[2023-11-22 17:12:20,054][fairseq_cli.train][INFO] - end of epoch 23 (average epoch stats below)
[2023-11-22 17:12:20,070][train][INFO] - {"epoch": 23, "train_loss": "4.338", "train_count_m_0": "65932.8", "train_count_u_0": "58225", "train_loss_m_0": "4.326", "train_loss_u_0": "2.021", "train_loss_features_pen": "0.011", "train_correct_m_0": "0.33148", "train_correct_u_0": "0.599443", "train_ppl": "20.22", "train_wps": "10324.5", "train_ups": "0.16", "train_wpb": "65932.8", "train_bsz": "198.1", "train_num_updates": "12028", "train_lr": "0.000187938", "train_gnorm": "0.564", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3269", "train_gb_free": "65.6", "train_wall": "76871"}
[2023-11-22 17:12:20,071][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 17:12:20,138][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 17:12:20,141][fairseq.trainer][INFO] - begin training epoch 24
[2023-11-22 17:12:20,141][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 17:16:07,601][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2023-11-22 17:30:35,231][train_inner][INFO] - {"epoch": 24, "update": 23.33, "loss": "4.286", "count_m_0": "65838.3", "count_u_0": "58146.2", "loss_m_0": "4.274", "loss_u_0": "1.982", "loss_features_pen": "0.011", "correct_m_0": "0.336975", "correct_u_0": "0.605277", "ppl": "19.5", "wps": "10256.6", "ups": "0.16", "wpb": "65838.3", "bsz": "198.8", "num_updates": "12200", "lr": "0.000190625", "gnorm": "0.56", "clip": "0", "loss_scale": "1", "train_wall": "1250", "gb_free": "65.5", "wall": "77966"}
[2023-11-22 17:51:36,036][train_inner][INFO] - {"epoch": 24, "update": 23.712, "loss": "4.256", "count_m_0": "66117.8", "count_u_0": "58327.8", "loss_m_0": "4.245", "loss_u_0": "1.939", "loss_features_pen": "0.011", "correct_m_0": "0.33984", "correct_u_0": "0.610538", "ppl": "19.11", "wps": "10488.3", "ups": "0.16", "wpb": "66117.8", "bsz": "196.9", "num_updates": "12400", "lr": "0.00019375", "gnorm": "0.565", "clip": "0", "loss_scale": "1", "train_wall": "1237", "gb_free": "65.5", "wall": "79227"}
[2023-11-22 18:07:29,285][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 24 @ 12551 updates
[2023-11-22 18:07:29,286][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 18:07:34,116][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 18:07:34,124][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 24 @ 12551 updates, score None) (writing took 4.8395781689323485 seconds)
[2023-11-22 18:07:34,124][fairseq_cli.train][INFO] - end of epoch 24 (average epoch stats below)
[2023-11-22 18:07:34,139][train][INFO] - {"epoch": 24, "train_loss": "4.256", "train_count_m_0": "65944.8", "train_count_u_0": "58209.7", "train_loss_m_0": "4.245", "train_loss_u_0": "1.945", "train_loss_features_pen": "0.011", "train_correct_m_0": "0.339911", "train_correct_u_0": "0.609787", "train_ppl": "19.11", "train_wps": "10406.9", "train_ups": "0.16", "train_wpb": "65944.8", "train_bsz": "198.1", "train_num_updates": "12551", "train_lr": "0.000196109", "train_gnorm": "0.562", "train_clip": "0", "train_loss_scale": "1", "train_train_wall": "3248", "train_gb_free": "65.6", "train_wall": "80185"}
[2023-11-22 18:07:34,140][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 18:07:34,211][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 18:07:34,215][fairseq.trainer][INFO] - begin training epoch 25
[2023-11-22 18:07:34,215][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 18:12:41,546][train_inner][INFO] - {"epoch": 25, "update": 24.094, "loss": "4.228", "count_m_0": "65886", "count_u_0": "58120.5", "loss_m_0": "4.216", "loss_u_0": "1.912", "loss_features_pen": "0.011", "correct_m_0": "0.342741", "correct_u_0": "0.613793", "ppl": "18.74", "wps": "10412.7", "ups": "0.16", "wpb": "65886", "bsz": "198.1", "num_updates": "12600", "lr": "0.000196875", "gnorm": "0.559", "clip": "0", "loss_scale": "2", "train_wall": "1237", "gb_free": "65.5", "wall": "80493"}
[2023-11-22 18:33:43,332][train_inner][INFO] - {"epoch": 25, "update": 24.475, "loss": "4.187", "count_m_0": "65880.1", "count_u_0": "58214", "loss_m_0": "4.175", "loss_u_0": "1.893", "loss_features_pen": "0.011", "correct_m_0": "0.347064", "correct_u_0": "0.616941", "ppl": "18.21", "wps": "10442.5", "ups": "0.16", "wpb": "65880.1", "bsz": "199.5", "num_updates": "12800", "lr": "0.0002", "gnorm": "0.55", "clip": "0", "loss_scale": "2", "train_wall": "1239", "gb_free": "65.4", "wall": "81755"}
[2023-11-22 18:54:55,440][train_inner][INFO] - {"epoch": 25, "update": 24.857, "loss": "4.163", "count_m_0": "65937.3", "count_u_0": "58237.4", "loss_m_0": "4.151", "loss_u_0": "1.873", "loss_features_pen": "0.012", "correct_m_0": "0.349631", "correct_u_0": "0.618927", "ppl": "17.91", "wps": "10366.8", "ups": "0.16", "wpb": "65937.3", "bsz": "198.3", "num_updates": "13000", "lr": "0.000203125", "gnorm": "0.555", "clip": "0", "loss_scale": "2", "train_wall": "1249", "gb_free": "65.5", "wall": "83027"}
[2023-11-22 19:02:51,054][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-22 19:02:51,055][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 19:03:13,529][dev-other][INFO] - {"epoch": 25, "dev-other_loss": "4.377", "dev-other_count_m_0": "1716.62", "dev-other_count_u_0": "1679.97", "dev-other_loss_m_0": "4.332", "dev-other_loss_u_0": "2.666", "dev-other_loss_features_pen": "0.011", "dev-other_correct_m_0": "0.320945", "dev-other_correct_u_0": "0.520275", "dev-other_ppl": "20.77", "dev-other_wps": "20015", "dev-other_wpb": "1716.6", "dev-other_bsz": "10.8", "dev-other_num_updates": "13075", "dev-other_best_loss": "4.377"}
[2023-11-22 19:03:13,537][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-22 19:03:13,538][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 19:03:36,013][dev-clean][INFO] - {"epoch": 25, "dev-clean_loss": "3.903", "dev-clean_count_m_0": "1788.81", "dev-clean_count_u_0": "1686.82", "dev-clean_loss_m_0": "3.842", "dev-clean_loss_u_0": "2.075", "dev-clean_loss_features_pen": "0.012", "dev-clean_correct_m_0": "0.383194", "dev-clean_correct_u_0": "0.604184", "dev-clean_ppl": "14.96", "dev-clean_wps": "21330.1", "dev-clean_wpb": "1788.8", "dev-clean_bsz": "10", "dev-clean_num_updates": "13075"}
[2023-11-22 19:03:36,014][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 25 @ 13075 updates
[2023-11-22 19:03:36,015][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-22 19:03:40,381][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-22 19:03:46,277][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt (epoch 25 @ 13075 updates, score 4.377) (writing took 10.263091693166643 seconds)
[2023-11-22 19:03:46,278][fairseq_cli.train][INFO] - end of epoch 25 (average epoch stats below)
[2023-11-22 19:03:46,292][train][INFO] - {"epoch": 25, "train_loss": "4.177", "train_count_m_0": "65933.1", "train_count_u_0": "58226", "train_loss_m_0": "4.165", "train_loss_u_0": "1.881", "train_loss_features_pen": "0.011", "train_correct_m_0": "0.348131", "train_correct_u_0": "0.617973", "train_ppl": "18.09", "train_wps": "10245.4", "train_ups": "0.16", "train_wpb": "65933.1", "train_bsz": "198.1", "train_num_updates": "13075", "train_lr": "0.000204297", "train_gnorm": "0.554", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3257", "train_gb_free": "65.8", "train_wall": "83558"}
[2023-11-22 19:03:46,293][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 19:03:46,361][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 19:03:46,363][fairseq.trainer][INFO] - begin training epoch 26
[2023-11-22 19:03:46,363][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 19:05:59,182][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-22 19:17:09,355][train_inner][INFO] - {"epoch": 26, "update": 25.24, "loss": "4.143", "count_m_0": "66007.5", "count_u_0": "58275.7", "loss_m_0": "4.131", "loss_u_0": "1.854", "loss_features_pen": "0.012", "correct_m_0": "0.351803", "correct_u_0": "0.622092", "ppl": "17.66", "wps": "9896.9", "ups": "0.15", "wpb": "66007.5", "bsz": "197.1", "num_updates": "13200", "lr": "0.00020625", "gnorm": "0.553", "clip": "0", "loss_scale": "2", "train_wall": "1255", "gb_free": "65.5", "wall": "84361"}
[2023-11-22 19:38:22,476][train_inner][INFO] - {"epoch": 26, "update": 25.622, "loss": "4.109", "count_m_0": "65893", "count_u_0": "58267.4", "loss_m_0": "4.097", "loss_u_0": "1.836", "loss_features_pen": "0.012", "correct_m_0": "0.355314", "correct_u_0": "0.624606", "ppl": "17.25", "wps": "10351.5", "ups": "0.16", "wpb": "65893", "bsz": "198.2", "num_updates": "13400", "lr": "0.000209375", "gnorm": "0.55", "clip": "0", "loss_scale": "2", "train_wall": "1250", "gb_free": "65.4", "wall": "85634"}
[2023-11-22 19:59:21,864][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 26 @ 13598 updates
[2023-11-22 19:59:21,865][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 19:59:29,924][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 19:59:29,933][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 26 @ 13598 updates, score None) (writing took 8.069462521001697 seconds)
[2023-11-22 19:59:29,934][fairseq_cli.train][INFO] - end of epoch 26 (average epoch stats below)
[2023-11-22 19:59:29,949][train][INFO] - {"epoch": 26, "train_loss": "4.109", "train_count_m_0": "65908.5", "train_count_u_0": "58247.2", "train_loss_m_0": "4.097", "train_loss_u_0": "1.831", "train_loss_features_pen": "0.012", "train_correct_m_0": "0.35538", "train_correct_u_0": "0.625475", "train_ppl": "17.25", "train_wps": "10309.2", "train_ups": "0.16", "train_wpb": "65908.5", "train_bsz": "198.1", "train_num_updates": "13598", "train_lr": "0.000212469", "train_gnorm": "0.55", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3274", "train_gb_free": "65.4", "train_wall": "86901"}
[2023-11-22 19:59:29,950][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 19:59:30,020][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 19:59:30,023][fairseq.trainer][INFO] - begin training epoch 27
[2023-11-22 19:59:30,023][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 19:59:42,702][train_inner][INFO] - {"epoch": 27, "update": 26.004, "loss": "4.093", "count_m_0": "65919.9", "count_u_0": "58261.7", "loss_m_0": "4.081", "loss_u_0": "1.815", "loss_features_pen": "0.012", "correct_m_0": "0.357041", "correct_u_0": "0.627613", "ppl": "17.06", "wps": "10298.3", "ups": "0.16", "wpb": "65919.9", "bsz": "197.6", "num_updates": "13600", "lr": "0.0002125", "gnorm": "0.55", "clip": "0", "loss_scale": "2", "train_wall": "1249", "gb_free": "65.3", "wall": "86914"}
[2023-11-22 20:03:08,491][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-22 20:13:24,493][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2023-11-22 20:14:40,426][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2023-11-22 20:20:59,918][train_inner][INFO] - {"epoch": 27, "update": 26.391, "loss": "4.056", "count_m_0": "65812.3", "count_u_0": "58181.9", "loss_m_0": "4.043", "loss_u_0": "1.792", "loss_features_pen": "0.012", "correct_m_0": "0.361108", "correct_u_0": "0.630694", "ppl": "16.63", "wps": "10305.7", "ups": "0.16", "wpb": "65812.3", "bsz": "197.7", "num_updates": "13800", "lr": "0.000215625", "gnorm": "0.55", "clip": "0", "loss_scale": "0.5", "train_wall": "1255", "gb_free": "65.4", "wall": "88191"}
[2023-11-22 20:42:04,176][train_inner][INFO] - {"epoch": 27, "update": 26.773, "loss": "4.046", "count_m_0": "66017.8", "count_u_0": "58290.4", "loss_m_0": "4.034", "loss_u_0": "1.77", "loss_features_pen": "0.012", "correct_m_0": "0.361982", "correct_u_0": "0.633384", "ppl": "16.52", "wps": "10443.9", "ups": "0.16", "wpb": "66017.8", "bsz": "198.9", "num_updates": "14000", "lr": "0.00021875", "gnorm": "0.546", "clip": "0", "loss_scale": "0.5", "train_wall": "1242", "gb_free": "65.5", "wall": "89455"}
[2023-11-22 20:54:33,236][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 27 @ 14119 updates
[2023-11-22 20:54:33,237][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 20:54:43,246][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 20:54:43,255][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 27 @ 14119 updates, score None) (writing took 10.018861741991714 seconds)
[2023-11-22 20:54:43,255][fairseq_cli.train][INFO] - end of epoch 27 (average epoch stats below)
[2023-11-22 20:54:43,270][train][INFO] - {"epoch": 27, "train_loss": "4.046", "train_count_m_0": "65928.9", "train_count_u_0": "58224.6", "train_loss_m_0": "4.034", "train_loss_u_0": "1.775", "train_loss_features_pen": "0.012", "train_correct_m_0": "0.362037", "train_correct_u_0": "0.63263", "train_ppl": "16.52", "train_wps": "10367", "train_ups": "0.16", "train_wpb": "65928.9", "train_bsz": "198.1", "train_num_updates": "14119", "train_lr": "0.000220609", "train_gnorm": "0.548", "train_clip": "0", "train_loss_scale": "0.5", "train_train_wall": "3245", "train_gb_free": "65.7", "train_wall": "90215"}
[2023-11-22 20:54:43,271][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 20:54:43,339][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 20:54:43,343][fairseq.trainer][INFO] - begin training epoch 28
[2023-11-22 20:54:43,344][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 21:03:13,914][train_inner][INFO] - {"epoch": 28, "update": 27.155, "loss": "4.022", "count_m_0": "66012.4", "count_u_0": "58240.6", "loss_m_0": "4.01", "loss_u_0": "1.754", "loss_features_pen": "0.012", "correct_m_0": "0.364519", "correct_u_0": "0.634751", "ppl": "16.25", "wps": "10397.9", "ups": "0.16", "wpb": "66012.4", "bsz": "198.9", "num_updates": "14200", "lr": "0.000221875", "gnorm": "0.548", "clip": "0", "loss_scale": "0.5", "train_wall": "1237", "gb_free": "65.9", "wall": "90725"}
[2023-11-22 21:24:20,046][train_inner][INFO] - {"epoch": 28, "update": 27.536, "loss": "3.992", "count_m_0": "65978", "count_u_0": "58250.6", "loss_m_0": "3.979", "loss_u_0": "1.745", "loss_features_pen": "0.012", "correct_m_0": "0.367912", "correct_u_0": "0.636408", "ppl": "15.91", "wps": "10422.1", "ups": "0.16", "wpb": "65978", "bsz": "198.2", "num_updates": "14400", "lr": "0.000225", "gnorm": "0.548", "clip": "0", "loss_scale": "1", "train_wall": "1243", "gb_free": "65.7", "wall": "91991"}
[2023-11-22 21:45:32,130][train_inner][INFO] - {"epoch": 28, "update": 27.918, "loss": "3.983", "count_m_0": "65854.1", "count_u_0": "58106.9", "loss_m_0": "3.97", "loss_u_0": "1.725", "loss_features_pen": "0.012", "correct_m_0": "0.368751", "correct_u_0": "0.638833", "ppl": "15.81", "wps": "10353.9", "ups": "0.16", "wpb": "65854.1", "bsz": "197", "num_updates": "14600", "lr": "0.000228125", "gnorm": "0.546", "clip": "0", "loss_scale": "1", "train_wall": "1249", "gb_free": "65.6", "wall": "93263"}
[2023-11-22 21:50:04,938][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 28 @ 14643 updates
[2023-11-22 21:50:04,939][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 21:50:09,598][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 21:50:09,607][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 28 @ 14643 updates, score None) (writing took 4.668625111924484 seconds)
[2023-11-22 21:50:09,607][fairseq_cli.train][INFO] - end of epoch 28 (average epoch stats below)
[2023-11-22 21:50:09,622][train][INFO] - {"epoch": 28, "train_loss": "3.99", "train_count_m_0": "65944.2", "train_count_u_0": "58215.1", "train_loss_m_0": "3.977", "train_loss_u_0": "1.737", "train_loss_features_pen": "0.012", "train_correct_m_0": "0.368067", "train_correct_u_0": "0.637408", "train_ppl": "15.89", "train_wps": "10388.2", "train_ups": "0.16", "train_wpb": "65944.2", "train_bsz": "198.1", "train_num_updates": "14643", "train_lr": "0.000228797", "train_gnorm": "0.546", "train_clip": "0", "train_loss_scale": "1", "train_train_wall": "3261", "train_gb_free": "65.6", "train_wall": "93541"}
[2023-11-22 21:50:09,623][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 21:50:09,690][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 21:50:09,693][fairseq.trainer][INFO] - begin training epoch 29
[2023-11-22 21:50:09,693][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 22:06:44,529][train_inner][INFO] - {"epoch": 29, "update": 28.3, "loss": "3.955", "count_m_0": "65979.8", "count_u_0": "58313", "loss_m_0": "3.943", "loss_u_0": "1.714", "loss_features_pen": "0.012", "correct_m_0": "0.372179", "correct_u_0": "0.641309", "ppl": "15.51", "wps": "10371.1", "ups": "0.16", "wpb": "65979.8", "bsz": "197.8", "num_updates": "14800", "lr": "0.00023125", "gnorm": "0.544", "clip": "0", "loss_scale": "2", "train_wall": "1245", "gb_free": "65.6", "wall": "94536"}
[2023-11-22 22:27:59,285][train_inner][INFO] - {"epoch": 29, "update": 28.681, "loss": "3.937", "count_m_0": "65880.7", "count_u_0": "58234.2", "loss_m_0": "3.924", "loss_u_0": "1.708", "loss_features_pen": "0.012", "correct_m_0": "0.374039", "correct_u_0": "0.642467", "ppl": "15.32", "wps": "10336.4", "ups": "0.16", "wpb": "65880.7", "bsz": "199.3", "num_updates": "15000", "lr": "0.000234375", "gnorm": "0.55", "clip": "0", "loss_scale": "2", "train_wall": "1252", "gb_free": "65.8", "wall": "95811"}
[2023-11-22 22:29:41,133][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2023-11-22 22:45:41,394][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 29 @ 15166 updates
[2023-11-22 22:45:41,395][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 22:45:51,888][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-22 22:45:51,899][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 29 @ 15166 updates, score None) (writing took 10.504426551051438 seconds)
[2023-11-22 22:45:51,899][fairseq_cli.train][INFO] - end of epoch 29 (average epoch stats below)
[2023-11-22 22:45:51,915][train][INFO] - {"epoch": 29, "train_loss": "3.941", "train_count_m_0": "65936.6", "train_count_u_0": "58218.7", "train_loss_m_0": "3.929", "train_loss_u_0": "1.704", "train_loss_features_pen": "0.012", "train_correct_m_0": "0.373659", "train_correct_u_0": "0.642659", "train_ppl": "15.36", "train_wps": "10317.8", "train_ups": "0.16", "train_wpb": "65936.6", "train_bsz": "198.1", "train_num_updates": "15166", "train_lr": "0.000236969", "train_gnorm": "0.545", "train_clip": "0", "train_loss_scale": "1", "train_train_wall": "3271", "train_gb_free": "65.7", "train_wall": "96883"}
[2023-11-22 22:45:51,916][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 22:45:51,983][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 22:45:51,986][fairseq.trainer][INFO] - begin training epoch 30
[2023-11-22 22:45:51,986][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 22:49:25,473][train_inner][INFO] - {"epoch": 30, "update": 29.065, "loss": "3.93", "count_m_0": "65963.4", "count_u_0": "58156.5", "loss_m_0": "3.918", "loss_u_0": "1.69", "loss_features_pen": "0.012", "correct_m_0": "0.374888", "correct_u_0": "0.64419", "ppl": "15.24", "wps": "10257.3", "ups": "0.16", "wpb": "65963.4", "bsz": "197.1", "num_updates": "15200", "lr": "0.0002375", "gnorm": "0.538", "clip": "0", "loss_scale": "1", "train_wall": "1252", "gb_free": "66", "wall": "97097"}
[2023-11-22 23:10:26,813][train_inner][INFO] - {"epoch": 30, "update": 29.447, "loss": "3.91", "count_m_0": "66000.8", "count_u_0": "58204.1", "loss_m_0": "3.898", "loss_u_0": "1.687", "loss_features_pen": "0.013", "correct_m_0": "0.377096", "correct_u_0": "0.6446", "ppl": "15.04", "wps": "10465.3", "ups": "0.16", "wpb": "66000.8", "bsz": "197", "num_updates": "15400", "lr": "0.000240625", "gnorm": "0.547", "clip": "0", "loss_scale": "1", "train_wall": "1237", "gb_free": "65.5", "wall": "98358"}
[2023-11-22 23:31:28,369][train_inner][INFO] - {"epoch": 30, "update": 29.828, "loss": "3.885", "count_m_0": "65868.7", "count_u_0": "58190.2", "loss_m_0": "3.872", "loss_u_0": "1.672", "loss_features_pen": "0.012", "correct_m_0": "0.379958", "correct_u_0": "0.647244", "ppl": "14.78", "wps": "10442.6", "ups": "0.16", "wpb": "65868.7", "bsz": "199.5", "num_updates": "15600", "lr": "0.00024375", "gnorm": "0.545", "clip": "0", "loss_scale": "2", "train_wall": "1239", "gb_free": "65.2", "wall": "99620"}
[2023-11-22 23:40:54,264][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-22 23:40:54,265][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 23:41:16,746][dev-other][INFO] - {"epoch": 30, "dev-other_loss": "4.133", "dev-other_count_m_0": "1712.58", "dev-other_count_u_0": "1684.17", "dev-other_loss_m_0": "4.081", "dev-other_loss_u_0": "2.5", "dev-other_loss_features_pen": "0.012", "dev-other_correct_m_0": "0.349632", "dev-other_correct_u_0": "0.542775", "dev-other_ppl": "17.54", "dev-other_wps": "20091.3", "dev-other_wpb": "1712.6", "dev-other_bsz": "10.8", "dev-other_num_updates": "15690", "dev-other_best_loss": "4.133"}
[2023-11-22 23:41:16,747][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-22 23:41:16,747][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 23:41:39,622][dev-clean][INFO] - {"epoch": 30, "dev-clean_loss": "3.553", "dev-clean_count_m_0": "1769.31", "dev-clean_count_u_0": "1706.55", "dev-clean_loss_m_0": "3.493", "dev-clean_loss_u_0": "1.938", "dev-clean_loss_features_pen": "0.012", "dev-clean_correct_m_0": "0.422192", "dev-clean_correct_u_0": "0.626989", "dev-clean_ppl": "11.74", "dev-clean_wps": "20824.6", "dev-clean_wpb": "1769.3", "dev-clean_bsz": "10", "dev-clean_num_updates": "15690"}
[2023-11-22 23:41:39,623][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 30 @ 15690 updates
[2023-11-22 23:41:39,623][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-22 23:41:43,926][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-22 23:41:52,753][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt (epoch 30 @ 15690 updates, score 4.133) (writing took 13.130301418947056 seconds)
[2023-11-22 23:41:52,754][fairseq_cli.train][INFO] - end of epoch 30 (average epoch stats below)
[2023-11-22 23:41:52,823][train][INFO] - {"epoch": 30, "train_loss": "3.894", "train_count_m_0": "65946.8", "train_count_u_0": "58212.2", "train_loss_m_0": "3.881", "train_loss_u_0": "1.676", "train_loss_features_pen": "0.013", "train_correct_m_0": "0.378964", "train_correct_u_0": "0.646356", "train_ppl": "14.87", "train_wps": "10282", "train_ups": "0.16", "train_wpb": "65946.8", "train_bsz": "198.1", "train_num_updates": "15690", "train_lr": "0.000245156", "train_gnorm": "0.543", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3241", "train_gb_free": "65.6", "train_wall": "100244"}
[2023-11-22 23:41:52,824][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-22 23:41:52,896][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-22 23:41:52,897][fairseq.trainer][INFO] - begin training epoch 31
[2023-11-22 23:41:52,898][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-22 23:53:26,862][train_inner][INFO] - {"epoch": 31, "update": 30.21, "loss": "3.874", "count_m_0": "65964.9", "count_u_0": "58187.9", "loss_m_0": "3.861", "loss_u_0": "1.656", "loss_features_pen": "0.013", "correct_m_0": "0.38131", "correct_u_0": "0.649553", "ppl": "14.66", "wps": "10006.2", "ups": "0.15", "wpb": "65964.9", "bsz": "197.3", "num_updates": "15800", "lr": "0.000246875", "gnorm": "0.54", "clip": "0", "loss_scale": "2", "train_wall": "1237", "gb_free": "65.8", "wall": "100938"}
[2023-11-23 00:14:35,511][train_inner][INFO] - {"epoch": 31, "update": 30.592, "loss": "3.851", "count_m_0": "65820.4", "count_u_0": "58175.2", "loss_m_0": "3.838", "loss_u_0": "1.633", "loss_features_pen": "0.013", "correct_m_0": "0.383839", "correct_u_0": "0.652986", "ppl": "14.43", "wps": "10376.6", "ups": "0.16", "wpb": "65820.4", "bsz": "198.2", "num_updates": "16000", "lr": "0.00025", "gnorm": "0.539", "clip": "0", "loss_scale": "2", "train_wall": "1246", "gb_free": "65.6", "wall": "102207"}
[2023-11-23 00:18:54,822][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-23 00:35:31,758][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2023-11-23 00:35:50,744][train_inner][INFO] - {"epoch": 31, "update": 30.977, "loss": "3.846", "count_m_0": "66059.1", "count_u_0": "58305.3", "loss_m_0": "3.833", "loss_u_0": "1.633", "loss_features_pen": "0.013", "correct_m_0": "0.384306", "correct_u_0": "0.65222", "ppl": "14.38", "wps": "10360.4", "ups": "0.16", "wpb": "66059.1", "bsz": "198.5", "num_updates": "16200", "lr": "0.000253125", "gnorm": "0.538", "clip": "0", "loss_scale": "1", "train_wall": "1252", "gb_free": "65.5", "wall": "103482"}
[2023-11-23 00:37:06,086][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 31 @ 16212 updates
[2023-11-23 00:37:06,087][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 00:37:10,649][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 00:37:10,656][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 31 @ 16212 updates, score None) (writing took 4.570176490815356 seconds)
[2023-11-23 00:37:10,657][fairseq_cli.train][INFO] - end of epoch 31 (average epoch stats below)
[2023-11-23 00:37:10,673][train][INFO] - {"epoch": 31, "train_loss": "3.852", "train_count_m_0": "65934.3", "train_count_u_0": "58219.4", "train_loss_m_0": "3.839", "train_loss_u_0": "1.637", "train_loss_features_pen": "0.013", "train_correct_m_0": "0.383647", "train_correct_u_0": "0.652207", "train_ppl": "14.44", "train_wps": "10373.5", "train_ups": "0.16", "train_wpb": "65934.3", "train_bsz": "198.1", "train_num_updates": "16212", "train_lr": "0.000253313", "train_gnorm": "0.539", "train_clip": "0", "train_loss_scale": "1", "train_train_wall": "3253", "train_gb_free": "65.6", "train_wall": "103562"}
[2023-11-23 00:37:10,674][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 00:37:10,740][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 00:37:10,743][fairseq.trainer][INFO] - begin training epoch 32
[2023-11-23 00:37:10,744][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 00:56:53,079][train_inner][INFO] - {"epoch": 32, "update": 31.359, "loss": "3.818", "count_m_0": "65830.6", "count_u_0": "58191.2", "loss_m_0": "3.805", "loss_u_0": "1.616", "loss_features_pen": "0.013", "correct_m_0": "0.387538", "correct_u_0": "0.655393", "ppl": "14.11", "wps": "10430.1", "ups": "0.16", "wpb": "65830.6", "bsz": "198.6", "num_updates": "16400", "lr": "0.00025625", "gnorm": "0.538", "clip": "0", "loss_scale": "1", "train_wall": "1235", "gb_free": "65.1", "wall": "104744"}
[2023-11-23 01:17:53,882][train_inner][INFO] - {"epoch": 32, "update": 31.74, "loss": "3.814", "count_m_0": "65963.5", "count_u_0": "58235.9", "loss_m_0": "3.801", "loss_u_0": "1.603", "loss_features_pen": "0.013", "correct_m_0": "0.388087", "correct_u_0": "0.657063", "ppl": "14.07", "wps": "10463.9", "ups": "0.16", "wpb": "65963.5", "bsz": "198", "num_updates": "16600", "lr": "0.000259375", "gnorm": "0.539", "clip": "0", "loss_scale": "1", "train_wall": "1238", "gb_free": "65.6", "wall": "106005"}
[2023-11-23 01:32:16,808][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 32 @ 16736 updates
[2023-11-23 01:32:16,809][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 01:32:29,154][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 01:32:29,163][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 32 @ 16736 updates, score None) (writing took 12.35496746795252 seconds)
[2023-11-23 01:32:29,163][fairseq_cli.train][INFO] - end of epoch 32 (average epoch stats below)
[2023-11-23 01:32:29,177][train][INFO] - {"epoch": 32, "train_loss": "3.812", "train_count_m_0": "65925.9", "train_count_u_0": "58233.3", "train_loss_m_0": "3.799", "train_loss_u_0": "1.605", "train_loss_features_pen": "0.013", "train_correct_m_0": "0.388417", "train_correct_u_0": "0.656833", "train_ppl": "14.04", "train_wps": "10409.9", "train_ups": "0.16", "train_wpb": "65925.9", "train_bsz": "198.1", "train_num_updates": "16736", "train_lr": "0.0002615", "train_gnorm": "0.538", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3246", "train_gb_free": "66.2", "train_wall": "106880"}
[2023-11-23 01:32:29,178][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 01:32:29,249][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 01:32:29,252][fairseq.trainer][INFO] - begin training epoch 33
[2023-11-23 01:32:29,252][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 01:35:56,535][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2023-11-23 01:39:19,481][train_inner][INFO] - {"epoch": 33, "update": 32.124, "loss": "3.797", "count_m_0": "66008.2", "count_u_0": "58283", "loss_m_0": "3.783", "loss_u_0": "1.588", "loss_features_pen": "0.013", "correct_m_0": "0.390123", "correct_u_0": "0.658926", "ppl": "13.9", "wps": "10269", "ups": "0.16", "wpb": "66008.2", "bsz": "197.8", "num_updates": "16800", "lr": "0.0002625", "gnorm": "0.537", "clip": "0", "loss_scale": "1", "train_wall": "1250", "gb_free": "65.6", "wall": "107291"}
[2023-11-23 02:00:31,028][train_inner][INFO] - {"epoch": 33, "update": 32.506, "loss": "3.775", "count_m_0": "65919.4", "count_u_0": "58283.5", "loss_m_0": "3.761", "loss_u_0": "1.576", "loss_features_pen": "0.013", "correct_m_0": "0.392654", "correct_u_0": "0.661241", "ppl": "13.69", "wps": "10368.5", "ups": "0.16", "wpb": "65919.4", "bsz": "199.3", "num_updates": "17000", "lr": "0.000265625", "gnorm": "0.537", "clip": "0", "loss_scale": "1", "train_wall": "1249", "gb_free": "65.2", "wall": "108562"}
[2023-11-23 02:21:41,247][train_inner][INFO] - {"epoch": 33, "update": 32.887, "loss": "3.767", "count_m_0": "65843.7", "count_u_0": "58152.6", "loss_m_0": "3.754", "loss_u_0": "1.578", "loss_features_pen": "0.013", "correct_m_0": "0.393542", "correct_u_0": "0.660897", "ppl": "13.62", "wps": "10367.7", "ups": "0.16", "wpb": "65843.7", "bsz": "196.6", "num_updates": "17200", "lr": "0.00026875", "gnorm": "0.536", "clip": "0", "loss_scale": "1", "train_wall": "1247", "gb_free": "65.1", "wall": "109832"}
[2023-11-23 02:27:55,187][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 33 @ 17259 updates
[2023-11-23 02:27:55,188][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 02:28:05,599][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 02:28:05,610][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 33 @ 17259 updates, score None) (writing took 10.422632581088692 seconds)
[2023-11-23 02:28:05,610][fairseq_cli.train][INFO] - end of epoch 33 (average epoch stats below)
[2023-11-23 02:28:05,626][train][INFO] - {"epoch": 33, "train_loss": "3.772", "train_count_m_0": "65913.7", "train_count_u_0": "58250.8", "train_loss_m_0": "3.759", "train_loss_u_0": "1.579", "train_loss_features_pen": "0.013", "train_correct_m_0": "0.39296", "train_correct_u_0": "0.660891", "train_ppl": "13.66", "train_wps": "10332.2", "train_ups": "0.16", "train_wpb": "65913.7", "train_bsz": "198.1", "train_num_updates": "17259", "train_lr": "0.000269672", "train_gnorm": "0.536", "train_clip": "0", "train_loss_scale": "1", "train_train_wall": "3266", "train_gb_free": "65.8", "train_wall": "110217"}
[2023-11-23 02:28:05,627][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 02:28:05,695][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 02:28:05,699][fairseq.trainer][INFO] - begin training epoch 34
[2023-11-23 02:28:05,699][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 02:42:55,426][train_inner][INFO] - {"epoch": 34, "update": 33.269, "loss": "3.763", "count_m_0": "66119.3", "count_u_0": "58369.4", "loss_m_0": "3.749", "loss_u_0": "1.582", "loss_features_pen": "0.013", "correct_m_0": "0.394393", "correct_u_0": "0.660814", "ppl": "13.58", "wps": "10378.5", "ups": "0.16", "wpb": "66119.3", "bsz": "197.5", "num_updates": "17400", "lr": "0.000271875", "gnorm": "0.537", "clip": "0", "loss_scale": "2", "train_wall": "1240", "gb_free": "66", "wall": "111107"}
[2023-11-23 02:53:58,698][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2023-11-23 03:04:16,065][train_inner][INFO] - {"epoch": 34, "update": 33.653, "loss": "3.744", "count_m_0": "65814.1", "count_u_0": "58132.2", "loss_m_0": "3.73", "loss_u_0": "1.569", "loss_features_pen": "0.013", "correct_m_0": "0.396255", "correct_u_0": "0.661928", "ppl": "13.4", "wps": "10278.4", "ups": "0.16", "wpb": "65814.1", "bsz": "199.3", "num_updates": "17600", "lr": "0.000275", "gnorm": "0.536", "clip": "0", "loss_scale": "1", "train_wall": "1257", "gb_free": "65.8", "wall": "112387"}
[2023-11-23 03:23:30,420][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 34 @ 17782 updates
[2023-11-23 03:23:30,421][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 03:23:46,298][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 03:23:46,306][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 34 @ 17782 updates, score None) (writing took 15.88646547892131 seconds)
[2023-11-23 03:23:46,307][fairseq_cli.train][INFO] - end of epoch 34 (average epoch stats below)
[2023-11-23 03:23:46,321][train][INFO] - {"epoch": 34, "train_loss": "3.75", "train_count_m_0": "65958.9", "train_count_u_0": "58197.5", "train_loss_m_0": "3.736", "train_loss_u_0": "1.568", "train_loss_features_pen": "0.013", "train_correct_m_0": "0.395553", "train_correct_u_0": "0.661935", "train_ppl": "13.45", "train_wps": "10326.2", "train_ups": "0.16", "train_wpb": "65958.9", "train_bsz": "198.1", "train_num_updates": "17782", "train_lr": "0.000277844", "train_gnorm": "0.536", "train_clip": "0", "train_loss_scale": "1", "train_train_wall": "3264", "train_gb_free": "66.1", "train_wall": "113558"}
[2023-11-23 03:23:46,322][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 03:23:46,389][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 03:23:46,392][fairseq.trainer][INFO] - begin training epoch 35
[2023-11-23 03:23:46,392][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 03:25:40,229][train_inner][INFO] - {"epoch": 35, "update": 34.034, "loss": "3.74", "count_m_0": "65923.5", "count_u_0": "58139.2", "loss_m_0": "3.727", "loss_u_0": "1.558", "loss_features_pen": "0.013", "correct_m_0": "0.396361", "correct_u_0": "0.663059", "ppl": "13.36", "wps": "10267.3", "ups": "0.16", "wpb": "65923.5", "bsz": "197.7", "num_updates": "17800", "lr": "0.000278125", "gnorm": "0.534", "clip": "0", "loss_scale": "1", "train_wall": "1245", "gb_free": "65.5", "wall": "113671"}
[2023-11-23 03:46:45,396][train_inner][INFO] - {"epoch": 35, "update": 34.416, "loss": "3.718", "count_m_0": "65899.7", "count_u_0": "58194.2", "loss_m_0": "3.704", "loss_u_0": "1.543", "loss_features_pen": "0.013", "correct_m_0": "0.399552", "correct_u_0": "0.665553", "ppl": "13.16", "wps": "10417.7", "ups": "0.16", "wpb": "65899.7", "bsz": "197.8", "num_updates": "18000", "lr": "0.00028125", "gnorm": "0.541", "clip": "0", "loss_scale": "1", "train_wall": "1242", "gb_free": "65.4", "wall": "114937"}
[2023-11-23 04:07:52,559][train_inner][INFO] - {"epoch": 35, "update": 34.798, "loss": "3.711", "count_m_0": "65912.2", "count_u_0": "58254.3", "loss_m_0": "3.697", "loss_u_0": "1.537", "loss_features_pen": "0.013", "correct_m_0": "0.400241", "correct_u_0": "0.666534", "ppl": "13.09", "wps": "10403.2", "ups": "0.16", "wpb": "65912.2", "bsz": "198.3", "num_updates": "18200", "lr": "0.000284375", "gnorm": "0.534", "clip": "0", "loss_scale": "2", "train_wall": "1245", "gb_free": "65.6", "wall": "116204"}
[2023-11-23 04:15:01,886][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2023-11-23 04:19:02,647][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-23 04:19:02,648][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 04:19:25,068][dev-other][INFO] - {"epoch": 35, "dev-other_loss": "4.034", "dev-other_count_m_0": "1721.56", "dev-other_count_u_0": "1675.15", "dev-other_loss_m_0": "3.976", "dev-other_loss_u_0": "2.27", "dev-other_loss_features_pen": "0.013", "dev-other_correct_m_0": "0.36234", "dev-other_correct_u_0": "0.567565", "dev-other_ppl": "16.38", "dev-other_wps": "20119.2", "dev-other_wpb": "1721.6", "dev-other_bsz": "10.8", "dev-other_num_updates": "18305", "dev-other_best_loss": "4.034"}
[2023-11-23 04:19:25,069][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-23 04:19:25,069][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 04:19:47,511][dev-clean][INFO] - {"epoch": 35, "dev-clean_loss": "3.492", "dev-clean_count_m_0": "1787.19", "dev-clean_count_u_0": "1688.41", "dev-clean_loss_m_0": "3.442", "dev-clean_loss_u_0": "1.746", "dev-clean_loss_features_pen": "0.014", "dev-clean_correct_m_0": "0.428343", "dev-clean_correct_u_0": "0.644654", "dev-clean_ppl": "11.25", "dev-clean_wps": "21337.2", "dev-clean_wpb": "1787.2", "dev-clean_bsz": "10", "dev-clean_num_updates": "18305"}
[2023-11-23 04:19:47,512][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 35 @ 18305 updates
[2023-11-23 04:19:47,513][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-23 04:19:52,253][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-23 04:19:58,433][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt (epoch 35 @ 18305 updates, score 4.034) (writing took 10.92040805099532 seconds)
[2023-11-23 04:19:58,434][fairseq_cli.train][INFO] - end of epoch 35 (average epoch stats below)
[2023-11-23 04:19:58,447][train][INFO] - {"epoch": 35, "train_loss": "3.713", "train_count_m_0": "65934", "train_count_u_0": "58228.3", "train_loss_m_0": "3.7", "train_loss_u_0": "1.537", "train_loss_features_pen": "0.013", "train_correct_m_0": "0.399936", "train_correct_u_0": "0.666276", "train_ppl": "13.12", "train_wps": "10226.1", "train_ups": "0.16", "train_wpb": "65934", "train_bsz": "198.1", "train_num_updates": "18305", "train_lr": "0.000286016", "train_gnorm": "0.538", "train_clip": "0", "train_loss_scale": "1", "train_train_wall": "3257", "train_gb_free": "65.5", "train_wall": "116930"}
[2023-11-23 04:19:58,448][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 04:19:58,524][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 04:19:58,526][fairseq.trainer][INFO] - begin training epoch 36
[2023-11-23 04:19:58,526][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 04:30:01,511][train_inner][INFO] - {"epoch": 36, "update": 35.181, "loss": "3.701", "count_m_0": "66000.8", "count_u_0": "58244.1", "loss_m_0": "3.688", "loss_u_0": "1.527", "loss_features_pen": "0.013", "correct_m_0": "0.401265", "correct_u_0": "0.667355", "ppl": "13.01", "wps": "9932.9", "ups": "0.15", "wpb": "66000.8", "bsz": "198.3", "num_updates": "18400", "lr": "0.0002875", "gnorm": "0.539", "clip": "0", "loss_scale": "1", "train_wall": "1250", "gb_free": "65.7", "wall": "117533"}
[2023-11-23 04:51:03,044][train_inner][INFO] - {"epoch": 36, "update": 35.563, "loss": "3.688", "count_m_0": "65987.6", "count_u_0": "58202.8", "loss_m_0": "3.674", "loss_u_0": "1.533", "loss_features_pen": "0.013", "correct_m_0": "0.402633", "correct_u_0": "0.667382", "ppl": "12.89", "wps": "10461.6", "ups": "0.16", "wpb": "65987.6", "bsz": "197.6", "num_updates": "18600", "lr": "0.000290625", "gnorm": "0.533", "clip": "0", "loss_scale": "1", "train_wall": "1239", "gb_free": "65.5", "wall": "118794"}
[2023-11-23 05:12:01,524][train_inner][INFO] - {"epoch": 36, "update": 35.945, "loss": "3.686", "count_m_0": "65964.3", "count_u_0": "58240.7", "loss_m_0": "3.672", "loss_u_0": "1.519", "loss_features_pen": "0.014", "correct_m_0": "0.403192", "correct_u_0": "0.668947", "ppl": "12.87", "wps": "10483.3", "ups": "0.16", "wpb": "65964.3", "bsz": "198.2", "num_updates": "18800", "lr": "0.00029375", "gnorm": "0.538", "clip": "0", "loss_scale": "2", "train_wall": "1236", "gb_free": "65.7", "wall": "120053"}
[2023-11-23 05:13:29,823][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2023-11-23 05:15:04,656][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 36 @ 18828 updates
[2023-11-23 05:15:04,657][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 05:15:09,240][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 05:15:09,247][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 36 @ 18828 updates, score None) (writing took 4.591042262036353 seconds)
[2023-11-23 05:15:09,248][fairseq_cli.train][INFO] - end of epoch 36 (average epoch stats below)
[2023-11-23 05:15:09,262][train][INFO] - {"epoch": 36, "train_loss": "3.687", "train_count_m_0": "65946.4", "train_count_u_0": "58210.8", "train_loss_m_0": "3.673", "train_loss_u_0": "1.527", "train_loss_features_pen": "0.014", "train_correct_m_0": "0.402946", "train_correct_u_0": "0.66805", "train_ppl": "12.88", "train_wps": "10417.4", "train_ups": "0.16", "train_wpb": "65946.4", "train_bsz": "198.1", "train_num_updates": "18828", "train_lr": "0.000294188", "train_gnorm": "0.536", "train_clip": "0", "train_loss_scale": "1", "train_train_wall": "3247", "train_gb_free": "65.8", "train_wall": "120241"}
[2023-11-23 05:15:09,263][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 05:15:09,336][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 05:15:09,339][fairseq.trainer][INFO] - begin training epoch 37
[2023-11-23 05:15:09,339][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 05:25:52,439][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2023-11-23 05:33:20,085][train_inner][INFO] - {"epoch": 37, "update": 36.33, "loss": "3.668", "count_m_0": "65835.3", "count_u_0": "58179.2", "loss_m_0": "3.654", "loss_u_0": "1.51", "loss_features_pen": "0.014", "correct_m_0": "0.405322", "correct_u_0": "0.670711", "ppl": "12.71", "wps": "10298.5", "ups": "0.16", "wpb": "65835.3", "bsz": "198.8", "num_updates": "19000", "lr": "0.000296875", "gnorm": "0.54", "clip": "0", "loss_scale": "0.5", "train_wall": "1251", "gb_free": "65.6", "wall": "121331"}
[2023-11-23 05:54:19,871][train_inner][INFO] - {"epoch": 37, "update": 36.712, "loss": "3.666", "count_m_0": "66103.3", "count_u_0": "58201.9", "loss_m_0": "3.652", "loss_u_0": "1.513", "loss_features_pen": "0.014", "correct_m_0": "0.405425", "correct_u_0": "0.669641", "ppl": "12.7", "wps": "10494.5", "ups": "0.16", "wpb": "66103.3", "bsz": "197.8", "num_updates": "19200", "lr": "0.0003", "gnorm": "0.534", "clip": "0", "loss_scale": "0.5", "train_wall": "1238", "gb_free": "65.7", "wall": "122591"}
[2023-11-23 06:10:09,992][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 37 @ 19351 updates
[2023-11-23 06:10:09,993][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 06:10:16,776][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 06:10:16,784][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 37 @ 19351 updates, score None) (writing took 6.792109383968636 seconds)
[2023-11-23 06:10:16,785][fairseq_cli.train][INFO] - end of epoch 37 (average epoch stats below)
[2023-11-23 06:10:16,800][train][INFO] - {"epoch": 37, "train_loss": "3.662", "train_count_m_0": "65952.4", "train_count_u_0": "58200.7", "train_loss_m_0": "3.647", "train_loss_u_0": "1.512", "train_loss_features_pen": "0.014", "train_correct_m_0": "0.406053", "train_correct_u_0": "0.670427", "train_ppl": "12.65", "train_wps": "10428.7", "train_ups": "0.16", "train_wpb": "65952.4", "train_bsz": "198.1", "train_num_updates": "19351", "train_lr": "0.000302359", "train_gnorm": "0.536", "train_clip": "0", "train_loss_scale": "0.5", "train_train_wall": "3241", "train_gb_free": "65.5", "train_wall": "123548"}
[2023-11-23 06:10:16,801][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 06:10:16,869][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 06:10:16,872][fairseq.trainer][INFO] - begin training epoch 38
[2023-11-23 06:10:16,872][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 06:15:24,304][train_inner][INFO] - {"epoch": 38, "update": 37.094, "loss": "3.646", "count_m_0": "65896.7", "count_u_0": "58232.1", "loss_m_0": "3.631", "loss_u_0": "1.514", "loss_features_pen": "0.014", "correct_m_0": "0.408086", "correct_u_0": "0.671084", "ppl": "12.51", "wps": "10423.2", "ups": "0.16", "wpb": "65896.7", "bsz": "197.9", "num_updates": "19400", "lr": "0.000303125", "gnorm": "0.536", "clip": "0", "loss_scale": "0.5", "train_wall": "1235", "gb_free": "65.3", "wall": "123856"}
[2023-11-23 06:36:25,311][train_inner][INFO] - {"epoch": 38, "update": 37.475, "loss": "3.644", "count_m_0": "65879.9", "count_u_0": "58167.3", "loss_m_0": "3.629", "loss_u_0": "1.498", "loss_features_pen": "0.014", "correct_m_0": "0.408146", "correct_u_0": "0.672861", "ppl": "12.5", "wps": "10448.9", "ups": "0.16", "wpb": "65879.9", "bsz": "199.3", "num_updates": "19600", "lr": "0.00030625", "gnorm": "0.538", "clip": "0", "loss_scale": "1", "train_wall": "1238", "gb_free": "65.8", "wall": "125117"}
[2023-11-23 06:57:26,018][train_inner][INFO] - {"epoch": 38, "update": 37.857, "loss": "3.627", "count_m_0": "65980.9", "count_u_0": "58242.8", "loss_m_0": "3.613", "loss_u_0": "1.498", "loss_features_pen": "0.014", "correct_m_0": "0.410089", "correct_u_0": "0.672569", "ppl": "12.35", "wps": "10467.4", "ups": "0.16", "wpb": "65980.9", "bsz": "196.6", "num_updates": "19800", "lr": "0.000309375", "gnorm": "0.54", "clip": "0", "loss_scale": "1", "train_wall": "1238", "gb_free": "65.7", "wall": "126377"}
[2023-11-23 07:05:16,363][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 38 @ 19875 updates
[2023-11-23 07:05:16,364][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 07:05:21,116][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 07:05:21,124][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 38 @ 19875 updates, score None) (writing took 4.761109014041722 seconds)
[2023-11-23 07:05:21,124][fairseq_cli.train][INFO] - end of epoch 38 (average epoch stats below)
[2023-11-23 07:05:21,138][train][INFO] - {"epoch": 38, "train_loss": "3.636", "train_count_m_0": "65943.1", "train_count_u_0": "58215.9", "train_loss_m_0": "3.622", "train_loss_u_0": "1.499", "train_loss_features_pen": "0.014", "train_correct_m_0": "0.409088", "train_correct_u_0": "0.672693", "train_ppl": "12.43", "train_wps": "10457.3", "train_ups": "0.16", "train_wpb": "65943.1", "train_bsz": "198.1", "train_num_updates": "19875", "train_lr": "0.000310547", "train_gnorm": "0.539", "train_clip": "0", "train_loss_scale": "1", "train_train_wall": "3240", "train_gb_free": "65.2", "train_wall": "126852"}
[2023-11-23 07:05:21,139][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 07:05:21,209][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 07:05:21,212][fairseq.trainer][INFO] - begin training epoch 39
[2023-11-23 07:05:21,212][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 07:13:36,763][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2023-11-23 07:18:30,452][train_inner][INFO] - {"epoch": 39, "update": 38.24, "loss": "3.631", "count_m_0": "66000.6", "count_u_0": "58217.3", "loss_m_0": "3.617", "loss_u_0": "1.489", "loss_features_pen": "0.014", "correct_m_0": "0.409618", "correct_u_0": "0.674271", "ppl": "12.39", "wps": "10439.7", "ups": "0.16", "wpb": "66000.6", "bsz": "197", "num_updates": "20000", "lr": "0.0003125", "gnorm": "0.54", "clip": "0", "loss_scale": "1", "train_wall": "1237", "gb_free": "65.4", "wall": "127642"}
[2023-11-23 07:18:30,453][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-23 07:18:30,453][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 07:18:52,886][dev-other][INFO] - {"epoch": 39, "dev-other_loss": "3.989", "dev-other_count_m_0": "1727.05", "dev-other_count_u_0": "1669.55", "dev-other_loss_m_0": "3.944", "dev-other_loss_u_0": "2.207", "dev-other_loss_features_pen": "0.014", "dev-other_correct_m_0": "0.366099", "dev-other_correct_u_0": "0.575304", "dev-other_ppl": "15.88", "dev-other_wps": "20173.2", "dev-other_wpb": "1727.1", "dev-other_bsz": "10.8", "dev-other_num_updates": "20000", "dev-other_best_loss": "3.989"}
[2023-11-23 07:18:52,886][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-23 07:18:52,887][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 07:19:15,722][dev-clean][INFO] - {"epoch": 39, "dev-clean_loss": "3.35", "dev-clean_count_m_0": "1777.67", "dev-clean_count_u_0": "1698.05", "dev-clean_loss_m_0": "3.3", "dev-clean_loss_u_0": "1.713", "dev-clean_loss_features_pen": "0.014", "dev-clean_correct_m_0": "0.445099", "dev-clean_correct_u_0": "0.65251", "dev-clean_ppl": "10.2", "dev-clean_wps": "21111.3", "dev-clean_wpb": "1777.7", "dev-clean_bsz": "10", "dev-clean_num_updates": "20000"}
[2023-11-23 07:40:16,243][train_inner][INFO] - {"epoch": 39, "update": 38.622, "loss": "3.611", "count_m_0": "65953.4", "count_u_0": "58292.1", "loss_m_0": "3.597", "loss_u_0": "1.496", "loss_features_pen": "0.014", "correct_m_0": "0.411843", "correct_u_0": "0.673797", "ppl": "12.22", "wps": "10101.8", "ups": "0.15", "wpb": "65953.4", "bsz": "198.8", "num_updates": "20200", "lr": "0.000315625", "gnorm": "0.541", "clip": "0", "loss_scale": "1", "train_wall": "1237", "gb_free": "65.6", "wall": "128948"}
[2023-11-23 08:01:04,381][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 39 @ 20398 updates
[2023-11-23 08:01:04,382][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 08:01:08,339][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 08:01:08,348][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 39 @ 20398 updates, score None) (writing took 3.966473923996091 seconds)
[2023-11-23 08:01:08,348][fairseq_cli.train][INFO] - end of epoch 39 (average epoch stats below)
[2023-11-23 08:01:08,362][train][INFO] - {"epoch": 39, "train_loss": "3.614", "train_count_m_0": "65939.1", "train_count_u_0": "58218.3", "train_loss_m_0": "3.6", "train_loss_u_0": "1.488", "train_loss_features_pen": "0.014", "train_correct_m_0": "0.411631", "train_correct_u_0": "0.674553", "train_ppl": "12.25", "train_wps": "10303", "train_ups": "0.16", "train_wpb": "65939.1", "train_bsz": "198.1", "train_num_updates": "20398", "train_lr": "0.000318719", "train_gnorm": "0.54", "train_clip": "0", "train_loss_scale": "1", "train_train_wall": "3238", "train_gb_free": "65.6", "train_wall": "130200"}
[2023-11-23 08:01:08,363][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 08:01:08,434][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 08:01:08,437][fairseq.trainer][INFO] - begin training epoch 40
[2023-11-23 08:01:08,437][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 08:01:21,004][train_inner][INFO] - {"epoch": 40, "update": 39.004, "loss": "3.611", "count_m_0": "65865.7", "count_u_0": "58136.7", "loss_m_0": "3.597", "loss_u_0": "1.483", "loss_features_pen": "0.014", "correct_m_0": "0.412177", "correct_u_0": "0.674992", "ppl": "12.22", "wps": "10415.7", "ups": "0.16", "wpb": "65865.7", "bsz": "198.6", "num_updates": "20400", "lr": "0.00031875", "gnorm": "0.54", "clip": "0", "loss_scale": "1", "train_wall": "1238", "gb_free": "65.4", "wall": "130212"}
[2023-11-23 08:17:12,963][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2023-11-23 08:22:36,411][train_inner][INFO] - {"epoch": 40, "update": 39.387, "loss": "3.595", "count_m_0": "66021.8", "count_u_0": "58259.4", "loss_m_0": "3.581", "loss_u_0": "1.483", "loss_features_pen": "0.014", "correct_m_0": "0.413886", "correct_u_0": "0.674792", "ppl": "12.08", "wps": "10353.2", "ups": "0.16", "wpb": "66021.8", "bsz": "197", "num_updates": "20600", "lr": "0.000321875", "gnorm": "0.538", "clip": "0", "loss_scale": "1", "train_wall": "1252", "gb_free": "65.5", "wall": "131488"}
[2023-11-23 08:43:52,339][train_inner][INFO] - {"epoch": 40, "update": 39.769, "loss": "3.59", "count_m_0": "65746.1", "count_u_0": "58141.2", "loss_m_0": "3.575", "loss_u_0": "1.483", "loss_features_pen": "0.014", "correct_m_0": "0.414411", "correct_u_0": "0.675649", "ppl": "12.04", "wps": "10305.8", "ups": "0.16", "wpb": "65746.1", "bsz": "199.8", "num_updates": "20800", "lr": "0.000325", "gnorm": "0.54", "clip": "0", "loss_scale": "1", "train_wall": "1253", "gb_free": "65.5", "wall": "132764"}
[2023-11-23 08:49:01,591][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2023-11-23 08:56:34,606][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-23 08:56:34,607][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 08:56:57,075][dev-other][INFO] - {"epoch": 40, "dev-other_loss": "3.971", "dev-other_count_m_0": "1730.63", "dev-other_count_u_0": "1665.66", "dev-other_loss_m_0": "3.933", "dev-other_loss_u_0": "2.181", "dev-other_loss_features_pen": "0.015", "dev-other_correct_m_0": "0.36868", "dev-other_correct_u_0": "0.576487", "dev-other_ppl": "15.68", "dev-other_wps": "20170.8", "dev-other_wpb": "1730.6", "dev-other_bsz": "10.8", "dev-other_num_updates": "20920", "dev-other_best_loss": "3.971"}
[2023-11-23 08:56:57,076][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-23 08:56:57,076][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 08:57:19,681][dev-clean][INFO] - {"epoch": 40, "dev-clean_loss": "3.345", "dev-clean_count_m_0": "1784.38", "dev-clean_count_u_0": "1691.45", "dev-clean_loss_m_0": "3.286", "dev-clean_loss_u_0": "1.672", "dev-clean_loss_features_pen": "0.015", "dev-clean_correct_m_0": "0.447332", "dev-clean_correct_u_0": "0.655817", "dev-clean_ppl": "10.16", "dev-clean_wps": "21162.8", "dev-clean_wpb": "1784.4", "dev-clean_bsz": "10", "dev-clean_num_updates": "20920"}
[2023-11-23 08:57:19,682][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 40 @ 20920 updates
[2023-11-23 08:57:19,683][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-23 08:57:23,558][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-23 08:57:29,671][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt (epoch 40 @ 20920 updates, score 3.971) (writing took 9.988272776128724 seconds)
[2023-11-23 08:57:29,671][fairseq_cli.train][INFO] - end of epoch 40 (average epoch stats below)
[2023-11-23 08:57:29,683][train][INFO] - {"epoch": 40, "train_loss": "3.594", "train_count_m_0": "65938.9", "train_count_u_0": "58222.9", "train_loss_m_0": "3.58", "train_loss_u_0": "1.479", "train_loss_features_pen": "0.014", "train_correct_m_0": "0.413924", "train_correct_u_0": "0.675738", "train_ppl": "12.08", "train_wps": "10179.5", "train_ups": "0.15", "train_wpb": "65938.9", "train_bsz": "198.1", "train_num_updates": "20920", "train_lr": "0.000326875", "train_gnorm": "0.539", "train_clip": "0", "train_loss_scale": "0.5", "train_train_wall": "3266", "train_gb_free": "65.5", "train_wall": "133581"}
[2023-11-23 08:57:29,684][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 08:57:29,752][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 08:57:29,754][fairseq.trainer][INFO] - begin training epoch 41
[2023-11-23 08:57:29,754][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 09:05:55,821][train_inner][INFO] - {"epoch": 41, "update": 40.153, "loss": "3.591", "count_m_0": "66044.4", "count_u_0": "58313.4", "loss_m_0": "3.577", "loss_u_0": "1.465", "loss_features_pen": "0.014", "correct_m_0": "0.414351", "correct_u_0": "0.677951", "ppl": "12.05", "wps": "9980.5", "ups": "0.15", "wpb": "66044.4", "bsz": "197.6", "num_updates": "21000", "lr": "0.000328125", "gnorm": "0.543", "clip": "0", "loss_scale": "0.5", "train_wall": "1245", "gb_free": "65.7", "wall": "134087"}
[2023-11-23 09:27:02,223][train_inner][INFO] - {"epoch": 41, "update": 40.534, "loss": "3.574", "count_m_0": "65770.9", "count_u_0": "58132.6", "loss_m_0": "3.56", "loss_u_0": "1.461", "loss_features_pen": "0.014", "correct_m_0": "0.416602", "correct_u_0": "0.678482", "ppl": "11.91", "wps": "10387.2", "ups": "0.16", "wpb": "65770.9", "bsz": "198.4", "num_updates": "21200", "lr": "0.00033125", "gnorm": "0.542", "clip": "0", "loss_scale": "0.5", "train_wall": "1243", "gb_free": "65.7", "wall": "135353"}
[2023-11-23 09:48:06,407][train_inner][INFO] - {"epoch": 41, "update": 40.916, "loss": "3.577", "count_m_0": "66010.8", "count_u_0": "58356.8", "loss_m_0": "3.562", "loss_u_0": "1.463", "loss_features_pen": "0.014", "correct_m_0": "0.416189", "correct_u_0": "0.67866", "ppl": "11.93", "wps": "10443.4", "ups": "0.16", "wpb": "66010.8", "bsz": "197.8", "num_updates": "21400", "lr": "0.000334375", "gnorm": "0.542", "clip": "0", "loss_scale": "1", "train_wall": "1241", "gb_free": "65.4", "wall": "136618"}
[2023-11-23 09:52:42,760][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 41 @ 21444 updates
[2023-11-23 09:52:42,761][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 09:52:49,119][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 09:52:49,133][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 41 @ 21444 updates, score None) (writing took 6.372765145963058 seconds)
[2023-11-23 09:52:49,133][fairseq_cli.train][INFO] - end of epoch 41 (average epoch stats below)
[2023-11-23 09:52:49,368][train][INFO] - {"epoch": 41, "train_loss": "3.577", "train_count_m_0": "65913.3", "train_count_u_0": "58245.7", "train_loss_m_0": "3.563", "train_loss_u_0": "1.462", "train_loss_features_pen": "0.014", "train_correct_m_0": "0.416175", "train_correct_u_0": "0.678523", "train_ppl": "11.94", "train_wps": "10404.9", "train_ups": "0.16", "train_wpb": "65913.3", "train_bsz": "198.1", "train_num_updates": "21444", "train_lr": "0.000335062", "train_gnorm": "0.544", "train_clip": "0", "train_loss_scale": "1", "train_train_wall": "3251", "train_gb_free": "65.4", "train_wall": "136900"}
[2023-11-23 09:52:49,369][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 09:52:49,439][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 09:52:49,443][fairseq.trainer][INFO] - begin training epoch 42
[2023-11-23 09:52:49,444][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 10:09:09,402][train_inner][INFO] - {"epoch": 42, "update": 41.298, "loss": "3.571", "count_m_0": "65976.1", "count_u_0": "58201.9", "loss_m_0": "3.556", "loss_u_0": "1.46", "loss_features_pen": "0.015", "correct_m_0": "0.417057", "correct_u_0": "0.678883", "ppl": "11.89", "wps": "10447.7", "ups": "0.16", "wpb": "65976.1", "bsz": "198", "num_updates": "21600", "lr": "0.0003375", "gnorm": "0.547", "clip": "0", "loss_scale": "1", "train_wall": "1232", "gb_free": "65.8", "wall": "137881"}
[2023-11-23 10:30:08,204][train_inner][INFO] - {"epoch": 42, "update": 41.679, "loss": "3.559", "count_m_0": "66011.5", "count_u_0": "58257.1", "loss_m_0": "3.545", "loss_u_0": "1.457", "loss_features_pen": "0.015", "correct_m_0": "0.418502", "correct_u_0": "0.679556", "ppl": "11.79", "wps": "10488.1", "ups": "0.16", "wpb": "66011.5", "bsz": "196.8", "num_updates": "21800", "lr": "0.000340625", "gnorm": "0.546", "clip": "0", "loss_scale": "1", "train_wall": "1235", "gb_free": "65.3", "wall": "139139"}
[2023-11-23 10:38:06,923][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2023-11-23 10:47:51,467][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 42 @ 21967 updates
[2023-11-23 10:47:51,468][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 10:47:55,818][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 10:47:55,827][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 42 @ 21967 updates, score None) (writing took 4.360030390089378 seconds)
[2023-11-23 10:47:55,827][fairseq_cli.train][INFO] - end of epoch 42 (average epoch stats below)
[2023-11-23 10:47:55,842][train][INFO] - {"epoch": 42, "train_loss": "3.56", "train_count_m_0": "65930.2", "train_count_u_0": "58226.6", "train_loss_m_0": "3.546", "train_loss_u_0": "1.463", "train_loss_features_pen": "0.015", "train_correct_m_0": "0.418314", "train_correct_u_0": "0.678843", "train_ppl": "11.8", "train_wps": "10428.5", "train_ups": "0.16", "train_wpb": "65930.2", "train_bsz": "198.1", "train_num_updates": "21967", "train_lr": "0.000343234", "train_gnorm": "0.547", "train_clip": "0", "train_loss_scale": "1", "train_train_wall": "3240", "train_gb_free": "65.8", "train_wall": "140207"}
[2023-11-23 10:47:55,843][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 10:47:55,911][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 10:47:55,917][fairseq.trainer][INFO] - begin training epoch 43
[2023-11-23 10:47:55,917][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 10:51:24,407][train_inner][INFO] - {"epoch": 43, "update": 42.063, "loss": "3.548", "count_m_0": "65739.1", "count_u_0": "58161.1", "loss_m_0": "3.533", "loss_u_0": "1.471", "loss_features_pen": "0.015", "correct_m_0": "0.419669", "correct_u_0": "0.678221", "ppl": "11.7", "wps": "10302.4", "ups": "0.16", "wpb": "65739.1", "bsz": "200.2", "num_updates": "22000", "lr": "0.00034375", "gnorm": "0.547", "clip": "0", "loss_scale": "1", "train_wall": "1248", "gb_free": "65.4", "wall": "140416"}
[2023-11-23 11:12:28,848][train_inner][INFO] - {"epoch": 43, "update": 42.445, "loss": "3.557", "count_m_0": "65956.3", "count_u_0": "58173.9", "loss_m_0": "3.542", "loss_u_0": "1.461", "loss_features_pen": "0.015", "correct_m_0": "0.418387", "correct_u_0": "0.679205", "ppl": "11.77", "wps": "10432.7", "ups": "0.16", "wpb": "65956.3", "bsz": "197.2", "num_updates": "22200", "lr": "0.000346875", "gnorm": "0.551", "clip": "0", "loss_scale": "1", "train_wall": "1241", "gb_free": "65.5", "wall": "141680"}
[2023-11-23 11:32:47,565][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2023-11-23 11:33:38,577][train_inner][INFO] - {"epoch": 43, "update": 42.828, "loss": "3.543", "count_m_0": "66032.2", "count_u_0": "58265.1", "loss_m_0": "3.528", "loss_u_0": "1.453", "loss_features_pen": "0.015", "correct_m_0": "0.419981", "correct_u_0": "0.680488", "ppl": "11.66", "wps": "10401.1", "ups": "0.16", "wpb": "66032.2", "bsz": "198.2", "num_updates": "22400", "lr": "0.00035", "gnorm": "0.549", "clip": "0", "loss_scale": "1", "train_wall": "1247", "gb_free": "65.3", "wall": "142950"}
[2023-11-23 11:34:54,873][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2023-11-23 11:43:06,575][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 43 @ 22489 updates
[2023-11-23 11:43:06,576][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 11:43:11,202][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 11:43:11,210][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 43 @ 22489 updates, score None) (writing took 4.634433801053092 seconds)
[2023-11-23 11:43:11,210][fairseq_cli.train][INFO] - end of epoch 43 (average epoch stats below)
[2023-11-23 11:43:11,224][train][INFO] - {"epoch": 43, "train_loss": "3.547", "train_count_m_0": "65946.4", "train_count_u_0": "58204", "train_loss_m_0": "3.532", "train_loss_u_0": "1.455", "train_loss_features_pen": "0.015", "train_correct_m_0": "0.419647", "train_correct_u_0": "0.680284", "train_ppl": "11.69", "train_wps": "10383.2", "train_ups": "0.16", "train_wpb": "65946.4", "train_bsz": "198.1", "train_num_updates": "22489", "train_lr": "0.000351391", "train_gnorm": "0.549", "train_clip": "0", "train_loss_scale": "0.5", "train_train_wall": "3250", "train_gb_free": "65.2", "train_wall": "143522"}
[2023-11-23 11:43:11,225][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 11:43:11,296][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 11:43:11,298][fairseq.trainer][INFO] - begin training epoch 44
[2023-11-23 11:43:11,299][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 11:54:50,746][train_inner][INFO] - {"epoch": 44, "update": 43.212, "loss": "3.537", "count_m_0": "65867.1", "count_u_0": "58159.9", "loss_m_0": "3.522", "loss_u_0": "1.444", "loss_features_pen": "0.015", "correct_m_0": "0.42093", "correct_u_0": "0.681387", "ppl": "11.61", "wps": "10355.2", "ups": "0.16", "wpb": "65867.1", "bsz": "199.1", "num_updates": "22600", "lr": "0.000353125", "gnorm": "0.551", "clip": "0", "loss_scale": "0.5", "train_wall": "1244", "gb_free": "65.4", "wall": "144222"}
[2023-11-23 12:15:57,184][train_inner][INFO] - {"epoch": 44, "update": 43.594, "loss": "3.539", "count_m_0": "66055.3", "count_u_0": "58242.4", "loss_m_0": "3.524", "loss_u_0": "1.45", "loss_features_pen": "0.015", "correct_m_0": "0.4211", "correct_u_0": "0.680931", "ppl": "11.62", "wps": "10431.8", "ups": "0.16", "wpb": "66055.3", "bsz": "197.6", "num_updates": "22800", "lr": "0.00035625", "gnorm": "0.553", "clip": "0", "loss_scale": "0.5", "train_wall": "1243", "gb_free": "65.3", "wall": "145488"}
[2023-11-23 12:36:57,582][train_inner][INFO] - {"epoch": 44, "update": 43.975, "loss": "3.534", "count_m_0": "66003.9", "count_u_0": "58118.6", "loss_m_0": "3.518", "loss_u_0": "1.437", "loss_features_pen": "0.015", "correct_m_0": "0.421326", "correct_u_0": "0.682454", "ppl": "11.58", "wps": "10473.6", "ups": "0.16", "wpb": "66003.9", "bsz": "197.6", "num_updates": "23000", "lr": "0.000359375", "gnorm": "0.555", "clip": "0", "loss_scale": "1", "train_wall": "1238", "gb_free": "65.5", "wall": "146749"}
[2023-11-23 12:38:20,190][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 44 @ 23013 updates
[2023-11-23 12:38:20,190][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 12:38:24,766][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 12:38:24,774][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 44 @ 23013 updates, score None) (writing took 4.584762248210609 seconds)
[2023-11-23 12:38:24,775][fairseq_cli.train][INFO] - end of epoch 44 (average epoch stats below)
[2023-11-23 12:38:24,791][train][INFO] - {"epoch": 44, "train_loss": "3.535", "train_count_m_0": "65983.9", "train_count_u_0": "58175.1", "train_loss_m_0": "3.52", "train_loss_u_0": "1.444", "train_loss_features_pen": "0.015", "train_correct_m_0": "0.421353", "train_correct_u_0": "0.681486", "train_ppl": "11.59", "train_wps": "10434.6", "train_ups": "0.16", "train_wpb": "65983.9", "train_bsz": "198.1", "train_num_updates": "23013", "train_lr": "0.000359578", "train_gnorm": "0.553", "train_clip": "0", "train_loss_scale": "1", "train_train_wall": "3249", "train_gb_free": "65.5", "train_wall": "146836"}
[2023-11-23 12:38:24,792][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 12:38:24,859][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 12:38:24,862][fairseq.trainer][INFO] - begin training epoch 45
[2023-11-23 12:38:24,862][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 12:58:02,749][train_inner][INFO] - {"epoch": 45, "update": 44.357, "loss": "3.514", "count_m_0": "65895.6", "count_u_0": "58301.8", "loss_m_0": "3.499", "loss_u_0": "1.444", "loss_features_pen": "0.015", "correct_m_0": "0.424008", "correct_u_0": "0.68196", "ppl": "11.42", "wps": "10417", "ups": "0.16", "wpb": "65895.6", "bsz": "198.2", "num_updates": "23200", "lr": "0.0003625", "gnorm": "0.553", "clip": "0", "loss_scale": "1", "train_wall": "1238", "gb_free": "65.5", "wall": "148014"}
[2023-11-23 13:19:06,878][train_inner][INFO] - {"epoch": 45, "update": 44.739, "loss": "3.513", "count_m_0": "65949.5", "count_u_0": "58279.1", "loss_m_0": "3.497", "loss_u_0": "1.45", "loss_features_pen": "0.015", "correct_m_0": "0.423925", "correct_u_0": "0.681229", "ppl": "11.41", "wps": "10434.1", "ups": "0.16", "wpb": "65949.5", "bsz": "198.5", "num_updates": "23400", "lr": "0.000365625", "gnorm": "0.556", "clip": "0", "loss_scale": "1", "train_wall": "1241", "gb_free": "65.2", "wall": "149278"}
[2023-11-23 13:33:34,657][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-23 13:33:34,658][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 13:33:56,976][dev-other][INFO] - {"epoch": 45, "dev-other_loss": "3.866", "dev-other_count_m_0": "1710.5", "dev-other_count_u_0": "1685.82", "dev-other_loss_m_0": "3.81", "dev-other_loss_u_0": "2.193", "dev-other_loss_features_pen": "0.015", "dev-other_correct_m_0": "0.382745", "dev-other_correct_u_0": "0.58394", "dev-other_ppl": "14.58", "dev-other_wps": "20080.1", "dev-other_wpb": "1710.5", "dev-other_bsz": "10.8", "dev-other_num_updates": "23537", "dev-other_best_loss": "3.866"}
[2023-11-23 13:33:56,976][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-23 13:33:56,977][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 13:34:19,522][dev-clean][INFO] - {"epoch": 45, "dev-clean_loss": "3.278", "dev-clean_count_m_0": "1776.52", "dev-clean_count_u_0": "1698.82", "dev-clean_loss_m_0": "3.219", "dev-clean_loss_u_0": "1.677", "dev-clean_loss_features_pen": "0.015", "dev-clean_correct_m_0": "0.455441", "dev-clean_correct_u_0": "0.659027", "dev-clean_ppl": "9.7", "dev-clean_wps": "21110.8", "dev-clean_wpb": "1776.5", "dev-clean_bsz": "10", "dev-clean_num_updates": "23537"}
[2023-11-23 13:34:19,523][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 45 @ 23537 updates
[2023-11-23 13:34:19,523][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-23 13:34:28,936][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-23 13:34:36,447][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt (epoch 45 @ 23537 updates, score 3.866) (writing took 16.924005675129592 seconds)
[2023-11-23 13:34:36,448][fairseq_cli.train][INFO] - end of epoch 45 (average epoch stats below)
[2023-11-23 13:34:36,479][train][INFO] - {"epoch": 45, "train_loss": "3.511", "train_count_m_0": "65886", "train_count_u_0": "58273.1", "train_loss_m_0": "3.496", "train_loss_u_0": "1.448", "train_loss_features_pen": "0.015", "train_correct_m_0": "0.424174", "train_correct_u_0": "0.681398", "train_ppl": "11.4", "train_wps": "10239.5", "train_ups": "0.16", "train_wpb": "65886", "train_bsz": "198.1", "train_num_updates": "23537", "train_lr": "0.000367766", "train_gnorm": "0.556", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3250", "train_gb_free": "65.3", "train_wall": "150208"}
[2023-11-23 13:34:36,480][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 13:34:36,563][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 13:34:36,567][fairseq.trainer][INFO] - begin training epoch 46
[2023-11-23 13:34:36,568][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 13:37:40,363][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2023-11-23 13:41:22,446][train_inner][INFO] - {"epoch": 46, "update": 45.122, "loss": "3.504", "count_m_0": "65828.6", "count_u_0": "58216", "loss_m_0": "3.488", "loss_u_0": "1.446", "loss_features_pen": "0.015", "correct_m_0": "0.425032", "correct_u_0": "0.681616", "ppl": "11.34", "wps": "9857.9", "ups": "0.15", "wpb": "65828.6", "bsz": "198.3", "num_updates": "23600", "lr": "0.00036875", "gnorm": "0.559", "clip": "0", "loss_scale": "1", "train_wall": "1251", "gb_free": "65.8", "wall": "150614"}
[2023-11-23 14:02:28,815][train_inner][INFO] - {"epoch": 46, "update": 45.504, "loss": "3.506", "count_m_0": "65926.6", "count_u_0": "58226.9", "loss_m_0": "3.49", "loss_u_0": "1.433", "loss_features_pen": "0.015", "correct_m_0": "0.424873", "correct_u_0": "0.682887", "ppl": "11.36", "wps": "10412", "ups": "0.16", "wpb": "65926.6", "bsz": "198.1", "num_updates": "23800", "lr": "0.000371875", "gnorm": "0.562", "clip": "0", "loss_scale": "1", "train_wall": "1244", "gb_free": "65.3", "wall": "151880"}
[2023-11-23 14:07:56,711][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2023-11-23 14:23:40,185][train_inner][INFO] - {"epoch": 46, "update": 45.887, "loss": "3.5", "count_m_0": "65956.1", "count_u_0": "58228.3", "loss_m_0": "3.484", "loss_u_0": "1.423", "loss_features_pen": "0.015", "correct_m_0": "0.425653", "correct_u_0": "0.684614", "ppl": "11.31", "wps": "10375.7", "ups": "0.16", "wpb": "65956.1", "bsz": "197.1", "num_updates": "24000", "lr": "0.000375", "gnorm": "0.562", "clip": "0", "loss_scale": "0.5", "train_wall": "1249", "gb_free": "65.5", "wall": "153151"}
[2023-11-23 14:29:54,037][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 46 @ 24059 updates
[2023-11-23 14:29:54,041][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 14:29:58,698][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 14:29:58,708][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 46 @ 24059 updates, score None) (writing took 4.670407906873152 seconds)
[2023-11-23 14:29:58,708][fairseq_cli.train][INFO] - end of epoch 46 (average epoch stats below)
[2023-11-23 14:29:58,722][train][INFO] - {"epoch": 46, "train_loss": "3.501", "train_count_m_0": "65935", "train_count_u_0": "58222.4", "train_loss_m_0": "3.485", "train_loss_u_0": "1.429", "train_loss_features_pen": "0.015", "train_correct_m_0": "0.425457", "train_correct_u_0": "0.683663", "train_ppl": "11.32", "train_wps": "10359.9", "train_ups": "0.16", "train_wpb": "65935", "train_bsz": "198.1", "train_num_updates": "24059", "train_lr": "0.000375922", "train_gnorm": "0.562", "train_clip": "0", "train_loss_scale": "0.5", "train_train_wall": "3258", "train_gb_free": "65.5", "train_wall": "153530"}
[2023-11-23 14:29:58,723][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 14:29:58,790][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 14:29:58,792][fairseq.trainer][INFO] - begin training epoch 47
[2023-11-23 14:29:58,793][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 14:44:50,955][train_inner][INFO] - {"epoch": 47, "update": 46.269, "loss": "3.495", "count_m_0": "65996.3", "count_u_0": "58243.6", "loss_m_0": "3.479", "loss_u_0": "1.434", "loss_features_pen": "0.015", "correct_m_0": "0.42605", "correct_u_0": "0.683234", "ppl": "11.27", "wps": "10387", "ups": "0.16", "wpb": "65996.3", "bsz": "198.5", "num_updates": "24200", "lr": "0.000378125", "gnorm": "0.562", "clip": "0", "loss_scale": "0.5", "train_wall": "1243", "gb_free": "65.5", "wall": "154422"}
[2023-11-23 15:06:06,185][train_inner][INFO] - {"epoch": 47, "update": 46.651, "loss": "3.49", "count_m_0": "65884.3", "count_u_0": "58238", "loss_m_0": "3.475", "loss_u_0": "1.427", "loss_features_pen": "0.015", "correct_m_0": "0.426699", "correct_u_0": "0.684505", "ppl": "11.24", "wps": "10333.1", "ups": "0.16", "wpb": "65884.3", "bsz": "199.2", "num_updates": "24400", "lr": "0.00038125", "gnorm": "0.565", "clip": "0", "loss_scale": "1", "train_wall": "1253", "gb_free": "65.2", "wall": "155697"}
[2023-11-23 15:25:35,930][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 47 @ 24583 updates
[2023-11-23 15:25:35,931][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 15:25:46,527][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 15:25:46,537][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 47 @ 24583 updates, score None) (writing took 10.607295006047934 seconds)
[2023-11-23 15:25:46,538][fairseq_cli.train][INFO] - end of epoch 47 (average epoch stats below)
[2023-11-23 15:25:46,555][train][INFO] - {"epoch": 47, "train_loss": "3.497", "train_count_m_0": "65953.4", "train_count_u_0": "58205.7", "train_loss_m_0": "3.481", "train_loss_u_0": "1.433", "train_loss_features_pen": "0.015", "train_correct_m_0": "0.42594", "train_correct_u_0": "0.683374", "train_ppl": "11.29", "train_wps": "10323", "train_ups": "0.16", "train_wpb": "65953.4", "train_bsz": "198.1", "train_num_updates": "24583", "train_lr": "0.000384109", "train_gnorm": "0.566", "train_clip": "0", "train_loss_scale": "1", "train_train_wall": "3277", "train_gb_free": "65.2", "train_wall": "156878"}
[2023-11-23 15:25:46,556][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 15:25:46,628][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 15:25:46,633][fairseq.trainer][INFO] - begin training epoch 48
[2023-11-23 15:25:46,633][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 15:27:34,578][train_inner][INFO] - {"epoch": 48, "update": 47.032, "loss": "3.502", "count_m_0": "65974.3", "count_u_0": "58165.6", "loss_m_0": "3.486", "loss_u_0": "1.44", "loss_features_pen": "0.015", "correct_m_0": "0.425393", "correct_u_0": "0.682485", "ppl": "11.33", "wps": "10241.5", "ups": "0.16", "wpb": "65974.3", "bsz": "197", "num_updates": "24600", "lr": "0.000384375", "gnorm": "0.569", "clip": "0", "loss_scale": "1", "train_wall": "1255", "gb_free": "65.5", "wall": "156986"}
[2023-11-23 15:48:50,042][train_inner][INFO] - {"epoch": 48, "update": 47.414, "loss": "3.479", "count_m_0": "66004.4", "count_u_0": "58298.6", "loss_m_0": "3.464", "loss_u_0": "1.414", "loss_features_pen": "0.015", "correct_m_0": "0.428258", "correct_u_0": "0.686337", "ppl": "11.15", "wps": "10350", "ups": "0.16", "wpb": "66004.4", "bsz": "198.5", "num_updates": "24800", "lr": "0.0003875", "gnorm": "0.57", "clip": "0", "loss_scale": "1", "train_wall": "1252", "gb_free": "65.7", "wall": "158261"}
[2023-11-23 15:58:49,243][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2023-11-23 16:10:14,304][train_inner][INFO] - {"epoch": 48, "update": 47.798, "loss": "3.483", "count_m_0": "65876", "count_u_0": "58179.7", "loss_m_0": "3.467", "loss_u_0": "1.418", "loss_features_pen": "0.016", "correct_m_0": "0.427513", "correct_u_0": "0.685843", "ppl": "11.18", "wps": "10259.1", "ups": "0.16", "wpb": "65876", "bsz": "197.7", "num_updates": "25000", "lr": "0.000390625", "gnorm": "0.575", "clip": "0", "loss_scale": "1", "train_wall": "1261", "gb_free": "65.6", "wall": "159546"}
[2023-11-23 16:10:14,306][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-23 16:10:14,306][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 16:10:36,783][dev-other][INFO] - {"epoch": 48, "dev-other_loss": "3.833", "dev-other_count_m_0": "1712.39", "dev-other_count_u_0": "1683.88", "dev-other_loss_m_0": "3.78", "dev-other_loss_u_0": "2.159", "dev-other_loss_features_pen": "0.016", "dev-other_correct_m_0": "0.385546", "dev-other_correct_u_0": "0.589539", "dev-other_ppl": "14.25", "dev-other_wps": "19948.1", "dev-other_wpb": "1712.4", "dev-other_bsz": "10.8", "dev-other_num_updates": "25000", "dev-other_best_loss": "3.833"}
[2023-11-23 16:10:36,783][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-23 16:10:36,783][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 16:10:59,589][dev-clean][INFO] - {"epoch": 48, "dev-clean_loss": "3.205", "dev-clean_count_m_0": "1769.99", "dev-clean_count_u_0": "1705.72", "dev-clean_loss_m_0": "3.148", "dev-clean_loss_u_0": "1.648", "dev-clean_loss_features_pen": "0.016", "dev-clean_correct_m_0": "0.463706", "dev-clean_correct_u_0": "0.665757", "dev-clean_ppl": "9.22", "dev-clean_wps": "20791.6", "dev-clean_wpb": "1770", "dev-clean_bsz": "10", "dev-clean_num_updates": "25000"}
[2023-11-23 16:10:59,591][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 48 @ 25000 updates
[2023-11-23 16:10:59,591][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_48_25000.pt
[2023-11-23 16:11:09,326][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_48_25000.pt
[2023-11-23 16:11:30,954][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_48_25000.pt (epoch 48 @ 25000 updates, score 3.833) (writing took 31.36303661391139 seconds)
[2023-11-23 16:22:50,162][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 48 @ 25106 updates
[2023-11-23 16:22:50,163][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 16:22:58,183][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 16:22:58,191][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 48 @ 25106 updates, score None) (writing took 8.029606417985633 seconds)
[2023-11-23 16:22:58,192][fairseq_cli.train][INFO] - end of epoch 48 (average epoch stats below)
[2023-11-23 16:22:58,209][train][INFO] - {"epoch": 48, "train_loss": "3.479", "train_count_m_0": "65915.7", "train_count_u_0": "58240.8", "train_loss_m_0": "3.463", "train_loss_u_0": "1.417", "train_loss_features_pen": "0.015", "train_correct_m_0": "0.428206", "train_correct_u_0": "0.686049", "train_ppl": "11.15", "train_wps": "10045.9", "train_ups": "0.15", "train_wpb": "65915.7", "train_bsz": "198.1", "train_num_updates": "25106", "train_lr": "0.000392281", "train_gnorm": "0.572", "train_clip": "0", "train_loss_scale": "1", "train_train_wall": "3287", "train_gb_free": "65.9", "train_wall": "160309"}
[2023-11-23 16:22:58,210][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 16:22:58,283][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 16:22:58,285][fairseq.trainer][INFO] - begin training epoch 49
[2023-11-23 16:22:58,286][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 16:32:56,613][train_inner][INFO] - {"epoch": 49, "update": 48.179, "loss": "3.469", "count_m_0": "65829.8", "count_u_0": "58187.1", "loss_m_0": "3.453", "loss_u_0": "1.418", "loss_features_pen": "0.016", "correct_m_0": "0.429361", "correct_u_0": "0.685922", "ppl": "11.08", "wps": "9664.6", "ups": "0.15", "wpb": "65829.8", "bsz": "198.2", "num_updates": "25200", "lr": "0.00039375", "gnorm": "0.573", "clip": "0", "loss_scale": "1", "train_wall": "1255", "gb_free": "65.8", "wall": "160908"}
[2023-11-23 16:54:16,315][train_inner][INFO] - {"epoch": 49, "update": 48.561, "loss": "3.459", "count_m_0": "65855.8", "count_u_0": "58248.6", "loss_m_0": "3.443", "loss_u_0": "1.428", "loss_features_pen": "0.016", "correct_m_0": "0.430639", "correct_u_0": "0.685419", "ppl": "10.99", "wps": "10292.5", "ups": "0.16", "wpb": "65855.8", "bsz": "199.6", "num_updates": "25400", "lr": "0.000396875", "gnorm": "0.574", "clip": "0", "loss_scale": "1", "train_wall": "1257", "gb_free": "65.6", "wall": "162188"}
[2023-11-23 16:58:30,921][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2023-11-23 17:15:38,298][train_inner][INFO] - {"epoch": 49, "update": 48.945, "loss": "3.476", "count_m_0": "66061.6", "count_u_0": "58287.6", "loss_m_0": "3.46", "loss_u_0": "1.421", "loss_features_pen": "0.016", "correct_m_0": "0.428778", "correct_u_0": "0.685787", "ppl": "11.13", "wps": "10306.4", "ups": "0.16", "wpb": "66061.6", "bsz": "196.6", "num_updates": "25600", "lr": "0.0004", "gnorm": "0.575", "clip": "0", "loss_scale": "1", "train_wall": "1259", "gb_free": "65.8", "wall": "163470"}
[2023-11-23 17:18:43,156][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 49 @ 25629 updates
[2023-11-23 17:18:43,157][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 17:18:53,837][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 17:18:53,845][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 49 @ 25629 updates, score None) (writing took 10.688958363141865 seconds)
[2023-11-23 17:18:53,845][fairseq_cli.train][INFO] - end of epoch 49 (average epoch stats below)
[2023-11-23 17:18:53,859][train][INFO] - {"epoch": 49, "train_loss": "3.468", "train_count_m_0": "65924.6", "train_count_u_0": "58234.3", "train_loss_m_0": "3.452", "train_loss_u_0": "1.423", "train_loss_features_pen": "0.016", "train_correct_m_0": "0.429639", "train_correct_u_0": "0.685768", "train_ppl": "11.06", "train_wps": "10274.8", "train_ups": "0.16", "train_wpb": "65924.6", "train_bsz": "198.1", "train_num_updates": "25629", "train_lr": "0.000400453", "train_gnorm": "0.575", "train_clip": "0", "train_loss_scale": "1", "train_train_wall": "3285", "train_gb_free": "65.3", "train_wall": "163665"}
[2023-11-23 17:18:53,860][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 17:18:53,925][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 17:18:53,927][fairseq.trainer][INFO] - begin training epoch 50
[2023-11-23 17:18:53,927][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 17:36:59,039][train_inner][INFO] - {"epoch": 50, "update": 49.326, "loss": "3.466", "count_m_0": "65915.6", "count_u_0": "58175.9", "loss_m_0": "3.45", "loss_u_0": "1.414", "loss_features_pen": "0.016", "correct_m_0": "0.430132", "correct_u_0": "0.686965", "ppl": "11.05", "wps": "10293.5", "ups": "0.16", "wpb": "65915.6", "bsz": "197.7", "num_updates": "25800", "lr": "0.000403125", "gnorm": "0.582", "clip": "0", "loss_scale": "1", "train_wall": "1247", "gb_free": "65.4", "wall": "164750"}
[2023-11-23 17:58:03,801][train_inner][INFO] - {"epoch": 50, "update": 49.708, "loss": "3.46", "count_m_0": "65966.6", "count_u_0": "58269.9", "loss_m_0": "3.444", "loss_u_0": "1.413", "loss_features_pen": "0.016", "correct_m_0": "0.430315", "correct_u_0": "0.686578", "ppl": "11", "wps": "10431.7", "ups": "0.16", "wpb": "65966.6", "bsz": "198.6", "num_updates": "26000", "lr": "0.00040625", "gnorm": "0.579", "clip": "0", "loss_scale": "2", "train_wall": "1241", "gb_free": "65.2", "wall": "166015"}
[2023-11-23 18:14:08,531][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-23 18:14:08,532][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 18:14:30,609][dev-other][INFO] - {"epoch": 50, "dev-other_loss": "3.878", "dev-other_count_m_0": "1726.42", "dev-other_count_u_0": "1670.25", "dev-other_loss_m_0": "3.823", "dev-other_loss_u_0": "2.106", "dev-other_loss_features_pen": "0.015", "dev-other_correct_m_0": "0.380952", "dev-other_correct_u_0": "0.589512", "dev-other_ppl": "14.7", "dev-other_wps": "20482.6", "dev-other_wpb": "1726.4", "dev-other_bsz": "10.8", "dev-other_num_updates": "26153", "dev-other_best_loss": "3.833"}
[2023-11-23 18:14:30,610][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-23 18:14:30,610][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 18:14:53,120][dev-clean][INFO] - {"epoch": 50, "dev-clean_loss": "3.226", "dev-clean_count_m_0": "1774.85", "dev-clean_count_u_0": "1700.82", "dev-clean_loss_m_0": "3.178", "dev-clean_loss_u_0": "1.606", "dev-clean_loss_features_pen": "0.016", "dev-clean_correct_m_0": "0.458128", "dev-clean_correct_u_0": "0.667994", "dev-clean_ppl": "9.36", "dev-clean_wps": "21134.2", "dev-clean_wpb": "1774.8", "dev-clean_bsz": "10", "dev-clean_num_updates": "26153"}
[2023-11-23 18:14:53,122][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 50 @ 26153 updates
[2023-11-23 18:14:53,122][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 18:15:00,820][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 18:15:00,828][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 50 @ 26153 updates, score 3.878) (writing took 7.70615775603801 seconds)
[2023-11-23 18:15:00,828][fairseq_cli.train][INFO] - end of epoch 50 (average epoch stats below)
[2023-11-23 18:15:00,846][train][INFO] - {"epoch": 50, "train_loss": "3.463", "train_count_m_0": "65937.9", "train_count_u_0": "58221", "train_loss_m_0": "3.447", "train_loss_u_0": "1.414", "train_loss_features_pen": "0.016", "train_correct_m_0": "0.430128", "train_correct_u_0": "0.686737", "train_ppl": "11.03", "train_wps": "10261.9", "train_ups": "0.16", "train_wpb": "65937.9", "train_bsz": "198.1", "train_num_updates": "26153", "train_lr": "0.000408641", "train_gnorm": "0.581", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3254", "train_gb_free": "65.7", "train_wall": "167032"}
[2023-11-23 18:15:00,847][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 18:15:00,916][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 18:15:00,918][fairseq.trainer][INFO] - begin training epoch 51
[2023-11-23 18:15:00,918][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 18:19:57,830][train_inner][INFO] - {"epoch": 51, "update": 50.09, "loss": "3.458", "count_m_0": "65958.7", "count_u_0": "58275", "loss_m_0": "3.442", "loss_u_0": "1.412", "loss_features_pen": "0.016", "correct_m_0": "0.43049", "correct_u_0": "0.68705", "ppl": "10.99", "wps": "10039.3", "ups": "0.15", "wpb": "65958.7", "bsz": "197.5", "num_updates": "26200", "lr": "0.000409375", "gnorm": "0.584", "clip": "0", "loss_scale": "2", "train_wall": "1239", "gb_free": "65.1", "wall": "167329"}
[2023-11-23 18:25:14,923][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2023-11-23 18:41:20,275][train_inner][INFO] - {"epoch": 51, "update": 50.473, "loss": "3.46", "count_m_0": "65971.5", "count_u_0": "58145.4", "loss_m_0": "3.444", "loss_u_0": "1.419", "loss_features_pen": "0.016", "correct_m_0": "0.43042", "correct_u_0": "0.686059", "ppl": "11.01", "wps": "10288.6", "ups": "0.16", "wpb": "65971.5", "bsz": "198.3", "num_updates": "26400", "lr": "0.0004125", "gnorm": "0.587", "clip": "0", "loss_scale": "1", "train_wall": "1258", "gb_free": "65.4", "wall": "168612"}
[2023-11-23 19:02:31,031][train_inner][INFO] - {"epoch": 51, "update": 50.855, "loss": "3.452", "count_m_0": "65903.5", "count_u_0": "58192", "loss_m_0": "3.435", "loss_u_0": "1.409", "loss_features_pen": "0.016", "correct_m_0": "0.431468", "correct_u_0": "0.687143", "ppl": "10.94", "wps": "10372.5", "ups": "0.16", "wpb": "65903.5", "bsz": "198.7", "num_updates": "26600", "lr": "0.000415625", "gnorm": "0.586", "clip": "0", "loss_scale": "1", "train_wall": "1248", "gb_free": "65.4", "wall": "169882"}
[2023-11-23 19:10:28,585][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 51 @ 26676 updates
[2023-11-23 19:10:28,586][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 19:10:32,504][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 19:10:32,514][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 51 @ 26676 updates, score None) (writing took 3.9285000630188733 seconds)
[2023-11-23 19:10:32,514][fairseq_cli.train][INFO] - end of epoch 51 (average epoch stats below)
[2023-11-23 19:10:32,528][train][INFO] - {"epoch": 51, "train_loss": "3.454", "train_count_m_0": "65954.9", "train_count_u_0": "58209", "train_loss_m_0": "3.438", "train_loss_u_0": "1.415", "train_loss_features_pen": "0.016", "train_correct_m_0": "0.431208", "train_correct_u_0": "0.686581", "train_ppl": "10.96", "train_wps": "10353.5", "train_ups": "0.16", "train_wpb": "65954.9", "train_bsz": "198.1", "train_num_updates": "26676", "train_lr": "0.000416812", "train_gnorm": "0.586", "train_clip": "0", "train_loss_scale": "1", "train_train_wall": "3266", "train_gb_free": "65.7", "train_wall": "170364"}
[2023-11-23 19:10:32,529][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 19:10:32,596][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 19:10:32,598][fairseq.trainer][INFO] - begin training epoch 52
[2023-11-23 19:10:32,599][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 19:23:35,772][train_inner][INFO] - {"epoch": 52, "update": 51.237, "loss": "3.447", "count_m_0": "65918.4", "count_u_0": "58247.5", "loss_m_0": "3.43", "loss_u_0": "1.428", "loss_features_pen": "0.016", "correct_m_0": "0.432151", "correct_u_0": "0.685604", "ppl": "10.9", "wps": "10424.2", "ups": "0.16", "wpb": "65918.4", "bsz": "196.9", "num_updates": "26800", "lr": "0.00041875", "gnorm": "0.59", "clip": "0", "loss_scale": "2", "train_wall": "1238", "gb_free": "65.7", "wall": "171147"}
[2023-11-23 19:39:20,189][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2023-11-23 19:45:10,929][train_inner][INFO] - {"epoch": 52, "update": 51.62, "loss": "3.446", "count_m_0": "66032.4", "count_u_0": "58195.4", "loss_m_0": "3.43", "loss_u_0": "1.397", "loss_features_pen": "0.016", "correct_m_0": "0.43235", "correct_u_0": "0.688958", "ppl": "10.9", "wps": "10196.9", "ups": "0.15", "wpb": "66032.4", "bsz": "197.3", "num_updates": "27000", "lr": "0.000421875", "gnorm": "0.592", "clip": "0", "loss_scale": "1", "train_wall": "1272", "gb_free": "65.6", "wall": "172442"}
[2023-11-23 20:06:30,097][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 52 @ 27199 updates
[2023-11-23 20:06:30,098][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 20:06:35,029][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 20:06:35,037][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 52 @ 27199 updates, score None) (writing took 4.939606287982315 seconds)
[2023-11-23 20:06:35,037][fairseq_cli.train][INFO] - end of epoch 52 (average epoch stats below)
[2023-11-23 20:06:35,050][train][INFO] - {"epoch": 52, "train_loss": "3.443", "train_count_m_0": "65940.3", "train_count_u_0": "58224.3", "train_loss_m_0": "3.427", "train_loss_u_0": "1.408", "train_loss_features_pen": "0.016", "train_correct_m_0": "0.432603", "train_correct_u_0": "0.687516", "train_ppl": "10.88", "train_wps": "10256.3", "train_ups": "0.16", "train_wpb": "65940.3", "train_bsz": "198", "train_num_updates": "27199", "train_lr": "0.000424984", "train_gnorm": "0.593", "train_clip": "0", "train_loss_scale": "1", "train_train_wall": "3297", "train_gb_free": "65.5", "train_wall": "173726"}
[2023-11-23 20:06:35,051][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 20:06:35,119][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 20:06:35,122][fairseq.trainer][INFO] - begin training epoch 53
[2023-11-23 20:06:35,122][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 20:06:41,629][train_inner][INFO] - {"epoch": 53, "update": 52.002, "loss": "3.441", "count_m_0": "65868.9", "count_u_0": "58223.8", "loss_m_0": "3.424", "loss_u_0": "1.407", "loss_features_pen": "0.016", "correct_m_0": "0.432898", "correct_u_0": "0.687307", "ppl": "10.86", "wps": "10206.8", "ups": "0.15", "wpb": "65868.9", "bsz": "199.1", "num_updates": "27200", "lr": "0.000425", "gnorm": "0.595", "clip": "0", "loss_scale": "1", "train_wall": "1262", "gb_free": "65.3", "wall": "173733"}
[2023-11-23 20:27:59,621][train_inner][INFO] - {"epoch": 53, "update": 52.384, "loss": "3.44", "count_m_0": "65965.7", "count_u_0": "58221.8", "loss_m_0": "3.424", "loss_u_0": "1.405", "loss_features_pen": "0.016", "correct_m_0": "0.433027", "correct_u_0": "0.687552", "ppl": "10.86", "wps": "10323.5", "ups": "0.16", "wpb": "65965.7", "bsz": "198.3", "num_updates": "27400", "lr": "0.000428125", "gnorm": "0.597", "clip": "0", "loss_scale": "1", "train_wall": "1255", "gb_free": "65.3", "wall": "175011"}
[2023-11-23 20:49:17,099][train_inner][INFO] - {"epoch": 53, "update": 52.765, "loss": "3.44", "count_m_0": "65980.9", "count_u_0": "58204.9", "loss_m_0": "3.423", "loss_u_0": "1.403", "loss_features_pen": "0.016", "correct_m_0": "0.432897", "correct_u_0": "0.687434", "ppl": "10.85", "wps": "10330", "ups": "0.16", "wpb": "65980.9", "bsz": "198.7", "num_updates": "27600", "lr": "0.00043125", "gnorm": "0.598", "clip": "0", "loss_scale": "2", "train_wall": "1254", "gb_free": "65.8", "wall": "176288"}
[2023-11-23 21:02:21,101][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 53 @ 27723 updates
[2023-11-23 21:02:21,102][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 21:02:29,255][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 21:02:29,263][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 53 @ 27723 updates, score None) (writing took 8.162377591943368 seconds)
[2023-11-23 21:02:29,264][fairseq_cli.train][INFO] - end of epoch 53 (average epoch stats below)
[2023-11-23 21:02:29,277][train][INFO] - {"epoch": 53, "train_loss": "3.441", "train_count_m_0": "65970.5", "train_count_u_0": "58188.4", "train_loss_m_0": "3.424", "train_loss_u_0": "1.405", "train_loss_features_pen": "0.016", "train_correct_m_0": "0.432917", "train_correct_u_0": "0.687383", "train_ppl": "10.86", "train_wps": "10306", "train_ups": "0.16", "train_wpb": "65970.5", "train_bsz": "198.1", "train_num_updates": "27723", "train_lr": "0.000433172", "train_gnorm": "0.599", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3286", "train_gb_free": "65.4", "train_wall": "177081"}
[2023-11-23 21:02:29,278][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 21:02:29,345][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 21:02:29,348][fairseq.trainer][INFO] - begin training epoch 54
[2023-11-23 21:02:29,348][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 21:06:06,640][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2023-11-23 21:10:47,049][train_inner][INFO] - {"epoch": 54, "update": 53.149, "loss": "3.439", "count_m_0": "66002.9", "count_u_0": "58149.9", "loss_m_0": "3.423", "loss_u_0": "1.406", "loss_features_pen": "0.016", "correct_m_0": "0.433196", "correct_u_0": "0.687819", "ppl": "10.85", "wps": "10233.5", "ups": "0.16", "wpb": "66002.9", "bsz": "197.5", "num_updates": "27800", "lr": "0.000434375", "gnorm": "0.601", "clip": "0", "loss_scale": "1", "train_wall": "1258", "gb_free": "65.4", "wall": "177578"}
[2023-11-23 21:32:03,714][train_inner][INFO] - {"epoch": 54, "update": 53.531, "loss": "3.429", "count_m_0": "65919.6", "count_u_0": "58204.2", "loss_m_0": "3.413", "loss_u_0": "1.41", "loss_features_pen": "0.016", "correct_m_0": "0.434205", "correct_u_0": "0.687401", "ppl": "10.77", "wps": "10327", "ups": "0.16", "wpb": "65919.6", "bsz": "197.9", "num_updates": "28000", "lr": "0.0004375", "gnorm": "0.606", "clip": "0", "loss_scale": "1", "train_wall": "1254", "gb_free": "65.3", "wall": "178855"}
[2023-11-23 21:53:24,438][train_inner][INFO] - {"epoch": 54, "update": 53.912, "loss": "3.422", "count_m_0": "65862.7", "count_u_0": "58246.2", "loss_m_0": "3.405", "loss_u_0": "1.399", "loss_features_pen": "0.016", "correct_m_0": "0.43494", "correct_u_0": "0.688967", "ppl": "10.72", "wps": "10285.4", "ups": "0.16", "wpb": "65862.7", "bsz": "198.4", "num_updates": "28200", "lr": "0.000440625", "gnorm": "0.608", "clip": "0", "loss_scale": "1", "train_wall": "1258", "gb_free": "65.5", "wall": "180136"}
[2023-11-23 21:58:14,666][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 54 @ 28246 updates
[2023-11-23 21:58:14,667][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 21:58:24,618][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 21:58:24,625][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 54 @ 28246 updates, score None) (writing took 9.95956075983122 seconds)
[2023-11-23 21:58:24,626][fairseq_cli.train][INFO] - end of epoch 54 (average epoch stats below)
[2023-11-23 21:58:24,639][train][INFO] - {"epoch": 54, "train_loss": "3.428", "train_count_m_0": "65937.4", "train_count_u_0": "58224.2", "train_loss_m_0": "3.412", "train_loss_u_0": "1.404", "train_loss_features_pen": "0.016", "train_correct_m_0": "0.434319", "train_correct_u_0": "0.688222", "train_ppl": "10.77", "train_wps": "10277.7", "train_ups": "0.16", "train_wpb": "65937.4", "train_bsz": "198.1", "train_num_updates": "28246", "train_lr": "0.000441344", "train_gnorm": "0.606", "train_clip": "0", "train_loss_scale": "1", "train_train_wall": "3285", "train_gb_free": "65.4", "train_wall": "180436"}
[2023-11-23 21:58:24,640][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 21:58:24,708][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 21:58:24,711][fairseq.trainer][INFO] - begin training epoch 55
[2023-11-23 21:58:24,711][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 22:14:47,120][train_inner][INFO] - {"epoch": 55, "update": 54.294, "loss": "3.425", "count_m_0": "65905.8", "count_u_0": "58140.7", "loss_m_0": "3.409", "loss_u_0": "1.405", "loss_features_pen": "0.016", "correct_m_0": "0.434825", "correct_u_0": "0.687975", "ppl": "10.74", "wps": "10276.4", "ups": "0.16", "wpb": "65905.8", "bsz": "197.9", "num_updates": "28400", "lr": "0.00044375", "gnorm": "0.609", "clip": "0", "loss_scale": "2", "train_wall": "1249", "gb_free": "65.4", "wall": "181418"}
[2023-11-23 22:35:53,166][train_inner][INFO] - {"epoch": 55, "update": 54.676, "loss": "3.422", "count_m_0": "66001.7", "count_u_0": "58279.5", "loss_m_0": "3.405", "loss_u_0": "1.395", "loss_features_pen": "0.016", "correct_m_0": "0.435003", "correct_u_0": "0.689183", "ppl": "10.71", "wps": "10426.6", "ups": "0.16", "wpb": "66001.7", "bsz": "197.7", "num_updates": "28600", "lr": "0.000446875", "gnorm": "0.608", "clip": "0", "loss_scale": "2", "train_wall": "1243", "gb_free": "65.4", "wall": "182684"}
[2023-11-23 22:53:51,231][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-23 22:53:51,232][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 22:54:13,901][dev-other][INFO] - {"epoch": 55, "dev-other_loss": "3.837", "dev-other_count_m_0": "1721.57", "dev-other_count_u_0": "1675", "dev-other_loss_m_0": "3.787", "dev-other_loss_u_0": "2.094", "dev-other_loss_features_pen": "0.016", "dev-other_correct_m_0": "0.386392", "dev-other_correct_u_0": "0.594699", "dev-other_ppl": "14.29", "dev-other_wps": "19905.2", "dev-other_wpb": "1721.6", "dev-other_bsz": "10.8", "dev-other_num_updates": "28770", "dev-other_best_loss": "3.833"}
[2023-11-23 22:54:13,902][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-23 22:54:13,903][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 22:54:36,538][dev-clean][INFO] - {"epoch": 55, "dev-clean_loss": "3.189", "dev-clean_count_m_0": "1775.89", "dev-clean_count_u_0": "1699.93", "dev-clean_loss_m_0": "3.128", "dev-clean_loss_u_0": "1.595", "dev-clean_loss_features_pen": "0.017", "dev-clean_correct_m_0": "0.466219", "dev-clean_correct_u_0": "0.672931", "dev-clean_ppl": "9.12", "dev-clean_wps": "21040.8", "dev-clean_wpb": "1775.9", "dev-clean_bsz": "10", "dev-clean_num_updates": "28770"}
[2023-11-23 22:54:36,539][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 55 @ 28770 updates
[2023-11-23 22:54:36,539][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 22:54:40,183][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 22:54:40,192][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 55 @ 28770 updates, score 3.837) (writing took 3.653369478881359 seconds)
[2023-11-23 22:54:40,193][fairseq_cli.train][INFO] - end of epoch 55 (average epoch stats below)
[2023-11-23 22:54:40,209][train][INFO] - {"epoch": 55, "train_loss": "3.423", "train_count_m_0": "65952.7", "train_count_u_0": "58206.4", "train_loss_m_0": "3.406", "train_loss_u_0": "1.399", "train_loss_features_pen": "0.016", "train_correct_m_0": "0.434992", "train_correct_u_0": "0.688614", "train_ppl": "10.72", "train_wps": "10238.1", "train_ups": "0.16", "train_wpb": "65952.7", "train_bsz": "198.1", "train_num_updates": "28770", "train_lr": "0.000449531", "train_gnorm": "0.609", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3266", "train_gb_free": "65.5", "train_wall": "183811"}
[2023-11-23 22:54:40,209][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 22:54:40,278][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 22:54:40,280][fairseq.trainer][INFO] - begin training epoch 56
[2023-11-23 22:54:40,280][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-23 22:57:49,199][train_inner][INFO] - {"epoch": 56, "update": 55.057, "loss": "3.423", "count_m_0": "65981", "count_u_0": "58191.4", "loss_m_0": "3.407", "loss_u_0": "1.4", "loss_features_pen": "0.016", "correct_m_0": "0.434829", "correct_u_0": "0.688204", "ppl": "10.73", "wps": "10027.4", "ups": "0.15", "wpb": "65981", "bsz": "197.9", "num_updates": "28800", "lr": "0.00045", "gnorm": "0.609", "clip": "0", "loss_scale": "4", "train_wall": "1244", "gb_free": "65.3", "wall": "184000"}
[2023-11-23 23:02:09,354][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-23 23:19:00,192][train_inner][INFO] - {"epoch": 56, "update": 55.441, "loss": "3.413", "count_m_0": "65821.1", "count_u_0": "58166.7", "loss_m_0": "3.397", "loss_u_0": "1.392", "loss_features_pen": "0.016", "correct_m_0": "0.43633", "correct_u_0": "0.689949", "ppl": "10.65", "wps": "10357.6", "ups": "0.16", "wpb": "65821.1", "bsz": "197.4", "num_updates": "29000", "lr": "0.000453125", "gnorm": "0.615", "clip": "0", "loss_scale": "2", "train_wall": "1248", "gb_free": "65.3", "wall": "185271"}
[2023-11-23 23:40:06,517][train_inner][INFO] - {"epoch": 56, "update": 55.823, "loss": "3.412", "count_m_0": "65972.9", "count_u_0": "58299.6", "loss_m_0": "3.395", "loss_u_0": "1.398", "loss_features_pen": "0.016", "correct_m_0": "0.436338", "correct_u_0": "0.689333", "ppl": "10.65", "wps": "10419.7", "ups": "0.16", "wpb": "65972.9", "bsz": "198.6", "num_updates": "29200", "lr": "0.00045625", "gnorm": "0.615", "clip": "0", "loss_scale": "2", "train_wall": "1243", "gb_free": "65.8", "wall": "186538"}
[2023-11-23 23:49:56,846][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 56 @ 29293 updates
[2023-11-23 23:49:56,847][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 23:50:01,108][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-23 23:50:01,117][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 56 @ 29293 updates, score None) (writing took 4.270602380856872 seconds)
[2023-11-23 23:50:01,117][fairseq_cli.train][INFO] - end of epoch 56 (average epoch stats below)
[2023-11-23 23:50:01,132][train][INFO] - {"epoch": 56, "train_loss": "3.413", "train_count_m_0": "65919.3", "train_count_u_0": "58244.2", "train_loss_m_0": "3.396", "train_loss_u_0": "1.396", "train_loss_features_pen": "0.016", "train_correct_m_0": "0.436252", "train_correct_u_0": "0.689311", "train_ppl": "10.65", "train_wps": "10381.4", "train_ups": "0.16", "train_wpb": "65919.3", "train_bsz": "198.1", "train_num_updates": "29293", "train_lr": "0.000457703", "train_gnorm": "0.616", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3257", "train_gb_free": "65.4", "train_wall": "187132"}
[2023-11-23 23:50:01,133][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-23 23:50:01,202][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-23 23:50:01,205][fairseq.trainer][INFO] - begin training epoch 57
[2023-11-23 23:50:01,205][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 00:01:19,739][train_inner][INFO] - {"epoch": 57, "update": 56.204, "loss": "3.411", "count_m_0": "65927.6", "count_u_0": "58228.2", "loss_m_0": "3.394", "loss_u_0": "1.4", "loss_features_pen": "0.017", "correct_m_0": "0.436494", "correct_u_0": "0.688878", "ppl": "10.64", "wps": "10356.1", "ups": "0.16", "wpb": "65927.6", "bsz": "198.9", "num_updates": "29400", "lr": "0.000459375", "gnorm": "0.622", "clip": "0", "loss_scale": "4", "train_wall": "1246", "gb_free": "65.4", "wall": "187811"}
[2023-11-24 00:22:38,805][train_inner][INFO] - {"epoch": 57, "update": 56.586, "loss": "3.409", "count_m_0": "65929.5", "count_u_0": "58209.8", "loss_m_0": "3.392", "loss_u_0": "1.41", "loss_features_pen": "0.017", "correct_m_0": "0.436834", "correct_u_0": "0.687933", "ppl": "10.62", "wps": "10309.1", "ups": "0.16", "wpb": "65929.5", "bsz": "197.8", "num_updates": "29600", "lr": "0.0004625", "gnorm": "0.622", "clip": "0", "loss_scale": "4", "train_wall": "1256", "gb_free": "65.4", "wall": "189090"}
[2023-11-24 00:24:27,668][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-24 00:44:04,453][train_inner][INFO] - {"epoch": 57, "update": 56.969, "loss": "3.414", "count_m_0": "65989.6", "count_u_0": "58279.5", "loss_m_0": "3.397", "loss_u_0": "1.396", "loss_features_pen": "0.016", "correct_m_0": "0.435938", "correct_u_0": "0.689418", "ppl": "10.66", "wps": "10265.7", "ups": "0.16", "wpb": "65989.6", "bsz": "198", "num_updates": "29800", "lr": "0.000465625", "gnorm": "0.623", "clip": "0", "loss_scale": "2", "train_wall": "1263", "gb_free": "65.4", "wall": "190376"}
[2023-11-24 00:45:45,725][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 57 @ 29816 updates
[2023-11-24 00:45:45,725][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 00:45:49,789][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 00:45:49,802][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 57 @ 29816 updates, score None) (writing took 4.077269313158467 seconds)
[2023-11-24 00:45:49,802][fairseq_cli.train][INFO] - end of epoch 57 (average epoch stats below)
[2023-11-24 00:45:49,822][train][INFO] - {"epoch": 57, "train_loss": "3.411", "train_count_m_0": "65938.7", "train_count_u_0": "58219.7", "train_loss_m_0": "3.394", "train_loss_u_0": "1.402", "train_loss_features_pen": "0.017", "train_correct_m_0": "0.436478", "train_correct_u_0": "0.688866", "train_ppl": "10.64", "train_wps": "10298.4", "train_ups": "0.16", "train_wpb": "65938.7", "train_bsz": "198.1", "train_num_updates": "29816", "train_lr": "0.000465875", "train_gnorm": "0.622", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3284", "train_gb_free": "65.7", "train_wall": "190481"}
[2023-11-24 00:45:49,823][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 00:45:49,960][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 00:45:49,963][fairseq.trainer][INFO] - begin training epoch 58
[2023-11-24 00:45:49,963][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 01:05:23,768][train_inner][INFO] - {"epoch": 58, "update": 57.351, "loss": "3.408", "count_m_0": "65889.2", "count_u_0": "58209.7", "loss_m_0": "3.391", "loss_u_0": "1.404", "loss_features_pen": "0.017", "correct_m_0": "0.43696", "correct_u_0": "0.688853", "ppl": "10.61", "wps": "10300.8", "ups": "0.16", "wpb": "65889.2", "bsz": "198.4", "num_updates": "30000", "lr": "0.00046875", "gnorm": "0.628", "clip": "0", "loss_scale": "2", "train_wall": "1252", "gb_free": "65.7", "wall": "191655"}
[2023-11-24 01:05:23,769][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-24 01:05:23,769][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 01:05:46,902][dev-other][INFO] - {"epoch": 58, "dev-other_loss": "3.799", "dev-other_count_m_0": "1718.51", "dev-other_count_u_0": "1678.04", "dev-other_loss_m_0": "3.748", "dev-other_loss_u_0": "2.129", "dev-other_loss_features_pen": "0.017", "dev-other_correct_m_0": "0.390177", "dev-other_correct_u_0": "0.590043", "dev-other_ppl": "13.92", "dev-other_wps": "19532", "dev-other_wpb": "1718.5", "dev-other_bsz": "10.8", "dev-other_num_updates": "30000", "dev-other_best_loss": "3.799"}
[2023-11-24 01:05:46,902][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-24 01:05:46,903][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 01:06:09,439][dev-clean][INFO] - {"epoch": 58, "dev-clean_loss": "3.139", "dev-clean_count_m_0": "1774.52", "dev-clean_count_u_0": "1701.06", "dev-clean_loss_m_0": "3.075", "dev-clean_loss_u_0": "1.604", "dev-clean_loss_features_pen": "0.017", "dev-clean_correct_m_0": "0.472444", "dev-clean_correct_u_0": "0.67081", "dev-clean_ppl": "8.81", "dev-clean_wps": "21096.5", "dev-clean_wpb": "1774.5", "dev-clean_bsz": "10", "dev-clean_num_updates": "30000"}
[2023-11-24 01:27:31,941][train_inner][INFO] - {"epoch": 58, "update": 57.733, "loss": "3.412", "count_m_0": "66078.2", "count_u_0": "58316.7", "loss_m_0": "3.395", "loss_u_0": "1.393", "loss_features_pen": "0.017", "correct_m_0": "0.436277", "correct_u_0": "0.69031", "ppl": "10.64", "wps": "9950.4", "ups": "0.15", "wpb": "66078.2", "bsz": "197.5", "num_updates": "30200", "lr": "0.000471875", "gnorm": "0.628", "clip": "0", "loss_scale": "4", "train_wall": "1259", "gb_free": "65.3", "wall": "192983"}
[2023-11-24 01:40:26,451][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-24 01:42:27,450][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 58 @ 30339 updates
[2023-11-24 01:42:27,451][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 01:42:37,845][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 01:42:37,853][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 58 @ 30339 updates, score None) (writing took 10.402994440868497 seconds)
[2023-11-24 01:42:37,853][fairseq_cli.train][INFO] - end of epoch 58 (average epoch stats below)
[2023-11-24 01:42:37,869][train][INFO] - {"epoch": 58, "train_loss": "3.409", "train_count_m_0": "65928.4", "train_count_u_0": "58227.4", "train_loss_m_0": "3.392", "train_loss_u_0": "1.401", "train_loss_features_pen": "0.017", "train_correct_m_0": "0.43671", "train_correct_u_0": "0.68938", "train_ppl": "10.62", "train_wps": "10117.4", "train_ups": "0.15", "train_wpb": "65928.4", "train_bsz": "198.1", "train_num_updates": "30339", "train_lr": "0.000474047", "train_gnorm": "0.629", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3291", "train_gb_free": "65.6", "train_wall": "193889"}
[2023-11-24 01:42:37,870][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 01:42:37,937][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 01:42:37,940][fairseq.trainer][INFO] - begin training epoch 59
[2023-11-24 01:42:37,940][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 01:49:05,505][train_inner][INFO] - {"epoch": 59, "update": 58.116, "loss": "3.407", "count_m_0": "65802.5", "count_u_0": "58120.3", "loss_m_0": "3.39", "loss_u_0": "1.405", "loss_features_pen": "0.017", "correct_m_0": "0.437049", "correct_u_0": "0.688895", "ppl": "10.6", "wps": "10174", "ups": "0.15", "wpb": "65802.5", "bsz": "198.5", "num_updates": "30400", "lr": "0.000475", "gnorm": "0.633", "clip": "0", "loss_scale": "2", "train_wall": "1260", "gb_free": "65.7", "wall": "194277"}
[2023-11-24 02:10:23,469][train_inner][INFO] - {"epoch": 59, "update": 58.498, "loss": "3.408", "count_m_0": "65884.3", "count_u_0": "58172.7", "loss_m_0": "3.391", "loss_u_0": "1.389", "loss_features_pen": "0.017", "correct_m_0": "0.436877", "correct_u_0": "0.690542", "ppl": "10.61", "wps": "10310.9", "ups": "0.16", "wpb": "65884.3", "bsz": "197.7", "num_updates": "30600", "lr": "0.000478125", "gnorm": "0.634", "clip": "0", "loss_scale": "2", "train_wall": "1255", "gb_free": "65.5", "wall": "195555"}
[2023-11-24 02:31:31,900][train_inner][INFO] - {"epoch": 59, "update": 58.88, "loss": "3.399", "count_m_0": "66026.6", "count_u_0": "58291.1", "loss_m_0": "3.382", "loss_u_0": "1.382", "loss_features_pen": "0.017", "correct_m_0": "0.438073", "correct_u_0": "0.691694", "ppl": "10.55", "wps": "10410.9", "ups": "0.16", "wpb": "66026.6", "bsz": "197.2", "num_updates": "30800", "lr": "0.00048125", "gnorm": "0.639", "clip": "0", "loss_scale": "2", "train_wall": "1246", "gb_free": "65.3", "wall": "196823"}
[2023-11-24 02:36:37,018][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-24 02:38:12,131][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 59 @ 30862 updates
[2023-11-24 02:38:12,132][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 02:38:16,093][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 02:38:16,101][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 59 @ 30862 updates, score None) (writing took 3.97003704495728 seconds)
[2023-11-24 02:38:16,101][fairseq_cli.train][INFO] - end of epoch 59 (average epoch stats below)
[2023-11-24 02:38:16,116][train][INFO] - {"epoch": 59, "train_loss": "3.401", "train_count_m_0": "65936.5", "train_count_u_0": "58225.3", "train_loss_m_0": "3.384", "train_loss_u_0": "1.388", "train_loss_features_pen": "0.017", "train_correct_m_0": "0.437659", "train_correct_u_0": "0.690837", "train_ppl": "10.56", "train_wps": "10330.3", "train_ups": "0.16", "train_wpb": "65936.5", "train_bsz": "198.1", "train_num_updates": "30862", "train_lr": "0.000482219", "train_gnorm": "0.636", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3275", "train_gb_free": "65.2", "train_wall": "197227"}
[2023-11-24 02:38:16,117][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 02:38:16,184][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 02:38:16,187][fairseq.trainer][INFO] - begin training epoch 60
[2023-11-24 02:38:16,187][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 02:52:51,345][train_inner][INFO] - {"epoch": 60, "update": 59.263, "loss": "3.388", "count_m_0": "65909.7", "count_u_0": "58236.8", "loss_m_0": "3.371", "loss_u_0": "1.381", "loss_features_pen": "0.017", "correct_m_0": "0.439356", "correct_u_0": "0.691659", "ppl": "10.47", "wps": "10303", "ups": "0.16", "wpb": "65909.7", "bsz": "199.1", "num_updates": "31000", "lr": "0.000484375", "gnorm": "0.641", "clip": "0", "loss_scale": "2", "train_wall": "1252", "gb_free": "65.5", "wall": "198103"}
[2023-11-24 03:13:57,923][train_inner][INFO] - {"epoch": 60, "update": 59.645, "loss": "3.402", "count_m_0": "65969.9", "count_u_0": "58218.9", "loss_m_0": "3.385", "loss_u_0": "1.386", "loss_features_pen": "0.017", "correct_m_0": "0.437325", "correct_u_0": "0.690317", "ppl": "10.57", "wps": "10417.2", "ups": "0.16", "wpb": "65969.9", "bsz": "199", "num_updates": "31200", "lr": "0.0004875", "gnorm": "0.645", "clip": "0", "loss_scale": "2", "train_wall": "1244", "gb_free": "65.7", "wall": "199369"}
[2023-11-24 03:33:32,008][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-24 03:33:32,009][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 03:33:54,305][dev-other][INFO] - {"epoch": 60, "dev-other_loss": "3.825", "dev-other_count_m_0": "1718.55", "dev-other_count_u_0": "1678.05", "dev-other_loss_m_0": "3.775", "dev-other_loss_u_0": "2.101", "dev-other_loss_features_pen": "0.017", "dev-other_correct_m_0": "0.387867", "dev-other_correct_u_0": "0.592767", "dev-other_ppl": "14.18", "dev-other_wps": "20185.8", "dev-other_wpb": "1718.5", "dev-other_bsz": "10.8", "dev-other_num_updates": "31386", "dev-other_best_loss": "3.825"}
[2023-11-24 03:33:54,305][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-24 03:33:54,305][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 03:34:16,868][dev-clean][INFO] - {"epoch": 60, "dev-clean_loss": "3.139", "dev-clean_count_m_0": "1776.77", "dev-clean_count_u_0": "1698.71", "dev-clean_loss_m_0": "3.088", "dev-clean_loss_u_0": "1.57", "dev-clean_loss_features_pen": "0.017", "dev-clean_correct_m_0": "0.47064", "dev-clean_correct_u_0": "0.673213", "dev-clean_ppl": "8.81", "dev-clean_wps": "21107.4", "dev-clean_wpb": "1776.8", "dev-clean_bsz": "10", "dev-clean_num_updates": "31386"}
[2023-11-24 03:34:16,869][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 60 @ 31386 updates
[2023-11-24 03:34:16,870][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-24 03:34:25,018][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-24 03:34:30,604][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt (epoch 60 @ 31386 updates, score 3.825) (writing took 13.73505349108018 seconds)
[2023-11-24 03:34:30,605][fairseq_cli.train][INFO] - end of epoch 60 (average epoch stats below)
[2023-11-24 03:34:30,620][train][INFO] - {"epoch": 60, "train_loss": "3.398", "train_count_m_0": "65948.3", "train_count_u_0": "58210.7", "train_loss_m_0": "3.381", "train_loss_u_0": "1.385", "train_loss_features_pen": "0.017", "train_correct_m_0": "0.438037", "train_correct_u_0": "0.690694", "train_ppl": "10.54", "train_wps": "10240.6", "train_ups": "0.16", "train_wpb": "65948.3", "train_bsz": "198.1", "train_num_updates": "31386", "train_lr": "0.000490406", "train_gnorm": "0.644", "train_clip": "0", "train_loss_scale": "4", "train_train_wall": "3257", "train_gb_free": "65.4", "train_wall": "200602"}
[2023-11-24 03:34:30,620][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 03:34:30,745][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 03:34:30,747][fairseq.trainer][INFO] - begin training epoch 61
[2023-11-24 03:34:30,747][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 03:35:59,132][train_inner][INFO] - {"epoch": 61, "update": 60.027, "loss": "3.398", "count_m_0": "65909.7", "count_u_0": "58188.2", "loss_m_0": "3.381", "loss_u_0": "1.387", "loss_features_pen": "0.017", "correct_m_0": "0.438181", "correct_u_0": "0.690592", "ppl": "10.54", "wps": "9977.3", "ups": "0.15", "wpb": "65909.7", "bsz": "197.2", "num_updates": "31400", "lr": "0.000490625", "gnorm": "0.643", "clip": "0", "loss_scale": "4", "train_wall": "1240", "gb_free": "65.5", "wall": "200690"}
[2023-11-24 03:50:43,567][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-24 03:57:20,977][train_inner][INFO] - {"epoch": 61, "update": 60.41, "loss": "3.388", "count_m_0": "65922.1", "count_u_0": "58170.1", "loss_m_0": "3.371", "loss_u_0": "1.379", "loss_features_pen": "0.017", "correct_m_0": "0.439467", "correct_u_0": "0.691618", "ppl": "10.47", "wps": "10285.6", "ups": "0.16", "wpb": "65922.1", "bsz": "198.7", "num_updates": "31600", "lr": "0.00049375", "gnorm": "0.649", "clip": "0", "loss_scale": "2", "train_wall": "1259", "gb_free": "65.8", "wall": "201972"}
[2023-11-24 04:18:27,396][train_inner][INFO] - {"epoch": 61, "update": 60.792, "loss": "3.39", "count_m_0": "65914.9", "count_u_0": "58165.4", "loss_m_0": "3.373", "loss_u_0": "1.378", "loss_features_pen": "0.017", "correct_m_0": "0.438863", "correct_u_0": "0.691383", "ppl": "10.48", "wps": "10409.8", "ups": "0.16", "wpb": "65914.9", "bsz": "197.5", "num_updates": "31800", "lr": "0.000496875", "gnorm": "0.644", "clip": "0", "loss_scale": "2", "train_wall": "1244", "gb_free": "65.6", "wall": "203239"}
[2023-11-24 04:29:55,960][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 61 @ 31909 updates
[2023-11-24 04:29:55,961][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 04:30:07,278][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 04:30:07,313][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 61 @ 31909 updates, score None) (writing took 11.352634131908417 seconds)
[2023-11-24 04:30:07,313][fairseq_cli.train][INFO] - end of epoch 61 (average epoch stats below)
[2023-11-24 04:30:07,330][train][INFO] - {"epoch": 61, "train_loss": "3.389", "train_count_m_0": "65951.4", "train_count_u_0": "58202.3", "train_loss_m_0": "3.372", "train_loss_u_0": "1.377", "train_loss_features_pen": "0.017", "train_correct_m_0": "0.439129", "train_correct_u_0": "0.691769", "train_ppl": "10.48", "train_wps": "10337.4", "train_ups": "0.16", "train_wpb": "65951.4", "train_bsz": "198.1", "train_num_updates": "31909", "train_lr": "0.000498578", "train_gnorm": "0.646", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3266", "train_gb_free": "65.6", "train_wall": "203939"}
[2023-11-24 04:30:07,331][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 04:30:07,396][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 04:30:07,399][fairseq.trainer][INFO] - begin training epoch 62
[2023-11-24 04:30:07,399][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 04:39:39,913][train_inner][INFO] - {"epoch": 62, "update": 61.174, "loss": "3.392", "count_m_0": "66167.6", "count_u_0": "58299.9", "loss_m_0": "3.375", "loss_u_0": "1.368", "loss_features_pen": "0.017", "correct_m_0": "0.438725", "correct_u_0": "0.692565", "ppl": "10.5", "wps": "10399.6", "ups": "0.16", "wpb": "66167.6", "bsz": "197.9", "num_updates": "32000", "lr": "0.0005", "gnorm": "0.648", "clip": "0", "loss_scale": "2", "train_wall": "1238", "gb_free": "65.6", "wall": "204511"}
[2023-11-24 05:00:41,835][train_inner][INFO] - {"epoch": 62, "update": 61.555, "loss": "3.38", "count_m_0": "65873.6", "count_u_0": "58266.6", "loss_m_0": "3.363", "loss_u_0": "1.395", "loss_features_pen": "0.017", "correct_m_0": "0.440162", "correct_u_0": "0.690028", "ppl": "10.41", "wps": "10440.3", "ups": "0.16", "wpb": "65873.6", "bsz": "198.1", "num_updates": "32200", "lr": "0.000498529", "gnorm": "0.652", "clip": "0", "loss_scale": "4", "train_wall": "1239", "gb_free": "65.6", "wall": "205773"}
[2023-11-24 05:13:14,331][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-24 05:21:51,875][train_inner][INFO] - {"epoch": 62, "update": 61.939, "loss": "3.383", "count_m_0": "65891.6", "count_u_0": "58154", "loss_m_0": "3.366", "loss_u_0": "1.377", "loss_features_pen": "0.017", "correct_m_0": "0.439966", "correct_u_0": "0.691962", "ppl": "10.43", "wps": "10376.5", "ups": "0.16", "wpb": "65891.6", "bsz": "198.4", "num_updates": "32400", "lr": "0.000497059", "gnorm": "0.654", "clip": "0", "loss_scale": "2", "train_wall": "1247", "gb_free": "65.7", "wall": "207043"}
[2023-11-24 05:25:12,646][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 62 @ 32432 updates
[2023-11-24 05:25:12,647][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 05:25:17,087][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 05:25:17,096][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 62 @ 32432 updates, score None) (writing took 4.449633606011048 seconds)
[2023-11-24 05:25:17,096][fairseq_cli.train][INFO] - end of epoch 62 (average epoch stats below)
[2023-11-24 05:25:17,111][train][INFO] - {"epoch": 62, "train_loss": "3.383", "train_count_m_0": "65934.7", "train_count_u_0": "58220.1", "train_loss_m_0": "3.365", "train_loss_u_0": "1.382", "train_loss_features_pen": "0.017", "train_correct_m_0": "0.439983", "train_correct_u_0": "0.691313", "train_ppl": "10.43", "train_wps": "10418.8", "train_ups": "0.16", "train_wpb": "65934.7", "train_bsz": "198.1", "train_num_updates": "32432", "train_lr": "0.000496824", "train_gnorm": "0.652", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3245", "train_gb_free": "65.7", "train_wall": "207248"}
[2023-11-24 05:25:17,112][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 05:25:17,183][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 05:25:17,186][fairseq.trainer][INFO] - begin training epoch 63
[2023-11-24 05:25:17,186][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 05:42:53,764][train_inner][INFO] - {"epoch": 63, "update": 62.321, "loss": "3.377", "count_m_0": "65893.2", "count_u_0": "58207", "loss_m_0": "3.36", "loss_u_0": "1.378", "loss_features_pen": "0.017", "correct_m_0": "0.440892", "correct_u_0": "0.692435", "ppl": "10.39", "wps": "10443.7", "ups": "0.16", "wpb": "65893.2", "bsz": "198.6", "num_updates": "32600", "lr": "0.000495588", "gnorm": "0.656", "clip": "0", "loss_scale": "2", "train_wall": "1234", "gb_free": "65.4", "wall": "208305"}
[2023-11-24 06:03:55,560][train_inner][INFO] - {"epoch": 63, "update": 62.702, "loss": "3.376", "count_m_0": "65880.8", "count_u_0": "58112", "loss_m_0": "3.359", "loss_u_0": "1.368", "loss_features_pen": "0.017", "correct_m_0": "0.4411", "correct_u_0": "0.693804", "ppl": "10.38", "wps": "10442.5", "ups": "0.16", "wpb": "65880.8", "bsz": "198.1", "num_updates": "32800", "lr": "0.000494118", "gnorm": "0.654", "clip": "0", "loss_scale": "2", "train_wall": "1239", "gb_free": "65.7", "wall": "209567"}
[2023-11-24 06:20:18,487][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 63 @ 32956 updates
[2023-11-24 06:20:18,488][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 06:20:22,543][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 06:20:22,551][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 63 @ 32956 updates, score None) (writing took 4.064222927205265 seconds)
[2023-11-24 06:20:22,551][fairseq_cli.train][INFO] - end of epoch 63 (average epoch stats below)
[2023-11-24 06:20:22,567][train][INFO] - {"epoch": 63, "train_loss": "3.376", "train_count_m_0": "65951", "train_count_u_0": "58208.2", "train_loss_m_0": "3.359", "train_loss_u_0": "1.371", "train_loss_features_pen": "0.017", "train_correct_m_0": "0.44102", "train_correct_u_0": "0.693392", "train_ppl": "10.38", "train_wps": "10455", "train_ups": "0.16", "train_wpb": "65951", "train_bsz": "198.1", "train_num_updates": "32956", "train_lr": "0.000492971", "train_gnorm": "0.657", "train_clip": "0", "train_loss_scale": "4", "train_train_wall": "3242", "train_gb_free": "65.7", "train_wall": "210554"}
[2023-11-24 06:20:22,567][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 06:20:22,633][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 06:20:22,636][fairseq.trainer][INFO] - begin training epoch 64
[2023-11-24 06:20:22,636][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 06:24:59,585][train_inner][INFO] - {"epoch": 64, "update": 63.084, "loss": "3.371", "count_m_0": "66086.8", "count_u_0": "58340.9", "loss_m_0": "3.354", "loss_u_0": "1.368", "loss_features_pen": "0.017", "correct_m_0": "0.441578", "correct_u_0": "0.693849", "ppl": "10.34", "wps": "10456.7", "ups": "0.16", "wpb": "66086.8", "bsz": "197.6", "num_updates": "33000", "lr": "0.000492647", "gnorm": "0.658", "clip": "0", "loss_scale": "4", "train_wall": "1237", "gb_free": "65.6", "wall": "210831"}
[2023-11-24 06:46:00,969][train_inner][INFO] - {"epoch": 64, "update": 63.466, "loss": "3.355", "count_m_0": "65890.6", "count_u_0": "58254.8", "loss_m_0": "3.338", "loss_u_0": "1.366", "loss_features_pen": "0.016", "correct_m_0": "0.443615", "correct_u_0": "0.694229", "ppl": "10.23", "wps": "10447.5", "ups": "0.16", "wpb": "65890.6", "bsz": "198", "num_updates": "33200", "lr": "0.000491176", "gnorm": "0.659", "clip": "0", "loss_scale": "4", "train_wall": "1238", "gb_free": "65.7", "wall": "212092"}
[2023-11-24 06:58:38,299][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-24 07:07:14,580][train_inner][INFO] - {"epoch": 64, "update": 63.849, "loss": "3.358", "count_m_0": "65852.7", "count_u_0": "58164.1", "loss_m_0": "3.341", "loss_u_0": "1.378", "loss_features_pen": "0.016", "correct_m_0": "0.443263", "correct_u_0": "0.693001", "ppl": "10.25", "wps": "10341.2", "ups": "0.16", "wpb": "65852.7", "bsz": "198.1", "num_updates": "33400", "lr": "0.000489706", "gnorm": "0.661", "clip": "0", "loss_scale": "2", "train_wall": "1250", "gb_free": "65.4", "wall": "213366"}
[2023-11-24 07:15:37,280][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 64 @ 33479 updates
[2023-11-24 07:15:37,281][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 07:15:42,858][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 07:15:42,867][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 64 @ 33479 updates, score None) (writing took 5.586741785053164 seconds)
[2023-11-24 07:15:42,867][fairseq_cli.train][INFO] - end of epoch 64 (average epoch stats below)
[2023-11-24 07:15:42,884][train][INFO] - {"epoch": 64, "train_loss": "3.356", "train_count_m_0": "65911.6", "train_count_u_0": "58243.8", "train_loss_m_0": "3.339", "train_loss_u_0": "1.373", "train_loss_features_pen": "0.016", "train_correct_m_0": "0.443522", "train_correct_u_0": "0.693597", "train_ppl": "10.24", "train_wps": "10382.1", "train_ups": "0.16", "train_wpb": "65911.6", "train_bsz": "198.1", "train_num_updates": "33479", "train_lr": "0.000489125", "train_gnorm": "0.659", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3254", "train_gb_free": "65.5", "train_wall": "213874"}
[2023-11-24 07:15:42,885][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 07:15:42,953][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 07:15:42,955][fairseq.trainer][INFO] - begin training epoch 65
[2023-11-24 07:15:42,956][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 07:28:29,918][train_inner][INFO] - {"epoch": 65, "update": 64.231, "loss": "3.343", "count_m_0": "65965.4", "count_u_0": "58300.8", "loss_m_0": "3.327", "loss_u_0": "1.371", "loss_features_pen": "0.016", "correct_m_0": "0.444966", "correct_u_0": "0.694523", "ppl": "10.15", "wps": "10344.9", "ups": "0.16", "wpb": "65965.4", "bsz": "197.7", "num_updates": "33600", "lr": "0.000488235", "gnorm": "0.659", "clip": "0", "loss_scale": "2", "train_wall": "1246", "gb_free": "65.3", "wall": "214641"}
[2023-11-24 07:49:46,416][train_inner][INFO] - {"epoch": 65, "update": 64.613, "loss": "3.351", "count_m_0": "65943.9", "count_u_0": "58190.6", "loss_m_0": "3.334", "loss_u_0": "1.361", "loss_features_pen": "0.017", "correct_m_0": "0.444134", "correct_u_0": "0.695514", "ppl": "10.2", "wps": "10332.2", "ups": "0.16", "wpb": "65943.9", "bsz": "198", "num_updates": "33800", "lr": "0.000486765", "gnorm": "0.663", "clip": "0", "loss_scale": "2", "train_wall": "1254", "gb_free": "65.4", "wall": "215918"}
[2023-11-24 08:05:36,359][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-24 08:11:15,250][train_inner][INFO] - {"epoch": 65, "update": 64.996, "loss": "3.343", "count_m_0": "65906.4", "count_u_0": "58263.2", "loss_m_0": "3.327", "loss_u_0": "1.366", "loss_features_pen": "0.016", "correct_m_0": "0.445086", "correct_u_0": "0.695169", "ppl": "10.15", "wps": "10227.4", "ups": "0.16", "wpb": "65906.4", "bsz": "198.5", "num_updates": "34000", "lr": "0.000485294", "gnorm": "0.665", "clip": "0", "loss_scale": "2", "train_wall": "1265", "gb_free": "65.2", "wall": "217207"}
[2023-11-24 08:11:27,878][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-24 08:11:27,879][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 08:11:50,232][dev-other][INFO] - {"epoch": 65, "dev-other_loss": "3.774", "dev-other_count_m_0": "1719.59", "dev-other_count_u_0": "1677.03", "dev-other_loss_m_0": "3.732", "dev-other_loss_u_0": "2.047", "dev-other_loss_features_pen": "0.016", "dev-other_correct_m_0": "0.392021", "dev-other_correct_u_0": "0.603091", "dev-other_ppl": "13.68", "dev-other_wps": "20150.1", "dev-other_wpb": "1719.6", "dev-other_bsz": "10.8", "dev-other_num_updates": "34002", "dev-other_best_loss": "3.774"}
[2023-11-24 08:11:50,232][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-24 08:11:50,233][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 08:12:12,851][dev-clean][INFO] - {"epoch": 65, "dev-clean_loss": "3.077", "dev-clean_count_m_0": "1773.85", "dev-clean_count_u_0": "1701.57", "dev-clean_loss_m_0": "3.02", "dev-clean_loss_u_0": "1.556", "dev-clean_loss_features_pen": "0.016", "dev-clean_correct_m_0": "0.479379", "dev-clean_correct_u_0": "0.679897", "dev-clean_ppl": "8.44", "dev-clean_wps": "21005.9", "dev-clean_wpb": "1773.8", "dev-clean_bsz": "10", "dev-clean_num_updates": "34002"}
[2023-11-24 08:12:12,852][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 65 @ 34002 updates
[2023-11-24 08:12:12,853][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-24 08:12:17,391][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-24 08:12:23,927][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt (epoch 65 @ 34002 updates, score 3.774) (writing took 11.074644576059654 seconds)
[2023-11-24 08:12:23,927][fairseq_cli.train][INFO] - end of epoch 65 (average epoch stats below)
[2023-11-24 08:12:23,942][train][INFO] - {"epoch": 65, "train_loss": "3.345", "train_count_m_0": "65928", "train_count_u_0": "58233.7", "train_loss_m_0": "3.328", "train_loss_u_0": "1.363", "train_loss_features_pen": "0.016", "train_correct_m_0": "0.444812", "train_correct_u_0": "0.69541", "train_ppl": "10.16", "train_wps": "10138.2", "train_ups": "0.15", "train_wpb": "65928", "train_bsz": "198.1", "train_num_updates": "34002", "train_lr": "0.000485279", "train_gnorm": "0.664", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3284", "train_gb_free": "65.5", "train_wall": "217275"}
[2023-11-24 08:12:23,943][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 08:12:24,011][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 08:12:24,012][fairseq.trainer][INFO] - begin training epoch 66
[2023-11-24 08:12:24,013][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 08:33:27,065][train_inner][INFO] - {"epoch": 66, "update": 65.378, "loss": "3.331", "count_m_0": "66058.8", "count_u_0": "58294.5", "loss_m_0": "3.314", "loss_u_0": "1.353", "loss_features_pen": "0.016", "correct_m_0": "0.446353", "correct_u_0": "0.697208", "ppl": "10.06", "wps": "9920.3", "ups": "0.15", "wpb": "66058.8", "bsz": "198.6", "num_updates": "34200", "lr": "0.000483824", "gnorm": "0.663", "clip": "0", "loss_scale": "2", "train_wall": "1253", "gb_free": "65.5", "wall": "218538"}
[2023-11-24 08:54:44,669][train_inner][INFO] - {"epoch": 66, "update": 65.76, "loss": "3.326", "count_m_0": "65835.5", "count_u_0": "58167.7", "loss_m_0": "3.31", "loss_u_0": "1.349", "loss_features_pen": "0.016", "correct_m_0": "0.447023", "correct_u_0": "0.697524", "ppl": "10.03", "wps": "10306.2", "ups": "0.16", "wpb": "65835.5", "bsz": "197.9", "num_updates": "34400", "lr": "0.000482353", "gnorm": "0.666", "clip": "0", "loss_scale": "2", "train_wall": "1254", "gb_free": "65.4", "wall": "219816"}
[2023-11-24 09:05:20,643][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-24 09:08:06,475][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 66 @ 34525 updates
[2023-11-24 09:08:06,476][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 09:08:10,651][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 09:08:10,660][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 66 @ 34525 updates, score None) (writing took 4.18575897696428 seconds)
[2023-11-24 09:08:10,661][fairseq_cli.train][INFO] - end of epoch 66 (average epoch stats below)
[2023-11-24 09:08:10,676][train][INFO] - {"epoch": 66, "train_loss": "3.329", "train_count_m_0": "65926.6", "train_count_u_0": "58234.8", "train_loss_m_0": "3.313", "train_loss_u_0": "1.348", "train_loss_features_pen": "0.016", "train_correct_m_0": "0.446601", "train_correct_u_0": "0.697849", "train_ppl": "10.05", "train_wps": "10302.5", "train_ups": "0.16", "train_wpb": "65926.6", "train_bsz": "198.1", "train_num_updates": "34525", "train_lr": "0.000481434", "train_gnorm": "0.664", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3282", "train_gb_free": "65.6", "train_wall": "220622"}
[2023-11-24 09:08:10,677][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 09:08:10,749][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 09:08:10,751][fairseq.trainer][INFO] - begin training epoch 67
[2023-11-24 09:08:10,752][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 09:16:06,983][train_inner][INFO] - {"epoch": 67, "update": 66.143, "loss": "3.326", "count_m_0": "65918.3", "count_u_0": "58249.3", "loss_m_0": "3.31", "loss_u_0": "1.339", "loss_features_pen": "0.016", "correct_m_0": "0.447038", "correct_u_0": "0.698992", "ppl": "10.03", "wps": "10281.3", "ups": "0.16", "wpb": "65918.3", "bsz": "197.5", "num_updates": "34600", "lr": "0.000480882", "gnorm": "0.666", "clip": "0", "loss_scale": "2", "train_wall": "1255", "gb_free": "65.4", "wall": "221098"}
[2023-11-24 09:37:24,554][train_inner][INFO] - {"epoch": 67, "update": 66.525, "loss": "3.311", "count_m_0": "65935.1", "count_u_0": "58326.9", "loss_m_0": "3.295", "loss_u_0": "1.344", "loss_features_pen": "0.016", "correct_m_0": "0.449226", "correct_u_0": "0.69901", "ppl": "9.92", "wps": "10322.1", "ups": "0.16", "wpb": "65935.1", "bsz": "199", "num_updates": "34800", "lr": "0.000479412", "gnorm": "0.665", "clip": "0", "loss_scale": "2", "train_wall": "1255", "gb_free": "65.4", "wall": "222376"}
[2023-11-24 09:58:41,763][train_inner][INFO] - {"epoch": 67, "update": 66.906, "loss": "3.322", "count_m_0": "65922.3", "count_u_0": "58175.8", "loss_m_0": "3.306", "loss_u_0": "1.345", "loss_features_pen": "0.016", "correct_m_0": "0.4475", "correct_u_0": "0.698669", "ppl": "10", "wps": "10323", "ups": "0.16", "wpb": "65922.3", "bsz": "197.7", "num_updates": "35000", "lr": "0.000477941", "gnorm": "0.669", "clip": "0", "loss_scale": "2", "train_wall": "1254", "gb_free": "65.8", "wall": "223653"}
[2023-11-24 10:03:54,558][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 67 @ 35049 updates
[2023-11-24 10:03:54,559][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 10:03:58,762][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 10:03:58,772][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 67 @ 35049 updates, score None) (writing took 4.213749292073771 seconds)
[2023-11-24 10:03:58,772][fairseq_cli.train][INFO] - end of epoch 67 (average epoch stats below)
[2023-11-24 10:03:58,788][train][INFO] - {"epoch": 67, "train_loss": "3.317", "train_count_m_0": "65930.3", "train_count_u_0": "58228.7", "train_loss_m_0": "3.301", "train_loss_u_0": "1.345", "train_loss_features_pen": "0.016", "train_correct_m_0": "0.448239", "train_correct_u_0": "0.698638", "train_ppl": "9.97", "train_wps": "10318.6", "train_ups": "0.16", "train_wpb": "65930.3", "train_bsz": "198.1", "train_num_updates": "35049", "train_lr": "0.000477581", "train_gnorm": "0.667", "train_clip": "0", "train_loss_scale": "4", "train_train_wall": "3284", "train_gb_free": "65.6", "train_wall": "223970"}
[2023-11-24 10:03:58,789][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 10:03:58,859][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 10:03:58,862][fairseq.trainer][INFO] - begin training epoch 68
[2023-11-24 10:03:58,862][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 10:20:00,455][train_inner][INFO] - {"epoch": 68, "update": 67.288, "loss": "3.303", "count_m_0": "65821.9", "count_u_0": "58124.4", "loss_m_0": "3.286", "loss_u_0": "1.349", "loss_features_pen": "0.016", "correct_m_0": "0.449864", "correct_u_0": "0.698354", "ppl": "9.87", "wps": "10295.3", "ups": "0.16", "wpb": "65821.9", "bsz": "199.4", "num_updates": "35200", "lr": "0.000476471", "gnorm": "0.666", "clip": "0", "loss_scale": "4", "train_wall": "1251", "gb_free": "65.5", "wall": "224932"}
[2023-11-24 10:41:16,614][train_inner][INFO] - {"epoch": 68, "update": 67.67, "loss": "3.309", "count_m_0": "65914.5", "count_u_0": "58208.6", "loss_m_0": "3.293", "loss_u_0": "1.339", "loss_features_pen": "0.016", "correct_m_0": "0.449439", "correct_u_0": "0.700243", "ppl": "9.91", "wps": "10330.3", "ups": "0.16", "wpb": "65914.5", "bsz": "197.2", "num_updates": "35400", "lr": "0.000475", "gnorm": "0.669", "clip": "0", "loss_scale": "4", "train_wall": "1253", "gb_free": "65.3", "wall": "226208"}
[2023-11-24 10:54:33,810][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2023-11-24 10:59:39,301][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 68 @ 35572 updates
[2023-11-24 10:59:39,302][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 10:59:43,198][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 10:59:43,206][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 68 @ 35572 updates, score None) (writing took 3.905096797971055 seconds)
[2023-11-24 10:59:43,206][fairseq_cli.train][INFO] - end of epoch 68 (average epoch stats below)
[2023-11-24 10:59:43,221][train][INFO] - {"epoch": 68, "train_loss": "3.302", "train_count_m_0": "65935.9", "train_count_u_0": "58218.2", "train_loss_m_0": "3.286", "train_loss_u_0": "1.34", "train_loss_features_pen": "0.016", "train_correct_m_0": "0.450187", "train_correct_u_0": "0.700009", "train_ppl": "9.86", "train_wps": "10311.1", "train_ups": "0.16", "train_wpb": "65935.9", "train_bsz": "198.1", "train_num_updates": "35572", "train_lr": "0.000473735", "train_gnorm": "0.667", "train_clip": "0", "train_loss_scale": "4", "train_train_wall": "3280", "train_gb_free": "65.5", "train_wall": "227314"}
[2023-11-24 10:59:43,222][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 10:59:43,448][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 10:59:43,451][fairseq.trainer][INFO] - begin training epoch 69
[2023-11-24 10:59:43,451][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 11:02:41,412][train_inner][INFO] - {"epoch": 69, "update": 68.053, "loss": "3.298", "count_m_0": "65987.9", "count_u_0": "58241.9", "loss_m_0": "3.282", "loss_u_0": "1.335", "loss_features_pen": "0.016", "correct_m_0": "0.450762", "correct_u_0": "0.700778", "ppl": "9.84", "wps": "10272.3", "ups": "0.16", "wpb": "65987.9", "bsz": "197.2", "num_updates": "35600", "lr": "0.000473529", "gnorm": "0.669", "clip": "0", "loss_scale": "4", "train_wall": "1257", "gb_free": "65.7", "wall": "227493"}
[2023-11-24 11:23:50,896][train_inner][INFO] - {"epoch": 69, "update": 68.435, "loss": "3.295", "count_m_0": "65917.4", "count_u_0": "58120.4", "loss_m_0": "3.279", "loss_u_0": "1.327", "loss_features_pen": "0.015", "correct_m_0": "0.45116", "correct_u_0": "0.702016", "ppl": "9.81", "wps": "10385", "ups": "0.16", "wpb": "65917.4", "bsz": "198.1", "num_updates": "35800", "lr": "0.000472059", "gnorm": "0.677", "clip": "0", "loss_scale": "4", "train_wall": "1246", "gb_free": "65.4", "wall": "228762"}
[2023-11-24 11:30:42,570][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-24 11:45:04,191][train_inner][INFO] - {"epoch": 69, "update": 68.819, "loss": "3.292", "count_m_0": "65986.4", "count_u_0": "58271.8", "loss_m_0": "3.276", "loss_u_0": "1.345", "loss_features_pen": "0.015", "correct_m_0": "0.451628", "correct_u_0": "0.69982", "ppl": "9.79", "wps": "10364.8", "ups": "0.16", "wpb": "65986.4", "bsz": "197.9", "num_updates": "36000", "lr": "0.000470588", "gnorm": "0.676", "clip": "0", "loss_scale": "2", "train_wall": "1250", "gb_free": "65.6", "wall": "230035"}
[2023-11-24 11:55:07,082][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 69 @ 36095 updates
[2023-11-24 11:55:07,083][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 11:55:11,114][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 11:55:11,122][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 69 @ 36095 updates, score None) (writing took 4.040498560993001 seconds)
[2023-11-24 11:55:11,123][fairseq_cli.train][INFO] - end of epoch 69 (average epoch stats below)
[2023-11-24 11:55:11,137][train][INFO] - {"epoch": 69, "train_loss": "3.291", "train_count_m_0": "65948.5", "train_count_u_0": "58208.7", "train_loss_m_0": "3.276", "train_loss_u_0": "1.339", "train_loss_features_pen": "0.015", "train_correct_m_0": "0.451645", "train_correct_u_0": "0.700479", "train_ppl": "9.79", "train_wps": "10364.2", "train_ups": "0.16", "train_wpb": "65948.5", "train_bsz": "198.1", "train_num_updates": "36095", "train_lr": "0.00046989", "train_gnorm": "0.675", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3262", "train_gb_free": "66", "train_wall": "230642"}
[2023-11-24 11:55:11,138][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 11:55:11,209][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 11:55:11,212][fairseq.trainer][INFO] - begin training epoch 70
[2023-11-24 11:55:11,212][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 12:06:16,965][train_inner][INFO] - {"epoch": 70, "update": 69.2, "loss": "3.286", "count_m_0": "65926.7", "count_u_0": "58188.1", "loss_m_0": "3.27", "loss_u_0": "1.35", "loss_features_pen": "0.015", "correct_m_0": "0.452183", "correct_u_0": "0.69952", "ppl": "9.75", "wps": "10359.7", "ups": "0.16", "wpb": "65926.7", "bsz": "198.9", "num_updates": "36200", "lr": "0.000469118", "gnorm": "0.669", "clip": "0", "loss_scale": "2", "train_wall": "1245", "gb_free": "65.7", "wall": "231308"}
[2023-11-24 12:27:56,273][train_inner][INFO] - {"epoch": 70, "update": 69.582, "loss": "3.267", "count_m_0": "65926.9", "count_u_0": "58311.2", "loss_m_0": "3.252", "loss_u_0": "1.342", "loss_features_pen": "0.015", "correct_m_0": "0.454602", "correct_u_0": "0.701359", "ppl": "9.63", "wps": "10148.1", "ups": "0.15", "wpb": "65926.9", "bsz": "198.5", "num_updates": "36400", "lr": "0.000467647", "gnorm": "0.669", "clip": "0", "loss_scale": "4", "train_wall": "1276", "gb_free": "65.6", "wall": "232608"}
[2023-11-24 12:49:44,575][train_inner][INFO] - {"epoch": 70, "update": 69.964, "loss": "3.278", "count_m_0": "66051.2", "count_u_0": "58235.2", "loss_m_0": "3.263", "loss_u_0": "1.34", "loss_features_pen": "0.015", "correct_m_0": "0.453148", "correct_u_0": "0.700897", "ppl": "9.7", "wps": "10097.4", "ups": "0.15", "wpb": "66051.2", "bsz": "196.8", "num_updates": "36600", "lr": "0.000466176", "gnorm": "0.678", "clip": "0", "loss_scale": "4", "train_wall": "1285", "gb_free": "65.8", "wall": "233916"}
[2023-11-24 12:51:45,931][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-24 12:51:45,932][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 12:52:08,626][dev-other][INFO] - {"epoch": 70, "dev-other_loss": "3.728", "dev-other_count_m_0": "1723.87", "dev-other_count_u_0": "1672.91", "dev-other_loss_m_0": "3.691", "dev-other_loss_u_0": "2.029", "dev-other_loss_features_pen": "0.015", "dev-other_correct_m_0": "0.399411", "dev-other_correct_u_0": "0.605083", "dev-other_ppl": "13.25", "dev-other_wps": "19897.8", "dev-other_wpb": "1723.9", "dev-other_bsz": "10.8", "dev-other_num_updates": "36619", "dev-other_best_loss": "3.728"}
[2023-11-24 12:52:08,626][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-24 12:52:08,627][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 12:52:31,535][dev-clean][INFO] - {"epoch": 70, "dev-clean_loss": "3.049", "dev-clean_count_m_0": "1776.53", "dev-clean_count_u_0": "1699.3", "dev-clean_loss_m_0": "2.989", "dev-clean_loss_u_0": "1.577", "dev-clean_loss_features_pen": "0.015", "dev-clean_correct_m_0": "0.483858", "dev-clean_correct_u_0": "0.678422", "dev-clean_ppl": "8.28", "dev-clean_wps": "20781.3", "dev-clean_wpb": "1776.5", "dev-clean_bsz": "10", "dev-clean_num_updates": "36619"}
[2023-11-24 12:52:31,536][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 70 @ 36619 updates
[2023-11-24 12:52:31,537][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-24 12:52:35,573][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-24 12:52:41,916][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt (epoch 70 @ 36619 updates, score 3.728) (writing took 10.379905411973596 seconds)
[2023-11-24 12:52:41,918][fairseq_cli.train][INFO] - end of epoch 70 (average epoch stats below)
[2023-11-24 12:52:42,049][train][INFO] - {"epoch": 70, "train_loss": "3.276", "train_count_m_0": "65940.5", "train_count_u_0": "58218.5", "train_loss_m_0": "3.261", "train_loss_u_0": "1.343", "train_loss_features_pen": "0.015", "train_correct_m_0": "0.45341", "train_correct_u_0": "0.700741", "train_ppl": "9.69", "train_wps": "10013", "train_ups": "0.15", "train_wpb": "65940.5", "train_bsz": "198.1", "train_num_updates": "36619", "train_lr": "0.000466037", "train_gnorm": "0.674", "train_clip": "0", "train_loss_scale": "4", "train_train_wall": "3333", "train_gb_free": "65.5", "train_wall": "234093"}
[2023-11-24 12:52:42,050][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 12:52:42,160][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 12:52:42,162][fairseq.trainer][INFO] - begin training epoch 71
[2023-11-24 12:52:42,162][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 13:12:13,022][train_inner][INFO] - {"epoch": 71, "update": 70.345, "loss": "3.274", "count_m_0": "65903.5", "count_u_0": "58151.7", "loss_m_0": "3.259", "loss_u_0": "1.336", "loss_features_pen": "0.015", "correct_m_0": "0.453779", "correct_u_0": "0.701821", "ppl": "9.67", "wps": "9774.8", "ups": "0.15", "wpb": "65903.5", "bsz": "198.3", "num_updates": "36800", "lr": "0.000464706", "gnorm": "0.679", "clip": "0", "loss_scale": "4", "train_wall": "1268", "gb_free": "65.3", "wall": "235264"}
[2023-11-24 13:22:34,766][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2023-11-24 13:33:54,568][train_inner][INFO] - {"epoch": 71, "update": 70.729, "loss": "3.26", "count_m_0": "65993.6", "count_u_0": "58317.3", "loss_m_0": "3.245", "loss_u_0": "1.314", "loss_features_pen": "0.015", "correct_m_0": "0.455365", "correct_u_0": "0.705498", "ppl": "9.58", "wps": "10141", "ups": "0.15", "wpb": "65993.6", "bsz": "198.2", "num_updates": "37000", "lr": "0.000463235", "gnorm": "0.673", "clip": "0", "loss_scale": "4", "train_wall": "1278", "gb_free": "65.7", "wall": "236566"}
[2023-11-24 13:49:16,950][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 71 @ 37142 updates
[2023-11-24 13:49:16,951][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 13:49:26,145][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 13:49:26,163][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 71 @ 37142 updates, score None) (writing took 9.213246914092451 seconds)
[2023-11-24 13:49:26,163][fairseq_cli.train][INFO] - end of epoch 71 (average epoch stats below)
[2023-11-24 13:49:26,179][train][INFO] - {"epoch": 71, "train_loss": "3.265", "train_count_m_0": "65930.3", "train_count_u_0": "58228.9", "train_loss_m_0": "3.25", "train_loss_u_0": "1.322", "train_loss_features_pen": "0.015", "train_correct_m_0": "0.454763", "train_correct_u_0": "0.704166", "train_ppl": "9.62", "train_wps": "10129.4", "train_ups": "0.15", "train_wpb": "65930.3", "train_bsz": "198.1", "train_num_updates": "37142", "train_lr": "0.000462191", "train_gnorm": "0.676", "train_clip": "0", "train_loss_scale": "4", "train_train_wall": "3331", "train_gb_free": "65.9", "train_wall": "237497"}
[2023-11-24 13:49:26,180][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 13:49:26,256][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 13:49:26,259][fairseq.trainer][INFO] - begin training epoch 72
[2023-11-24 13:49:26,259][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 13:55:43,149][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-24 13:55:49,852][train_inner][INFO] - {"epoch": 72, "update": 71.113, "loss": "3.261", "count_m_0": "65875.7", "count_u_0": "58169.2", "loss_m_0": "3.246", "loss_u_0": "1.319", "loss_features_pen": "0.015", "correct_m_0": "0.455248", "correct_u_0": "0.704878", "ppl": "9.59", "wps": "10017.1", "ups": "0.15", "wpb": "65875.7", "bsz": "197.1", "num_updates": "37200", "lr": "0.000461765", "gnorm": "0.677", "clip": "0", "loss_scale": "2", "train_wall": "1281", "gb_free": "65.3", "wall": "237881"}
[2023-11-24 14:17:33,973][train_inner][INFO] - {"epoch": 72, "update": 71.494, "loss": "3.255", "count_m_0": "65951.6", "count_u_0": "58262.4", "loss_m_0": "3.239", "loss_u_0": "1.313", "loss_features_pen": "0.015", "correct_m_0": "0.456066", "correct_u_0": "0.705042", "ppl": "9.54", "wps": "10114.5", "ups": "0.15", "wpb": "65951.6", "bsz": "198", "num_updates": "37400", "lr": "0.000460294", "gnorm": "0.681", "clip": "0", "loss_scale": "2", "train_wall": "1277", "gb_free": "65.2", "wall": "239185"}
[2023-11-24 14:39:21,934][train_inner][INFO] - {"epoch": 72, "update": 71.876, "loss": "3.258", "count_m_0": "65903.8", "count_u_0": "58219.4", "loss_m_0": "3.242", "loss_u_0": "1.325", "loss_features_pen": "0.015", "correct_m_0": "0.45572", "correct_u_0": "0.704118", "ppl": "9.56", "wps": "10077.5", "ups": "0.15", "wpb": "65903.8", "bsz": "198.6", "num_updates": "37600", "lr": "0.000458824", "gnorm": "0.676", "clip": "0", "loss_scale": "2", "train_wall": "1278", "gb_free": "65.4", "wall": "240493"}
[2023-11-24 14:46:28,034][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 72 @ 37665 updates
[2023-11-24 14:46:28,035][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 14:46:37,607][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 14:46:37,620][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 72 @ 37665 updates, score None) (writing took 9.586040324065834 seconds)
[2023-11-24 14:46:37,621][fairseq_cli.train][INFO] - end of epoch 72 (average epoch stats below)
[2023-11-24 14:46:37,636][train][INFO] - {"epoch": 72, "train_loss": "3.255", "train_count_m_0": "65935.3", "train_count_u_0": "58224.5", "train_loss_m_0": "3.24", "train_loss_u_0": "1.321", "train_loss_features_pen": "0.015", "train_correct_m_0": "0.455979", "train_correct_u_0": "0.704467", "train_ppl": "9.55", "train_wps": "10049.5", "train_ups": "0.15", "train_wpb": "65935.3", "train_bsz": "198.1", "train_num_updates": "37665", "train_lr": "0.000458346", "train_gnorm": "0.679", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3347", "train_gb_free": "65.3", "train_wall": "240929"}
[2023-11-24 14:46:37,637][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 14:46:37,704][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 14:46:37,707][fairseq.trainer][INFO] - begin training epoch 73
[2023-11-24 14:46:37,707][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 15:02:12,590][train_inner][INFO] - {"epoch": 73, "update": 72.258, "loss": "3.254", "count_m_0": "65990.2", "count_u_0": "58158", "loss_m_0": "3.239", "loss_u_0": "1.33", "loss_features_pen": "0.015", "correct_m_0": "0.455915", "correct_u_0": "0.703133", "ppl": "9.54", "wps": "9629.1", "ups": "0.15", "wpb": "65990.2", "bsz": "197.8", "num_updates": "37800", "lr": "0.000457353", "gnorm": "0.68", "clip": "0", "loss_scale": "4", "train_wall": "1332", "gb_free": "65.6", "wall": "241864"}
[2023-11-24 15:25:22,545][train_inner][INFO] - {"epoch": 73, "update": 72.639, "loss": "3.241", "count_m_0": "65864.8", "count_u_0": "58210.8", "loss_m_0": "3.226", "loss_u_0": "1.317", "loss_features_pen": "0.015", "correct_m_0": "0.457812", "correct_u_0": "0.705185", "ppl": "9.46", "wps": "9477.4", "ups": "0.14", "wpb": "65864.8", "bsz": "198.6", "num_updates": "38000", "lr": "0.000455882", "gnorm": "0.678", "clip": "0", "loss_scale": "4", "train_wall": "1362", "gb_free": "65.8", "wall": "243254"}
[2023-11-24 15:46:20,443][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 73 @ 38189 updates
[2023-11-24 15:46:20,444][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 15:46:25,271][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 15:46:25,288][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 73 @ 38189 updates, score None) (writing took 4.844430191908032 seconds)
[2023-11-24 15:46:25,288][fairseq_cli.train][INFO] - end of epoch 73 (average epoch stats below)
[2023-11-24 15:46:25,302][train][INFO] - {"epoch": 73, "train_loss": "3.244", "train_count_m_0": "65942", "train_count_u_0": "58217.1", "train_loss_m_0": "3.229", "train_loss_u_0": "1.319", "train_loss_features_pen": "0.015", "train_correct_m_0": "0.457431", "train_correct_u_0": "0.705044", "train_ppl": "9.47", "train_wps": "9631.3", "train_ups": "0.15", "train_wpb": "65942", "train_bsz": "198.1", "train_num_updates": "38189", "train_lr": "0.000454493", "train_gnorm": "0.678", "train_clip": "0", "train_loss_scale": "4", "train_train_wall": "3511", "train_gb_free": "65.4", "train_wall": "244517"}
[2023-11-24 15:46:25,303][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 15:46:25,371][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 15:46:25,374][fairseq.trainer][INFO] - begin training epoch 74
[2023-11-24 15:46:25,374][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 15:47:36,995][train_inner][INFO] - {"epoch": 74, "update": 73.021, "loss": "3.238", "count_m_0": "65962.9", "count_u_0": "58239.9", "loss_m_0": "3.223", "loss_u_0": "1.316", "loss_features_pen": "0.015", "correct_m_0": "0.45821", "correct_u_0": "0.705844", "ppl": "9.44", "wps": "9886.3", "ups": "0.15", "wpb": "65962.9", "bsz": "198.2", "num_updates": "38200", "lr": "0.000454412", "gnorm": "0.678", "clip": "0", "loss_scale": "4", "train_wall": "1302", "gb_free": "65.6", "wall": "244588"}
[2023-11-24 15:53:24,461][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2023-11-24 16:09:18,275][train_inner][INFO] - {"epoch": 74, "update": 73.405, "loss": "3.227", "count_m_0": "66011.9", "count_u_0": "58219.9", "loss_m_0": "3.212", "loss_u_0": "1.32", "loss_features_pen": "0.015", "correct_m_0": "0.459648", "correct_u_0": "0.704921", "ppl": "9.36", "wps": "10145.8", "ups": "0.15", "wpb": "66011.9", "bsz": "198.5", "num_updates": "38400", "lr": "0.000452941", "gnorm": "0.679", "clip": "0", "loss_scale": "4", "train_wall": "1277", "gb_free": "65.5", "wall": "245890"}
[2023-11-24 16:30:59,137][train_inner][INFO] - {"epoch": 74, "update": 73.786, "loss": "3.227", "count_m_0": "66084", "count_u_0": "58337.4", "loss_m_0": "3.213", "loss_u_0": "1.319", "loss_features_pen": "0.014", "correct_m_0": "0.459471", "correct_u_0": "0.705341", "ppl": "9.37", "wps": "10160.2", "ups": "0.15", "wpb": "66084", "bsz": "197.9", "num_updates": "38600", "lr": "0.000451471", "gnorm": "0.679", "clip": "0", "loss_scale": "4", "train_wall": "1277", "gb_free": "65.3", "wall": "247190"}
[2023-11-24 16:35:56,697][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-24 16:43:04,960][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 74 @ 38711 updates
[2023-11-24 16:43:04,961][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 16:43:09,114][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 16:43:09,131][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 74 @ 38711 updates, score None) (writing took 4.170957942027599 seconds)
[2023-11-24 16:43:09,131][fairseq_cli.train][INFO] - end of epoch 74 (average epoch stats below)
[2023-11-24 16:43:09,146][train][INFO] - {"epoch": 74, "train_loss": "3.228", "train_count_m_0": "65966.2", "train_count_u_0": "58193.9", "train_loss_m_0": "3.213", "train_loss_u_0": "1.32", "train_loss_features_pen": "0.015", "train_correct_m_0": "0.459384", "train_correct_u_0": "0.705117", "train_ppl": "9.37", "train_wps": "10116.4", "train_ups": "0.15", "train_wpb": "65966.2", "train_bsz": "198.1", "train_num_updates": "38711", "train_lr": "0.000450654", "train_gnorm": "0.68", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3337", "train_gb_free": "65.5", "train_wall": "247920"}
[2023-11-24 16:43:09,146][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 16:43:09,213][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 16:43:09,216][fairseq.trainer][INFO] - begin training epoch 75
[2023-11-24 16:43:09,216][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 16:52:47,827][train_inner][INFO] - {"epoch": 75, "update": 74.17, "loss": "3.221", "count_m_0": "65765.7", "count_u_0": "58025.7", "loss_m_0": "3.206", "loss_u_0": "1.319", "loss_features_pen": "0.014", "correct_m_0": "0.460322", "correct_u_0": "0.705444", "ppl": "9.32", "wps": "10050.7", "ups": "0.15", "wpb": "65765.7", "bsz": "198.7", "num_updates": "38800", "lr": "0.00045", "gnorm": "0.683", "clip": "0", "loss_scale": "2", "train_wall": "1281", "gb_free": "65.6", "wall": "248499"}
[2023-11-24 17:14:32,142][train_inner][INFO] - {"epoch": 75, "update": 74.552, "loss": "3.219", "count_m_0": "66011.9", "count_u_0": "58307", "loss_m_0": "3.205", "loss_u_0": "1.314", "loss_features_pen": "0.014", "correct_m_0": "0.460687", "correct_u_0": "0.706441", "ppl": "9.31", "wps": "10122.2", "ups": "0.15", "wpb": "66011.9", "bsz": "198.1", "num_updates": "39000", "lr": "0.000448529", "gnorm": "0.678", "clip": "0", "loss_scale": "2", "train_wall": "1281", "gb_free": "65.6", "wall": "249803"}
[2023-11-24 17:36:13,374][train_inner][INFO] - {"epoch": 75, "update": 74.933, "loss": "3.22", "count_m_0": "65985.5", "count_u_0": "58150.8", "loss_m_0": "3.205", "loss_u_0": "1.314", "loss_features_pen": "0.014", "correct_m_0": "0.460416", "correct_u_0": "0.705923", "ppl": "9.32", "wps": "10142.1", "ups": "0.15", "wpb": "65985.5", "bsz": "197.7", "num_updates": "39200", "lr": "0.000447059", "gnorm": "0.679", "clip": "0", "loss_scale": "4", "train_wall": "1277", "gb_free": "65.4", "wall": "251105"}
[2023-11-24 17:40:01,106][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-24 17:40:01,106][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 17:40:24,195][dev-other][INFO] - {"epoch": 75, "dev-other_loss": "3.687", "dev-other_count_m_0": "1726.11", "dev-other_count_u_0": "1670.8", "dev-other_loss_m_0": "3.652", "dev-other_loss_u_0": "1.945", "dev-other_loss_features_pen": "0.014", "dev-other_correct_m_0": "0.403028", "dev-other_correct_u_0": "0.616422", "dev-other_ppl": "12.88", "dev-other_wps": "19610.2", "dev-other_wpb": "1726.1", "dev-other_bsz": "10.8", "dev-other_num_updates": "39235", "dev-other_best_loss": "3.687"}
[2023-11-24 17:40:24,196][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-24 17:40:24,196][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 17:40:47,592][dev-clean][INFO] - {"epoch": 75, "dev-clean_loss": "2.938", "dev-clean_count_m_0": "1764.36", "dev-clean_count_u_0": "1711.33", "dev-clean_loss_m_0": "2.886", "dev-clean_loss_u_0": "1.507", "dev-clean_loss_features_pen": "0.014", "dev-clean_correct_m_0": "0.498088", "dev-clean_correct_u_0": "0.689423", "dev-clean_ppl": "7.66", "dev-clean_wps": "20319.8", "dev-clean_wpb": "1764.4", "dev-clean_bsz": "10", "dev-clean_num_updates": "39235"}
[2023-11-24 17:40:47,594][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 75 @ 39235 updates
[2023-11-24 17:40:47,594][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-24 17:40:51,670][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-24 17:40:57,181][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt (epoch 75 @ 39235 updates, score 3.687) (writing took 9.587379343109205 seconds)
[2023-11-24 17:40:57,181][fairseq_cli.train][INFO] - end of epoch 75 (average epoch stats below)
[2023-11-24 17:40:57,224][train][INFO] - {"epoch": 75, "train_loss": "3.218", "train_count_m_0": "65955.2", "train_count_u_0": "58203.8", "train_loss_m_0": "3.203", "train_loss_u_0": "1.313", "train_loss_features_pen": "0.014", "train_correct_m_0": "0.460869", "train_correct_u_0": "0.706308", "train_ppl": "9.3", "train_wps": "9965.4", "train_ups": "0.15", "train_wpb": "65955.2", "train_bsz": "198.1", "train_num_updates": "39235", "train_lr": "0.000446801", "train_gnorm": "0.68", "train_clip": "0", "train_loss_scale": "4", "train_train_wall": "3349", "train_gb_free": "65.4", "train_wall": "251388"}
[2023-11-24 17:40:57,225][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 17:40:57,437][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 17:40:57,439][fairseq.trainer][INFO] - begin training epoch 76
[2023-11-24 17:40:57,439][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 17:48:00,647][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-24 17:59:01,804][train_inner][INFO] - {"epoch": 76, "update": 75.317, "loss": "3.205", "count_m_0": "65887.9", "count_u_0": "58185.1", "loss_m_0": "3.19", "loss_u_0": "1.306", "loss_features_pen": "0.014", "correct_m_0": "0.462673", "correct_u_0": "0.70838", "ppl": "9.22", "wps": "9629.8", "ups": "0.15", "wpb": "65887.9", "bsz": "197.2", "num_updates": "39400", "lr": "0.000445588", "gnorm": "0.684", "clip": "0", "loss_scale": "2", "train_wall": "1288", "gb_free": "65.4", "wall": "252473"}
[2023-11-24 18:20:46,030][train_inner][INFO] - {"epoch": 76, "update": 75.698, "loss": "3.202", "count_m_0": "65930.4", "count_u_0": "58184.4", "loss_m_0": "3.187", "loss_u_0": "1.315", "loss_features_pen": "0.014", "correct_m_0": "0.463136", "correct_u_0": "0.707148", "ppl": "9.2", "wps": "10110.4", "ups": "0.15", "wpb": "65930.4", "bsz": "198.3", "num_updates": "39600", "lr": "0.000444118", "gnorm": "0.679", "clip": "0", "loss_scale": "2", "train_wall": "1281", "gb_free": "65.1", "wall": "253777"}
[2023-11-24 18:37:57,756][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 76 @ 39758 updates
[2023-11-24 18:37:57,757][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 18:38:01,948][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 18:38:01,959][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 76 @ 39758 updates, score None) (writing took 4.2028962429612875 seconds)
[2023-11-24 18:38:01,959][fairseq_cli.train][INFO] - end of epoch 76 (average epoch stats below)
[2023-11-24 18:38:01,974][train][INFO] - {"epoch": 76, "train_loss": "3.203", "train_count_m_0": "65946.9", "train_count_u_0": "58212.7", "train_loss_m_0": "3.189", "train_loss_u_0": "1.312", "train_loss_features_pen": "0.014", "train_correct_m_0": "0.462783", "train_correct_u_0": "0.707562", "train_ppl": "9.21", "train_wps": "10070.9", "train_ups": "0.15", "train_wpb": "65946.9", "train_bsz": "198.1", "train_num_updates": "39758", "train_lr": "0.000442956", "train_gnorm": "0.681", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3358", "train_gb_free": "65.5", "train_wall": "254813"}
[2023-11-24 18:38:01,975][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 18:38:02,042][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 18:38:02,045][fairseq.trainer][INFO] - begin training epoch 77
[2023-11-24 18:38:02,045][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 18:42:32,895][train_inner][INFO] - {"epoch": 77, "update": 76.08, "loss": "3.202", "count_m_0": "65885", "count_u_0": "58181.6", "loss_m_0": "3.187", "loss_u_0": "1.314", "loss_features_pen": "0.014", "correct_m_0": "0.462885", "correct_u_0": "0.707032", "ppl": "9.2", "wps": "10083.1", "ups": "0.15", "wpb": "65885", "bsz": "198.8", "num_updates": "39800", "lr": "0.000442647", "gnorm": "0.681", "clip": "0", "loss_scale": "2", "train_wall": "1279", "gb_free": "65.7", "wall": "255084"}
[2023-11-24 18:52:45,741][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-24 19:04:23,309][train_inner][INFO] - {"epoch": 77, "update": 76.464, "loss": "3.196", "count_m_0": "65951.4", "count_u_0": "58239.6", "loss_m_0": "3.182", "loss_u_0": "1.304", "loss_features_pen": "0.014", "correct_m_0": "0.463493", "correct_u_0": "0.70839", "ppl": "9.16", "wps": "10065.9", "ups": "0.15", "wpb": "65951.4", "bsz": "197.7", "num_updates": "40000", "lr": "0.000441176", "gnorm": "0.683", "clip": "0", "loss_scale": "2", "train_wall": "1286", "gb_free": "65.4", "wall": "256395"}
[2023-11-24 19:04:23,310][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-24 19:04:23,310][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 19:04:47,253][dev-other][INFO] - {"epoch": 77, "dev-other_loss": "3.676", "dev-other_count_m_0": "1721.72", "dev-other_count_u_0": "1674.85", "dev-other_loss_m_0": "3.639", "dev-other_loss_u_0": "2.032", "dev-other_loss_features_pen": "0.014", "dev-other_correct_m_0": "0.406187", "dev-other_correct_u_0": "0.608753", "dev-other_ppl": "12.78", "dev-other_wps": "18816.8", "dev-other_wpb": "1721.7", "dev-other_bsz": "10.8", "dev-other_num_updates": "40000", "dev-other_best_loss": "3.676"}
[2023-11-24 19:04:47,254][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-24 19:04:47,254][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 19:05:10,789][dev-clean][INFO] - {"epoch": 77, "dev-clean_loss": "2.999", "dev-clean_count_m_0": "1772.7", "dev-clean_count_u_0": "1703.14", "dev-clean_loss_m_0": "2.946", "dev-clean_loss_u_0": "1.554", "dev-clean_loss_features_pen": "0.014", "dev-clean_correct_m_0": "0.48863", "dev-clean_correct_u_0": "0.684925", "dev-clean_ppl": "7.99", "dev-clean_wps": "20201.3", "dev-clean_wpb": "1772.7", "dev-clean_bsz": "10", "dev-clean_num_updates": "40000"}
[2023-11-24 19:26:59,580][train_inner][INFO] - {"epoch": 77, "update": 76.845, "loss": "3.194", "count_m_0": "65990.9", "count_u_0": "58312.7", "loss_m_0": "3.18", "loss_u_0": "1.304", "loss_features_pen": "0.014", "correct_m_0": "0.463722", "correct_u_0": "0.708456", "ppl": "9.15", "wps": "9731.3", "ups": "0.15", "wpb": "65990.9", "bsz": "197.8", "num_updates": "40200", "lr": "0.000439706", "gnorm": "0.685", "clip": "0", "loss_scale": "2", "train_wall": "1284", "gb_free": "65.5", "wall": "257751"}
[2023-11-24 19:35:53,786][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 77 @ 40281 updates
[2023-11-24 19:35:53,786][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 19:36:05,353][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 19:36:05,364][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 77 @ 40281 updates, score None) (writing took 11.578756453935057 seconds)
[2023-11-24 19:36:05,365][fairseq_cli.train][INFO] - end of epoch 77 (average epoch stats below)
[2023-11-24 19:36:05,379][train][INFO] - {"epoch": 77, "train_loss": "3.195", "train_count_m_0": "65921.3", "train_count_u_0": "58241.5", "train_loss_m_0": "3.18", "train_loss_u_0": "1.303", "train_loss_features_pen": "0.014", "train_correct_m_0": "0.463718", "train_correct_u_0": "0.708556", "train_ppl": "9.16", "train_wps": "9897.5", "train_ups": "0.15", "train_wpb": "65921.3", "train_bsz": "198.1", "train_num_updates": "40281", "train_lr": "0.00043911", "train_gnorm": "0.683", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3361", "train_gb_free": "65.9", "train_wall": "258297"}
[2023-11-24 19:36:05,380][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 19:36:05,448][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 19:36:05,451][fairseq.trainer][INFO] - begin training epoch 78
[2023-11-24 19:36:05,451][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 19:49:00,843][train_inner][INFO] - {"epoch": 78, "update": 77.227, "loss": "3.194", "count_m_0": "65873.9", "count_u_0": "58160.1", "loss_m_0": "3.18", "loss_u_0": "1.295", "loss_features_pen": "0.014", "correct_m_0": "0.46386", "correct_u_0": "0.709874", "ppl": "9.15", "wps": "9971.5", "ups": "0.15", "wpb": "65873.9", "bsz": "198.4", "num_updates": "40400", "lr": "0.000438235", "gnorm": "0.685", "clip": "0", "loss_scale": "2", "train_wall": "1285", "gb_free": "65.4", "wall": "259072"}
[2023-11-24 20:10:46,303][train_inner][INFO] - {"epoch": 78, "update": 77.609, "loss": "3.186", "count_m_0": "65946.6", "count_u_0": "58211.4", "loss_m_0": "3.172", "loss_u_0": "1.313", "loss_features_pen": "0.014", "correct_m_0": "0.464993", "correct_u_0": "0.707429", "ppl": "9.1", "wps": "10103.3", "ups": "0.15", "wpb": "65946.6", "bsz": "198", "num_updates": "40600", "lr": "0.000436765", "gnorm": "0.689", "clip": "0", "loss_scale": "4", "train_wall": "1282", "gb_free": "65.5", "wall": "260378"}
[2023-11-24 20:29:47,613][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-24 20:32:30,222][train_inner][INFO] - {"epoch": 78, "update": 77.992, "loss": "3.191", "count_m_0": "66060.8", "count_u_0": "58268.3", "loss_m_0": "3.177", "loss_u_0": "1.31", "loss_features_pen": "0.014", "correct_m_0": "0.464545", "correct_u_0": "0.708126", "ppl": "9.13", "wps": "10132.8", "ups": "0.15", "wpb": "66060.8", "bsz": "198.3", "num_updates": "40800", "lr": "0.000435294", "gnorm": "0.684", "clip": "0", "loss_scale": "2", "train_wall": "1280", "gb_free": "65.7", "wall": "261681"}
[2023-11-24 20:32:55,566][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 78 @ 40804 updates
[2023-11-24 20:32:55,567][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 20:32:59,720][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 20:32:59,734][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 78 @ 40804 updates, score None) (writing took 4.167929236078635 seconds)
[2023-11-24 20:32:59,734][fairseq_cli.train][INFO] - end of epoch 78 (average epoch stats below)
[2023-11-24 20:32:59,750][train][INFO] - {"epoch": 78, "train_loss": "3.189", "train_count_m_0": "65959.2", "train_count_u_0": "58201", "train_loss_m_0": "3.175", "train_loss_u_0": "1.309", "train_loss_features_pen": "0.014", "train_correct_m_0": "0.464613", "train_correct_u_0": "0.708098", "train_ppl": "9.12", "train_wps": "10103.4", "train_ups": "0.15", "train_wpb": "65959.2", "train_bsz": "198.1", "train_num_updates": "40804", "train_lr": "0.000435265", "train_gnorm": "0.687", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3347", "train_gb_free": "65.2", "train_wall": "261711"}
[2023-11-24 20:32:59,751][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 20:32:59,817][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 20:32:59,820][fairseq.trainer][INFO] - begin training epoch 79
[2023-11-24 20:32:59,820][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 20:54:17,115][train_inner][INFO] - {"epoch": 79, "update": 78.374, "loss": "3.174", "count_m_0": "65851", "count_u_0": "58150", "loss_m_0": "3.16", "loss_u_0": "1.296", "loss_features_pen": "0.014", "correct_m_0": "0.466615", "correct_u_0": "0.710458", "ppl": "9.03", "wps": "10077.6", "ups": "0.15", "wpb": "65851", "bsz": "198.6", "num_updates": "41000", "lr": "0.000433824", "gnorm": "0.687", "clip": "0", "loss_scale": "2", "train_wall": "1278", "gb_free": "65.3", "wall": "262988"}
[2023-11-24 21:15:56,306][train_inner][INFO] - {"epoch": 79, "update": 78.756, "loss": "3.173", "count_m_0": "66131.9", "count_u_0": "58322.5", "loss_m_0": "3.159", "loss_u_0": "1.314", "loss_features_pen": "0.014", "correct_m_0": "0.466609", "correct_u_0": "0.707841", "ppl": "9.02", "wps": "10180.6", "ups": "0.15", "wpb": "66131.9", "bsz": "197.5", "num_updates": "41200", "lr": "0.000432353", "gnorm": "0.685", "clip": "0", "loss_scale": "2", "train_wall": "1275", "gb_free": "65.6", "wall": "264288"}
[2023-11-24 21:28:32,861][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-24 21:29:50,856][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 79 @ 41327 updates
[2023-11-24 21:29:50,857][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 21:29:55,007][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 21:29:55,020][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 79 @ 41327 updates, score None) (writing took 4.164553563809022 seconds)
[2023-11-24 21:29:55,021][fairseq_cli.train][INFO] - end of epoch 79 (average epoch stats below)
[2023-11-24 21:29:55,036][train][INFO] - {"epoch": 79, "train_loss": "3.173", "train_count_m_0": "65958.2", "train_count_u_0": "58206.8", "train_loss_m_0": "3.159", "train_loss_u_0": "1.304", "train_loss_features_pen": "0.014", "train_correct_m_0": "0.466629", "train_correct_u_0": "0.70922", "train_ppl": "9.02", "train_wps": "10100.6", "train_ups": "0.15", "train_wpb": "65958.2", "train_bsz": "198.1", "train_num_updates": "41327", "train_lr": "0.000431419", "train_gnorm": "0.685", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3348", "train_gb_free": "65.6", "train_wall": "265126"}
[2023-11-24 21:29:55,037][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 21:29:55,104][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 21:29:55,107][fairseq.trainer][INFO] - begin training epoch 80
[2023-11-24 21:29:55,107][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 21:37:46,858][train_inner][INFO] - {"epoch": 80, "update": 79.139, "loss": "3.168", "count_m_0": "65888.1", "count_u_0": "58163.3", "loss_m_0": "3.154", "loss_u_0": "1.302", "loss_features_pen": "0.013", "correct_m_0": "0.466937", "correct_u_0": "0.709748", "ppl": "8.99", "wps": "10055.1", "ups": "0.15", "wpb": "65888.1", "bsz": "198.2", "num_updates": "41400", "lr": "0.000430882", "gnorm": "0.686", "clip": "0", "loss_scale": "2", "train_wall": "1282", "gb_free": "65.7", "wall": "265598"}
[2023-11-24 21:59:24,778][train_inner][INFO] - {"epoch": 80, "update": 79.521, "loss": "3.157", "count_m_0": "65809.1", "count_u_0": "58116.6", "loss_m_0": "3.143", "loss_u_0": "1.293", "loss_features_pen": "0.014", "correct_m_0": "0.468567", "correct_u_0": "0.711417", "ppl": "8.92", "wps": "10140.8", "ups": "0.15", "wpb": "65809.1", "bsz": "197.7", "num_updates": "41600", "lr": "0.000429412", "gnorm": "0.682", "clip": "0", "loss_scale": "2", "train_wall": "1274", "gb_free": "65.6", "wall": "266896"}
[2023-11-24 22:21:03,879][train_inner][INFO] - {"epoch": 80, "update": 79.903, "loss": "3.168", "count_m_0": "65989.4", "count_u_0": "58249.5", "loss_m_0": "3.154", "loss_u_0": "1.283", "loss_features_pen": "0.013", "correct_m_0": "0.467289", "correct_u_0": "0.713168", "ppl": "8.99", "wps": "10159.4", "ups": "0.15", "wpb": "65989.4", "bsz": "198.7", "num_updates": "41800", "lr": "0.000427941", "gnorm": "0.683", "clip": "0", "loss_scale": "2", "train_wall": "1275", "gb_free": "65.4", "wall": "268195"}
[2023-11-24 22:26:35,070][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-24 22:26:35,071][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 22:26:58,793][dev-other][INFO] - {"epoch": 80, "dev-other_loss": "3.658", "dev-other_count_m_0": "1721.61", "dev-other_count_u_0": "1675.08", "dev-other_loss_m_0": "3.617", "dev-other_loss_u_0": "1.972", "dev-other_loss_features_pen": "0.014", "dev-other_correct_m_0": "0.407886", "dev-other_correct_u_0": "0.617275", "dev-other_ppl": "12.62", "dev-other_wps": "19008.7", "dev-other_wpb": "1721.6", "dev-other_bsz": "10.8", "dev-other_num_updates": "41851", "dev-other_best_loss": "3.658"}
[2023-11-24 22:26:58,794][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-24 22:26:58,794][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 22:27:22,441][dev-clean][INFO] - {"epoch": 80, "dev-clean_loss": "2.981", "dev-clean_count_m_0": "1780.03", "dev-clean_count_u_0": "1695.83", "dev-clean_loss_m_0": "2.924", "dev-clean_loss_u_0": "1.499", "dev-clean_loss_features_pen": "0.014", "dev-clean_correct_m_0": "0.492675", "dev-clean_correct_u_0": "0.690958", "dev-clean_ppl": "7.89", "dev-clean_wps": "20157.3", "dev-clean_wpb": "1780", "dev-clean_bsz": "10", "dev-clean_num_updates": "41851"}
[2023-11-24 22:27:22,443][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 80 @ 41851 updates
[2023-11-24 22:27:22,443][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-24 22:27:31,237][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-24 22:27:39,100][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt (epoch 80 @ 41851 updates, score 3.658) (writing took 16.65738211502321 seconds)
[2023-11-24 22:27:39,109][fairseq_cli.train][INFO] - end of epoch 80 (average epoch stats below)
[2023-11-24 22:27:39,218][train][INFO] - {"epoch": 80, "train_loss": "3.161", "train_count_m_0": "65926.7", "train_count_u_0": "58232.3", "train_loss_m_0": "3.147", "train_loss_u_0": "1.291", "train_loss_features_pen": "0.013", "train_correct_m_0": "0.468092", "train_correct_u_0": "0.712058", "train_ppl": "8.95", "train_wps": "9972.5", "train_ups": "0.15", "train_wpb": "65926.7", "train_bsz": "198.1", "train_num_updates": "41851", "train_lr": "0.000427566", "train_gnorm": "0.684", "train_clip": "0", "train_loss_scale": "4", "train_train_wall": "3337", "train_gb_free": "65.4", "train_wall": "268590"}
[2023-11-24 22:27:39,219][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 22:27:39,325][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 22:27:39,355][fairseq.trainer][INFO] - begin training epoch 81
[2023-11-24 22:27:39,356][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 22:43:46,687][train_inner][INFO] - {"epoch": 81, "update": 80.284, "loss": "3.144", "count_m_0": "65977.5", "count_u_0": "58329", "loss_m_0": "3.13", "loss_u_0": "1.301", "loss_features_pen": "0.014", "correct_m_0": "0.47024", "correct_u_0": "0.711296", "ppl": "8.84", "wps": "9682.7", "ups": "0.15", "wpb": "65977.5", "bsz": "197.8", "num_updates": "42000", "lr": "0.000426471", "gnorm": "0.683", "clip": "0", "loss_scale": "4", "train_wall": "1275", "gb_free": "65.5", "wall": "269558"}
[2023-11-24 22:53:35,560][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-24 23:05:28,066][train_inner][INFO] - {"epoch": 81, "update": 80.668, "loss": "3.156", "count_m_0": "65896.6", "count_u_0": "58163.8", "loss_m_0": "3.142", "loss_u_0": "1.311", "loss_features_pen": "0.013", "correct_m_0": "0.468819", "correct_u_0": "0.709729", "ppl": "8.91", "wps": "10127.3", "ups": "0.15", "wpb": "65896.6", "bsz": "198", "num_updates": "42200", "lr": "0.000425", "gnorm": "0.688", "clip": "0", "loss_scale": "2", "train_wall": "1277", "gb_free": "65.3", "wall": "270859"}
[2023-11-24 23:24:22,759][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 81 @ 42374 updates
[2023-11-24 23:24:22,760][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 23:24:29,670][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-24 23:24:29,682][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 81 @ 42374 updates, score None) (writing took 6.922709340928122 seconds)
[2023-11-24 23:24:29,682][fairseq_cli.train][INFO] - end of epoch 81 (average epoch stats below)
[2023-11-24 23:24:29,702][train][INFO] - {"epoch": 81, "train_loss": "3.15", "train_count_m_0": "65934.4", "train_count_u_0": "58225.4", "train_loss_m_0": "3.137", "train_loss_u_0": "1.307", "train_loss_features_pen": "0.013", "train_correct_m_0": "0.469457", "train_correct_u_0": "0.710521", "train_ppl": "8.88", "train_wps": "10111.1", "train_ups": "0.15", "train_wpb": "65934.4", "train_bsz": "198.1", "train_num_updates": "42374", "train_lr": "0.000423721", "train_gnorm": "0.684", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3341", "train_gb_free": "65.5", "train_wall": "272001"}
[2023-11-24 23:24:29,703][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-24 23:24:29,773][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-24 23:24:29,776][fairseq.trainer][INFO] - begin training epoch 82
[2023-11-24 23:24:29,776][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-24 23:27:16,935][train_inner][INFO] - {"epoch": 82, "update": 81.05, "loss": "3.152", "count_m_0": "65973.4", "count_u_0": "58248.8", "loss_m_0": "3.138", "loss_u_0": "1.302", "loss_features_pen": "0.013", "correct_m_0": "0.469314", "correct_u_0": "0.711439", "ppl": "8.89", "wps": "10081.1", "ups": "0.15", "wpb": "65973.4", "bsz": "198.1", "num_updates": "42400", "lr": "0.000423529", "gnorm": "0.681", "clip": "0", "loss_scale": "2", "train_wall": "1278", "gb_free": "65.3", "wall": "272168"}
[2023-11-24 23:49:00,864][train_inner][INFO] - {"epoch": 82, "update": 81.431, "loss": "3.147", "count_m_0": "66041.8", "count_u_0": "58209.1", "loss_m_0": "3.134", "loss_u_0": "1.304", "loss_features_pen": "0.013", "correct_m_0": "0.469881", "correct_u_0": "0.710723", "ppl": "8.86", "wps": "10129.8", "ups": "0.15", "wpb": "66041.8", "bsz": "198", "num_updates": "42600", "lr": "0.000422059", "gnorm": "0.688", "clip": "0", "loss_scale": "2", "train_wall": "1281", "gb_free": "65.9", "wall": "273472"}
[2023-11-25 00:00:14,564][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-25 00:10:59,819][train_inner][INFO] - {"epoch": 82, "update": 81.815, "loss": "3.139", "count_m_0": "65886.7", "count_u_0": "58216.1", "loss_m_0": "3.125", "loss_u_0": "1.294", "loss_features_pen": "0.013", "correct_m_0": "0.47093", "correct_u_0": "0.712544", "ppl": "8.81", "wps": "9990.9", "ups": "0.15", "wpb": "65886.7", "bsz": "199.2", "num_updates": "42800", "lr": "0.000420588", "gnorm": "0.687", "clip": "0", "loss_scale": "2", "train_wall": "1294", "gb_free": "65.4", "wall": "274791"}
[2023-11-25 00:21:34,622][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 82 @ 42897 updates
[2023-11-25 00:21:34,623][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 00:21:42,559][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 00:21:42,576][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 82 @ 42897 updates, score None) (writing took 7.953694358933717 seconds)
[2023-11-25 00:21:42,576][fairseq_cli.train][INFO] - end of epoch 82 (average epoch stats below)
[2023-11-25 00:21:42,589][train][INFO] - {"epoch": 82, "train_loss": "3.142", "train_count_m_0": "65954.4", "train_count_u_0": "58207", "train_loss_m_0": "3.129", "train_loss_u_0": "1.301", "train_loss_features_pen": "0.013", "train_correct_m_0": "0.47045", "train_correct_u_0": "0.711409", "train_ppl": "8.83", "train_wps": "10048.2", "train_ups": "0.15", "train_wpb": "65954.4", "train_bsz": "198.1", "train_num_updates": "42897", "train_lr": "0.000419875", "train_gnorm": "0.686", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3362", "train_gb_free": "65.4", "train_wall": "275434"}
[2023-11-25 00:21:42,590][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-25 00:21:42,657][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-25 00:21:42,660][fairseq.trainer][INFO] - begin training epoch 83
[2023-11-25 00:21:42,660][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-25 00:32:40,605][train_inner][INFO] - {"epoch": 83, "update": 82.197, "loss": "3.136", "count_m_0": "65982.4", "count_u_0": "58224.1", "loss_m_0": "3.123", "loss_u_0": "1.302", "loss_features_pen": "0.013", "correct_m_0": "0.471373", "correct_u_0": "0.711625", "ppl": "8.79", "wps": "10145.1", "ups": "0.15", "wpb": "65982.4", "bsz": "195.6", "num_updates": "43000", "lr": "0.000419118", "gnorm": "0.68", "clip": "0", "loss_scale": "2", "train_wall": "1264", "gb_free": "65.8", "wall": "276092"}
[2023-11-25 00:53:41,018][train_inner][INFO] - {"epoch": 83, "update": 82.578, "loss": "3.141", "count_m_0": "65949.7", "count_u_0": "58167.7", "loss_m_0": "3.128", "loss_u_0": "1.301", "loss_features_pen": "0.013", "correct_m_0": "0.470735", "correct_u_0": "0.711019", "ppl": "8.82", "wps": "10464.9", "ups": "0.16", "wpb": "65949.7", "bsz": "198.3", "num_updates": "43200", "lr": "0.000417647", "gnorm": "0.679", "clip": "0", "loss_scale": "2", "train_wall": "1237", "gb_free": "65.5", "wall": "277352"}
[2023-11-25 01:14:43,656][train_inner][INFO] - {"epoch": 83, "update": 82.96, "loss": "3.13", "count_m_0": "65862.2", "count_u_0": "58196.4", "loss_m_0": "3.117", "loss_u_0": "1.298", "loss_features_pen": "0.013", "correct_m_0": "0.472159", "correct_u_0": "0.711805", "ppl": "8.76", "wps": "10432.6", "ups": "0.16", "wpb": "65862.2", "bsz": "199.4", "num_updates": "43400", "lr": "0.000416176", "gnorm": "0.682", "clip": "0", "loss_scale": "4", "train_wall": "1239", "gb_free": "65.3", "wall": "278615"}
[2023-11-25 01:16:12,645][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-25 01:16:56,442][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 83 @ 43420 updates
[2023-11-25 01:16:56,443][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 01:17:07,282][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 01:17:07,298][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 83 @ 43420 updates, score None) (writing took 10.855965649010614 seconds)
[2023-11-25 01:17:07,298][fairseq_cli.train][INFO] - end of epoch 83 (average epoch stats below)
[2023-11-25 01:17:07,313][train][INFO] - {"epoch": 83, "train_loss": "3.136", "train_count_m_0": "65955.8", "train_count_u_0": "58198.7", "train_loss_m_0": "3.122", "train_loss_u_0": "1.297", "train_loss_features_pen": "0.013", "train_correct_m_0": "0.471496", "train_correct_u_0": "0.711814", "train_ppl": "8.79", "train_wps": "10375.3", "train_ups": "0.16", "train_wpb": "65955.8", "train_bsz": "198.1", "train_num_updates": "43420", "train_lr": "0.000416029", "train_gnorm": "0.681", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3247", "train_gb_free": "65.6", "train_wall": "278759"}
[2023-11-25 01:17:07,314][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-25 01:17:07,382][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-25 01:17:07,384][fairseq.trainer][INFO] - begin training epoch 84
[2023-11-25 01:17:07,384][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-25 01:35:57,554][train_inner][INFO] - {"epoch": 84, "update": 83.344, "loss": "3.13", "count_m_0": "65989.7", "count_u_0": "58116.8", "loss_m_0": "3.116", "loss_u_0": "1.289", "loss_features_pen": "0.013", "correct_m_0": "0.472248", "correct_u_0": "0.712777", "ppl": "8.75", "wps": "10360.4", "ups": "0.16", "wpb": "65989.7", "bsz": "197.2", "num_updates": "43600", "lr": "0.000414706", "gnorm": "0.681", "clip": "0", "loss_scale": "2", "train_wall": "1239", "gb_free": "65.3", "wall": "279889"}
[2023-11-25 01:56:57,033][train_inner][INFO] - {"epoch": 84, "update": 83.725, "loss": "3.126", "count_m_0": "65983.7", "count_u_0": "58239.8", "loss_m_0": "3.113", "loss_u_0": "1.294", "loss_features_pen": "0.013", "correct_m_0": "0.472611", "correct_u_0": "0.712997", "ppl": "8.73", "wps": "10478.1", "ups": "0.16", "wpb": "65983.7", "bsz": "197.8", "num_updates": "43800", "lr": "0.000413235", "gnorm": "0.681", "clip": "0", "loss_scale": "2", "train_wall": "1236", "gb_free": "65.8", "wall": "281148"}
[2023-11-25 02:12:11,658][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 84 @ 43944 updates
[2023-11-25 02:12:11,659][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 02:12:16,431][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 02:12:16,506][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 84 @ 43944 updates, score None) (writing took 4.848750030854717 seconds)
[2023-11-25 02:12:16,507][fairseq_cli.train][INFO] - end of epoch 84 (average epoch stats below)
[2023-11-25 02:12:16,521][train][INFO] - {"epoch": 84, "train_loss": "3.125", "train_count_m_0": "65960.1", "train_count_u_0": "58198.8", "train_loss_m_0": "3.112", "train_loss_u_0": "1.292", "train_loss_features_pen": "0.013", "train_correct_m_0": "0.472817", "train_correct_u_0": "0.713129", "train_ppl": "8.72", "train_wps": "10444.6", "train_ups": "0.16", "train_wpb": "65960.1", "train_bsz": "198.1", "train_num_updates": "43944", "train_lr": "0.000412176", "train_gnorm": "0.68", "train_clip": "0", "train_loss_scale": "4", "train_train_wall": "3242", "train_gb_free": "65.6", "train_wall": "282068"}
[2023-11-25 02:12:16,522][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-25 02:12:16,589][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-25 02:12:16,594][fairseq.trainer][INFO] - begin training epoch 85
[2023-11-25 02:12:16,594][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-25 02:18:05,670][train_inner][INFO] - {"epoch": 85, "update": 84.107, "loss": "3.119", "count_m_0": "65863.6", "count_u_0": "58186.5", "loss_m_0": "3.105", "loss_u_0": "1.299", "loss_features_pen": "0.013", "correct_m_0": "0.473679", "correct_u_0": "0.713047", "ppl": "8.69", "wps": "10383.5", "ups": "0.16", "wpb": "65863.6", "bsz": "198.9", "num_updates": "44000", "lr": "0.000411765", "gnorm": "0.678", "clip": "0", "loss_scale": "4", "train_wall": "1240", "gb_free": "65.7", "wall": "282417"}
[2023-11-25 02:22:04,650][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-25 02:39:11,280][train_inner][INFO] - {"epoch": 85, "update": 84.49, "loss": "3.102", "count_m_0": "66015", "count_u_0": "58356.6", "loss_m_0": "3.089", "loss_u_0": "1.303", "loss_features_pen": "0.013", "correct_m_0": "0.475788", "correct_u_0": "0.712971", "ppl": "8.58", "wps": "10432.3", "ups": "0.16", "wpb": "66015", "bsz": "198.7", "num_updates": "44200", "lr": "0.000410294", "gnorm": "0.682", "clip": "0", "loss_scale": "2", "train_wall": "1242", "gb_free": "66", "wall": "283683"}
[2023-11-25 03:00:12,663][train_inner][INFO] - {"epoch": 85, "update": 84.872, "loss": "3.103", "count_m_0": "65846.6", "count_u_0": "58184.5", "loss_m_0": "3.09", "loss_u_0": "1.292", "loss_features_pen": "0.013", "correct_m_0": "0.475303", "correct_u_0": "0.714188", "ppl": "8.59", "wps": "10440.5", "ups": "0.16", "wpb": "65846.6", "bsz": "198", "num_updates": "44400", "lr": "0.000408824", "gnorm": "0.681", "clip": "0", "loss_scale": "2", "train_wall": "1238", "gb_free": "65.6", "wall": "284944"}
[2023-11-25 03:07:14,374][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-25 03:07:14,375][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-25 03:07:36,819][dev-other][INFO] - {"epoch": 85, "dev-other_loss": "3.576", "dev-other_count_m_0": "1715.9", "dev-other_count_u_0": "1680.95", "dev-other_loss_m_0": "3.523", "dev-other_loss_u_0": "1.984", "dev-other_loss_features_pen": "0.013", "dev-other_correct_m_0": "0.420539", "dev-other_correct_u_0": "0.619254", "dev-other_ppl": "11.93", "dev-other_wps": "20033.7", "dev-other_wpb": "1715.9", "dev-other_bsz": "10.8", "dev-other_num_updates": "44467", "dev-other_best_loss": "3.576"}
[2023-11-25 03:07:36,819][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-25 03:07:36,820][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-25 03:07:59,374][dev-clean][INFO] - {"epoch": 85, "dev-clean_loss": "3.01", "dev-clean_count_m_0": "1794.12", "dev-clean_count_u_0": "1681.47", "dev-clean_loss_m_0": "2.955", "dev-clean_loss_u_0": "1.484", "dev-clean_loss_features_pen": "0.013", "dev-clean_correct_m_0": "0.490167", "dev-clean_correct_u_0": "0.690022", "dev-clean_ppl": "8.05", "dev-clean_wps": "21311.4", "dev-clean_wpb": "1794.1", "dev-clean_bsz": "10", "dev-clean_num_updates": "44467"}
[2023-11-25 03:07:59,375][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 85 @ 44467 updates
[2023-11-25 03:07:59,376][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-25 03:08:05,107][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-25 03:08:10,733][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt (epoch 85 @ 44467 updates, score 3.576) (writing took 11.35767221194692 seconds)
[2023-11-25 03:08:10,733][fairseq_cli.train][INFO] - end of epoch 85 (average epoch stats below)
[2023-11-25 03:08:10,826][train][INFO] - {"epoch": 85, "train_loss": "3.109", "train_count_m_0": "65931.5", "train_count_u_0": "58236.4", "train_loss_m_0": "3.095", "train_loss_u_0": "1.297", "train_loss_features_pen": "0.013", "train_correct_m_0": "0.474834", "train_correct_u_0": "0.713426", "train_ppl": "8.62", "train_wps": "10280.3", "train_ups": "0.16", "train_wpb": "65931.5", "train_bsz": "198.1", "train_num_updates": "44467", "train_lr": "0.000408331", "train_gnorm": "0.682", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3235", "train_gb_free": "65.7", "train_wall": "285422"}
[2023-11-25 03:08:10,827][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-25 03:08:10,927][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-25 03:08:10,929][fairseq.trainer][INFO] - begin training epoch 86
[2023-11-25 03:08:10,929][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-25 03:22:12,631][train_inner][INFO] - {"epoch": 86, "update": 85.254, "loss": "3.115", "count_m_0": "65889.2", "count_u_0": "58089.6", "loss_m_0": "3.102", "loss_u_0": "1.289", "loss_features_pen": "0.013", "correct_m_0": "0.473921", "correct_u_0": "0.714141", "ppl": "8.67", "wps": "9983.6", "ups": "0.15", "wpb": "65889.2", "bsz": "197.6", "num_updates": "44600", "lr": "0.000407353", "gnorm": "0.685", "clip": "0", "loss_scale": "4", "train_wall": "1239", "gb_free": "65.6", "wall": "286264"}
[2023-11-25 03:43:11,389][train_inner][INFO] - {"epoch": 86, "update": 85.635, "loss": "3.101", "count_m_0": "66113.5", "count_u_0": "58333.8", "loss_m_0": "3.088", "loss_u_0": "1.31", "loss_features_pen": "0.013", "correct_m_0": "0.475637", "correct_u_0": "0.711557", "ppl": "8.58", "wps": "10504.7", "ups": "0.16", "wpb": "66113.5", "bsz": "197", "num_updates": "44800", "lr": "0.000405882", "gnorm": "0.683", "clip": "0", "loss_scale": "4", "train_wall": "1235", "gb_free": "65.8", "wall": "287523"}
[2023-11-25 04:03:15,274][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 86 @ 44991 updates
[2023-11-25 04:03:15,275][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 04:03:19,600][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 04:03:19,612][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 86 @ 44991 updates, score None) (writing took 4.3383597591891885 seconds)
[2023-11-25 04:03:19,613][fairseq_cli.train][INFO] - end of epoch 86 (average epoch stats below)
[2023-11-25 04:03:19,627][train][INFO] - {"epoch": 86, "train_loss": "3.101", "train_count_m_0": "65940.2", "train_count_u_0": "58219", "train_loss_m_0": "3.088", "train_loss_u_0": "1.303", "train_loss_features_pen": "0.013", "train_correct_m_0": "0.475633", "train_correct_u_0": "0.71253", "train_ppl": "8.58", "train_wps": "10442.7", "train_ups": "0.16", "train_wpb": "65940.2", "train_bsz": "198.1", "train_num_updates": "44991", "train_lr": "0.000404478", "train_gnorm": "0.682", "train_clip": "0", "train_loss_scale": "4", "train_train_wall": "3242", "train_gb_free": "65.4", "train_wall": "288731"}
[2023-11-25 04:03:19,628][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-25 04:03:19,697][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-25 04:03:19,700][fairseq.trainer][INFO] - begin training epoch 87
[2023-11-25 04:03:19,701][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-25 04:04:16,313][train_inner][INFO] - {"epoch": 87, "update": 86.017, "loss": "3.096", "count_m_0": "65884.4", "count_u_0": "58228.4", "loss_m_0": "3.083", "loss_u_0": "1.305", "loss_features_pen": "0.013", "correct_m_0": "0.47615", "correct_u_0": "0.712516", "ppl": "8.55", "wps": "10417.3", "ups": "0.16", "wpb": "65884.4", "bsz": "199.1", "num_updates": "45000", "lr": "0.000404412", "gnorm": "0.678", "clip": "0", "loss_scale": "4", "train_wall": "1236", "gb_free": "65.3", "wall": "288788"}
[2023-11-25 04:05:49,195][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-25 04:25:21,576][train_inner][INFO] - {"epoch": 87, "update": 86.401, "loss": "3.086", "count_m_0": "66013.2", "count_u_0": "58234.9", "loss_m_0": "3.073", "loss_u_0": "1.286", "loss_features_pen": "0.012", "correct_m_0": "0.477681", "correct_u_0": "0.715523", "ppl": "8.49", "wps": "10434.8", "ups": "0.16", "wpb": "66013.2", "bsz": "198.9", "num_updates": "45200", "lr": "0.000402941", "gnorm": "0.68", "clip": "0", "loss_scale": "2", "train_wall": "1242", "gb_free": "66", "wall": "290053"}
[2023-11-25 04:46:22,520][train_inner][INFO] - {"epoch": 87, "update": 86.782, "loss": "3.097", "count_m_0": "65898.9", "count_u_0": "58163.3", "loss_m_0": "3.084", "loss_u_0": "1.281", "loss_features_pen": "0.012", "correct_m_0": "0.476215", "correct_u_0": "0.716042", "ppl": "8.55", "wps": "10452.4", "ups": "0.16", "wpb": "65898.9", "bsz": "198.2", "num_updates": "45400", "lr": "0.000401471", "gnorm": "0.678", "clip": "0", "loss_scale": "2", "train_wall": "1237", "gb_free": "65.5", "wall": "291314"}
[2023-11-25 04:58:21,021][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 87 @ 45514 updates
[2023-11-25 04:58:21,021][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 04:58:30,664][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 04:58:30,678][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 87 @ 45514 updates, score None) (writing took 9.657070282148197 seconds)
[2023-11-25 04:58:30,678][fairseq_cli.train][INFO] - end of epoch 87 (average epoch stats below)
[2023-11-25 04:58:30,693][train][INFO] - {"epoch": 87, "train_loss": "3.091", "train_count_m_0": "65959.9", "train_count_u_0": "58198.6", "train_loss_m_0": "3.079", "train_loss_u_0": "1.285", "train_loss_features_pen": "0.012", "train_correct_m_0": "0.476925", "train_correct_u_0": "0.715389", "train_ppl": "8.52", "train_wps": "10418.8", "train_ups": "0.16", "train_wpb": "65959.9", "train_bsz": "198.1", "train_num_updates": "45514", "train_lr": "0.000400632", "train_gnorm": "0.68", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3240", "train_gb_free": "65.5", "train_wall": "292042"}
[2023-11-25 04:58:30,694][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-25 04:58:30,760][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-25 04:58:30,763][fairseq.trainer][INFO] - begin training epoch 88
[2023-11-25 04:58:30,763][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-25 05:07:31,445][train_inner][INFO] - {"epoch": 88, "update": 87.164, "loss": "3.081", "count_m_0": "65959", "count_u_0": "58237.9", "loss_m_0": "3.069", "loss_u_0": "1.287", "loss_features_pen": "0.012", "correct_m_0": "0.478327", "correct_u_0": "0.715421", "ppl": "8.46", "wps": "10396.2", "ups": "0.16", "wpb": "65959", "bsz": "197.8", "num_updates": "45600", "lr": "0.0004", "gnorm": "0.684", "clip": "0", "loss_scale": "4", "train_wall": "1235", "gb_free": "65.5", "wall": "292583"}
[2023-11-25 05:28:30,503][train_inner][INFO] - {"epoch": 88, "update": 87.546, "loss": "3.081", "count_m_0": "66083", "count_u_0": "58300.8", "loss_m_0": "3.069", "loss_u_0": "1.277", "loss_features_pen": "0.012", "correct_m_0": "0.478181", "correct_u_0": "0.716632", "ppl": "8.46", "wps": "10497.4", "ups": "0.16", "wpb": "66083", "bsz": "197.7", "num_updates": "45800", "lr": "0.000398529", "gnorm": "0.682", "clip": "0", "loss_scale": "4", "train_wall": "1235", "gb_free": "65.7", "wall": "293842"}
[2023-11-25 05:49:30,239][train_inner][INFO] - {"epoch": 88, "update": 87.927, "loss": "3.082", "count_m_0": "65792.7", "count_u_0": "58120.2", "loss_m_0": "3.069", "loss_u_0": "1.289", "loss_features_pen": "0.012", "correct_m_0": "0.478292", "correct_u_0": "0.715842", "ppl": "8.47", "wps": "10445.6", "ups": "0.16", "wpb": "65792.7", "bsz": "198.1", "num_updates": "46000", "lr": "0.000397059", "gnorm": "0.679", "clip": "0", "loss_scale": "4", "train_wall": "1237", "gb_free": "65.7", "wall": "295101"}
[2023-11-25 05:53:29,677][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 88 @ 46038 updates
[2023-11-25 05:53:29,678][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 05:53:35,500][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 05:53:35,510][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 88 @ 46038 updates, score None) (writing took 5.832902950933203 seconds)
[2023-11-25 05:53:35,510][fairseq_cli.train][INFO] - end of epoch 88 (average epoch stats below)
[2023-11-25 05:53:35,525][train][INFO] - {"epoch": 88, "train_loss": "3.08", "train_count_m_0": "65938.7", "train_count_u_0": "58220.4", "train_loss_m_0": "3.067", "train_loss_u_0": "1.285", "train_loss_features_pen": "0.012", "train_correct_m_0": "0.478479", "train_correct_u_0": "0.716204", "train_ppl": "8.46", "train_wps": "10455", "train_ups": "0.16", "train_wpb": "65938.7", "train_bsz": "198.1", "train_num_updates": "46038", "train_lr": "0.000396779", "train_gnorm": "0.68", "train_clip": "0", "train_loss_scale": "8", "train_train_wall": "3237", "train_gb_free": "65.5", "train_wall": "295347"}
[2023-11-25 05:53:35,526][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-25 05:53:35,688][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-25 05:53:35,697][fairseq.trainer][INFO] - begin training epoch 89
[2023-11-25 05:53:35,697][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-25 05:56:18,112][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2023-11-25 06:10:38,457][train_inner][INFO] - {"epoch": 89, "update": 88.311, "loss": "3.077", "count_m_0": "65976.2", "count_u_0": "58204.6", "loss_m_0": "3.064", "loss_u_0": "1.303", "loss_features_pen": "0.012", "correct_m_0": "0.479117", "correct_u_0": "0.71434", "ppl": "8.44", "wps": "10404.7", "ups": "0.16", "wpb": "65976.2", "bsz": "197.1", "num_updates": "46200", "lr": "0.000395588", "gnorm": "0.68", "clip": "0", "loss_scale": "4", "train_wall": "1238", "gb_free": "65.5", "wall": "296370"}
[2023-11-25 06:14:56,683][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-25 06:31:45,718][train_inner][INFO] - {"epoch": 89, "update": 88.695, "loss": "3.066", "count_m_0": "65906.7", "count_u_0": "58341.9", "loss_m_0": "3.053", "loss_u_0": "1.292", "loss_features_pen": "0.012", "correct_m_0": "0.480194", "correct_u_0": "0.716105", "ppl": "8.37", "wps": "10401.6", "ups": "0.16", "wpb": "65906.7", "bsz": "198.8", "num_updates": "46400", "lr": "0.000394118", "gnorm": "0.68", "clip": "0", "loss_scale": "2", "train_wall": "1243", "gb_free": "65.3", "wall": "297637"}
[2023-11-25 06:48:35,328][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 89 @ 46560 updates
[2023-11-25 06:48:35,329][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 06:48:55,248][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 06:48:55,263][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 89 @ 46560 updates, score None) (writing took 19.93428934714757 seconds)
[2023-11-25 06:48:55,263][fairseq_cli.train][INFO] - end of epoch 89 (average epoch stats below)
[2023-11-25 06:48:55,283][train][INFO] - {"epoch": 89, "train_loss": "3.07", "train_count_m_0": "65925.9", "train_count_u_0": "58234.6", "train_loss_m_0": "3.058", "train_loss_u_0": "1.289", "train_loss_features_pen": "0.012", "train_correct_m_0": "0.479808", "train_correct_u_0": "0.716234", "train_ppl": "8.4", "train_wps": "10366.3", "train_ups": "0.16", "train_wpb": "65925.9", "train_bsz": "198.1", "train_num_updates": "46560", "train_lr": "0.000392941", "train_gnorm": "0.679", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3237", "train_gb_free": "65.3", "train_wall": "298667"}
[2023-11-25 06:48:55,284][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-25 06:48:55,357][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-25 06:48:55,359][fairseq.trainer][INFO] - begin training epoch 90
[2023-11-25 06:48:55,359][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-25 06:53:05,244][train_inner][INFO] - {"epoch": 90, "update": 89.076, "loss": "3.072", "count_m_0": "65836", "count_u_0": "58079.9", "loss_m_0": "3.06", "loss_u_0": "1.275", "loss_features_pen": "0.012", "correct_m_0": "0.479455", "correct_u_0": "0.71798", "ppl": "8.41", "wps": "10290.8", "ups": "0.16", "wpb": "65836", "bsz": "198", "num_updates": "46600", "lr": "0.000392647", "gnorm": "0.68", "clip": "0", "loss_scale": "2", "train_wall": "1235", "gb_free": "65.6", "wall": "298917"}
[2023-11-25 07:14:05,121][train_inner][INFO] - {"epoch": 90, "update": 89.458, "loss": "3.058", "count_m_0": "65884.9", "count_u_0": "58210.8", "loss_m_0": "3.046", "loss_u_0": "1.294", "loss_features_pen": "0.012", "correct_m_0": "0.481277", "correct_u_0": "0.715959", "ppl": "8.33", "wps": "10459.1", "ups": "0.16", "wpb": "65884.9", "bsz": "198.2", "num_updates": "46800", "lr": "0.000391176", "gnorm": "0.681", "clip": "0", "loss_scale": "4", "train_wall": "1236", "gb_free": "65.4", "wall": "300176"}
[2023-11-25 07:33:42,331][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-25 07:35:10,871][train_inner][INFO] - {"epoch": 90, "update": 89.842, "loss": "3.065", "count_m_0": "66081.5", "count_u_0": "58239.6", "loss_m_0": "3.053", "loss_u_0": "1.295", "loss_features_pen": "0.012", "correct_m_0": "0.480363", "correct_u_0": "0.715432", "ppl": "8.37", "wps": "10441.6", "ups": "0.16", "wpb": "66081.5", "bsz": "196.7", "num_updates": "47000", "lr": "0.000389706", "gnorm": "0.68", "clip": "0", "loss_scale": "2", "train_wall": "1242", "gb_free": "65.7", "wall": "301442"}
[2023-11-25 07:43:54,372][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-25 07:43:54,373][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-25 07:44:17,099][dev-other][INFO] - {"epoch": 90, "dev-other_loss": "3.614", "dev-other_count_m_0": "1725.81", "dev-other_count_u_0": "1670.76", "dev-other_loss_m_0": "3.572", "dev-other_loss_u_0": "1.98", "dev-other_loss_features_pen": "0.012", "dev-other_correct_m_0": "0.413709", "dev-other_correct_u_0": "0.618989", "dev-other_ppl": "12.25", "dev-other_wps": "19903.3", "dev-other_wpb": "1725.8", "dev-other_bsz": "10.8", "dev-other_num_updates": "47083", "dev-other_best_loss": "3.576"}
[2023-11-25 07:44:17,100][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-25 07:44:17,100][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-25 07:44:39,663][dev-clean][INFO] - {"epoch": 90, "dev-clean_loss": "2.9", "dev-clean_count_m_0": "1777.17", "dev-clean_count_u_0": "1698.68", "dev-clean_loss_m_0": "2.855", "dev-clean_loss_u_0": "1.502", "dev-clean_loss_features_pen": "0.012", "dev-clean_correct_m_0": "0.501184", "dev-clean_correct_u_0": "0.693992", "dev-clean_ppl": "7.46", "dev-clean_wps": "21102.7", "dev-clean_wpb": "1777.2", "dev-clean_bsz": "10", "dev-clean_num_updates": "47083"}
[2023-11-25 07:44:39,664][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 90 @ 47083 updates
[2023-11-25 07:44:39,665][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 07:44:49,566][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 07:44:49,580][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 90 @ 47083 updates, score 3.614) (writing took 9.915364071028307 seconds)
[2023-11-25 07:44:49,580][fairseq_cli.train][INFO] - end of epoch 90 (average epoch stats below)
[2023-11-25 07:44:49,595][train][INFO] - {"epoch": 90, "train_loss": "3.061", "train_count_m_0": "65945.6", "train_count_u_0": "58213", "train_loss_m_0": "3.049", "train_loss_u_0": "1.292", "train_loss_features_pen": "0.012", "train_correct_m_0": "0.480883", "train_correct_u_0": "0.716185", "train_ppl": "8.35", "train_wps": "10282.2", "train_ups": "0.16", "train_wpb": "65945.6", "train_bsz": "198.1", "train_num_updates": "47083", "train_lr": "0.000389096", "train_gnorm": "0.679", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3237", "train_gb_free": "65.5", "train_wall": "302021"}
[2023-11-25 07:44:49,596][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-25 07:44:49,669][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-25 07:44:49,670][fairseq.trainer][INFO] - begin training epoch 91
[2023-11-25 07:44:49,670][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-25 07:57:09,310][train_inner][INFO] - {"epoch": 91, "update": 90.223, "loss": "3.054", "count_m_0": "65975.4", "count_u_0": "58317.9", "loss_m_0": "3.041", "loss_u_0": "1.283", "loss_features_pen": "0.012", "correct_m_0": "0.482084", "correct_u_0": "0.718333", "ppl": "8.3", "wps": "10008.2", "ups": "0.15", "wpb": "65975.4", "bsz": "198.9", "num_updates": "47200", "lr": "0.000388235", "gnorm": "0.678", "clip": "0", "loss_scale": "2", "train_wall": "1239", "gb_free": "65.1", "wall": "302761"}
[2023-11-25 08:18:07,157][train_inner][INFO] - {"epoch": 91, "update": 90.605, "loss": "3.056", "count_m_0": "65969.5", "count_u_0": "58237.2", "loss_m_0": "3.043", "loss_u_0": "1.288", "loss_features_pen": "0.012", "correct_m_0": "0.481609", "correct_u_0": "0.716488", "ppl": "8.31", "wps": "10489.4", "ups": "0.16", "wpb": "65969.5", "bsz": "198", "num_updates": "47400", "lr": "0.000386765", "gnorm": "0.68", "clip": "0", "loss_scale": "2", "train_wall": "1235", "gb_free": "65.6", "wall": "304018"}
[2023-11-25 08:39:07,204][train_inner][INFO] - {"epoch": 91, "update": 90.987, "loss": "3.053", "count_m_0": "65834.6", "count_u_0": "58189", "loss_m_0": "3.041", "loss_u_0": "1.29", "loss_features_pen": "0.012", "correct_m_0": "0.48206", "correct_u_0": "0.716738", "ppl": "8.3", "wps": "10449.7", "ups": "0.16", "wpb": "65834.6", "bsz": "198.5", "num_updates": "47600", "lr": "0.000385294", "gnorm": "0.68", "clip": "0", "loss_scale": "4", "train_wall": "1237", "gb_free": "65.6", "wall": "305278"}
[2023-11-25 08:39:50,984][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 91 @ 47607 updates
[2023-11-25 08:39:50,985][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 08:39:55,239][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 08:39:55,248][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 91 @ 47607 updates, score None) (writing took 4.26437397999689 seconds)
[2023-11-25 08:39:55,249][fairseq_cli.train][INFO] - end of epoch 91 (average epoch stats below)
[2023-11-25 08:39:55,262][train][INFO] - {"epoch": 91, "train_loss": "3.054", "train_count_m_0": "65921.3", "train_count_u_0": "58237.9", "train_loss_m_0": "3.042", "train_loss_u_0": "1.288", "train_loss_features_pen": "0.012", "train_correct_m_0": "0.481896", "train_correct_u_0": "0.717048", "train_ppl": "8.31", "train_wps": "10449.6", "train_ups": "0.16", "train_wpb": "65921.3", "train_bsz": "198.1", "train_num_updates": "47607", "train_lr": "0.000385243", "train_gnorm": "0.681", "train_clip": "0", "train_loss_scale": "4", "train_train_wall": "3240", "train_gb_free": "65.9", "train_wall": "305327"}
[2023-11-25 08:39:55,263][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-25 08:39:55,329][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-25 08:39:55,332][fairseq.trainer][INFO] - begin training epoch 92
[2023-11-25 08:39:55,332][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-25 09:00:07,745][train_inner][INFO] - {"epoch": 92, "update": 91.368, "loss": "3.052", "count_m_0": "65914.8", "count_u_0": "58067", "loss_m_0": "3.04", "loss_u_0": "1.284", "loss_features_pen": "0.012", "correct_m_0": "0.482121", "correct_u_0": "0.717446", "ppl": "8.29", "wps": "10458.3", "ups": "0.16", "wpb": "65914.8", "bsz": "198", "num_updates": "47800", "lr": "0.000383824", "gnorm": "0.677", "clip": "0", "loss_scale": "4", "train_wall": "1233", "gb_free": "65.5", "wall": "306539"}
[2023-11-25 09:21:08,224][train_inner][INFO] - {"epoch": 92, "update": 91.75, "loss": "3.051", "count_m_0": "65973.1", "count_u_0": "58238.8", "loss_m_0": "3.039", "loss_u_0": "1.29", "loss_features_pen": "0.012", "correct_m_0": "0.482305", "correct_u_0": "0.717056", "ppl": "8.29", "wps": "10468.1", "ups": "0.16", "wpb": "65973.1", "bsz": "197.9", "num_updates": "48000", "lr": "0.000382353", "gnorm": "0.675", "clip": "0", "loss_scale": "4", "train_wall": "1237", "gb_free": "65.6", "wall": "307799"}
[2023-11-25 09:22:42,471][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2023-11-25 09:34:53,726][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 92 @ 48130 updates
[2023-11-25 09:34:53,726][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 09:34:57,904][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 09:34:57,916][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 92 @ 48130 updates, score None) (writing took 4.190588699886575 seconds)
[2023-11-25 09:34:57,916][fairseq_cli.train][INFO] - end of epoch 92 (average epoch stats below)
[2023-11-25 09:34:57,931][train][INFO] - {"epoch": 92, "train_loss": "3.051", "train_count_m_0": "65975.4", "train_count_u_0": "58181.2", "train_loss_m_0": "3.038", "train_loss_u_0": "1.285", "train_loss_features_pen": "0.012", "train_correct_m_0": "0.482401", "train_correct_u_0": "0.717548", "train_ppl": "8.29", "train_wps": "10447.7", "train_ups": "0.16", "train_wpb": "65975.4", "train_bsz": "198.1", "train_num_updates": "48130", "train_lr": "0.000381397", "train_gnorm": "0.676", "train_clip": "0", "train_loss_scale": "4", "train_train_wall": "3237", "train_gb_free": "65.3", "train_wall": "308629"}
[2023-11-25 09:34:57,932][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-25 09:34:57,999][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-25 09:34:58,002][fairseq.trainer][INFO] - begin training epoch 93
[2023-11-25 09:34:58,002][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-25 09:42:15,731][train_inner][INFO] - {"epoch": 93, "update": 92.134, "loss": "3.044", "count_m_0": "66028.4", "count_u_0": "58276.2", "loss_m_0": "3.032", "loss_u_0": "1.29", "loss_features_pen": "0.012", "correct_m_0": "0.483345", "correct_u_0": "0.717627", "ppl": "8.25", "wps": "10418.7", "ups": "0.16", "wpb": "66028.4", "bsz": "197.3", "num_updates": "48200", "lr": "0.000380882", "gnorm": "0.676", "clip": "0", "loss_scale": "4", "train_wall": "1240", "gb_free": "65.5", "wall": "309067"}
[2023-11-25 10:03:16,750][train_inner][INFO] - {"epoch": 93, "update": 92.515, "loss": "3.027", "count_m_0": "65882.4", "count_u_0": "58272.9", "loss_m_0": "3.015", "loss_u_0": "1.285", "loss_features_pen": "0.012", "correct_m_0": "0.485287", "correct_u_0": "0.718286", "ppl": "8.15", "wps": "10449.2", "ups": "0.16", "wpb": "65882.4", "bsz": "199.3", "num_updates": "48400", "lr": "0.000379412", "gnorm": "0.676", "clip": "0", "loss_scale": "4", "train_wall": "1238", "gb_free": "65.2", "wall": "310328"}
[2023-11-25 10:19:39,297][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2023-11-25 10:24:17,331][train_inner][INFO] - {"epoch": 93, "update": 92.899, "loss": "3.034", "count_m_0": "65966.5", "count_u_0": "58169.9", "loss_m_0": "3.022", "loss_u_0": "1.272", "loss_features_pen": "0.012", "correct_m_0": "0.484509", "correct_u_0": "0.719566", "ppl": "8.19", "wps": "10466.2", "ups": "0.16", "wpb": "65966.5", "bsz": "198", "num_updates": "48600", "lr": "0.000377941", "gnorm": "0.677", "clip": "0", "loss_scale": "4", "train_wall": "1237", "gb_free": "65.7", "wall": "311589"}
[2023-11-25 10:29:41,494][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 93 @ 48653 updates
[2023-11-25 10:29:41,495][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 10:29:46,695][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 10:29:46,709][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 93 @ 48653 updates, score None) (writing took 5.214675133116543 seconds)
[2023-11-25 10:29:46,709][fairseq_cli.train][INFO] - end of epoch 93 (average epoch stats below)
[2023-11-25 10:29:46,727][train][INFO] - {"epoch": 93, "train_loss": "3.032", "train_count_m_0": "65933.5", "train_count_u_0": "58220.1", "train_loss_m_0": "3.02", "train_loss_u_0": "1.281", "train_loss_features_pen": "0.012", "train_correct_m_0": "0.484756", "train_correct_u_0": "0.718686", "train_ppl": "8.18", "train_wps": "10485.1", "train_ups": "0.16", "train_wpb": "65933.5", "train_bsz": "198.1", "train_num_updates": "48653", "train_lr": "0.000377551", "train_gnorm": "0.677", "train_clip": "0", "train_loss_scale": "4", "train_train_wall": "3222", "train_gb_free": "65.4", "train_wall": "311918"}
[2023-11-25 10:29:46,728][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-25 10:29:46,796][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-25 10:29:46,799][fairseq.trainer][INFO] - begin training epoch 94
[2023-11-25 10:29:46,799][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-25 10:33:36,713][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-25 10:44:34,574][train_inner][INFO] - {"epoch": 94, "update": 93.282, "loss": "3.029", "count_m_0": "65952.3", "count_u_0": "58218.2", "loss_m_0": "3.017", "loss_u_0": "1.277", "loss_features_pen": "0.012", "correct_m_0": "0.485194", "correct_u_0": "0.71969", "ppl": "8.16", "wps": "10836.5", "ups": "0.16", "wpb": "65952.3", "bsz": "198", "num_updates": "48800", "lr": "0.000376471", "gnorm": "0.677", "clip": "0", "loss_scale": "2", "train_wall": "1188", "gb_free": "65.4", "wall": "312806"}
[2023-11-25 11:04:31,860][train_inner][INFO] - {"epoch": 94, "update": 93.664, "loss": "3.027", "count_m_0": "65937", "count_u_0": "58155.2", "loss_m_0": "3.015", "loss_u_0": "1.275", "loss_features_pen": "0.011", "correct_m_0": "0.485446", "correct_u_0": "0.719489", "ppl": "8.15", "wps": "11014.5", "ups": "0.17", "wpb": "65937", "bsz": "197.2", "num_updates": "49000", "lr": "0.000375", "gnorm": "0.674", "clip": "0", "loss_scale": "2", "train_wall": "1174", "gb_free": "65.4", "wall": "314003"}
[2023-11-25 11:22:02,499][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 94 @ 49176 updates
[2023-11-25 11:22:02,499][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 11:22:06,699][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 11:22:06,708][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 94 @ 49176 updates, score None) (writing took 4.209887044969946 seconds)
[2023-11-25 11:22:06,709][fairseq_cli.train][INFO] - end of epoch 94 (average epoch stats below)
[2023-11-25 11:22:06,723][train][INFO] - {"epoch": 94, "train_loss": "3.026", "train_count_m_0": "65940.2", "train_count_u_0": "58217.9", "train_loss_m_0": "3.014", "train_loss_u_0": "1.276", "train_loss_features_pen": "0.012", "train_correct_m_0": "0.485491", "train_correct_u_0": "0.719591", "train_ppl": "8.15", "train_wps": "10983.1", "train_ups": "0.17", "train_wpb": "65940.2", "train_bsz": "198.1", "train_num_updates": "49176", "train_lr": "0.000373706", "train_gnorm": "0.675", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3075", "train_gb_free": "65.3", "train_wall": "315058"}
[2023-11-25 11:22:06,723][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-25 11:22:06,790][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-25 11:22:06,792][fairseq.trainer][INFO] - begin training epoch 95
[2023-11-25 11:22:06,793][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-25 11:24:29,773][train_inner][INFO] - {"epoch": 95, "update": 94.046, "loss": "3.023", "count_m_0": "65933.2", "count_u_0": "58268.4", "loss_m_0": "3.011", "loss_u_0": "1.273", "loss_features_pen": "0.012", "correct_m_0": "0.485654", "correct_u_0": "0.72005", "ppl": "8.13", "wps": "11008.2", "ups": "0.17", "wpb": "65933.2", "bsz": "199.1", "num_updates": "49200", "lr": "0.000373529", "gnorm": "0.674", "clip": "0", "loss_scale": "2", "train_wall": "1170", "gb_free": "65.7", "wall": "315201"}
[2023-11-25 11:42:42,696][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-25 11:44:30,630][train_inner][INFO] - {"epoch": 95, "update": 94.429, "loss": "3.025", "count_m_0": "65989.6", "count_u_0": "58163.6", "loss_m_0": "3.013", "loss_u_0": "1.281", "loss_features_pen": "0.012", "correct_m_0": "0.485679", "correct_u_0": "0.71906", "ppl": "8.14", "wps": "10990.6", "ups": "0.17", "wpb": "65989.6", "bsz": "197.6", "num_updates": "49400", "lr": "0.000372059", "gnorm": "0.675", "clip": "0", "loss_scale": "2", "train_wall": "1177", "gb_free": "65.1", "wall": "316402"}
[2023-11-25 12:04:26,682][train_inner][INFO] - {"epoch": 95, "update": 94.811, "loss": "3.017", "count_m_0": "65894.1", "count_u_0": "58202.5", "loss_m_0": "3.005", "loss_u_0": "1.275", "loss_features_pen": "0.011", "correct_m_0": "0.486735", "correct_u_0": "0.720097", "ppl": "8.09", "wps": "11018.8", "ups": "0.17", "wpb": "65894.1", "bsz": "198", "num_updates": "49600", "lr": "0.000370588", "gnorm": "0.675", "clip": "0", "loss_scale": "2", "train_wall": "1173", "gb_free": "65.6", "wall": "317598"}
[2023-11-25 12:14:18,130][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-25 12:14:18,131][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-25 12:14:39,400][dev-other][INFO] - {"epoch": 95, "dev-other_loss": "3.534", "dev-other_count_m_0": "1719", "dev-other_count_u_0": "1677.81", "dev-other_loss_m_0": "3.496", "dev-other_loss_u_0": "1.949", "dev-other_loss_features_pen": "0.011", "dev-other_correct_m_0": "0.424909", "dev-other_correct_u_0": "0.626063", "dev-other_ppl": "11.58", "dev-other_wps": "21173.9", "dev-other_wpb": "1719", "dev-other_bsz": "10.8", "dev-other_num_updates": "49699", "dev-other_best_loss": "3.534"}
[2023-11-25 12:14:39,401][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-25 12:14:39,401][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-25 12:15:00,859][dev-clean][INFO] - {"epoch": 95, "dev-clean_loss": "2.887", "dev-clean_count_m_0": "1778.17", "dev-clean_count_u_0": "1697.28", "dev-clean_loss_m_0": "2.836", "dev-clean_loss_u_0": "1.494", "dev-clean_loss_features_pen": "0.011", "dev-clean_correct_m_0": "0.504791", "dev-clean_correct_u_0": "0.694863", "dev-clean_ppl": "7.4", "dev-clean_wps": "22213.8", "dev-clean_wpb": "1778.2", "dev-clean_bsz": "10", "dev-clean_num_updates": "49699"}
[2023-11-25 12:15:00,860][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 95 @ 49699 updates
[2023-11-25 12:15:00,861][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-25 12:15:07,611][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt
[2023-11-25 12:15:13,013][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_best.pt (epoch 95 @ 49699 updates, score 3.534) (writing took 12.152637566905469 seconds)
[2023-11-25 12:15:13,013][fairseq_cli.train][INFO] - end of epoch 95 (average epoch stats below)
[2023-11-25 12:15:13,074][train][INFO] - {"epoch": 95, "train_loss": "3.021", "train_count_m_0": "65947", "train_count_u_0": "58213.1", "train_loss_m_0": "3.01", "train_loss_u_0": "1.276", "train_loss_features_pen": "0.011", "train_correct_m_0": "0.486129", "train_correct_u_0": "0.719767", "train_ppl": "8.12", "train_wps": "10824.6", "train_ups": "0.16", "train_wpb": "65947", "train_bsz": "198.1", "train_num_updates": "49699", "train_lr": "0.00036986", "train_gnorm": "0.675", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3071", "train_gb_free": "65.7", "train_wall": "318244"}
[2023-11-25 12:15:13,075][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-25 12:15:13,150][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-25 12:15:13,152][fairseq.trainer][INFO] - begin training epoch 96
[2023-11-25 12:15:13,152][fairseq_cli.train][INFO] - Start iterating over samples
[2023-11-25 12:25:19,561][train_inner][INFO] - {"epoch": 96, "update": 95.193, "loss": "3.016", "count_m_0": "65994.6", "count_u_0": "58287.2", "loss_m_0": "3.004", "loss_u_0": "1.274", "loss_features_pen": "0.011", "correct_m_0": "0.486943", "correct_u_0": "0.720002", "ppl": "8.09", "wps": "10535.1", "ups": "0.16", "wpb": "65994.6", "bsz": "198.7", "num_updates": "49800", "lr": "0.000369118", "gnorm": "0.675", "clip": "0", "loss_scale": "2", "train_wall": "1175", "gb_free": "65.6", "wall": "318851"}
[2023-11-25 12:45:16,400][train_inner][INFO] - {"epoch": 96, "update": 95.574, "loss": "3.008", "count_m_0": "65840.6", "count_u_0": "58152.6", "loss_m_0": "2.996", "loss_u_0": "1.289", "loss_features_pen": "0.011", "correct_m_0": "0.487834", "correct_u_0": "0.718803", "ppl": "8.04", "wps": "11002.6", "ups": "0.17", "wpb": "65840.6", "bsz": "198.9", "num_updates": "50000", "lr": "0.000367647", "gnorm": "0.674", "clip": "0", "loss_scale": "4", "train_wall": "1174", "gb_free": "65.4", "wall": "320048"}
[2023-11-25 12:45:16,401][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2023-11-25 12:45:16,401][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-25 12:45:37,868][dev-other][INFO] - {"epoch": 96, "dev-other_loss": "3.581", "dev-other_count_m_0": "1724.49", "dev-other_count_u_0": "1672.27", "dev-other_loss_m_0": "3.537", "dev-other_loss_u_0": "1.951", "dev-other_loss_features_pen": "0.011", "dev-other_correct_m_0": "0.419794", "dev-other_correct_u_0": "0.623517", "dev-other_ppl": "11.97", "dev-other_wps": "21049.9", "dev-other_wpb": "1724.5", "dev-other_bsz": "10.8", "dev-other_num_updates": "50000", "dev-other_best_loss": "3.534"}
[2023-11-25 12:45:37,868][fairseq_cli.train][INFO] - begin validation on "dev-clean" subset
[2023-11-25 12:45:37,868][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-25 12:45:59,658][dev-clean][INFO] - {"epoch": 96, "dev-clean_loss": "2.832", "dev-clean_count_m_0": "1769.5", "dev-clean_count_u_0": "1706.26", "dev-clean_loss_m_0": "2.781", "dev-clean_loss_u_0": "1.487", "dev-clean_loss_features_pen": "0.011", "dev-clean_correct_m_0": "0.512643", "dev-clean_correct_u_0": "0.699104", "dev-clean_ppl": "7.12", "dev-clean_wps": "21759", "dev-clean_wpb": "1769.5", "dev-clean_bsz": "10", "dev-clean_num_updates": "50000"}
[2023-11-25 12:45:59,659][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 96 @ 50000 updates
[2023-11-25 12:45:59,660][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_96_50000.pt
[2023-11-25 12:46:03,269][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_96_50000.pt
[2023-11-25 12:46:08,925][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_96_50000.pt (epoch 96 @ 50000 updates, score 3.581) (writing took 9.265585854882374 seconds)
[2023-11-25 13:05:09,157][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-11-25 13:06:14,591][train_inner][INFO] - {"epoch": 96, "update": 95.958, "loss": "3.013", "count_m_0": "66013.6", "count_u_0": "58277.8", "loss_m_0": "3.001", "loss_u_0": "1.286", "loss_features_pen": "0.011", "correct_m_0": "0.487361", "correct_u_0": "0.718814", "ppl": "8.07", "wps": "10493.5", "ups": "0.16", "wpb": "66013.6", "bsz": "196.7", "num_updates": "50200", "lr": "0.000366176", "gnorm": "0.673", "clip": "0", "loss_scale": "2", "train_wall": "1183", "gb_free": "65.5", "wall": "321306"}
[2023-11-25 13:08:25,589][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 96 @ 50222 updates
[2023-11-25 13:08:25,590][fairseq.trainer][INFO] - Saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 13:08:29,616][fairseq.trainer][INFO] - Finished saving checkpoint to /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt
[2023-11-25 13:08:29,625][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntnfs/lee_data1/maduo/exp/pretrain/continue_pretain_base_hubert_with_llama_on_train_360/checkpoint_last.pt (epoch 96 @ 50222 updates, score None) (writing took 4.0353723738808185 seconds)
[2023-11-25 13:08:29,625][fairseq_cli.train][INFO] - end of epoch 96 (average epoch stats below)
[2023-11-25 13:08:29,639][train][INFO] - {"epoch": 96, "train_loss": "3.01", "train_count_m_0": "65935.1", "train_count_u_0": "58218.7", "train_loss_m_0": "2.998", "train_loss_u_0": "1.287", "train_loss_features_pen": "0.011", "train_correct_m_0": "0.487692", "train_correct_u_0": "0.718828", "train_ppl": "8.05", "train_wps": "10787.9", "train_ups": "0.16", "train_wpb": "65935.1", "train_bsz": "198.1", "train_num_updates": "50222", "train_lr": "0.000366015", "train_gnorm": "0.674", "train_clip": "0", "train_loss_scale": "2", "train_train_wall": "3079", "train_gb_free": "65.4", "train_wall": "321441"}
[2023-11-25 13:08:29,640][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-11-25 13:08:29,705][fairseq.data.iterators][INFO] - grouped total_num_itrs = 524
[2023-11-25 13:08:29,709][fairseq.trainer][INFO] - begin training epoch 97
[2023-11-25 13:08:29,710][fairseq_cli.train][INFO] - Start iterating over samples
