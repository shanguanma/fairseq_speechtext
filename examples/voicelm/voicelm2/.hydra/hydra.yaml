hydra:
  run:
    dir: /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/voicelm/voicelm2
  sweep:
    dir: ???
    subdir: ${hydra.job.config_name}__${hydra.job.override_dirname}
  hydra_logging:
    version: 1
    formatters:
      simple:
        format: '[%(asctime)s][HYDRA] %(message)s'
    handlers:
      console:
        class: logging.StreamHandler
        formatter: simple
        stream: ext://sys.stdout
    root:
      level: INFO
      handlers:
      - console
    loggers:
      logging_example:
        level: DEBUG
    disable_existing_loggers: false
  job_logging:
    version: 1
    formatters:
      simple:
        format: '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'
    handlers:
      console:
        class: logging.StreamHandler
        formatter: simple
        stream: ext://sys.stdout
      file:
        class: logging.FileHandler
        formatter: simple
        filename: ${hydra.job.name}.log
    root:
      level: INFO
      handlers:
      - console
      - file
    disable_existing_loggers: false
  sweeper:
    _target_: hydra._internal.core_plugins.basic_sweeper.BasicSweeper
    max_batch_size: null
  launcher:
    _target_: hydra._internal.core_plugins.basic_launcher.BasicLauncher
  help:
    app_name: ${hydra.job.name}
    header: '${hydra.help.app_name} is powered by Hydra.

      '
    footer: 'Powered by Hydra (https://hydra.cc)

      Use --hydra-help to view Hydra specific help

      '
    template: '${hydra.help.header}

      == Configuration groups ==

      Compose your configuration from those groups (group=option)


      $APP_CONFIG_GROUPS


      == Config ==

      Override anything in the config (foo.bar=value)


      $CONFIG


      ${hydra.help.footer}

      '
  hydra_help:
    hydra_help: ???
    template: 'Hydra (${hydra.runtime.version})

      See https://hydra.cc for more info.


      == Flags ==

      $FLAGS_HELP


      == Configuration groups ==

      Compose your configuration from those groups (For example, append hydra/job_logging=disabled
      to command line)


      $HYDRA_CONFIG_GROUPS


      Use ''--cfg hydra'' to Show the Hydra config.

      '
  output_subdir: .hydra
  overrides:
    hydra:
    - hydra.run.dir=/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/voicelm/voicelm2
    - hydra.job.name=/mntnfs/lee_data1/maduo/exp/finetune/pretrain_on_base_voicelm2_4gpu_8update_960h_400k_update_flash_attention_lr4e_4_100h_asr_finetune_text_drop_true_feature_fuse_wo_freeze/finetune
    task:
    - task.data=/mntcephfs/lab_data/maduo/datasets/format/librispeech/
    - task.label_dir=/mntcephfs/lab_data/maduo/datasets/format/librispeech//librispeech_lm_monophncode_using_monophn_dict_librispeech_frame_monophncode_using_wav2vec-u2_model
    - task.labels=["ltr","textphncode"]
    - task.text_drop=true
    - model.w2v_path=/mntnfs/lee_data1/maduo/exp/pretrain/pretrain_on_base_voicelm2_4gpu_8update_960h_400k_update_flash_attention_lr4e_4/checkpoint_359_400000.pt
    - model.feature_fuse_freeze=false
    - common.user_dir=/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/voicelm/voicelm2
    - dataset.train_subset=train-clean-100
    - dataset.valid_subset='dev-other'
    - distributed_training.distributed_world_size=4
    - distributed_training.distributed_port=-1
    - distributed_training.ddp_backend=legacy_ddp
    - optimization.update_freq=[2]
    - common.tensorboard_logdir=/mntnfs/lee_data1/maduo/exp/finetune/pretrain_on_base_voicelm2_4gpu_8update_960h_400k_update_flash_attention_lr4e_4_100h_asr_finetune_text_drop_true_feature_fuse_wo_freeze
    - checkpoint.save_dir=/mntnfs/lee_data1/maduo/exp/finetune/pretrain_on_base_voicelm2_4gpu_8update_960h_400k_update_flash_attention_lr4e_4_100h_asr_finetune_text_drop_true_feature_fuse_wo_freeze
  job:
    name: /mntnfs/lee_data1/maduo/exp/finetune/pretrain_on_base_voicelm2_4gpu_8update_960h_400k_update_flash_attention_lr4e_4_100h_asr_finetune_text_drop_true_feature_fuse_wo_freeze/finetune
    override_dirname: checkpoint.save_dir-/mntnfs/lee_data1/maduo/exp/finetune/pretrain_on_base_voicelm2_4gpu_8update_960h_400k_update_flash_attention_lr4e_4_100h_asr_finetune_text_drop_true_feature_fuse_wo_freeze__common.tensorboard_logdir-/mntnfs/lee_data1/maduo/exp/finetune/pretrain_on_base_voicelm2_4gpu_8update_960h_400k_update_flash_attention_lr4e_4_100h_asr_finetune_text_drop_true_feature_fuse_wo_freeze__common.user_dir-/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/voicelm/voicelm2__distributed_training.ddp_backend-legacy_ddp__distributed_training.distributed_port--1__distributed_training.distributed_world_size-4__model.feature_fuse_freeze-false__optimization.update_freq-[2]__task.labels-["ltr","textphncode"]__task.text_drop-true
    id: ???
    num: ???
    config_name: voicelm2_base_100h_ctc_ltr
    env_set: {}
    env_copy: []
    config:
      override_dirname:
        kv_sep: '-'
        item_sep: __
        exclude_keys:
        - run
        - task.data
        - task.label_dir
        - model.w2v_path
        - dataset.train_subset
        - dataset.valid_subset
        - criterion.wer_kenlm_model
        - criterion.wer_lexicon
  runtime:
    version: 1.0.7
    cwd: /mntnfs/lee_data1/maduo
  verbose: false
