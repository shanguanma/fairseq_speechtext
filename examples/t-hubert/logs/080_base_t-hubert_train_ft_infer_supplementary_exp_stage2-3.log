Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple
Requirement already satisfied: ninja in /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages (1.11.1)
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/setuptools/dist.py:490: UserWarning: Normalizing 'V1.0.0' to '1.0.0'
  warnings.warn(tmpl.format(**locals()))
running build_ext
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/utils/cpp_extension.py:398: UserWarning: There are no /cm/local/apps/gcc/11.2.0/bin/g++ version bounds defined for CUDA version 11.8
  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')
cythoning fairseq/data/data_utils_fast.pyx to fairseq/data/data_utils_fast.cpp
cythoning fairseq/data/token_block_utils_fast.pyx to fairseq/data/token_block_utils_fast.cpp
building 'fairseq.libbleu' extension
Emitting ninja build file /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/2] /cm/local/apps/gcc/11.2.0/bin/g++ -MMD -MF /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/libbleu/module.o.d -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -fPIC -O2 -isystem /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: -fPIC -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include/python3.9 -c -c /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libbleu/module.cpp -o /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/libbleu/module.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=libbleu -D_GLIBCXX_USE_CXX11_ABI=0
[2/2] /cm/local/apps/gcc/11.2.0/bin/g++ -MMD -MF /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/libbleu/libbleu.o.d -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -fPIC -O2 -isystem /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: -fPIC -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include/python3.9 -c -c /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libbleu/libbleu.cpp -o /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/libbleu/libbleu.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=libbleu -D_GLIBCXX_USE_CXX11_ABI=0
/cm/local/apps/gcc/11.2.0/bin/g++ -pthread -B /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/compiler_compat -shared -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/libbleu/libbleu.o /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/libbleu/module.o -o build/lib.linux-x86_64-3.9/fairseq/libbleu.cpython-39-x86_64-linux-gnu.so
building 'fairseq.data.data_utils_fast' extension
Emitting ninja build file /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/1] /cm/local/apps/gcc/11.2.0/bin/g++ -MMD -MF /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/data/data_utils_fast.o.d -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -fPIC -O2 -isystem /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: -fPIC -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/numpy/core/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/numpy/core/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include/python3.9 -c -c /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/data/data_utils_fast.cpp -o /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/data/data_utils_fast.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=data_utils_fast -D_GLIBCXX_USE_CXX11_ABI=0
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h:1948,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h:12,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h:5,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/data/data_utils_fast.cpp:760:
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: warning: #warning "Using deprecated NumPy API, disable it with " "#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION" [-Wcpp]
   17 | #warning "Using deprecated NumPy API, disable it with " \
      |  ^~~~~~~
/cm/local/apps/gcc/11.2.0/bin/g++ -pthread -B /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/compiler_compat -shared -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/data/data_utils_fast.o -o build/lib.linux-x86_64-3.9/fairseq/data/data_utils_fast.cpython-39-x86_64-linux-gnu.so
building 'fairseq.data.token_block_utils_fast' extension
Emitting ninja build file /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/1] /cm/local/apps/gcc/11.2.0/bin/g++ -MMD -MF /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/data/token_block_utils_fast.o.d -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -fPIC -O2 -isystem /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: -fPIC -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/numpy/core/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/numpy/core/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include/python3.9 -c -c /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/data/token_block_utils_fast.cpp -o /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/data/token_block_utils_fast.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=token_block_utils_fast -D_GLIBCXX_USE_CXX11_ABI=0
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h:1948,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h:12,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h:5,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/data/token_block_utils_fast.cpp:761:
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: warning: #warning "Using deprecated NumPy API, disable it with " "#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION" [-Wcpp]
   17 | #warning "Using deprecated NumPy API, disable it with " \
      |  ^~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/data/token_block_utils_fast.cpp: In function ‘PyArrayObject* __pyx_f_7fairseq_4data_22token_block_utils_fast__get_slice_indices_fast(PyArrayObject*, PyObject*, int, int, int)’:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/data/token_block_utils_fast.cpp:3469:36: warning: comparison of integer expressions of different signedness: ‘__pyx_t_7fairseq_4data_22token_block_utils_fast_DTYPE_t’ {aka ‘long int’} and ‘size_t’ {aka ‘long unsigned int’} [-Wsign-compare]
 3469 |       __pyx_t_4 = ((__pyx_v_sz_idx < __pyx_t_10) != 0);
      |                     ~~~~~~~~~~~~~~~^~~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/data/token_block_utils_fast.cpp:3664:36: warning: comparison of integer expressions of different signedness: ‘__pyx_t_7fairseq_4data_22token_block_utils_fast_DTYPE_t’ {aka ‘long int’} and ‘size_t’ {aka ‘long unsigned int’} [-Wsign-compare]
 3664 |       __pyx_t_3 = ((__pyx_v_sz_idx < __pyx_t_10) != 0);
      |                     ~~~~~~~~~~~~~~~^~~~~~~~~~~~
/cm/local/apps/gcc/11.2.0/bin/g++ -pthread -B /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/compiler_compat -shared -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/data/token_block_utils_fast.o -o build/lib.linux-x86_64-3.9/fairseq/data/token_block_utils_fast.cpython-39-x86_64-linux-gnu.so
building 'fairseq.libbase' extension
Emitting ninja build file /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/1] /cm/local/apps/gcc/11.2.0/bin/g++ -MMD -MF /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/libbase/balanced_assignment.o.d -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -fPIC -O2 -isystem /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: -fPIC -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/TH -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/THC -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include/python3.9 -c -c /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libbase/balanced_assignment.cpp -o /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/libbase/balanced_assignment.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=libbase -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
/cm/local/apps/gcc/11.2.0/bin/g++ -pthread -B /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/compiler_compat -shared -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/libbase/balanced_assignment.o -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.9/fairseq/libbase.cpython-39-x86_64-linux-gnu.so
building 'fairseq.libnat' extension
Emitting ninja build file /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/1] /cm/local/apps/gcc/11.2.0/bin/g++ -MMD -MF /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/libnat/edit_dist.o.d -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -fPIC -O2 -isystem /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: -fPIC -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/TH -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/THC -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include/python3.9 -c -c /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat/edit_dist.cpp -o /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/libnat/edit_dist.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=libnat -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
/cm/local/apps/gcc/11.2.0/bin/g++ -pthread -B /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/compiler_compat -shared -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/libnat/edit_dist.o -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.9/fairseq/libnat.cpython-39-x86_64-linux-gnu.so
building 'alignment_train_cpu_binding' extension
Emitting ninja build file /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/1] /cm/local/apps/gcc/11.2.0/bin/g++ -MMD -MF /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/examples/operators/alignment_train_cpu.o.d -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -fPIC -O2 -isystem /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: -fPIC -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/TH -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/THC -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include/python3.9 -c -c /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp -o /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/examples/operators/alignment_train_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=alignment_train_cpu_binding -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
In function ‘void {anonymous}::alignmentTrainCPUImpl(const T*, T*, uint32_t, uint32_t, uint32_t, float) [with T = double]’,
    inlined from ‘{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>::<lambda()>’ at /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:143:3,
    inlined from ‘{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>’ at /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:143:3,
    inlined from ‘void {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)’ at /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:143:3:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:131:7: warning: ‘void free(void*)’ called on pointer returned from a mismatched allocation function [-Wmismatched-new-delete]
  131 |   free(cumprod_1mp);
      |   ~~~~^~~~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp: In function ‘void {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)’:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:93:20: note: returned from ‘void* operator new [](std::size_t)’
   93 |   T* cumprod_1mp = new T[elements];
      |                    ^~~~~~~~~~~~~~~
In function ‘void {anonymous}::alignmentTrainCPUImpl(const T*, T*, uint32_t, uint32_t, uint32_t, float) [with T = double]’,
    inlined from ‘{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>::<lambda()>’ at /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:143:3,
    inlined from ‘{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>’ at /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:143:3,
    inlined from ‘void {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)’ at /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:143:3:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:132:7: warning: ‘void free(void*)’ called on pointer returned from a mismatched allocation function [-Wmismatched-new-delete]
  132 |   free(cumprod_1mp_clamp);
      |   ~~~~^~~~~~~~~~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp: In function ‘void {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)’:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:94:26: note: returned from ‘void* operator new [](std::size_t)’
   94 |   T* cumprod_1mp_clamp = new T[elements];
      |                          ^~~~~~~~~~~~~~~
In function ‘void {anonymous}::alignmentTrainCPUImpl(const T*, T*, uint32_t, uint32_t, uint32_t, float) [with T = float]’,
    inlined from ‘{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>::<lambda()>’ at /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:143:3,
    inlined from ‘{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>’ at /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:143:3,
    inlined from ‘void {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)’ at /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:143:3:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:131:7: warning: ‘void free(void*)’ called on pointer returned from a mismatched allocation function [-Wmismatched-new-delete]
  131 |   free(cumprod_1mp);
      |   ~~~~^~~~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp: In function ‘void {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)’:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:93:20: note: returned from ‘void* operator new [](std::size_t)’
   93 |   T* cumprod_1mp = new T[elements];
      |                    ^~~~~~~~~~~~~~~
In function ‘void {anonymous}::alignmentTrainCPUImpl(const T*, T*, uint32_t, uint32_t, uint32_t, float) [with T = float]’,
    inlined from ‘{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>::<lambda()>’ at /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:143:3,
    inlined from ‘{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>’ at /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:143:3,
    inlined from ‘void {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)’ at /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:143:3:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:132:7: warning: ‘void free(void*)’ called on pointer returned from a mismatched allocation function [-Wmismatched-new-delete]
  132 |   free(cumprod_1mp_clamp);
      |   ~~~~^~~~~~~~~~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp: In function ‘void {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)’:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:94:26: note: returned from ‘void* operator new [](std::size_t)’
   94 |   T* cumprod_1mp_clamp = new T[elements];
      |                          ^~~~~~~~~~~~~~~
In function ‘void {anonymous}::alignmentTrainCPUImpl(const T*, T*, uint32_t, uint32_t, uint32_t, float) [with T = c10::Half]’,
    inlined from ‘{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>::<lambda()>’ at /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:143:3,
    inlined from ‘{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>’ at /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:143:3,
    inlined from ‘void {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)’ at /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:143:3:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:131:7: warning: ‘void free(void*)’ called on pointer returned from a mismatched allocation function [-Wmismatched-new-delete]
  131 |   free(cumprod_1mp);
      |   ~~~~^~~~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp: In function ‘void {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)’:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:93:20: note: returned from ‘void* operator new [](std::size_t)’
   93 |   T* cumprod_1mp = new T[elements];
      |                    ^~~~~~~~~~~~~~~
In function ‘void {anonymous}::alignmentTrainCPUImpl(const T*, T*, uint32_t, uint32_t, uint32_t, float) [with T = c10::Half]’,
    inlined from ‘{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>::<lambda()>’ at /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:143:3,
    inlined from ‘{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>’ at /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:143:3,
    inlined from ‘void {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)’ at /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:143:3:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:132:7: warning: ‘void free(void*)’ called on pointer returned from a mismatched allocation function [-Wmismatched-new-delete]
  132 |   free(cumprod_1mp_clamp);
      |   ~~~~^~~~~~~~~~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp: In function ‘void {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)’:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:94:26: note: returned from ‘void* operator new [](std::size_t)’
   94 |   T* cumprod_1mp_clamp = new T[elements];
      |                          ^~~~~~~~~~~~~~~
In function ‘void {anonymous}::alignmentTrainCPUImpl(const T*, T*, uint32_t, uint32_t, uint32_t, float) [with T = c10::BFloat16]’,
    inlined from ‘{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>::<lambda()>’ at /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:143:3,
    inlined from ‘{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>’ at /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:143:3,
    inlined from ‘void {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)’ at /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:143:3:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:131:7: warning: ‘void free(void*)’ called on pointer returned from a mismatched allocation function [-Wmismatched-new-delete]
  131 |   free(cumprod_1mp);
      |   ~~~~^~~~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp: In function ‘void {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)’:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:93:20: note: returned from ‘void* operator new [](std::size_t)’
   93 |   T* cumprod_1mp = new T[elements];
      |                    ^~~~~~~~~~~~~~~
In function ‘void {anonymous}::alignmentTrainCPUImpl(const T*, T*, uint32_t, uint32_t, uint32_t, float) [with T = c10::BFloat16]’,
    inlined from ‘{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>::<lambda()>’ at /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:143:3,
    inlined from ‘{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>’ at /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:143:3,
    inlined from ‘void {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)’ at /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:143:3:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:132:7: warning: ‘void free(void*)’ called on pointer returned from a mismatched allocation function [-Wmismatched-new-delete]
  132 |   free(cumprod_1mp_clamp);
      |   ~~~~^~~~~~~~~~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp: In function ‘void {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)’:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cpu.cpp:94:26: note: returned from ‘void* operator new [](std::size_t)’
   94 |   T* cumprod_1mp_clamp = new T[elements];
      |                          ^~~~~~~~~~~~~~~
/cm/local/apps/gcc/11.2.0/bin/g++ -pthread -B /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/compiler_compat -shared -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/examples/operators/alignment_train_cpu.o -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.9/alignment_train_cpu_binding.cpython-39-x86_64-linux-gnu.so
building 'fairseq.libnat_cuda' extension
Emitting ninja build file /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/2] /cm/local/apps/gcc/11.2.0/bin/g++ -MMD -MF /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/libnat_cuda/binding.o.d -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -fPIC -O2 -isystem /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: -fPIC -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/TH -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/THC -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include/python3.9 -c -c /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp -o /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/libnat_cuda/binding.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=libnat_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/Exception.h:4,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/Generator.h:11,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/CPUGeneratorImpl.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/Context.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/ATen.h:7,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:14:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp: In function ‘at::Tensor LevenshteinDistance(at::Tensor, at::Tensor, at::Tensor, at::Tensor)’:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:22:21: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
   22 |   TORCH_CHECK(x.type().is_cuda(), #x " must be a CUDA tensor")
      |                     ^
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/macros/Macros.h:200:64: note: in definition of macro ‘C10_UNLIKELY’
  200 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))
      |                                                                ^~~~
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/Exception.h:506:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’
  506 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \
      |       ^~~~~~~~~~~~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:22:3: note: in expansion of macro ‘TORCH_CHECK’
   22 |   TORCH_CHECK(x.type().is_cuda(), #x " must be a CUDA tensor")
      |   ^~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:26:3: note: in expansion of macro ‘CHECK_CUDA’
   26 |   CHECK_CUDA(x);       \
      |   ^~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:34:3: note: in expansion of macro ‘CHECK_INPUT’
   34 |   CHECK_INPUT(source);
      |   ^~~~~~~~~~~
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/ivalue.h:4,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/List_inl.h:4,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/List.h:494,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/IListRef_inl.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/IListRef.h:632,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/DeviceGuard.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/ATen.h:9,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:14:
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here
  222 |   DeprecatedTypeProperties & type() const {
      |                              ^~~~
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/Exception.h:4,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/Generator.h:11,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/CPUGeneratorImpl.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/Context.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/ATen.h:7,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:14:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:22:21: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
   22 |   TORCH_CHECK(x.type().is_cuda(), #x " must be a CUDA tensor")
      |                     ^
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/macros/Macros.h:200:64: note: in definition of macro ‘C10_UNLIKELY’
  200 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))
      |                                                                ^~~~
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/Exception.h:506:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’
  506 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \
      |       ^~~~~~~~~~~~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:22:3: note: in expansion of macro ‘TORCH_CHECK’
   22 |   TORCH_CHECK(x.type().is_cuda(), #x " must be a CUDA tensor")
      |   ^~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:26:3: note: in expansion of macro ‘CHECK_CUDA’
   26 |   CHECK_CUDA(x);       \
      |   ^~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:35:3: note: in expansion of macro ‘CHECK_INPUT’
   35 |   CHECK_INPUT(target);
      |   ^~~~~~~~~~~
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/ivalue.h:4,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/List_inl.h:4,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/List.h:494,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/IListRef_inl.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/IListRef.h:632,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/DeviceGuard.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/ATen.h:9,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:14:
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here
  222 |   DeprecatedTypeProperties & type() const {
      |                              ^~~~
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/Exception.h:4,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/Generator.h:11,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/CPUGeneratorImpl.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/Context.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/ATen.h:7,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:14:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:22:21: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
   22 |   TORCH_CHECK(x.type().is_cuda(), #x " must be a CUDA tensor")
      |                     ^
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/macros/Macros.h:200:64: note: in definition of macro ‘C10_UNLIKELY’
  200 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))
      |                                                                ^~~~
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/Exception.h:506:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’
  506 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \
      |       ^~~~~~~~~~~~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:22:3: note: in expansion of macro ‘TORCH_CHECK’
   22 |   TORCH_CHECK(x.type().is_cuda(), #x " must be a CUDA tensor")
      |   ^~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:26:3: note: in expansion of macro ‘CHECK_CUDA’
   26 |   CHECK_CUDA(x);       \
      |   ^~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:36:3: note: in expansion of macro ‘CHECK_INPUT’
   36 |   CHECK_INPUT(source_length);
      |   ^~~~~~~~~~~
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/ivalue.h:4,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/List_inl.h:4,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/List.h:494,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/IListRef_inl.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/IListRef.h:632,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/DeviceGuard.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/ATen.h:9,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:14:
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here
  222 |   DeprecatedTypeProperties & type() const {
      |                              ^~~~
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/Exception.h:4,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/Generator.h:11,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/CPUGeneratorImpl.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/Context.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/ATen.h:7,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:14:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:22:21: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
   22 |   TORCH_CHECK(x.type().is_cuda(), #x " must be a CUDA tensor")
      |                     ^
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/macros/Macros.h:200:64: note: in definition of macro ‘C10_UNLIKELY’
  200 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))
      |                                                                ^~~~
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/Exception.h:506:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’
  506 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \
      |       ^~~~~~~~~~~~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:22:3: note: in expansion of macro ‘TORCH_CHECK’
   22 |   TORCH_CHECK(x.type().is_cuda(), #x " must be a CUDA tensor")
      |   ^~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:26:3: note: in expansion of macro ‘CHECK_CUDA’
   26 |   CHECK_CUDA(x);       \
      |   ^~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:37:3: note: in expansion of macro ‘CHECK_INPUT’
   37 |   CHECK_INPUT(target_length);
      |   ^~~~~~~~~~~
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/ivalue.h:4,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/List_inl.h:4,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/List.h:494,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/IListRef_inl.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/IListRef.h:632,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/DeviceGuard.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/ATen.h:9,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:14:
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here
  222 |   DeprecatedTypeProperties & type() const {
      |                              ^~~~
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/Exception.h:4,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/Generator.h:11,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/CPUGeneratorImpl.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/Context.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/ATen.h:7,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:14:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp: In function ‘at::Tensor GenerateDeletionLabel(at::Tensor, at::Tensor)’:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:22:21: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
   22 |   TORCH_CHECK(x.type().is_cuda(), #x " must be a CUDA tensor")
      |                     ^
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/macros/Macros.h:200:64: note: in definition of macro ‘C10_UNLIKELY’
  200 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))
      |                                                                ^~~~
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/Exception.h:506:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’
  506 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \
      |       ^~~~~~~~~~~~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:22:3: note: in expansion of macro ‘TORCH_CHECK’
   22 |   TORCH_CHECK(x.type().is_cuda(), #x " must be a CUDA tensor")
      |   ^~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:26:3: note: in expansion of macro ‘CHECK_CUDA’
   26 |   CHECK_CUDA(x);       \
      |   ^~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:44:3: note: in expansion of macro ‘CHECK_INPUT’
   44 |   CHECK_INPUT(source);
      |   ^~~~~~~~~~~
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/ivalue.h:4,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/List_inl.h:4,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/List.h:494,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/IListRef_inl.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/IListRef.h:632,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/DeviceGuard.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/ATen.h:9,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:14:
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here
  222 |   DeprecatedTypeProperties & type() const {
      |                              ^~~~
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/Exception.h:4,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/Generator.h:11,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/CPUGeneratorImpl.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/Context.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/ATen.h:7,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:14:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:22:21: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
   22 |   TORCH_CHECK(x.type().is_cuda(), #x " must be a CUDA tensor")
      |                     ^
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/macros/Macros.h:200:64: note: in definition of macro ‘C10_UNLIKELY’
  200 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))
      |                                                                ^~~~
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/Exception.h:506:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’
  506 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \
      |       ^~~~~~~~~~~~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:22:3: note: in expansion of macro ‘TORCH_CHECK’
   22 |   TORCH_CHECK(x.type().is_cuda(), #x " must be a CUDA tensor")
      |   ^~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:26:3: note: in expansion of macro ‘CHECK_CUDA’
   26 |   CHECK_CUDA(x);       \
      |   ^~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:45:3: note: in expansion of macro ‘CHECK_INPUT’
   45 |   CHECK_INPUT(operations);
      |   ^~~~~~~~~~~
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/ivalue.h:4,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/List_inl.h:4,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/List.h:494,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/IListRef_inl.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/IListRef.h:632,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/DeviceGuard.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/ATen.h:9,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:14:
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here
  222 |   DeprecatedTypeProperties & type() const {
      |                              ^~~~
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/Exception.h:4,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/Generator.h:11,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/CPUGeneratorImpl.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/Context.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/ATen.h:7,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:14:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp: In function ‘std::pair<at::Tensor, at::Tensor> GenerateInsertionLabel(at::Tensor, at::Tensor)’:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:22:21: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
   22 |   TORCH_CHECK(x.type().is_cuda(), #x " must be a CUDA tensor")
      |                     ^
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/macros/Macros.h:200:64: note: in definition of macro ‘C10_UNLIKELY’
  200 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))
      |                                                                ^~~~
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/Exception.h:506:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’
  506 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \
      |       ^~~~~~~~~~~~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:22:3: note: in expansion of macro ‘TORCH_CHECK’
   22 |   TORCH_CHECK(x.type().is_cuda(), #x " must be a CUDA tensor")
      |   ^~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:26:3: note: in expansion of macro ‘CHECK_CUDA’
   26 |   CHECK_CUDA(x);       \
      |   ^~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:52:3: note: in expansion of macro ‘CHECK_INPUT’
   52 |   CHECK_INPUT(target);
      |   ^~~~~~~~~~~
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/ivalue.h:4,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/List_inl.h:4,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/List.h:494,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/IListRef_inl.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/IListRef.h:632,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/DeviceGuard.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/ATen.h:9,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:14:
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here
  222 |   DeprecatedTypeProperties & type() const {
      |                              ^~~~
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/Exception.h:4,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/Generator.h:11,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/CPUGeneratorImpl.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/Context.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/ATen.h:7,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:14:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:22:21: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
   22 |   TORCH_CHECK(x.type().is_cuda(), #x " must be a CUDA tensor")
      |                     ^
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/macros/Macros.h:200:64: note: in definition of macro ‘C10_UNLIKELY’
  200 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))
      |                                                                ^~~~
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/Exception.h:506:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’
  506 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \
      |       ^~~~~~~~~~~~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:22:3: note: in expansion of macro ‘TORCH_CHECK’
   22 |   TORCH_CHECK(x.type().is_cuda(), #x " must be a CUDA tensor")
      |   ^~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:26:3: note: in expansion of macro ‘CHECK_CUDA’
   26 |   CHECK_CUDA(x);       \
      |   ^~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:53:3: note: in expansion of macro ‘CHECK_INPUT’
   53 |   CHECK_INPUT(operations);
      |   ^~~~~~~~~~~
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/ivalue.h:4,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/List_inl.h:4,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/List.h:494,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/IListRef_inl.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/IListRef.h:632,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/DeviceGuard.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/ATen.h:9,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/binding.cpp:14:
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here
  222 |   DeprecatedTypeProperties & type() const {
      |                              ^~~~
[2/2] /mntnfs/lee_data1/maduo/installed/cuda-11.8.0/bin/nvcc  -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/TH -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/THC -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include/python3.9 -c -c /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/libnat_cuda/edit_dist.cu -o /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/libnat_cuda/edit_dist.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=libnat_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -ccbin /cm/local/apps/gcc/11.2.0/bin/gcc -std=c++17
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero
          detected during:
            instantiation of "__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]" 
(61): here
            instantiation of "__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]" 
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/core/TensorImpl.h(77): here

/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero
          detected during:
            instantiation of "__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]" 
(61): here
            instantiation of "__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]" 
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/qualified_name.h(73): here

/cm/local/apps/gcc/11.2.0/bin/g++ -pthread -B /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/compiler_compat -shared -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/libnat_cuda/binding.o /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/libnat_cuda/edit_dist.o -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.9/fairseq/libnat_cuda.cpython-39-x86_64-linux-gnu.so
building 'fairseq.ngram_repeat_block_cuda' extension
Emitting ninja build file /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/2] /cm/local/apps/gcc/11.2.0/bin/g++ -MMD -MF /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/cuda/ngram_repeat_block_cuda.o.d -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -fPIC -O2 -isystem /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: -fPIC -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/TH -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/THC -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include/python3.9 -c -c /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/cuda/ngram_repeat_block_cuda.cpp -o /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/cuda/ngram_repeat_block_cuda.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=ngram_repeat_block_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/core/DeviceType.h:8,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/core/Device.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:11,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/extension.h:4,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/cuda/ngram_repeat_block_cuda.cpp:6:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/cuda/ngram_repeat_block_cuda.cpp: In function ‘at::Tensor ngram_repeat_block_forward(at::Tensor, at::Tensor, int, int, int, int)’:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/cuda/ngram_repeat_block_cuda.cpp:23:21: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
   23 |   TORCH_CHECK(x.type().is_cuda(), #x " must be a CUDA tensor")
      |                     ^
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/macros/Macros.h:200:64: note: in definition of macro ‘C10_UNLIKELY’
  200 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))
      |                                                                ^~~~
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/Exception.h:506:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’
  506 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \
      |       ^~~~~~~~~~~~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/cuda/ngram_repeat_block_cuda.cpp:23:3: note: in expansion of macro ‘TORCH_CHECK’
   23 |   TORCH_CHECK(x.type().is_cuda(), #x " must be a CUDA tensor")
      |   ^~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/cuda/ngram_repeat_block_cuda.cpp:27:3: note: in expansion of macro ‘CHECK_CUDA’
   27 |   CHECK_CUDA(x);       \
      |   ^~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/cuda/ngram_repeat_block_cuda.cpp:39:3: note: in expansion of macro ‘CHECK_INPUT’
   39 |   CHECK_INPUT(tokens);
      |   ^~~~~~~~~~~
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/extension.h:4,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/cuda/ngram_repeat_block_cuda.cpp:6:
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here
  222 |   DeprecatedTypeProperties & type() const {
      |                              ^~~~
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/core/DeviceType.h:8,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/core/Device.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:11,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/extension.h:4,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/cuda/ngram_repeat_block_cuda.cpp:6:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/cuda/ngram_repeat_block_cuda.cpp:23:21: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
   23 |   TORCH_CHECK(x.type().is_cuda(), #x " must be a CUDA tensor")
      |                     ^
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/macros/Macros.h:200:64: note: in definition of macro ‘C10_UNLIKELY’
  200 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))
      |                                                                ^~~~
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/Exception.h:506:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’
  506 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \
      |       ^~~~~~~~~~~~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/cuda/ngram_repeat_block_cuda.cpp:23:3: note: in expansion of macro ‘TORCH_CHECK’
   23 |   TORCH_CHECK(x.type().is_cuda(), #x " must be a CUDA tensor")
      |   ^~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/cuda/ngram_repeat_block_cuda.cpp:27:3: note: in expansion of macro ‘CHECK_CUDA’
   27 |   CHECK_CUDA(x);       \
      |   ^~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/cuda/ngram_repeat_block_cuda.cpp:40:3: note: in expansion of macro ‘CHECK_INPUT’
   40 |   CHECK_INPUT(lprobs);
      |   ^~~~~~~~~~~
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/extension.h:4,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/cuda/ngram_repeat_block_cuda.cpp:6:
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here
  222 |   DeprecatedTypeProperties & type() const {
      |                              ^~~~
[2/2] /mntnfs/lee_data1/maduo/installed/cuda-11.8.0/bin/nvcc  -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/TH -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/THC -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include/python3.9 -c -c /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/clib/cuda/ngram_repeat_block_cuda_kernel.cu -o /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/cuda/ngram_repeat_block_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=ngram_repeat_block_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -ccbin /cm/local/apps/gcc/11.2.0/bin/gcc -std=c++17
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero
          detected during:
            instantiation of "__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]" 
(61): here
            instantiation of "__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]" 
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/core/TensorImpl.h(77): here

/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero
          detected during:
            instantiation of "__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]" 
(61): here
            instantiation of "__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]" 
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/qualified_name.h(73): here

/cm/local/apps/gcc/11.2.0/bin/g++ -pthread -B /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/compiler_compat -shared -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/cuda/ngram_repeat_block_cuda.o /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/cuda/ngram_repeat_block_cuda_kernel.o -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.9/fairseq/ngram_repeat_block_cuda.cpython-39-x86_64-linux-gnu.so
building 'alignment_train_cuda_binding' extension
Emitting ninja build file /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/2] /cm/local/apps/gcc/11.2.0/bin/g++ -MMD -MF /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/examples/operators/alignment_train_cuda.o.d -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -fPIC -O2 -isystem /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: -fPIC -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/TH -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/THC -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include/python3.9 -c -c /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cuda.cpp -o /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/examples/operators/alignment_train_cuda.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=alignment_train_cuda_binding -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/core/DeviceType.h:8,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/core/Device.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:11,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/extension.h:4,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cuda.h:11,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cuda.cpp:9:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cuda.cpp: In function ‘void {anonymous}::alignmentTrainCUDA(const at::Tensor&, at::Tensor&, float)’:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/utils.h:14:21: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
   14 |   TORCH_CHECK(x.type().is_cuda(), #x " must be a CUDA tensor")
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/macros/Macros.h:200:64: note: in definition of macro ‘C10_UNLIKELY’
  200 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))
      |                                                                ^~~~
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/Exception.h:506:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’
  506 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \
      |       ^~~~~~~~~~~~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/utils.h:14:3: note: in expansion of macro ‘TORCH_CHECK’
   14 |   TORCH_CHECK(x.type().is_cuda(), #x " must be a CUDA tensor")
      |   ^~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/utils.h:18:3: note: in expansion of macro ‘CHECK_CUDA’
   18 |   CHECK_CUDA(x);       \
      |   ^~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cuda.cpp:18:3: note: in expansion of macro ‘CHECK_INPUT’
   18 |   CHECK_INPUT(p_choose);
      |   ^~~~~~~~~~~
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/extension.h:4,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cuda.h:11,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cuda.cpp:9:
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here
  222 |   DeprecatedTypeProperties & type() const {
      |                              ^~~~
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/core/DeviceType.h:8,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/core/Device.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:11,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/extension.h:4,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cuda.h:11,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cuda.cpp:9:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/utils.h:14:21: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
   14 |   TORCH_CHECK(x.type().is_cuda(), #x " must be a CUDA tensor")
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/macros/Macros.h:200:64: note: in definition of macro ‘C10_UNLIKELY’
  200 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))
      |                                                                ^~~~
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/Exception.h:506:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’
  506 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \
      |       ^~~~~~~~~~~~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/utils.h:14:3: note: in expansion of macro ‘TORCH_CHECK’
   14 |   TORCH_CHECK(x.type().is_cuda(), #x " must be a CUDA tensor")
      |   ^~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/utils.h:18:3: note: in expansion of macro ‘CHECK_CUDA’
   18 |   CHECK_CUDA(x);       \
      |   ^~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cuda.cpp:19:3: note: in expansion of macro ‘CHECK_INPUT’
   19 |   CHECK_INPUT(alpha);
      |   ^~~~~~~~~~~
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/extension.h:4,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cuda.h:11,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_cuda.cpp:9:
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here
  222 |   DeprecatedTypeProperties & type() const {
      |                              ^~~~
[2/2] /mntnfs/lee_data1/maduo/installed/cuda-11.8.0/bin/nvcc  -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/TH -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/THC -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include/python3.9 -c -c /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/operators/alignment_train_kernel.cu -o /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/examples/operators/alignment_train_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=alignment_train_cuda_binding -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -ccbin /cm/local/apps/gcc/11.2.0/bin/gcc -std=c++17
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero
          detected during:
            instantiation of "__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]" 
(61): here
            instantiation of "__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]" 
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/core/TensorImpl.h(77): here

/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero
          detected during:
            instantiation of "__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]" 
(61): here
            instantiation of "__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]" 
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/include/ATen/core/qualified_name.h(73): here

/cm/local/apps/gcc/11.2.0/bin/g++ -pthread -B /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/compiler_compat -shared -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/examples/operators/alignment_train_cuda.o /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/examples/operators/alignment_train_kernel.o -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.9/alignment_train_cuda_binding.cpython-39-x86_64-linux-gnu.so
copying build/lib.linux-x86_64-3.9/fairseq/libbleu.cpython-39-x86_64-linux-gnu.so -> fairseq
copying build/lib.linux-x86_64-3.9/fairseq/data/data_utils_fast.cpython-39-x86_64-linux-gnu.so -> fairseq/data
copying build/lib.linux-x86_64-3.9/fairseq/data/token_block_utils_fast.cpython-39-x86_64-linux-gnu.so -> fairseq/data
copying build/lib.linux-x86_64-3.9/fairseq/libbase.cpython-39-x86_64-linux-gnu.so -> fairseq
copying build/lib.linux-x86_64-3.9/fairseq/libnat.cpython-39-x86_64-linux-gnu.so -> fairseq
copying build/lib.linux-x86_64-3.9/alignment_train_cpu_binding.cpython-39-x86_64-linux-gnu.so -> 
copying build/lib.linux-x86_64-3.9/fairseq/libnat_cuda.cpython-39-x86_64-linux-gnu.so -> fairseq
copying build/lib.linux-x86_64-3.9/fairseq/ngram_repeat_block_cuda.cpython-39-x86_64-linux-gnu.so -> fairseq
copying build/lib.linux-x86_64-3.9/alignment_train_cuda_binding.cpython-39-x86_64-linux-gnu.so -> 
fine tune base t-hubert model  using train-clean-360 supervision data
[2024-07-03 14:58:13,446][fairseq.distributed.utils][INFO] - Rank 0, device_id: 0
2024-07-03 14:58:21 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:23948
2024-07-03 14:58:21 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:23948
2024-07-03 14:58:21 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:23948
2024-07-03 14:58:21 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:23948
2024-07-03 14:58:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2024-07-03 14:58:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2024-07-03 14:58:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2024-07-03 14:58:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2024-07-03 14:58:22 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-07-03 14:58:22 | INFO | fairseq.distributed.utils | initialized host pgpu18 as rank 0
2024-07-03 14:58:22 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-07-03 14:58:22 | INFO | fairseq.distributed.utils | initialized host pgpu18 as rank 1
2024-07-03 14:58:22 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-07-03 14:58:22 | INFO | fairseq.distributed.utils | initialized host pgpu18 as rank 3
2024-07-03 14:58:22 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-07-03 14:58:22 | INFO | fairseq.distributed.utils | initialized host pgpu18 as rank 2
[2024-07-03 14:58:24,308][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/t-hubert', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:23948', 'distributed_port': 23948, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3200000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train-clean-360', 'valid_subset': 'dev-other', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3200000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 80000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [2], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'wer', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'hubert_ctc', 'w2v_path': '/mntcephfs/lab_data/maduo/exp/pretrain/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update/checkpoint_298_400000.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.1, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_embed_dim': 768, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 0, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'normalize': False, 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'w2v_args': None, 'autoregressive': False}, 'task': {'_name': 'hubert_pretraining', 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'fine_tuning': True, 'labels': ['ltr'], 'label_dir': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'label_rate': -1.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': None, 'min_sample_size': None, 'single_target': True, 'random_crop': True, 'pad_audio': False}, 'criterion': {'_name': 'ctc', 'zero_infinity': True, 'sentence_avg': True, 'post_process': 'letter', 'wer_kenlm_model': None, 'wer_lexicon': None, 'wer_lm_weight': 2.0, 'wer_word_score': -1.0, 'wer_sil_weight': 0.0, 'wer_args': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05], 'amsgrad': False}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 8000, 'hold_steps': 32000, 'decay_steps': 40000, 'phase_ratio': None, 'init_lr_scale': 0.01, 'final_lr_scale': 0.05, 'max_update': 80000.0, 'lr': [3e-05]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': '/mntcephfs/lab_data/maduo/exp/pretrain/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update/finetune.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-07-03 14:58:24,313][fairseq.tasks.hubert_pretraining][INFO] - current directory is /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/t-hubert
[2024-07-03 14:58:24,313][fairseq.tasks.hubert_pretraining][INFO] - HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'fine_tuning': True, 'labels': ['ltr'], 'label_dir': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'label_rate': -1.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': None, 'min_sample_size': None, 'single_target': True, 'random_crop': True, 'pad_audio': False}
[2024-07-03 14:58:24,319][fairseq.models.hubert.hubert_asr][INFO] - cfg: {'_name': 'hubert_ctc', 'w2v_path': '/mntcephfs/lab_data/maduo/exp/pretrain/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update/checkpoint_298_400000.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.1, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_embed_dim': 768, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 0, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'normalize': False, 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'w2v_args': None, 'autoregressive': False}, task: <fairseq.tasks.hubert_pretraining.HubertPretrainingTask object at 0x155407561700>
[2024-07-03 14:58:24,320][fairseq.models.hubert.hubert_asr][INFO] - mdddd:::/mntcephfs/lab_data/maduo/exp/pretrain/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update/checkpoint_298_400000.pt
[2024-07-03 14:58:25,890][fairseq.tasks.hubert_pretraining][INFO] - current directory is /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/t-hubert
[2024-07-03 14:58:25,890][fairseq.tasks.hubert_pretraining][INFO] - HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'fine_tuning': False, 'labels': ['phncode', 'km'], 'label_dir': '/mntcephfs/lab_data/maduo/datasets/format/librispeech//offical_hubert_codes_and_librispeech_frame_monophncode_using_wav2vec-u2_model', 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
[2024-07-03 14:58:25,905][fairseq.models.hubert.hubert2][INFO] - HubertModel2 Config: {'_name': 'ils_hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'attention_type': 'rel_attention', 'weighted_sum': False, 'predict_layers': '[7,12]', 'separate_label_embeds': True, 'separate_layer_targets': False, 'km4_bpekm7_km12': False, 'bpekm7_km12': False, 'phnkm6_km12': False, 'phnkm7_km12': True, 'km4_phnkm6_km12': False, 'km4_phnkm7_km12': False}
[2024-07-03 14:58:26,406][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-03 14:58:26,513][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-03 14:58:26,604][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-03 14:58:26,691][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-03 14:58:26,780][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-03 14:58:26,867][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-03 14:58:26,956][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-03 14:58:27,045][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-03 14:58:27,132][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-03 14:58:27,218][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-03 14:58:27,305][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-03 14:58:27,392][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-03 14:58:28,260][fairseq.models.hubert.ils_hubert][INFO] - HubertModel Config: {'_name': 'ils_hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'attention_type': 'rel_attention', 'weighted_sum': False, 'predict_layers': '[7,12]', 'separate_label_embeds': True, 'separate_layer_targets': False, 'km4_bpekm7_km12': False, 'bpekm7_km12': False, 'phnkm6_km12': False, 'phnkm7_km12': True, 'km4_phnkm6_km12': False, 'km4_phnkm7_km12': False}
[2024-07-03 14:58:32,611][fairseq_cli.train][INFO] - HubertCtc(
  (w2v_encoder): HubertEncoder(
    (w2v_model): ILSHubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention2(
              (dropout_module): FairseqDropout()
              (relative_attention_bias): Embedding(320, 12)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1-11): 11 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention2(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (proj): Linear(in_features=768, out_features=32, bias=True)
  )
)
[2024-07-03 14:58:32,623][fairseq_cli.train][INFO] - task: HubertPretrainingTask
[2024-07-03 14:58:32,623][fairseq_cli.train][INFO] - model: HubertCtc
[2024-07-03 14:58:32,623][fairseq_cli.train][INFO] - criterion: CtcCriterion
[2024-07-03 14:58:32,625][fairseq_cli.train][INFO] - num. shared model params: 94,400,160 (num. trained: 94,400,160)
[2024-07-03 14:58:32,625][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-07-03 14:58:32,629][fairseq.data.audio.hubert_dataset][INFO] - max_keep=None, min_keep=None, loaded 2864, skipped 0 short and 0 long, longest-loaded=562480, shortest-loaded=17040
[2024-07-03 14:58:32,631][fairseq.data.audio.hubert_dataset][INFO] - /mntcephfs/lab_data/maduo/datasets/format/librispeech//dev-other.ltr is sequence label. skipped
[2024-07-03 14:58:32,631][fairseq.data.audio.hubert_dataset][INFO] - pad_audio=False, random_crop=True, normalize=False, max_sample_size=9223372036854775807
[2024-07-03 14:58:35,880][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:2 to store for rank: 0
[2024-07-03 14:58:35,880][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
[2024-07-03 14:58:35,881][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
[2024-07-03 14:58:35,881][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
[2024-07-03 14:58:35,881][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
[2024-07-03 14:58:35,881][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
[2024-07-03 14:58:35,881][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
[2024-07-03 14:58:35,881][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
[2024-07-03 14:58:35,881][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
[2024-07-03 14:58:36,655][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2024-07-03 14:58:36,655][fairseq.utils][INFO] - rank   0: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A100-SXM4-80GB                   
[2024-07-03 14:58:36,655][fairseq.utils][INFO] - rank   1: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A100-SXM4-80GB                   
[2024-07-03 14:58:36,655][fairseq.utils][INFO] - rank   2: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A100-SXM4-80GB                   
[2024-07-03 14:58:36,655][fairseq.utils][INFO] - rank   3: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A100-SXM4-80GB                   
[2024-07-03 14:58:36,655][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2024-07-03 14:58:36,656][fairseq_cli.train][INFO] - training on 4 devices (GPUs/TPUs)
[2024-07-03 14:58:36,656][fairseq_cli.train][INFO] - max tokens per device = 3200000 and max sentences per device = None
[2024-07-03 14:58:36,657][fairseq.trainer][INFO] - Preparing to load checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_last.pt
[2024-07-03 14:58:36,657][fairseq.trainer][INFO] - No existing checkpoint found /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_last.pt
[2024-07-03 14:58:36,657][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-07-03 14:58:36,727][fairseq.data.audio.hubert_dataset][INFO] - max_keep=None, min_keep=None, loaded 104014, skipped 0 short and 0 long, longest-loaded=475760, shortest-loaded=17040
[2024-07-03 14:58:36,871][fairseq.data.audio.hubert_dataset][INFO] - /mntcephfs/lab_data/maduo/datasets/format/librispeech//train-clean-360.ltr is sequence label. skipped
[2024-07-03 14:58:36,871][fairseq.data.audio.hubert_dataset][INFO] - pad_audio=False, random_crop=True, normalize=False, max_sample_size=9223372036854775807
[2024-07-03 14:58:36,930][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 14:58:36,931][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2024-07-03 14:58:36,931][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = False
[2024-07-03 14:58:36,931][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2024-07-03 14:58:38,045][fairseq_cli.train][INFO] - begin dry-run validation on "dev-other" subset
[2024-07-03 14:58:38,047][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 14:58:38,048][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2024-07-03 14:58:38,048][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = False
[2024-07-03 14:58:38,048][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2024-07-03 14:59:17,844][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-03 14:59:17,850][fairseq.trainer][INFO] - begin training epoch 1
[2024-07-03 14:59:17,851][fairseq_cli.train][INFO] - Start iterating over samples
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
[2024-07-03 15:00:05,285][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2024-07-03 15:00:07,964][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2024-07-03 15:00:09,977][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-03 15:00:17,629][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-03 15:03:37,751][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-07-03 15:06:16,702][train_inner][INFO] - {"epoch": 1, "update": 0.158, "loss": "2144.51", "ntokens": "14761.8", "nsentences": "79.88", "nll_loss": "11.605", "wps": "8039.9", "ups": "0.54", "wpb": "14761.8", "bsz": "79.9", "num_updates": "200", "lr": "1.0425e-06", "gnorm": "1455.05", "loss_scale": "4", "train_wall": "381", "gb_free": "70.9", "wall": "460"}
[2024-07-03 15:07:49,374][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-07-03 15:12:07,520][train_inner][INFO] - {"epoch": 1, "update": 0.313, "loss": "1215.13", "ntokens": "14831.5", "nsentences": "79.84", "nll_loss": "6.541", "wps": "8455.9", "ups": "0.57", "wpb": "14831.5", "bsz": "79.8", "num_updates": "400", "lr": "1.785e-06", "gnorm": "1755", "loss_scale": "2", "train_wall": "350", "gb_free": "72.5", "wall": "811"}
[2024-07-03 15:17:54,902][train_inner][INFO] - {"epoch": 1, "update": 0.467, "loss": "820.712", "ntokens": "14870", "nsentences": "80.83", "nll_loss": "4.461", "wps": "8561.4", "ups": "0.58", "wpb": "14870", "bsz": "80.8", "num_updates": "600", "lr": "2.5275e-06", "gnorm": "518.929", "loss_scale": "2", "train_wall": "347", "gb_free": "71.5", "wall": "1158"}
[2024-07-03 15:23:32,189][train_inner][INFO] - {"epoch": 1, "update": 0.621, "loss": "781.426", "ntokens": "14854.8", "nsentences": "80.16", "nll_loss": "4.217", "wps": "8808.6", "ups": "0.59", "wpb": "14854.8", "bsz": "80.2", "num_updates": "800", "lr": "3.27e-06", "gnorm": "250.553", "loss_scale": "2", "train_wall": "337", "gb_free": "71.9", "wall": "1496"}
[2024-07-03 15:29:28,920][train_inner][INFO] - {"epoch": 1, "update": 0.776, "loss": "767.443", "ntokens": "14798.3", "nsentences": "80.52", "nll_loss": "4.176", "wps": "8296.8", "ups": "0.56", "wpb": "14798.3", "bsz": "80.5", "num_updates": "1000", "lr": "4.0125e-06", "gnorm": "207.483", "loss_scale": "2", "train_wall": "356", "gb_free": "71.8", "wall": "1852"}
[2024-07-03 15:35:16,189][train_inner][INFO] - {"epoch": 1, "update": 0.93, "loss": "764.496", "ntokens": "14840.1", "nsentences": "80.48", "nll_loss": "4.146", "wps": "8546.9", "ups": "0.58", "wpb": "14840.1", "bsz": "80.5", "num_updates": "1200", "lr": "4.755e-06", "gnorm": "187.467", "loss_scale": "2", "train_wall": "347", "gb_free": "71.4", "wall": "2200"}
[2024-07-03 15:37:56,495][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-03 15:37:56,500][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 15:38:36,694][dev-other][INFO] - {"epoch": 1, "dev-other_loss": "396.905", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "4.219", "dev-other_uer": "100", "dev-other_wer": "100", "dev-other_raw_wer": "100", "dev-other_wps": "6839", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "1291"}
[2024-07-03 15:38:36,695][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2024-07-03 15:38:36,699][train][INFO] - {"epoch": 1, "train_loss": "1059.42", "train_ntokens": "14822", "train_nsentences": "80.1844", "train_nll_loss": "5.731", "train_wps": "8293.8", "train_ups": "0.56", "train_wpb": "14822", "train_bsz": "80.2", "train_num_updates": "1291", "train_lr": "5.09284e-06", "train_gnorm": "690.853", "train_loss_scale": "2", "train_train_wall": "2278", "train_gb_free": "71.3", "train_wall": "2400"}
[2024-07-03 15:38:36,702][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 15:38:37,624][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-03 15:38:37,627][fairseq.trainer][INFO] - begin training epoch 2
[2024-07-03 15:38:37,627][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-03 15:41:38,058][train_inner][INFO] - {"epoch": 2, "update": 1.084, "loss": "757.099", "ntokens": "14764.8", "nsentences": "80.56", "nll_loss": "4.131", "wps": "7733.1", "ups": "0.52", "wpb": "14764.8", "bsz": "80.6", "num_updates": "1400", "lr": "5.4975e-06", "gnorm": "178.696", "loss_scale": "2", "train_wall": "340", "gb_free": "71.3", "wall": "2581"}
[2024-07-03 15:47:25,107][train_inner][INFO] - {"epoch": 2, "update": 1.238, "loss": "757.706", "ntokens": "14796.5", "nsentences": "80.32", "nll_loss": "4.113", "wps": "8527.3", "ups": "0.58", "wpb": "14796.5", "bsz": "80.3", "num_updates": "1600", "lr": "6.24e-06", "gnorm": "147.201", "loss_scale": "2", "train_wall": "346", "gb_free": "71.9", "wall": "2928"}
[2024-07-03 15:53:09,598][train_inner][INFO] - {"epoch": 2, "update": 1.392, "loss": "781.22", "ntokens": "14753.5", "nsentences": "77.44", "nll_loss": "4.101", "wps": "8565.6", "ups": "0.58", "wpb": "14753.5", "bsz": "77.4", "num_updates": "1800", "lr": "6.9825e-06", "gnorm": "163.439", "loss_scale": "2", "train_wall": "344", "gb_free": "72.9", "wall": "3273"}
[2024-07-03 15:58:59,697][train_inner][INFO] - {"epoch": 2, "update": 1.547, "loss": "735.923", "ntokens": "14894.3", "nsentences": "80.6", "nll_loss": "3.982", "wps": "8509", "ups": "0.57", "wpb": "14894.3", "bsz": "80.6", "num_updates": "2000", "lr": "7.725e-06", "gnorm": "230.374", "loss_scale": "2", "train_wall": "350", "gb_free": "72.6", "wall": "3623"}
[2024-07-03 16:04:44,275][train_inner][INFO] - {"epoch": 2, "update": 1.701, "loss": "656.27", "ntokens": "14738.6", "nsentences": "80", "nll_loss": "3.562", "wps": "8555", "ups": "0.58", "wpb": "14738.6", "bsz": "80", "num_updates": "2200", "lr": "8.4675e-06", "gnorm": "244.899", "loss_scale": "2", "train_wall": "344", "gb_free": "70.9", "wall": "3968"}
[2024-07-03 16:10:25,483][train_inner][INFO] - {"epoch": 2, "update": 1.855, "loss": "528.264", "ntokens": "14914.9", "nsentences": "81.59", "nll_loss": "2.89", "wps": "8742.6", "ups": "0.59", "wpb": "14914.9", "bsz": "81.6", "num_updates": "2400", "lr": "9.21e-06", "gnorm": "225.52", "loss_scale": "4", "train_wall": "341", "gb_free": "71.9", "wall": "4309"}
[2024-07-03 16:15:55,356][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-03 16:15:55,408][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 16:16:34,960][dev-other][INFO] - {"epoch": 2, "dev-other_loss": "130.872", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "1.391", "dev-other_uer": "29.38", "dev-other_wer": "71.472", "dev-other_raw_wer": "71.472", "dev-other_wps": "6966.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "2588"}
[2024-07-03 16:16:34,961][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2024-07-03 16:16:34,970][train][INFO] - {"epoch": 2, "train_loss": "658.262", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "3.561", "train_wps": "8438.6", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "2588", "train_lr": "9.90795e-06", "train_gnorm": "200.707", "train_loss_scale": "4", "train_train_wall": "2234", "train_gb_free": "72.1", "train_wall": "4678"}
[2024-07-03 16:16:34,973][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 16:16:35,877][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-03 16:16:35,883][fairseq.trainer][INFO] - begin training epoch 3
[2024-07-03 16:16:35,883][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-03 16:16:57,445][train_inner][INFO] - {"epoch": 3, "update": 2.009, "loss": "429.887", "ntokens": "14884", "nsentences": "80.44", "nll_loss": "2.323", "wps": "7594.8", "ups": "0.51", "wpb": "14884", "bsz": "80.4", "num_updates": "2600", "lr": "9.9525e-06", "gnorm": "206.668", "loss_scale": "4", "train_wall": "351", "gb_free": "71.8", "wall": "4701"}
[2024-07-03 16:22:50,317][train_inner][INFO] - {"epoch": 3, "update": 2.163, "loss": "348.579", "ntokens": "14750.2", "nsentences": "79.95", "nll_loss": "1.889", "wps": "8361.9", "ups": "0.57", "wpb": "14750.2", "bsz": "80", "num_updates": "2800", "lr": "1.0695e-05", "gnorm": "175.367", "loss_scale": "4", "train_wall": "352", "gb_free": "71.8", "wall": "5054"}
[2024-07-03 16:28:30,842][train_inner][INFO] - {"epoch": 3, "update": 2.318, "loss": "295.104", "ntokens": "14892", "nsentences": "79.68", "nll_loss": "1.579", "wps": "8749.2", "ups": "0.59", "wpb": "14892", "bsz": "79.7", "num_updates": "3000", "lr": "1.14375e-05", "gnorm": "163.046", "loss_scale": "4", "train_wall": "340", "gb_free": "72.2", "wall": "5394"}
[2024-07-03 16:34:21,548][train_inner][INFO] - {"epoch": 3, "update": 2.472, "loss": "264.034", "ntokens": "14901.6", "nsentences": "82.8", "nll_loss": "1.467", "wps": "8499.1", "ups": "0.57", "wpb": "14901.6", "bsz": "82.8", "num_updates": "3200", "lr": "1.218e-05", "gnorm": "180.274", "loss_scale": "4", "train_wall": "350", "gb_free": "72.5", "wall": "5745"}
[2024-07-03 16:40:07,288][train_inner][INFO] - {"epoch": 3, "update": 2.626, "loss": "245.762", "ntokens": "14864", "nsentences": "80.48", "nll_loss": "1.331", "wps": "8600.1", "ups": "0.58", "wpb": "14864", "bsz": "80.5", "num_updates": "3400", "lr": "1.29225e-05", "gnorm": "159.091", "loss_scale": "4", "train_wall": "345", "gb_free": "72.5", "wall": "6091"}
[2024-07-03 16:45:55,570][train_inner][INFO] - {"epoch": 3, "update": 2.78, "loss": "219.255", "ntokens": "14783.6", "nsentences": "80", "nll_loss": "1.186", "wps": "8491.8", "ups": "0.57", "wpb": "14783.6", "bsz": "80", "num_updates": "3600", "lr": "1.3665e-05", "gnorm": "149.405", "loss_scale": "4", "train_wall": "348", "gb_free": "70.7", "wall": "6439"}
[2024-07-03 16:51:43,166][train_inner][INFO] - {"epoch": 3, "update": 2.934, "loss": "199.814", "ntokens": "14794.2", "nsentences": "79.6", "nll_loss": "1.075", "wps": "8513.5", "ups": "0.58", "wpb": "14794.2", "bsz": "79.6", "num_updates": "3800", "lr": "1.44075e-05", "gnorm": "134.801", "loss_scale": "4", "train_wall": "347", "gb_free": "71.6", "wall": "6786"}
[2024-07-03 16:54:15,638][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-03 16:54:15,642][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 16:54:55,317][dev-other][INFO] - {"epoch": 3, "dev-other_loss": "50.672", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.539", "dev-other_uer": "9.64", "dev-other_wer": "31.371", "dev-other_raw_wer": "31.371", "dev-other_wps": "6927.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "3885"}
[2024-07-03 16:54:55,320][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)
[2024-07-03 16:54:55,324][train][INFO] - {"epoch": 3, "train_loss": "258.921", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "1.401", "train_wps": "8357.5", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "3885", "train_lr": "1.47231e-05", "train_gnorm": "158.939", "train_loss_scale": "4", "train_train_wall": "2256", "train_gb_free": "71.9", "train_wall": "6979"}
[2024-07-03 16:54:55,326][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 16:54:56,282][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-03 16:54:56,299][fairseq.trainer][INFO] - begin training epoch 4
[2024-07-03 16:54:56,299][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-03 16:58:14,185][train_inner][INFO] - {"epoch": 4, "update": 3.089, "loss": "185.482", "ntokens": "14789", "nsentences": "81.04", "nll_loss": "1.016", "wps": "7564.5", "ups": "0.51", "wpb": "14789", "bsz": "81", "num_updates": "4000", "lr": "1.515e-05", "gnorm": "134.256", "loss_scale": "4", "train_wall": "350", "gb_free": "71.4", "wall": "7178"}
[2024-07-03 17:03:59,014][train_inner][INFO] - {"epoch": 4, "update": 3.243, "loss": "177.557", "ntokens": "14845.6", "nsentences": "80.83", "nll_loss": "0.967", "wps": "8610.6", "ups": "0.58", "wpb": "14845.6", "bsz": "80.8", "num_updates": "4200", "lr": "1.58925e-05", "gnorm": "134.114", "loss_scale": "4", "train_wall": "344", "gb_free": "70.7", "wall": "7522"}
[2024-07-03 17:09:47,615][train_inner][INFO] - {"epoch": 4, "update": 3.397, "loss": "172.735", "ntokens": "14822.1", "nsentences": "81.72", "nll_loss": "0.952", "wps": "8505.8", "ups": "0.57", "wpb": "14822.1", "bsz": "81.7", "num_updates": "4400", "lr": "1.6635e-05", "gnorm": "145.008", "loss_scale": "8", "train_wall": "348", "gb_free": "71", "wall": "7871"}
[2024-07-03 17:15:35,467][train_inner][INFO] - {"epoch": 4, "update": 3.551, "loss": "165.145", "ntokens": "14828.2", "nsentences": "79.56", "nll_loss": "0.886", "wps": "8526.2", "ups": "0.58", "wpb": "14828.2", "bsz": "79.6", "num_updates": "4600", "lr": "1.73775e-05", "gnorm": "145.508", "loss_scale": "8", "train_wall": "347", "gb_free": "72.1", "wall": "8219"}
[2024-07-03 17:21:23,990][train_inner][INFO] - {"epoch": 4, "update": 3.705, "loss": "156.052", "ntokens": "14749.7", "nsentences": "78.36", "nll_loss": "0.829", "wps": "8464.4", "ups": "0.57", "wpb": "14749.7", "bsz": "78.4", "num_updates": "4800", "lr": "1.812e-05", "gnorm": "132.313", "loss_scale": "8", "train_wall": "348", "gb_free": "69.8", "wall": "8567"}
[2024-07-03 17:27:10,856][train_inner][INFO] - {"epoch": 4, "update": 3.86, "loss": "161.007", "ntokens": "14782.4", "nsentences": "77.24", "nll_loss": "0.841", "wps": "8526.4", "ups": "0.58", "wpb": "14782.4", "bsz": "77.2", "num_updates": "5000", "lr": "1.88625e-05", "gnorm": "133.882", "loss_scale": "8", "train_wall": "346", "gb_free": "70.2", "wall": "8914"}
[2024-07-03 17:32:23,508][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-03 17:32:23,514][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 17:33:03,028][dev-other][INFO] - {"epoch": 4, "dev-other_loss": "35.534", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.378", "dev-other_uer": "6.618", "dev-other_wer": "20.373", "dev-other_raw_wer": "20.373", "dev-other_wps": "6958.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "5182"}
[2024-07-03 17:33:03,030][fairseq_cli.train][INFO] - end of epoch 4 (average epoch stats below)
[2024-07-03 17:33:03,033][train][INFO] - {"epoch": 4, "train_loss": "165.04", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.893", "train_wps": "8403.7", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "5182", "train_lr": "1.95382e-05", "train_gnorm": "136.421", "train_loss_scale": "8", "train_train_wall": "2243", "train_gb_free": "71.9", "train_wall": "9266"}
[2024-07-03 17:33:03,036][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 17:33:03,966][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-03 17:33:03,971][fairseq.trainer][INFO] - begin training epoch 5
[2024-07-03 17:33:03,972][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-03 17:33:35,657][train_inner][INFO] - {"epoch": 5, "update": 4.014, "loss": "147.236", "ntokens": "14881", "nsentences": "80.72", "nll_loss": "0.799", "wps": "7738", "ups": "0.52", "wpb": "14881", "bsz": "80.7", "num_updates": "5200", "lr": "1.9605e-05", "gnorm": "129.759", "loss_scale": "8", "train_wall": "343", "gb_free": "71.9", "wall": "9299"}
[2024-07-03 17:39:18,930][train_inner][INFO] - {"epoch": 5, "update": 4.168, "loss": "144.033", "ntokens": "14801.8", "nsentences": "79.4", "nll_loss": "0.773", "wps": "8625.2", "ups": "0.58", "wpb": "14801.8", "bsz": "79.4", "num_updates": "5400", "lr": "2.03475e-05", "gnorm": "132.683", "loss_scale": "8", "train_wall": "343", "gb_free": "72.3", "wall": "9642"}
[2024-07-03 17:45:07,999][train_inner][INFO] - {"epoch": 5, "update": 4.322, "loss": "136.373", "ntokens": "14793.7", "nsentences": "79.76", "nll_loss": "0.735", "wps": "8477.9", "ups": "0.57", "wpb": "14793.7", "bsz": "79.8", "num_updates": "5600", "lr": "2.109e-05", "gnorm": "127.909", "loss_scale": "8", "train_wall": "348", "gb_free": "70.4", "wall": "9991"}
[2024-07-03 17:50:58,978][train_inner][INFO] - {"epoch": 5, "update": 4.476, "loss": "126.779", "ntokens": "14858.6", "nsentences": "82.12", "nll_loss": "0.701", "wps": "8467.3", "ups": "0.57", "wpb": "14858.6", "bsz": "82.1", "num_updates": "5800", "lr": "2.18325e-05", "gnorm": "120.065", "loss_scale": "8", "train_wall": "350", "gb_free": "72.9", "wall": "10342"}
[2024-07-03 17:56:44,962][train_inner][INFO] - {"epoch": 5, "update": 4.631, "loss": "128.968", "ntokens": "14887.3", "nsentences": "80.08", "nll_loss": "0.694", "wps": "8607.6", "ups": "0.58", "wpb": "14887.3", "bsz": "80.1", "num_updates": "6000", "lr": "2.2575e-05", "gnorm": "123.721", "loss_scale": "8", "train_wall": "345", "gb_free": "71.9", "wall": "10688"}
[2024-07-03 18:02:27,830][train_inner][INFO] - {"epoch": 5, "update": 4.785, "loss": "128.459", "ntokens": "14866.3", "nsentences": "80.64", "nll_loss": "0.697", "wps": "8672", "ups": "0.58", "wpb": "14866.3", "bsz": "80.6", "num_updates": "6200", "lr": "2.33175e-05", "gnorm": "124.163", "loss_scale": "8", "train_wall": "342", "gb_free": "71.1", "wall": "11031"}
[2024-07-03 18:08:10,049][train_inner][INFO] - {"epoch": 5, "update": 4.939, "loss": "128.641", "ntokens": "14738.8", "nsentences": "79.99", "nll_loss": "0.698", "wps": "8613.9", "ups": "0.58", "wpb": "14738.8", "bsz": "80", "num_updates": "6400", "lr": "2.406e-05", "gnorm": "131.542", "loss_scale": "16", "train_wall": "342", "gb_free": "71.5", "wall": "11373"}
[2024-07-03 18:10:32,260][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-03 18:10:32,265][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 18:11:11,748][dev-other][INFO] - {"epoch": 5, "dev-other_loss": "29.719", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.316", "dev-other_uer": "5.146", "dev-other_wer": "15.026", "dev-other_raw_wer": "15.026", "dev-other_wps": "6964.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "6479"}
[2024-07-03 18:11:11,761][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 6479 updates
[2024-07-03 18:11:11,762][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt
[2024-07-03 18:11:13,674][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt
[2024-07-03 18:11:14,349][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt (epoch 5 @ 6479 updates, score 15.026) (writing took 2.588418242521584 seconds)
[2024-07-03 18:11:14,350][fairseq_cli.train][INFO] - end of epoch 5 (average epoch stats below)
[2024-07-03 18:11:14,360][train][INFO] - {"epoch": 5, "train_loss": "131.094", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.709", "train_wps": "8390.5", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "6479", "train_lr": "2.43533e-05", "train_gnorm": "126.248", "train_loss_scale": "16", "train_train_wall": "2244", "train_gb_free": "72.1", "train_wall": "11558"}
[2024-07-03 18:11:14,362][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 18:11:14,600][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-03 18:11:14,603][fairseq.trainer][INFO] - begin training epoch 6
[2024-07-03 18:11:14,603][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-03 18:14:48,912][train_inner][INFO] - {"epoch": 6, "update": 5.093, "loss": "118.23", "ntokens": "14735.3", "nsentences": "79.32", "nll_loss": "0.636", "wps": "7388.8", "ups": "0.5", "wpb": "14735.3", "bsz": "79.3", "num_updates": "6600", "lr": "2.48025e-05", "gnorm": "120.401", "loss_scale": "16", "train_wall": "356", "gb_free": "71.6", "wall": "11772"}
[2024-07-03 18:20:34,930][train_inner][INFO] - {"epoch": 6, "update": 5.247, "loss": "122.548", "ntokens": "14934.5", "nsentences": "80.88", "nll_loss": "0.664", "wps": "8633.2", "ups": "0.58", "wpb": "14934.5", "bsz": "80.9", "num_updates": "6800", "lr": "2.5545e-05", "gnorm": "122.096", "loss_scale": "16", "train_wall": "345", "gb_free": "71.9", "wall": "12118"}
[2024-07-03 18:26:22,754][train_inner][INFO] - {"epoch": 6, "update": 5.402, "loss": "116.056", "ntokens": "14834.2", "nsentences": "80.56", "nll_loss": "0.63", "wps": "8530", "ups": "0.58", "wpb": "14834.2", "bsz": "80.6", "num_updates": "7000", "lr": "2.62875e-05", "gnorm": "122.078", "loss_scale": "16", "train_wall": "347", "gb_free": "71.4", "wall": "12466"}
[2024-07-03 18:32:15,525][train_inner][INFO] - {"epoch": 6, "update": 5.556, "loss": "110.448", "ntokens": "14904.6", "nsentences": "81.28", "nll_loss": "0.602", "wps": "8450.2", "ups": "0.57", "wpb": "14904.6", "bsz": "81.3", "num_updates": "7200", "lr": "2.703e-05", "gnorm": "116.733", "loss_scale": "16", "train_wall": "352", "gb_free": "70.7", "wall": "12819"}
[2024-07-03 18:38:02,091][train_inner][INFO] - {"epoch": 6, "update": 5.71, "loss": "117.217", "ntokens": "14780.6", "nsentences": "78.75", "nll_loss": "0.625", "wps": "8529.9", "ups": "0.58", "wpb": "14780.6", "bsz": "78.8", "num_updates": "7400", "lr": "2.77725e-05", "gnorm": "121.906", "loss_scale": "16", "train_wall": "346", "gb_free": "72.1", "wall": "13165"}
[2024-07-03 18:38:20,046][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-03 18:43:54,980][train_inner][INFO] - {"epoch": 6, "update": 5.865, "loss": "108.343", "ntokens": "14695.3", "nsentences": "79.32", "nll_loss": "0.585", "wps": "8329.2", "ups": "0.57", "wpb": "14695.3", "bsz": "79.3", "num_updates": "7600", "lr": "2.8515e-05", "gnorm": "117.976", "loss_scale": "8", "train_wall": "352", "gb_free": "72.4", "wall": "13518"}
[2024-07-03 18:49:01,008][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-03 18:49:01,023][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 18:49:40,298][dev-other][INFO] - {"epoch": 6, "dev-other_loss": "27.779", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.295", "dev-other_uer": "4.691", "dev-other_wer": "13.286", "dev-other_raw_wer": "13.286", "dev-other_wps": "7002.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "7775", "dev-other_best_wer": "13.286"}
[2024-07-03 18:49:40,298][fairseq_cli.train][INFO] - end of epoch 6 (average epoch stats below)
[2024-07-03 18:49:40,302][train][INFO] - {"epoch": 6, "train_loss": "114.859", "train_ntokens": "14822.1", "train_nsentences": "80.1775", "train_nll_loss": "0.621", "train_wps": "8330.4", "train_ups": "0.56", "train_wpb": "14822.1", "train_bsz": "80.2", "train_num_updates": "7775", "train_lr": "2.91647e-05", "train_gnorm": "120.183", "train_loss_scale": "8", "train_train_wall": "2262", "train_gb_free": "71.9", "train_wall": "13864"}
[2024-07-03 18:49:40,303][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 18:49:41,214][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-03 18:49:41,220][fairseq.trainer][INFO] - begin training epoch 7
[2024-07-03 18:49:41,220][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-03 18:50:25,122][train_inner][INFO] - {"epoch": 7, "update": 6.019, "loss": "109.804", "ntokens": "14826.9", "nsentences": "80.64", "nll_loss": "0.597", "wps": "7601.2", "ups": "0.51", "wpb": "14826.9", "bsz": "80.6", "num_updates": "7800", "lr": "2.92575e-05", "gnorm": "119.084", "loss_scale": "8", "train_wall": "349", "gb_free": "72.1", "wall": "13908"}
[2024-07-03 18:56:16,953][train_inner][INFO] - {"epoch": 7, "update": 6.173, "loss": "105.854", "ntokens": "14845.6", "nsentences": "79.64", "nll_loss": "0.568", "wps": "8439.2", "ups": "0.57", "wpb": "14845.6", "bsz": "79.6", "num_updates": "8000", "lr": "3e-05", "gnorm": "117.348", "loss_scale": "8", "train_wall": "351", "gb_free": "71.4", "wall": "14260"}
[2024-07-03 19:02:00,936][train_inner][INFO] - {"epoch": 7, "update": 6.328, "loss": "108.397", "ntokens": "14828.1", "nsentences": "81.03", "nll_loss": "0.592", "wps": "8621.6", "ups": "0.58", "wpb": "14828.1", "bsz": "81", "num_updates": "8200", "lr": "3e-05", "gnorm": "119.633", "loss_scale": "8", "train_wall": "343", "gb_free": "71.8", "wall": "14604"}
[2024-07-03 19:07:47,355][train_inner][INFO] - {"epoch": 7, "update": 6.482, "loss": "113.162", "ntokens": "14722.9", "nsentences": "79.04", "nll_loss": "0.608", "wps": "8500.2", "ups": "0.58", "wpb": "14722.9", "bsz": "79", "num_updates": "8400", "lr": "3e-05", "gnorm": "123.453", "loss_scale": "8", "train_wall": "346", "gb_free": "72", "wall": "14951"}
[2024-07-03 19:13:32,186][train_inner][INFO] - {"epoch": 7, "update": 6.636, "loss": "106.274", "ntokens": "14884.9", "nsentences": "80.28", "nll_loss": "0.573", "wps": "8634.9", "ups": "0.58", "wpb": "14884.9", "bsz": "80.3", "num_updates": "8600", "lr": "3e-05", "gnorm": "120.664", "loss_scale": "8", "train_wall": "344", "gb_free": "70.4", "wall": "15295"}
[2024-07-03 19:19:06,378][train_inner][INFO] - {"epoch": 7, "update": 6.79, "loss": "107.914", "ntokens": "14798.2", "nsentences": "80.84", "nll_loss": "0.59", "wps": "8856.9", "ups": "0.6", "wpb": "14798.2", "bsz": "80.8", "num_updates": "8800", "lr": "3e-05", "gnorm": "119.924", "loss_scale": "8", "train_wall": "334", "gb_free": "73", "wall": "15630"}
[2024-07-03 19:24:54,896][train_inner][INFO] - {"epoch": 7, "update": 6.944, "loss": "105.911", "ntokens": "14861.1", "nsentences": "79.36", "nll_loss": "0.566", "wps": "8528.7", "ups": "0.57", "wpb": "14861.1", "bsz": "79.4", "num_updates": "9000", "lr": "3e-05", "gnorm": "118.987", "loss_scale": "8", "train_wall": "348", "gb_free": "72.6", "wall": "15978"}
[2024-07-03 19:27:02,797][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-03 19:27:02,834][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 19:27:42,412][dev-other][INFO] - {"epoch": 7, "dev-other_loss": "25.93", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.276", "dev-other_uer": "4.38", "dev-other_wer": "12.173", "dev-other_raw_wer": "12.173", "dev-other_wps": "6933.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "9072", "dev-other_best_wer": "12.173"}
[2024-07-03 19:27:42,413][fairseq_cli.train][INFO] - end of epoch 7 (average epoch stats below)
[2024-07-03 19:27:42,417][train][INFO] - {"epoch": 7, "train_loss": "107.265", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.58", "train_wps": "8424.3", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "9072", "train_lr": "3e-05", "train_gnorm": "119.326", "train_loss_scale": "8", "train_train_wall": "2237", "train_gb_free": "72.8", "train_wall": "16146"}
[2024-07-03 19:27:42,420][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 19:27:43,462][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-03 19:27:43,471][fairseq.trainer][INFO] - begin training epoch 8
[2024-07-03 19:27:43,472][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-03 19:31:22,172][train_inner][INFO] - {"epoch": 8, "update": 7.099, "loss": "103.408", "ntokens": "14875", "nsentences": "81.07", "nll_loss": "0.564", "wps": "7685.7", "ups": "0.52", "wpb": "14875", "bsz": "81.1", "num_updates": "9200", "lr": "3e-05", "gnorm": "120.33", "loss_scale": "8", "train_wall": "346", "gb_free": "72", "wall": "16365"}
[2024-07-03 19:37:05,361][train_inner][INFO] - {"epoch": 8, "update": 7.253, "loss": "106.326", "ntokens": "14769.9", "nsentences": "80.48", "nll_loss": "0.579", "wps": "8612", "ups": "0.58", "wpb": "14769.9", "bsz": "80.5", "num_updates": "9400", "lr": "3e-05", "gnorm": "122.257", "loss_scale": "8", "train_wall": "342", "gb_free": "72.1", "wall": "16709"}
[2024-07-03 19:42:47,376][train_inner][INFO] - {"epoch": 8, "update": 7.407, "loss": "102.757", "ntokens": "14881.9", "nsentences": "79.96", "nll_loss": "0.552", "wps": "8704.4", "ups": "0.58", "wpb": "14881.9", "bsz": "80", "num_updates": "9600", "lr": "3e-05", "gnorm": "117.173", "loss_scale": "16", "train_wall": "341", "gb_free": "72.3", "wall": "17051"}
[2024-07-03 19:48:28,984][train_inner][INFO] - {"epoch": 8, "update": 7.561, "loss": "99.269", "ntokens": "14861.9", "nsentences": "81.8", "nll_loss": "0.546", "wps": "8701.4", "ups": "0.59", "wpb": "14861.9", "bsz": "81.8", "num_updates": "9800", "lr": "3e-05", "gnorm": "114.144", "loss_scale": "16", "train_wall": "341", "gb_free": "71.3", "wall": "17392"}
[2024-07-03 19:51:23,639][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-03 19:54:11,071][train_inner][INFO] - {"epoch": 8, "update": 7.716, "loss": "101.147", "ntokens": "14757.6", "nsentences": "79.64", "nll_loss": "0.546", "wps": "8628.1", "ups": "0.58", "wpb": "14757.6", "bsz": "79.6", "num_updates": "10000", "lr": "3e-05", "gnorm": "117.489", "loss_scale": "8", "train_wall": "341", "gb_free": "71.1", "wall": "17734"}
[2024-07-03 19:59:52,542][train_inner][INFO] - {"epoch": 8, "update": 7.87, "loss": "103.815", "ntokens": "14804.5", "nsentences": "77.6", "nll_loss": "0.544", "wps": "8673.2", "ups": "0.59", "wpb": "14804.6", "bsz": "77.6", "num_updates": "10200", "lr": "3e-05", "gnorm": "120.274", "loss_scale": "8", "train_wall": "341", "gb_free": "72.2", "wall": "18076"}
[2024-07-03 20:04:44,401][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-03 20:04:44,469][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 20:05:23,978][dev-other][INFO] - {"epoch": 8, "dev-other_loss": "25.03", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.266", "dev-other_uer": "4.158", "dev-other_wer": "11.512", "dev-other_raw_wer": "11.512", "dev-other_wps": "6955.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "10368", "dev-other_best_wer": "11.512"}
[2024-07-03 20:05:23,980][fairseq_cli.train][INFO] - end of epoch 8 (average epoch stats below)
[2024-07-03 20:05:23,984][train][INFO] - {"epoch": 8, "train_loss": "102.492", "train_ntokens": "14822.3", "train_nsentences": "80.196", "train_nll_loss": "0.555", "train_wps": "8494", "train_ups": "0.57", "train_wpb": "14822.3", "train_bsz": "80.2", "train_num_updates": "10368", "train_lr": "3e-05", "train_gnorm": "118.724", "train_loss_scale": "8", "train_train_wall": "2216", "train_gb_free": "72", "train_wall": "18407"}
[2024-07-03 20:05:23,986][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 20:05:24,936][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-03 20:05:24,942][fairseq.trainer][INFO] - begin training epoch 9
[2024-07-03 20:05:24,942][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-03 20:06:19,272][train_inner][INFO] - {"epoch": 9, "update": 8.025, "loss": "97.687", "ntokens": "14858.6", "nsentences": "82.08", "nll_loss": "0.54", "wps": "7685.1", "ups": "0.52", "wpb": "14858.6", "bsz": "82.1", "num_updates": "10400", "lr": "3e-05", "gnorm": "114.977", "loss_scale": "8", "train_wall": "345", "gb_free": "73", "wall": "18463"}
[2024-07-03 20:12:01,938][train_inner][INFO] - {"epoch": 9, "update": 8.179, "loss": "106.599", "ntokens": "14664.5", "nsentences": "77.88", "nll_loss": "0.566", "wps": "8560.5", "ups": "0.58", "wpb": "14664.5", "bsz": "77.9", "num_updates": "10600", "lr": "3e-05", "gnorm": "126.626", "loss_scale": "8", "train_wall": "342", "gb_free": "72.2", "wall": "18805"}
[2024-07-03 20:17:49,466][train_inner][INFO] - {"epoch": 9, "update": 8.333, "loss": "97.924", "ntokens": "14892.3", "nsentences": "81.39", "nll_loss": "0.535", "wps": "8572", "ups": "0.58", "wpb": "14892.3", "bsz": "81.4", "num_updates": "10800", "lr": "3e-05", "gnorm": "120.913", "loss_scale": "8", "train_wall": "347", "gb_free": "71.6", "wall": "19153"}
[2024-07-03 20:23:32,421][train_inner][INFO] - {"epoch": 9, "update": 8.487, "loss": "97.364", "ntokens": "14798.2", "nsentences": "80.72", "nll_loss": "0.531", "wps": "8631.7", "ups": "0.58", "wpb": "14798.2", "bsz": "80.7", "num_updates": "11000", "lr": "3e-05", "gnorm": "115.476", "loss_scale": "8", "train_wall": "342", "gb_free": "72.3", "wall": "19496"}
[2024-07-03 20:29:14,982][train_inner][INFO] - {"epoch": 9, "update": 8.641, "loss": "100.342", "ntokens": "14831.8", "nsentences": "79.24", "nll_loss": "0.536", "wps": "8661.3", "ups": "0.58", "wpb": "14831.8", "bsz": "79.2", "num_updates": "11200", "lr": "3e-05", "gnorm": "118.361", "loss_scale": "8", "train_wall": "342", "gb_free": "72", "wall": "19838"}
[2024-07-03 20:35:05,028][train_inner][INFO] - {"epoch": 9, "update": 8.796, "loss": "95.998", "ntokens": "14866.8", "nsentences": "80.16", "nll_loss": "0.518", "wps": "8496", "ups": "0.57", "wpb": "14866.8", "bsz": "80.2", "num_updates": "11400", "lr": "3e-05", "gnorm": "115.079", "loss_scale": "8", "train_wall": "349", "gb_free": "72.7", "wall": "20188"}
[2024-07-03 20:40:49,280][train_inner][INFO] - {"epoch": 9, "update": 8.95, "loss": "100.271", "ntokens": "14894.2", "nsentences": "81.64", "nll_loss": "0.55", "wps": "8654.8", "ups": "0.58", "wpb": "14894.2", "bsz": "81.6", "num_updates": "11600", "lr": "3e-05", "gnorm": "118.467", "loss_scale": "8", "train_wall": "344", "gb_free": "72.8", "wall": "20533"}
[2024-07-03 20:42:41,993][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-03 20:42:42,058][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 20:43:21,710][dev-other][INFO] - {"epoch": 9, "dev-other_loss": "24.813", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.264", "dev-other_uer": "4.117", "dev-other_wer": "11.359", "dev-other_raw_wer": "11.359", "dev-other_wps": "6922.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "11665", "dev-other_best_wer": "11.359"}
[2024-07-03 20:43:21,715][fairseq_cli.train][INFO] - end of epoch 9 (average epoch stats below)
[2024-07-03 20:43:21,720][train][INFO] - {"epoch": 9, "train_loss": "99.35", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.538", "train_wps": "8440.5", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "11665", "train_lr": "3e-05", "train_gnorm": "118.793", "train_loss_scale": "8", "train_train_wall": "2233", "train_gb_free": "72.2", "train_wall": "20685"}
[2024-07-03 20:43:21,723][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 20:43:22,568][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-03 20:43:22,574][fairseq.trainer][INFO] - begin training epoch 10
[2024-07-03 20:43:22,574][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-03 20:46:34,562][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-07-03 20:47:11,695][train_inner][INFO] - {"epoch": 10, "update": 9.105, "loss": "98.519", "ntokens": "14749.2", "nsentences": "80", "nll_loss": "0.534", "wps": "7715.3", "ups": "0.52", "wpb": "14749.2", "bsz": "80", "num_updates": "11800", "lr": "3e-05", "gnorm": "117.41", "loss_scale": "4", "train_wall": "341", "gb_free": "72.3", "wall": "20915"}
[2024-07-03 20:53:02,217][train_inner][INFO] - {"epoch": 10, "update": 9.259, "loss": "92.819", "ntokens": "14835.9", "nsentences": "79.76", "nll_loss": "0.499", "wps": "8465.3", "ups": "0.57", "wpb": "14835.9", "bsz": "79.8", "num_updates": "12000", "lr": "3e-05", "gnorm": "113.067", "loss_scale": "4", "train_wall": "350", "gb_free": "71.8", "wall": "21266"}
[2024-07-03 20:58:45,093][train_inner][INFO] - {"epoch": 10, "update": 9.413, "loss": "97.079", "ntokens": "14795.4", "nsentences": "80.48", "nll_loss": "0.528", "wps": "8631.9", "ups": "0.58", "wpb": "14795.4", "bsz": "80.5", "num_updates": "12200", "lr": "3e-05", "gnorm": "115.605", "loss_scale": "4", "train_wall": "342", "gb_free": "71.2", "wall": "21608"}
[2024-07-03 21:04:24,634][train_inner][INFO] - {"epoch": 10, "update": 9.567, "loss": "90.798", "ntokens": "14875.5", "nsentences": "82.24", "nll_loss": "0.502", "wps": "8764.1", "ups": "0.59", "wpb": "14875.5", "bsz": "82.2", "num_updates": "12400", "lr": "3e-05", "gnorm": "112.813", "loss_scale": "4", "train_wall": "339", "gb_free": "71.5", "wall": "21948"}
[2024-07-03 21:10:11,402][train_inner][INFO] - {"epoch": 10, "update": 9.722, "loss": "94.647", "ntokens": "14838.5", "nsentences": "80.4", "nll_loss": "0.513", "wps": "8559.9", "ups": "0.58", "wpb": "14838.5", "bsz": "80.4", "num_updates": "12600", "lr": "3e-05", "gnorm": "116.302", "loss_scale": "4", "train_wall": "346", "gb_free": "69.3", "wall": "22295"}
[2024-07-03 21:16:00,924][train_inner][INFO] - {"epoch": 10, "update": 9.876, "loss": "99.362", "ntokens": "14850.2", "nsentences": "78.67", "nll_loss": "0.526", "wps": "8499.1", "ups": "0.57", "wpb": "14850.2", "bsz": "78.7", "num_updates": "12800", "lr": "3e-05", "gnorm": "117.457", "loss_scale": "4", "train_wall": "349", "gb_free": "73", "wall": "22644"}
[2024-07-03 21:20:38,526][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-03 21:20:38,530][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 21:21:17,789][dev-other][INFO] - {"epoch": 10, "dev-other_loss": "23.656", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.251", "dev-other_uer": "3.975", "dev-other_wer": "10.907", "dev-other_raw_wer": "10.907", "dev-other_wps": "7024.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "12961", "dev-other_best_wer": "10.907"}
[2024-07-03 21:21:17,792][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 10 @ 12961 updates
[2024-07-03 21:21:17,793][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt
[2024-07-03 21:21:19,733][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt
[2024-07-03 21:21:20,345][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt (epoch 10 @ 12961 updates, score 10.907) (writing took 2.5536568770185113 seconds)
[2024-07-03 21:21:20,346][fairseq_cli.train][INFO] - end of epoch 10 (average epoch stats below)
[2024-07-03 21:21:20,350][train][INFO] - {"epoch": 10, "train_loss": "95.825", "train_ntokens": "14824.2", "train_nsentences": "80.2083", "train_nll_loss": "0.518", "train_wps": "8431.5", "train_ups": "0.57", "train_wpb": "14824.2", "train_bsz": "80.2", "train_num_updates": "12961", "train_lr": "3e-05", "train_gnorm": "115.626", "train_loss_scale": "4", "train_train_wall": "2232", "train_gb_free": "71.7", "train_wall": "22964"}
[2024-07-03 21:21:20,351][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 21:21:20,712][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-03 21:21:20,718][fairseq.trainer][INFO] - begin training epoch 11
[2024-07-03 21:21:20,718][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-03 21:22:28,195][train_inner][INFO] - {"epoch": 11, "update": 10.03, "loss": "95.907", "ntokens": "14803.7", "nsentences": "79.84", "nll_loss": "0.517", "wps": "7645.3", "ups": "0.52", "wpb": "14803.7", "bsz": "79.8", "num_updates": "13000", "lr": "3e-05", "gnorm": "116.099", "loss_scale": "4", "train_wall": "344", "gb_free": "70.7", "wall": "23032"}
[2024-07-03 21:28:14,315][train_inner][INFO] - {"epoch": 11, "update": 10.184, "loss": "90.349", "ntokens": "14820.8", "nsentences": "79.64", "nll_loss": "0.485", "wps": "8565.7", "ups": "0.58", "wpb": "14820.8", "bsz": "79.6", "num_updates": "13200", "lr": "3e-05", "gnorm": "115.07", "loss_scale": "4", "train_wall": "345", "gb_free": "70.3", "wall": "23378"}
[2024-07-03 21:34:00,050][train_inner][INFO] - {"epoch": 11, "update": 10.338, "loss": "91.825", "ntokens": "14731.7", "nsentences": "79.56", "nll_loss": "0.496", "wps": "8523.5", "ups": "0.58", "wpb": "14731.7", "bsz": "79.6", "num_updates": "13400", "lr": "3e-05", "gnorm": "113.2", "loss_scale": "4", "train_wall": "345", "gb_free": "71.3", "wall": "23723"}
[2024-07-03 21:39:46,043][train_inner][INFO] - {"epoch": 11, "update": 10.493, "loss": "92.305", "ntokens": "14827.6", "nsentences": "79.96", "nll_loss": "0.498", "wps": "8573", "ups": "0.58", "wpb": "14827.6", "bsz": "80", "num_updates": "13600", "lr": "3e-05", "gnorm": "113.696", "loss_scale": "4", "train_wall": "345", "gb_free": "72.7", "wall": "24069"}
[2024-07-03 21:45:34,273][train_inner][INFO] - {"epoch": 11, "update": 10.647, "loss": "93.563", "ntokens": "14830.8", "nsentences": "80.28", "nll_loss": "0.506", "wps": "8519.7", "ups": "0.57", "wpb": "14830.8", "bsz": "80.3", "num_updates": "13800", "lr": "3e-05", "gnorm": "117.091", "loss_scale": "4", "train_wall": "348", "gb_free": "72.1", "wall": "24418"}
[2024-07-03 21:51:25,559][train_inner][INFO] - {"epoch": 11, "update": 10.801, "loss": "90.586", "ntokens": "14811.8", "nsentences": "81.28", "nll_loss": "0.497", "wps": "8434.6", "ups": "0.57", "wpb": "14811.8", "bsz": "81.3", "num_updates": "14000", "lr": "3e-05", "gnorm": "110.786", "loss_scale": "8", "train_wall": "351", "gb_free": "71.8", "wall": "24769"}
[2024-07-03 21:57:08,043][train_inner][INFO] - {"epoch": 11, "update": 10.955, "loss": "91.628", "ntokens": "14901.4", "nsentences": "80.91", "nll_loss": "0.498", "wps": "8702.4", "ups": "0.58", "wpb": "14901.4", "bsz": "80.9", "num_updates": "14200", "lr": "3e-05", "gnorm": "113.733", "loss_scale": "8", "train_wall": "342", "gb_free": "71.8", "wall": "25111"}
[2024-07-03 21:58:48,837][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-03 21:58:48,841][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 21:59:28,238][dev-other][INFO] - {"epoch": 11, "dev-other_loss": "23.47", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.249", "dev-other_uer": "3.943", "dev-other_wer": "10.774", "dev-other_raw_wer": "10.774", "dev-other_wps": "6982.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "14258", "dev-other_best_wer": "10.774"}
[2024-07-03 21:59:28,240][fairseq_cli.train][INFO] - end of epoch 11 (average epoch stats below)
[2024-07-03 21:59:28,244][train][INFO] - {"epoch": 11, "train_loss": "91.609", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.496", "train_wps": "8403.1", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "14258", "train_lr": "3e-05", "train_gnorm": "113.911", "train_loss_scale": "8", "train_train_wall": "2244", "train_gb_free": "72.4", "train_wall": "25252"}
[2024-07-03 21:59:28,246][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 21:59:29,134][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-03 21:59:29,147][fairseq.trainer][INFO] - begin training epoch 12
[2024-07-03 21:59:29,147][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-03 22:03:32,001][train_inner][INFO] - {"epoch": 12, "update": 11.109, "loss": "88.438", "ntokens": "14846.9", "nsentences": "80.36", "nll_loss": "0.479", "wps": "7733.8", "ups": "0.52", "wpb": "14846.9", "bsz": "80.4", "num_updates": "14400", "lr": "3e-05", "gnorm": "114.11", "loss_scale": "8", "train_wall": "343", "gb_free": "72.8", "wall": "25495"}
[2024-07-03 22:09:17,146][train_inner][INFO] - {"epoch": 12, "update": 11.264, "loss": "93.013", "ntokens": "14701.4", "nsentences": "77.96", "nll_loss": "0.493", "wps": "8520.7", "ups": "0.58", "wpb": "14701.4", "bsz": "78", "num_updates": "14600", "lr": "3e-05", "gnorm": "116.093", "loss_scale": "8", "train_wall": "344", "gb_free": "73.1", "wall": "25840"}
[2024-07-03 22:15:04,484][train_inner][INFO] - {"epoch": 12, "update": 11.418, "loss": "93.311", "ntokens": "14749.1", "nsentences": "78.48", "nll_loss": "0.497", "wps": "8494.7", "ups": "0.58", "wpb": "14749.1", "bsz": "78.5", "num_updates": "14800", "lr": "3e-05", "gnorm": "114.704", "loss_scale": "8", "train_wall": "347", "gb_free": "71.6", "wall": "26188"}
[2024-07-03 22:20:50,713][train_inner][INFO] - {"epoch": 12, "update": 11.572, "loss": "87.351", "ntokens": "14817.5", "nsentences": "80.64", "nll_loss": "0.475", "wps": "8561.4", "ups": "0.58", "wpb": "14817.5", "bsz": "80.6", "num_updates": "15000", "lr": "3e-05", "gnorm": "110.802", "loss_scale": "8", "train_wall": "346", "gb_free": "72.4", "wall": "26534"}
[2024-07-03 22:26:32,640][train_inner][INFO] - {"epoch": 12, "update": 11.726, "loss": "90.009", "ntokens": "14916", "nsentences": "81.36", "nll_loss": "0.491", "wps": "8727.3", "ups": "0.59", "wpb": "14916", "bsz": "81.4", "num_updates": "15200", "lr": "3e-05", "gnorm": "111.042", "loss_scale": "8", "train_wall": "341", "gb_free": "72.8", "wall": "26876"}
[2024-07-03 22:32:15,607][train_inner][INFO] - {"epoch": 12, "update": 11.88, "loss": "87.304", "ntokens": "14929.6", "nsentences": "82.04", "nll_loss": "0.48", "wps": "8706.3", "ups": "0.58", "wpb": "14929.6", "bsz": "82", "num_updates": "15400", "lr": "3e-05", "gnorm": "110.406", "loss_scale": "8", "train_wall": "342", "gb_free": "72.4", "wall": "27219"}
[2024-07-03 22:36:42,383][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-03 22:36:42,450][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 22:37:21,477][dev-other][INFO] - {"epoch": 12, "dev-other_loss": "24.635", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.262", "dev-other_uer": "4.029", "dev-other_wer": "10.903", "dev-other_raw_wer": "10.903", "dev-other_wps": "7027.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "15555", "dev-other_best_wer": "10.903"}
[2024-07-03 22:37:21,479][fairseq_cli.train][INFO] - end of epoch 12 (average epoch stats below)
[2024-07-03 22:37:21,483][train][INFO] - {"epoch": 12, "train_loss": "90.117", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.488", "train_wps": "8457.2", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "15555", "train_lr": "3e-05", "train_gnorm": "112.834", "train_loss_scale": "8", "train_train_wall": "2229", "train_gb_free": "70.1", "train_wall": "27525"}
[2024-07-03 22:37:21,486][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 22:37:22,422][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-03 22:37:22,427][fairseq.trainer][INFO] - begin training epoch 13
[2024-07-03 22:37:22,428][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-03 22:38:43,487][train_inner][INFO] - {"epoch": 13, "update": 12.035, "loss": "92.368", "ntokens": "14858.2", "nsentences": "79.46", "nll_loss": "0.494", "wps": "7662.9", "ups": "0.52", "wpb": "14858.2", "bsz": "79.5", "num_updates": "15600", "lr": "3e-05", "gnorm": "113.052", "loss_scale": "8", "train_wall": "347", "gb_free": "71.9", "wall": "27607"}
[2024-07-03 22:44:30,781][train_inner][INFO] - {"epoch": 13, "update": 12.189, "loss": "87.137", "ntokens": "14808.4", "nsentences": "81.28", "nll_loss": "0.478", "wps": "8529.8", "ups": "0.58", "wpb": "14808.4", "bsz": "81.3", "num_updates": "15800", "lr": "3e-05", "gnorm": "114.603", "loss_scale": "8", "train_wall": "347", "gb_free": "71.1", "wall": "27954"}
[2024-07-03 22:50:15,922][train_inner][INFO] - {"epoch": 13, "update": 12.343, "loss": "88.611", "ntokens": "14827.1", "nsentences": "80.16", "nll_loss": "0.479", "wps": "8592.7", "ups": "0.58", "wpb": "14827.1", "bsz": "80.2", "num_updates": "16000", "lr": "3e-05", "gnorm": "112.56", "loss_scale": "16", "train_wall": "345", "gb_free": "72.2", "wall": "28299"}
[2024-07-03 22:56:04,211][train_inner][INFO] - {"epoch": 13, "update": 12.497, "loss": "90.19", "ntokens": "14822.5", "nsentences": "79.12", "nll_loss": "0.481", "wps": "8513.2", "ups": "0.57", "wpb": "14822.5", "bsz": "79.1", "num_updates": "16200", "lr": "3e-05", "gnorm": "111.737", "loss_scale": "16", "train_wall": "348", "gb_free": "71.7", "wall": "28647"}
[2024-07-03 23:01:47,788][train_inner][INFO] - {"epoch": 13, "update": 12.652, "loss": "87.395", "ntokens": "14856.6", "nsentences": "81.28", "nll_loss": "0.478", "wps": "8648.6", "ups": "0.58", "wpb": "14856.6", "bsz": "81.3", "num_updates": "16400", "lr": "3e-05", "gnorm": "111.969", "loss_scale": "16", "train_wall": "343", "gb_free": "72.7", "wall": "28991"}
[2024-07-03 23:07:27,160][train_inner][INFO] - {"epoch": 13, "update": 12.806, "loss": "88.684", "ntokens": "14799.2", "nsentences": "79.52", "nll_loss": "0.477", "wps": "8722.3", "ups": "0.59", "wpb": "14799.2", "bsz": "79.5", "num_updates": "16600", "lr": "3e-05", "gnorm": "114.217", "loss_scale": "16", "train_wall": "339", "gb_free": "72.4", "wall": "29330"}
[2024-07-03 23:13:13,557][train_inner][INFO] - {"epoch": 13, "update": 12.96, "loss": "90.712", "ntokens": "14788.7", "nsentences": "80.88", "nll_loss": "0.496", "wps": "8538.8", "ups": "0.58", "wpb": "14788.7", "bsz": "80.9", "num_updates": "16800", "lr": "3e-05", "gnorm": "112.978", "loss_scale": "16", "train_wall": "346", "gb_free": "69.8", "wall": "29677"}
[2024-07-03 23:14:42,537][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-03 23:14:42,606][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 23:15:22,257][dev-other][INFO] - {"epoch": 13, "dev-other_loss": "23.591", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.251", "dev-other_uer": "3.899", "dev-other_wer": "10.546", "dev-other_raw_wer": "10.546", "dev-other_wps": "6914.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "16852", "dev-other_best_wer": "10.546"}
[2024-07-03 23:15:22,258][fairseq_cli.train][INFO] - end of epoch 13 (average epoch stats below)
[2024-07-03 23:15:22,261][train][INFO] - {"epoch": 13, "train_loss": "88.967", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.481", "train_wps": "8429.3", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "16852", "train_lr": "3e-05", "train_gnorm": "113.031", "train_loss_scale": "16", "train_train_wall": "2236", "train_gb_free": "71.6", "train_wall": "29806"}
[2024-07-03 23:15:22,263][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 23:15:23,236][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-03 23:15:23,263][fairseq.trainer][INFO] - begin training epoch 14
[2024-07-03 23:15:23,263][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-03 23:19:37,463][train_inner][INFO] - {"epoch": 14, "update": 13.114, "loss": "92.297", "ntokens": "14695.9", "nsentences": "77.64", "nll_loss": "0.488", "wps": "7657.9", "ups": "0.52", "wpb": "14695.9", "bsz": "77.6", "num_updates": "17000", "lr": "3e-05", "gnorm": "116.01", "loss_scale": "16", "train_wall": "342", "gb_free": "72.8", "wall": "30061"}
[2024-07-03 23:25:23,923][train_inner][INFO] - {"epoch": 14, "update": 13.268, "loss": "88.321", "ntokens": "14852.7", "nsentences": "79.52", "nll_loss": "0.473", "wps": "8575.9", "ups": "0.58", "wpb": "14852.7", "bsz": "79.5", "num_updates": "17200", "lr": "3e-05", "gnorm": "112.073", "loss_scale": "16", "train_wall": "346", "gb_free": "71.1", "wall": "30407"}
[2024-07-03 23:31:07,082][train_inner][INFO] - {"epoch": 14, "update": 13.423, "loss": "87.21", "ntokens": "14803.8", "nsentences": "79.96", "nll_loss": "0.471", "wps": "8629.9", "ups": "0.58", "wpb": "14803.8", "bsz": "80", "num_updates": "17400", "lr": "3e-05", "gnorm": "111.518", "loss_scale": "16", "train_wall": "342", "gb_free": "72.2", "wall": "30750"}
[2024-07-03 23:36:56,438][train_inner][INFO] - {"epoch": 14, "update": 13.577, "loss": "88.169", "ntokens": "14751.8", "nsentences": "79.43", "nll_loss": "0.475", "wps": "8445.6", "ups": "0.57", "wpb": "14751.8", "bsz": "79.4", "num_updates": "17600", "lr": "3e-05", "gnorm": "110.862", "loss_scale": "16", "train_wall": "349", "gb_free": "72.6", "wall": "31100"}
[2024-07-03 23:42:41,530][train_inner][INFO] - {"epoch": 14, "update": 13.731, "loss": "87.595", "ntokens": "14868.3", "nsentences": "81.48", "nll_loss": "0.48", "wps": "8617.3", "ups": "0.58", "wpb": "14868.3", "bsz": "81.5", "num_updates": "17800", "lr": "3e-05", "gnorm": "112.844", "loss_scale": "16", "train_wall": "344", "gb_free": "72.5", "wall": "31445"}
[2024-07-03 23:48:27,553][train_inner][INFO] - {"epoch": 14, "update": 13.885, "loss": "83.537", "ntokens": "14862.3", "nsentences": "81.68", "nll_loss": "0.459", "wps": "8592", "ups": "0.58", "wpb": "14862.3", "bsz": "81.7", "num_updates": "18000", "lr": "3e-05", "gnorm": "109.57", "loss_scale": "32", "train_wall": "345", "gb_free": "71.1", "wall": "31791"}
[2024-07-03 23:52:45,242][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-03 23:52:45,246][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 23:53:24,754][dev-other][INFO] - {"epoch": 14, "dev-other_loss": "24.635", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.262", "dev-other_uer": "3.937", "dev-other_wer": "10.583", "dev-other_raw_wer": "10.583", "dev-other_wps": "6986.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "18149", "dev-other_best_wer": "10.583"}
[2024-07-03 23:53:24,755][fairseq_cli.train][INFO] - end of epoch 14 (average epoch stats below)
[2024-07-03 23:53:24,760][train][INFO] - {"epoch": 14, "train_loss": "87.549", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.474", "train_wps": "8422.9", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "18149", "train_lr": "3e-05", "train_gnorm": "111.842", "train_loss_scale": "32", "train_train_wall": "2238", "train_gb_free": "72.1", "train_wall": "32088"}
[2024-07-03 23:53:24,763][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-03 23:53:25,674][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-03 23:53:25,680][fairseq.trainer][INFO] - begin training epoch 15
[2024-07-03 23:53:25,681][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-03 23:54:54,905][train_inner][INFO] - {"epoch": 15, "update": 14.039, "loss": "86.386", "ntokens": "14907.2", "nsentences": "80.6", "nll_loss": "0.467", "wps": "7697.2", "ups": "0.52", "wpb": "14907.2", "bsz": "80.6", "num_updates": "18200", "lr": "3e-05", "gnorm": "110.785", "loss_scale": "32", "train_wall": "346", "gb_free": "71.5", "wall": "32178"}
[2024-07-04 00:00:44,613][train_inner][INFO] - {"epoch": 15, "update": 14.194, "loss": "84.387", "ntokens": "14872.2", "nsentences": "79.88", "nll_loss": "0.453", "wps": "8507.9", "ups": "0.57", "wpb": "14872.2", "bsz": "79.9", "num_updates": "18400", "lr": "3e-05", "gnorm": "109.156", "loss_scale": "32", "train_wall": "349", "gb_free": "72.1", "wall": "32528"}
[2024-07-04 00:06:30,827][train_inner][INFO] - {"epoch": 15, "update": 14.348, "loss": "86.56", "ntokens": "14726.9", "nsentences": "78.04", "nll_loss": "0.459", "wps": "8509.4", "ups": "0.58", "wpb": "14726.9", "bsz": "78", "num_updates": "18600", "lr": "3e-05", "gnorm": "113.815", "loss_scale": "32", "train_wall": "346", "gb_free": "72.6", "wall": "32874"}
[2024-07-04 00:11:29,619][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-04 00:11:36,444][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-04 00:12:18,580][train_inner][INFO] - {"epoch": 15, "update": 14.503, "loss": "82.482", "ntokens": "14865.2", "nsentences": "82.72", "nll_loss": "0.459", "wps": "8549.5", "ups": "0.58", "wpb": "14865.2", "bsz": "82.7", "num_updates": "18800", "lr": "3e-05", "gnorm": "108.837", "loss_scale": "8", "train_wall": "347", "gb_free": "71.4", "wall": "33222"}
[2024-07-04 00:18:02,235][train_inner][INFO] - {"epoch": 15, "update": 14.658, "loss": "87.064", "ntokens": "14799.3", "nsentences": "80.4", "nll_loss": "0.473", "wps": "8614.6", "ups": "0.58", "wpb": "14799.3", "bsz": "80.4", "num_updates": "19000", "lr": "3e-05", "gnorm": "111.377", "loss_scale": "8", "train_wall": "343", "gb_free": "72.4", "wall": "33566"}
[2024-07-04 00:23:54,128][train_inner][INFO] - {"epoch": 15, "update": 14.812, "loss": "83.819", "ntokens": "14840.8", "nsentences": "79.8", "nll_loss": "0.451", "wps": "8435.1", "ups": "0.57", "wpb": "14840.8", "bsz": "79.8", "num_updates": "19200", "lr": "3e-05", "gnorm": "110.405", "loss_scale": "8", "train_wall": "351", "gb_free": "72.7", "wall": "33917"}
[2024-07-04 00:29:41,414][train_inner][INFO] - {"epoch": 15, "update": 14.966, "loss": "83.668", "ntokens": "14850.3", "nsentences": "81.24", "nll_loss": "0.458", "wps": "8552.3", "ups": "0.58", "wpb": "14850.3", "bsz": "81.2", "num_updates": "19400", "lr": "3e-05", "gnorm": "108.945", "loss_scale": "8", "train_wall": "347", "gb_free": "72.4", "wall": "34265"}
[2024-07-04 00:31:00,628][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 00:31:00,707][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 00:31:39,901][dev-other][INFO] - {"epoch": 15, "dev-other_loss": "23.367", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.248", "dev-other_uer": "3.853", "dev-other_wer": "10.34", "dev-other_raw_wer": "10.34", "dev-other_wps": "6998.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "19444", "dev-other_best_wer": "10.34"}
[2024-07-04 00:31:39,904][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 15 @ 19444 updates
[2024-07-04 00:31:39,906][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt
[2024-07-04 00:31:42,068][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt
[2024-07-04 00:31:42,683][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt (epoch 15 @ 19444 updates, score 10.34) (writing took 2.7791893742978573 seconds)
[2024-07-04 00:31:42,684][fairseq_cli.train][INFO] - end of epoch 15 (average epoch stats below)
[2024-07-04 00:31:42,688][train][INFO] - {"epoch": 15, "train_loss": "84.571", "train_ntokens": "14822.5", "train_nsentences": "80.2039", "train_nll_loss": "0.458", "train_wps": "8353.2", "train_ups": "0.56", "train_wpb": "14822.5", "train_bsz": "80.2", "train_num_updates": "19444", "train_lr": "3e-05", "train_gnorm": "110.435", "train_loss_scale": "8", "train_train_wall": "2251", "train_gb_free": "72.3", "train_wall": "34386"}
[2024-07-04 00:31:42,689][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 00:31:42,974][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 00:31:42,980][fairseq.trainer][INFO] - begin training epoch 16
[2024-07-04 00:31:42,980][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 00:36:18,537][train_inner][INFO] - {"epoch": 16, "update": 15.12, "loss": "84.703", "ntokens": "14809.7", "nsentences": "79.56", "nll_loss": "0.455", "wps": "7458.7", "ups": "0.5", "wpb": "14809.7", "bsz": "79.6", "num_updates": "19600", "lr": "3e-05", "gnorm": "110.249", "loss_scale": "8", "train_wall": "354", "gb_free": "72.1", "wall": "34662"}
[2024-07-04 00:42:06,507][train_inner][INFO] - {"epoch": 16, "update": 15.274, "loss": "85.886", "ntokens": "14744.1", "nsentences": "78.59", "nll_loss": "0.458", "wps": "8474.5", "ups": "0.57", "wpb": "14744.1", "bsz": "78.6", "num_updates": "19800", "lr": "3e-05", "gnorm": "111.708", "loss_scale": "8", "train_wall": "347", "gb_free": "71.2", "wall": "35010"}
[2024-07-04 00:47:53,812][train_inner][INFO] - {"epoch": 16, "update": 15.429, "loss": "83.093", "ntokens": "14897.4", "nsentences": "81.56", "nll_loss": "0.455", "wps": "8579.1", "ups": "0.58", "wpb": "14897.4", "bsz": "81.6", "num_updates": "20000", "lr": "3e-05", "gnorm": "106.694", "loss_scale": "8", "train_wall": "347", "gb_free": "73", "wall": "35357"}
[2024-07-04 00:53:39,279][train_inner][INFO] - {"epoch": 16, "update": 15.583, "loss": "84.497", "ntokens": "14799.8", "nsentences": "80.24", "nll_loss": "0.458", "wps": "8568.2", "ups": "0.58", "wpb": "14799.8", "bsz": "80.2", "num_updates": "20200", "lr": "3e-05", "gnorm": "111.891", "loss_scale": "8", "train_wall": "345", "gb_free": "72.4", "wall": "35703"}
[2024-07-04 00:59:22,708][train_inner][INFO] - {"epoch": 16, "update": 15.737, "loss": "87.04", "ntokens": "14847.4", "nsentences": "79.48", "nll_loss": "0.466", "wps": "8648.2", "ups": "0.58", "wpb": "14847.4", "bsz": "79.5", "num_updates": "20400", "lr": "3e-05", "gnorm": "111.252", "loss_scale": "8", "train_wall": "343", "gb_free": "72.2", "wall": "36046"}
[2024-07-04 01:05:09,630][train_inner][INFO] - {"epoch": 16, "update": 15.891, "loss": "81.843", "ntokens": "14751.3", "nsentences": "79.68", "nll_loss": "0.442", "wps": "8504.3", "ups": "0.58", "wpb": "14751.3", "bsz": "79.7", "num_updates": "20600", "lr": "3e-05", "gnorm": "109.276", "loss_scale": "8", "train_wall": "346", "gb_free": "72.5", "wall": "36393"}
[2024-07-04 01:09:11,832][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 01:09:11,892][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 01:09:51,101][dev-other][INFO] - {"epoch": 16, "dev-other_loss": "23.646", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.251", "dev-other_uer": "3.843", "dev-other_wer": "10.238", "dev-other_raw_wer": "10.238", "dev-other_wps": "7012", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "20741", "dev-other_best_wer": "10.238"}
[2024-07-04 01:09:51,102][fairseq_cli.train][INFO] - end of epoch 16 (average epoch stats below)
[2024-07-04 01:09:51,107][train][INFO] - {"epoch": 16, "train_loss": "84.213", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.456", "train_wps": "8401.1", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "20741", "train_lr": "3e-05", "train_gnorm": "110.293", "train_loss_scale": "8", "train_train_wall": "2245", "train_gb_free": "71.4", "train_wall": "36674"}
[2024-07-04 01:09:51,110][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 01:09:51,965][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 01:09:51,969][fairseq.trainer][INFO] - begin training epoch 17
[2024-07-04 01:09:51,969][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 01:11:32,317][train_inner][INFO] - {"epoch": 17, "update": 16.045, "loss": "82.519", "ntokens": "14896.9", "nsentences": "81.92", "nll_loss": "0.454", "wps": "7786.5", "ups": "0.52", "wpb": "14896.9", "bsz": "81.9", "num_updates": "20800", "lr": "3e-05", "gnorm": "111.77", "loss_scale": "8", "train_wall": "342", "gb_free": "73.3", "wall": "36776"}
[2024-07-04 01:17:19,954][train_inner][INFO] - {"epoch": 17, "update": 16.2, "loss": "83.894", "ntokens": "14901.9", "nsentences": "80.2", "nll_loss": "0.452", "wps": "8573.5", "ups": "0.58", "wpb": "14901.9", "bsz": "80.2", "num_updates": "21000", "lr": "3e-05", "gnorm": "108.524", "loss_scale": "16", "train_wall": "347", "gb_free": "71.9", "wall": "37123"}
[2024-07-04 01:19:34,977][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-04 01:23:11,147][train_inner][INFO] - {"epoch": 17, "update": 16.355, "loss": "83.616", "ntokens": "14734.3", "nsentences": "79.12", "nll_loss": "0.449", "wps": "8392.5", "ups": "0.57", "wpb": "14734.3", "bsz": "79.1", "num_updates": "21200", "lr": "3e-05", "gnorm": "109.314", "loss_scale": "8", "train_wall": "351", "gb_free": "72.3", "wall": "37474"}
[2024-07-04 01:28:53,911][train_inner][INFO] - {"epoch": 17, "update": 16.509, "loss": "83.75", "ntokens": "14874.7", "nsentences": "80.84", "nll_loss": "0.455", "wps": "8680.8", "ups": "0.58", "wpb": "14874.7", "bsz": "80.8", "num_updates": "21400", "lr": "3e-05", "gnorm": "110.758", "loss_scale": "8", "train_wall": "342", "gb_free": "72.9", "wall": "37817"}
[2024-07-04 01:34:42,418][train_inner][INFO] - {"epoch": 17, "update": 16.663, "loss": "80.934", "ntokens": "14922.1", "nsentences": "81.92", "nll_loss": "0.444", "wps": "8565.2", "ups": "0.57", "wpb": "14922.1", "bsz": "81.9", "num_updates": "21600", "lr": "3e-05", "gnorm": "106.058", "loss_scale": "8", "train_wall": "348", "gb_free": "71.1", "wall": "38166"}
[2024-07-04 01:40:24,713][train_inner][INFO] - {"epoch": 17, "update": 16.817, "loss": "86.68", "ntokens": "14692.8", "nsentences": "79.64", "nll_loss": "0.47", "wps": "8587.3", "ups": "0.58", "wpb": "14692.8", "bsz": "79.6", "num_updates": "21800", "lr": "3e-05", "gnorm": "116.035", "loss_scale": "8", "train_wall": "342", "gb_free": "71.9", "wall": "38508"}
[2024-07-04 01:46:11,213][train_inner][INFO] - {"epoch": 17, "update": 16.971, "loss": "85.399", "ntokens": "14797.6", "nsentences": "79.43", "nll_loss": "0.458", "wps": "8543.4", "ups": "0.58", "wpb": "14797.6", "bsz": "79.4", "num_updates": "22000", "lr": "3e-05", "gnorm": "112.196", "loss_scale": "8", "train_wall": "346", "gb_free": "72.8", "wall": "38854"}
[2024-07-04 01:47:12,463][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 01:47:12,464][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 01:47:52,066][dev-other][INFO] - {"epoch": 17, "dev-other_loss": "23.155", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.246", "dev-other_uer": "3.846", "dev-other_wer": "10.277", "dev-other_raw_wer": "10.277", "dev-other_wps": "6955.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "22037", "dev-other_best_wer": "10.277"}
[2024-07-04 01:47:52,092][fairseq_cli.train][INFO] - end of epoch 17 (average epoch stats below)
[2024-07-04 01:47:52,100][train][INFO] - {"epoch": 17, "train_loss": "84.243", "train_ntokens": "14822.8", "train_nsentences": "80.196", "train_nll_loss": "0.456", "train_wps": "8422", "train_ups": "0.57", "train_wpb": "14822.8", "train_bsz": "80.2", "train_num_updates": "22037", "train_lr": "3e-05", "train_gnorm": "110.787", "train_loss_scale": "8", "train_train_wall": "2236", "train_gb_free": "73.2", "train_wall": "38955"}
[2024-07-04 01:47:52,103][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 01:47:53,014][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 01:47:53,019][fairseq.trainer][INFO] - begin training epoch 18
[2024-07-04 01:47:53,019][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 01:52:38,014][train_inner][INFO] - {"epoch": 18, "update": 17.126, "loss": "82.817", "ntokens": "14859.4", "nsentences": "78.88", "nll_loss": "0.44", "wps": "7683.5", "ups": "0.52", "wpb": "14859.4", "bsz": "78.9", "num_updates": "22200", "lr": "3e-05", "gnorm": "110.742", "loss_scale": "8", "train_wall": "346", "gb_free": "72", "wall": "39241"}
[2024-07-04 01:58:25,887][train_inner][INFO] - {"epoch": 18, "update": 17.28, "loss": "83.224", "ntokens": "14829.1", "nsentences": "80.11", "nll_loss": "0.45", "wps": "8527.4", "ups": "0.58", "wpb": "14829.1", "bsz": "80.1", "num_updates": "22400", "lr": "3e-05", "gnorm": "107.858", "loss_scale": "8", "train_wall": "347", "gb_free": "71.7", "wall": "39589"}
[2024-07-04 02:04:05,862][train_inner][INFO] - {"epoch": 18, "update": 17.434, "loss": "83.443", "ntokens": "14839.3", "nsentences": "81.48", "nll_loss": "0.458", "wps": "8735.7", "ups": "0.59", "wpb": "14839.3", "bsz": "81.5", "num_updates": "22600", "lr": "3e-05", "gnorm": "109.571", "loss_scale": "8", "train_wall": "339", "gb_free": "71.8", "wall": "39929"}
[2024-07-04 02:09:51,991][train_inner][INFO] - {"epoch": 18, "update": 17.588, "loss": "83.708", "ntokens": "14935.4", "nsentences": "81.48", "nll_loss": "0.457", "wps": "8631.5", "ups": "0.58", "wpb": "14935.4", "bsz": "81.5", "num_updates": "22800", "lr": "3e-05", "gnorm": "110.868", "loss_scale": "8", "train_wall": "345", "gb_free": "72.1", "wall": "40275"}
[2024-07-04 02:15:34,030][train_inner][INFO] - {"epoch": 18, "update": 17.742, "loss": "87.519", "ntokens": "14737.7", "nsentences": "78.48", "nll_loss": "0.466", "wps": "8620.3", "ups": "0.58", "wpb": "14737.7", "bsz": "78.5", "num_updates": "23000", "lr": "3e-05", "gnorm": "115.296", "loss_scale": "8", "train_wall": "341", "gb_free": "72.3", "wall": "40617"}
[2024-07-04 02:21:17,194][train_inner][INFO] - {"epoch": 18, "update": 17.897, "loss": "80.476", "ntokens": "14760.2", "nsentences": "80.64", "nll_loss": "0.44", "wps": "8604.3", "ups": "0.58", "wpb": "14760.2", "bsz": "80.6", "num_updates": "23200", "lr": "3e-05", "gnorm": "108.778", "loss_scale": "16", "train_wall": "342", "gb_free": "73.2", "wall": "40960"}
[2024-07-04 02:25:09,027][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 02:25:09,034][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 02:25:48,896][dev-other][INFO] - {"epoch": 18, "dev-other_loss": "23.808", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.253", "dev-other_uer": "3.858", "dev-other_wer": "10.177", "dev-other_raw_wer": "10.177", "dev-other_wps": "6894.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "23334", "dev-other_best_wer": "10.177"}
[2024-07-04 02:25:48,898][fairseq_cli.train][INFO] - end of epoch 18 (average epoch stats below)
[2024-07-04 02:25:48,902][train][INFO] - {"epoch": 18, "train_loss": "83.201", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.45", "train_wps": "8444", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "23334", "train_lr": "3e-05", "train_gnorm": "110.326", "train_loss_scale": "16", "train_train_wall": "2232", "train_gb_free": "73.3", "train_wall": "41232"}
[2024-07-04 02:25:48,904][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 02:25:49,800][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 02:25:49,805][fairseq.trainer][INFO] - begin training epoch 19
[2024-07-04 02:25:49,805][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 02:27:44,912][train_inner][INFO] - {"epoch": 19, "update": 18.051, "loss": "80.705", "ntokens": "14863.9", "nsentences": "81.19", "nll_loss": "0.441", "wps": "7668.8", "ups": "0.52", "wpb": "14863.9", "bsz": "81.2", "num_updates": "23400", "lr": "3e-05", "gnorm": "108.253", "loss_scale": "16", "train_wall": "346", "gb_free": "72", "wall": "41348"}
[2024-07-04 02:33:30,649][train_inner][INFO] - {"epoch": 19, "update": 18.205, "loss": "79.921", "ntokens": "14800.5", "nsentences": "79.88", "nll_loss": "0.431", "wps": "8562.5", "ups": "0.58", "wpb": "14800.5", "bsz": "79.9", "num_updates": "23600", "lr": "3e-05", "gnorm": "108.994", "loss_scale": "16", "train_wall": "345", "gb_free": "72", "wall": "41694"}
[2024-07-04 02:39:22,338][train_inner][INFO] - {"epoch": 19, "update": 18.359, "loss": "78.019", "ntokens": "14855.7", "nsentences": "80.64", "nll_loss": "0.424", "wps": "8450.5", "ups": "0.57", "wpb": "14855.7", "bsz": "80.6", "num_updates": "23800", "lr": "3e-05", "gnorm": "107.032", "loss_scale": "16", "train_wall": "351", "gb_free": "73.2", "wall": "42046"}
[2024-07-04 02:45:07,601][train_inner][INFO] - {"epoch": 19, "update": 18.513, "loss": "82.944", "ntokens": "14774.6", "nsentences": "79.36", "nll_loss": "0.446", "wps": "8560.3", "ups": "0.58", "wpb": "14774.6", "bsz": "79.4", "num_updates": "24000", "lr": "3e-05", "gnorm": "109.271", "loss_scale": "16", "train_wall": "345", "gb_free": "71.1", "wall": "42391"}
[2024-07-04 02:50:49,863][train_inner][INFO] - {"epoch": 19, "update": 18.668, "loss": "82.273", "ntokens": "14753.9", "nsentences": "79.6", "nll_loss": "0.444", "wps": "8622.4", "ups": "0.58", "wpb": "14753.9", "bsz": "79.6", "num_updates": "24200", "lr": "3e-05", "gnorm": "109.789", "loss_scale": "16", "train_wall": "342", "gb_free": "73.4", "wall": "42733"}
[2024-07-04 02:56:36,745][train_inner][INFO] - {"epoch": 19, "update": 18.822, "loss": "81.678", "ntokens": "14915.3", "nsentences": "81.28", "nll_loss": "0.445", "wps": "8599.8", "ups": "0.58", "wpb": "14915.3", "bsz": "81.3", "num_updates": "24400", "lr": "3e-05", "gnorm": "110.66", "loss_scale": "16", "train_wall": "346", "gb_free": "71.4", "wall": "43080"}
[2024-07-04 03:02:24,700][train_inner][INFO] - {"epoch": 19, "update": 18.976, "loss": "82.055", "ntokens": "14741", "nsentences": "79.16", "nll_loss": "0.441", "wps": "8474.7", "ups": "0.57", "wpb": "14741", "bsz": "79.2", "num_updates": "24600", "lr": "3e-05", "gnorm": "110.284", "loss_scale": "16", "train_wall": "347", "gb_free": "71.6", "wall": "43428"}
[2024-07-04 03:03:19,221][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 03:03:19,223][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 03:03:58,974][dev-other][INFO] - {"epoch": 19, "dev-other_loss": "23.567", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.251", "dev-other_uer": "3.837", "dev-other_wer": "10.122", "dev-other_raw_wer": "10.122", "dev-other_wps": "6915.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "24631", "dev-other_best_wer": "10.122"}
[2024-07-04 03:03:58,976][fairseq_cli.train][INFO] - end of epoch 19 (average epoch stats below)
[2024-07-04 03:03:58,981][train][INFO] - {"epoch": 19, "train_loss": "80.892", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.438", "train_wps": "8395", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "24631", "train_lr": "3e-05", "train_gnorm": "108.979", "train_loss_scale": "16", "train_train_wall": "2245", "train_gb_free": "71.6", "train_wall": "43522"}
[2024-07-04 03:03:58,983][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 03:03:59,833][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 03:03:59,861][fairseq.trainer][INFO] - begin training epoch 20
[2024-07-04 03:03:59,861][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 03:08:52,129][train_inner][INFO] - {"epoch": 20, "update": 19.13, "loss": "78.744", "ntokens": "14864.4", "nsentences": "81.76", "nll_loss": "0.433", "wps": "7675.5", "ups": "0.52", "wpb": "14864.4", "bsz": "81.8", "num_updates": "24800", "lr": "3e-05", "gnorm": "106.473", "loss_scale": "16", "train_wall": "346", "gb_free": "70", "wall": "43815"}
[2024-07-04 03:14:40,169][train_inner][INFO] - {"epoch": 20, "update": 19.285, "loss": "80.932", "ntokens": "14817.8", "nsentences": "80.52", "nll_loss": "0.44", "wps": "8516.9", "ups": "0.57", "wpb": "14817.8", "bsz": "80.5", "num_updates": "25000", "lr": "3e-05", "gnorm": "108.193", "loss_scale": "16", "train_wall": "347", "gb_free": "72.6", "wall": "44163"}
[2024-07-04 03:20:30,378][train_inner][INFO] - {"epoch": 20, "update": 19.439, "loss": "79.31", "ntokens": "14850", "nsentences": "81.92", "nll_loss": "0.438", "wps": "8481.6", "ups": "0.57", "wpb": "14850", "bsz": "81.9", "num_updates": "25200", "lr": "3e-05", "gnorm": "106.547", "loss_scale": "32", "train_wall": "350", "gb_free": "72.4", "wall": "44514"}
[2024-07-04 03:22:20,382][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-04 03:26:19,919][train_inner][INFO] - {"epoch": 20, "update": 19.594, "loss": "80.79", "ntokens": "14676.2", "nsentences": "77.44", "nll_loss": "0.426", "wps": "8402.2", "ups": "0.57", "wpb": "14676.2", "bsz": "77.4", "num_updates": "25400", "lr": "3e-05", "gnorm": "111.536", "loss_scale": "16", "train_wall": "349", "gb_free": "70.9", "wall": "44863"}
[2024-07-04 03:32:02,773][train_inner][INFO] - {"epoch": 20, "update": 19.748, "loss": "84.464", "ntokens": "14869.8", "nsentences": "80.76", "nll_loss": "0.459", "wps": "8676.6", "ups": "0.58", "wpb": "14869.8", "bsz": "80.8", "num_updates": "25600", "lr": "3e-05", "gnorm": "109.581", "loss_scale": "16", "train_wall": "342", "gb_free": "71.7", "wall": "45206"}
[2024-07-04 03:37:49,569][train_inner][INFO] - {"epoch": 20, "update": 19.902, "loss": "82.23", "ntokens": "14897.9", "nsentences": "80.44", "nll_loss": "0.444", "wps": "8593.6", "ups": "0.58", "wpb": "14897.9", "bsz": "80.4", "num_updates": "25800", "lr": "3e-05", "gnorm": "108.505", "loss_scale": "16", "train_wall": "346", "gb_free": "71.7", "wall": "45553"}
[2024-07-04 03:41:30,210][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 03:41:30,280][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 03:42:09,774][dev-other][INFO] - {"epoch": 20, "dev-other_loss": "23.305", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.248", "dev-other_uer": "3.789", "dev-other_wer": "10.026", "dev-other_raw_wer": "10.026", "dev-other_wps": "6945.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "25927", "dev-other_best_wer": "10.026"}
[2024-07-04 03:42:09,777][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 20 @ 25927 updates
[2024-07-04 03:42:09,779][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt
[2024-07-04 03:42:12,229][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt
[2024-07-04 03:42:12,873][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt (epoch 20 @ 25927 updates, score 10.026) (writing took 3.0966076273471117 seconds)
[2024-07-04 03:42:12,874][fairseq_cli.train][INFO] - end of epoch 20 (average epoch stats below)
[2024-07-04 03:42:12,879][train][INFO] - {"epoch": 20, "train_loss": "81.183", "train_ntokens": "14822.9", "train_nsentences": "80.2099", "train_nll_loss": "0.439", "train_wps": "8374.6", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "25927", "train_lr": "3e-05", "train_gnorm": "108.826", "train_loss_scale": "16", "train_train_wall": "2246", "train_gb_free": "71.6", "train_wall": "45816"}
[2024-07-04 03:42:12,881][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 03:42:13,151][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 03:42:13,155][fairseq.trainer][INFO] - begin training epoch 21
[2024-07-04 03:42:13,155][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 03:44:20,497][train_inner][INFO] - {"epoch": 21, "update": 20.056, "loss": "82.9", "ntokens": "14784.2", "nsentences": "78.68", "nll_loss": "0.441", "wps": "7565.2", "ups": "0.51", "wpb": "14784.2", "bsz": "78.7", "num_updates": "26000", "lr": "3e-05", "gnorm": "112.969", "loss_scale": "16", "train_wall": "347", "gb_free": "71.8", "wall": "45944"}
[2024-07-04 03:50:00,968][train_inner][INFO] - {"epoch": 21, "update": 20.21, "loss": "79.814", "ntokens": "14834.2", "nsentences": "81", "nll_loss": "0.436", "wps": "8715.8", "ups": "0.59", "wpb": "14834.2", "bsz": "81", "num_updates": "26200", "lr": "3e-05", "gnorm": "109.15", "loss_scale": "16", "train_wall": "340", "gb_free": "72.8", "wall": "46284"}
[2024-07-04 03:55:49,006][train_inner][INFO] - {"epoch": 21, "update": 20.365, "loss": "78.84", "ntokens": "14862", "nsentences": "79.84", "nll_loss": "0.424", "wps": "8542.2", "ups": "0.57", "wpb": "14862", "bsz": "79.8", "num_updates": "26400", "lr": "3e-05", "gnorm": "107.734", "loss_scale": "16", "train_wall": "347", "gb_free": "70.8", "wall": "46632"}
[2024-07-04 04:01:38,621][train_inner][INFO] - {"epoch": 21, "update": 20.519, "loss": "78.917", "ntokens": "14807.8", "nsentences": "79.19", "nll_loss": "0.422", "wps": "8473.1", "ups": "0.57", "wpb": "14807.8", "bsz": "79.2", "num_updates": "26600", "lr": "3e-05", "gnorm": "107.705", "loss_scale": "16", "train_wall": "349", "gb_free": "72.6", "wall": "46982"}
[2024-07-04 04:07:28,942][train_inner][INFO] - {"epoch": 21, "update": 20.673, "loss": "76.75", "ntokens": "14806.8", "nsentences": "80.36", "nll_loss": "0.417", "wps": "8455.3", "ups": "0.57", "wpb": "14806.8", "bsz": "80.4", "num_updates": "26800", "lr": "3e-05", "gnorm": "105.684", "loss_scale": "16", "train_wall": "350", "gb_free": "71.9", "wall": "47332"}
[2024-07-04 04:13:11,092][train_inner][INFO] - {"epoch": 21, "update": 20.827, "loss": "80.744", "ntokens": "14762.6", "nsentences": "80.28", "nll_loss": "0.439", "wps": "8629.6", "ups": "0.58", "wpb": "14762.6", "bsz": "80.3", "num_updates": "27000", "lr": "3e-05", "gnorm": "109.451", "loss_scale": "16", "train_wall": "342", "gb_free": "71.5", "wall": "47674"}
[2024-07-04 04:18:57,233][train_inner][INFO] - {"epoch": 21, "update": 20.981, "loss": "76.96", "ntokens": "14900.7", "nsentences": "81.4", "nll_loss": "0.42", "wps": "8610", "ups": "0.58", "wpb": "14900.7", "bsz": "81.4", "num_updates": "27200", "lr": "3e-05", "gnorm": "106.212", "loss_scale": "16", "train_wall": "346", "gb_free": "71.6", "wall": "48021"}
[2024-07-04 04:19:39,355][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 04:19:39,356][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 04:20:18,834][dev-other][INFO] - {"epoch": 21, "dev-other_loss": "23.355", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.248", "dev-other_uer": "3.807", "dev-other_wer": "10.096", "dev-other_raw_wer": "10.096", "dev-other_wps": "6977.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "27224", "dev-other_best_wer": "10.026"}
[2024-07-04 04:20:18,835][fairseq_cli.train][INFO] - end of epoch 21 (average epoch stats below)
[2024-07-04 04:20:18,840][train][INFO] - {"epoch": 21, "train_loss": "79.219", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.429", "train_wps": "8410.2", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "27224", "train_lr": "3e-05", "train_gnorm": "108.211", "train_loss_scale": "16", "train_train_wall": "2242", "train_gb_free": "69.7", "train_wall": "48102"}
[2024-07-04 04:20:18,843][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 04:20:19,762][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 04:20:19,768][fairseq.trainer][INFO] - begin training epoch 22
[2024-07-04 04:20:19,768][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 04:25:23,961][train_inner][INFO] - {"epoch": 22, "update": 21.136, "loss": "79.705", "ntokens": "14829.2", "nsentences": "80.32", "nll_loss": "0.432", "wps": "7670.5", "ups": "0.52", "wpb": "14829.2", "bsz": "80.3", "num_updates": "27400", "lr": "3e-05", "gnorm": "108.932", "loss_scale": "32", "train_wall": "346", "gb_free": "73.2", "wall": "48407"}
[2024-07-04 04:31:08,426][train_inner][INFO] - {"epoch": 22, "update": 21.29, "loss": "79.812", "ntokens": "14826.2", "nsentences": "80.4", "nll_loss": "0.433", "wps": "8610.5", "ups": "0.58", "wpb": "14826.2", "bsz": "80.4", "num_updates": "27600", "lr": "3e-05", "gnorm": "109.896", "loss_scale": "32", "train_wall": "344", "gb_free": "70.6", "wall": "48752"}
[2024-07-04 04:32:16,106][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-04 04:36:50,169][train_inner][INFO] - {"epoch": 22, "update": 21.445, "loss": "78.543", "ntokens": "14808.1", "nsentences": "80.83", "nll_loss": "0.429", "wps": "8668.3", "ups": "0.59", "wpb": "14808.1", "bsz": "80.8", "num_updates": "27800", "lr": "3e-05", "gnorm": "108.867", "loss_scale": "16", "train_wall": "341", "gb_free": "70.2", "wall": "49093"}
[2024-07-04 04:42:34,907][train_inner][INFO] - {"epoch": 22, "update": 21.599, "loss": "78.563", "ntokens": "14763.8", "nsentences": "79.88", "nll_loss": "0.425", "wps": "8567.2", "ups": "0.58", "wpb": "14763.8", "bsz": "79.9", "num_updates": "28000", "lr": "3e-05", "gnorm": "108.623", "loss_scale": "16", "train_wall": "344", "gb_free": "73.2", "wall": "49438"}
[2024-07-04 04:48:27,730][train_inner][INFO] - {"epoch": 22, "update": 21.753, "loss": "80.391", "ntokens": "14863.8", "nsentences": "79.48", "nll_loss": "0.43", "wps": "8427.3", "ups": "0.57", "wpb": "14863.8", "bsz": "79.5", "num_updates": "28200", "lr": "3e-05", "gnorm": "110.083", "loss_scale": "16", "train_wall": "352", "gb_free": "72", "wall": "49791"}
[2024-07-04 04:54:09,927][train_inner][INFO] - {"epoch": 22, "update": 21.907, "loss": "83.042", "ntokens": "14849.8", "nsentences": "80.48", "nll_loss": "0.45", "wps": "8680.9", "ups": "0.58", "wpb": "14849.8", "bsz": "80.5", "num_updates": "28400", "lr": "3e-05", "gnorm": "111.534", "loss_scale": "16", "train_wall": "342", "gb_free": "72.4", "wall": "50133"}
[2024-07-04 04:57:32,626][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 04:57:32,696][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 04:58:12,466][dev-other][INFO] - {"epoch": 22, "dev-other_loss": "23.134", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.246", "dev-other_uer": "3.747", "dev-other_wer": "9.908", "dev-other_raw_wer": "9.908", "dev-other_wps": "6908.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "28520", "dev-other_best_wer": "9.908"}
[2024-07-04 04:58:12,467][fairseq_cli.train][INFO] - end of epoch 22 (average epoch stats below)
[2024-07-04 04:58:12,472][train][INFO] - {"epoch": 22, "train_loss": "80.389", "train_ntokens": "14823.9", "train_nsentences": "80.2083", "train_nll_loss": "0.435", "train_wps": "8449.8", "train_ups": "0.57", "train_wpb": "14823.9", "train_bsz": "80.2", "train_num_updates": "28520", "train_lr": "3e-05", "train_gnorm": "109.987", "train_loss_scale": "16", "train_train_wall": "2228", "train_gb_free": "71.1", "train_wall": "50376"}
[2024-07-04 04:58:12,475][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 04:58:13,354][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 04:58:13,359][fairseq.trainer][INFO] - begin training epoch 23
[2024-07-04 04:58:13,360][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 04:59:33,735][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-04 05:00:35,784][train_inner][INFO] - {"epoch": 23, "update": 22.062, "loss": "82.987", "ntokens": "14905.2", "nsentences": "79.76", "nll_loss": "0.444", "wps": "7725.9", "ups": "0.52", "wpb": "14905.2", "bsz": "79.8", "num_updates": "28600", "lr": "3e-05", "gnorm": "109.969", "loss_scale": "8", "train_wall": "344", "gb_free": "71.7", "wall": "50519"}
[2024-07-04 05:06:18,139][train_inner][INFO] - {"epoch": 23, "update": 22.217, "loss": "82.438", "ntokens": "14670.9", "nsentences": "78.64", "nll_loss": "0.442", "wps": "8572.5", "ups": "0.58", "wpb": "14670.9", "bsz": "78.6", "num_updates": "28800", "lr": "3e-05", "gnorm": "112.335", "loss_scale": "8", "train_wall": "342", "gb_free": "70.9", "wall": "50861"}
[2024-07-04 05:12:01,431][train_inner][INFO] - {"epoch": 23, "update": 22.371, "loss": "79.072", "ntokens": "14832.9", "nsentences": "78.88", "nll_loss": "0.42", "wps": "8642.3", "ups": "0.58", "wpb": "14832.9", "bsz": "78.9", "num_updates": "29000", "lr": "3e-05", "gnorm": "109.921", "loss_scale": "8", "train_wall": "343", "gb_free": "72.2", "wall": "51205"}
[2024-07-04 05:17:43,652][train_inner][INFO] - {"epoch": 23, "update": 22.525, "loss": "79.279", "ntokens": "14862.1", "nsentences": "80.96", "nll_loss": "0.432", "wps": "8687.8", "ups": "0.58", "wpb": "14862.1", "bsz": "81", "num_updates": "29200", "lr": "3e-05", "gnorm": "108.939", "loss_scale": "8", "train_wall": "342", "gb_free": "71.6", "wall": "51547"}
[2024-07-04 05:23:29,082][train_inner][INFO] - {"epoch": 23, "update": 22.679, "loss": "79.264", "ntokens": "14838.1", "nsentences": "80.72", "nll_loss": "0.431", "wps": "8592.9", "ups": "0.58", "wpb": "14838.1", "bsz": "80.7", "num_updates": "29400", "lr": "3e-05", "gnorm": "109.296", "loss_scale": "8", "train_wall": "345", "gb_free": "72.3", "wall": "51892"}
[2024-07-04 05:29:17,369][train_inner][INFO] - {"epoch": 23, "update": 22.833, "loss": "77.509", "ntokens": "14794.8", "nsentences": "80", "nll_loss": "0.419", "wps": "8498.2", "ups": "0.57", "wpb": "14794.8", "bsz": "80", "num_updates": "29600", "lr": "3e-05", "gnorm": "105.383", "loss_scale": "8", "train_wall": "348", "gb_free": "71.3", "wall": "52241"}
[2024-07-04 05:35:00,245][train_inner][INFO] - {"epoch": 23, "update": 22.988, "loss": "79.945", "ntokens": "14843.9", "nsentences": "81.56", "nll_loss": "0.439", "wps": "8660.4", "ups": "0.58", "wpb": "14843.9", "bsz": "81.6", "num_updates": "29800", "lr": "3e-05", "gnorm": "108.55", "loss_scale": "8", "train_wall": "342", "gb_free": "69.5", "wall": "52584"}
[2024-07-04 05:35:27,541][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 05:35:27,543][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 05:36:07,129][dev-other][INFO] - {"epoch": 23, "dev-other_loss": "23.248", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.247", "dev-other_uer": "3.775", "dev-other_wer": "9.953", "dev-other_raw_wer": "9.953", "dev-other_wps": "6954.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "29816", "dev-other_best_wer": "9.953"}
[2024-07-04 05:36:07,130][fairseq_cli.train][INFO] - end of epoch 23 (average epoch stats below)
[2024-07-04 05:36:07,140][train][INFO] - {"epoch": 23, "train_loss": "79.587", "train_ntokens": "14821.3", "train_nsentences": "80.1728", "train_nll_loss": "0.431", "train_wps": "8444.5", "train_ups": "0.57", "train_wpb": "14821.3", "train_bsz": "80.2", "train_num_updates": "29816", "train_lr": "3e-05", "train_gnorm": "108.828", "train_loss_scale": "8", "train_train_wall": "2230", "train_gb_free": "72.2", "train_wall": "52650"}
[2024-07-04 05:36:07,143][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 05:36:08,034][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 05:36:08,040][fairseq.trainer][INFO] - begin training epoch 24
[2024-07-04 05:36:08,040][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 05:41:20,633][train_inner][INFO] - {"epoch": 24, "update": 23.142, "loss": "78.859", "ntokens": "14822.6", "nsentences": "81.91", "nll_loss": "0.436", "wps": "7795.1", "ups": "0.53", "wpb": "14822.6", "bsz": "81.9", "num_updates": "30000", "lr": "3e-05", "gnorm": "109.805", "loss_scale": "8", "train_wall": "339", "gb_free": "71", "wall": "52964"}
[2024-07-04 05:47:08,799][train_inner][INFO] - {"epoch": 24, "update": 23.296, "loss": "77.758", "ntokens": "14676.1", "nsentences": "78.6", "nll_loss": "0.416", "wps": "8430.9", "ups": "0.57", "wpb": "14676.1", "bsz": "78.6", "num_updates": "30200", "lr": "3e-05", "gnorm": "109.366", "loss_scale": "8", "train_wall": "348", "gb_free": "72.9", "wall": "53312"}
[2024-07-04 05:52:51,590][train_inner][INFO] - {"epoch": 24, "update": 23.45, "loss": "80.237", "ntokens": "14880.2", "nsentences": "80.64", "nll_loss": "0.435", "wps": "8683.4", "ups": "0.58", "wpb": "14880.2", "bsz": "80.6", "num_updates": "30400", "lr": "3e-05", "gnorm": "109.046", "loss_scale": "8", "train_wall": "342", "gb_free": "72.3", "wall": "53655"}
[2024-07-04 05:58:41,180][train_inner][INFO] - {"epoch": 24, "update": 23.604, "loss": "77.146", "ntokens": "14923.6", "nsentences": "81.52", "nll_loss": "0.421", "wps": "8538", "ups": "0.57", "wpb": "14923.6", "bsz": "81.5", "num_updates": "30600", "lr": "3e-05", "gnorm": "106.419", "loss_scale": "8", "train_wall": "349", "gb_free": "72.2", "wall": "54005"}
[2024-07-04 06:04:22,463][train_inner][INFO] - {"epoch": 24, "update": 23.759, "loss": "81.217", "ntokens": "14886.1", "nsentences": "80.08", "nll_loss": "0.437", "wps": "8725.3", "ups": "0.59", "wpb": "14886.1", "bsz": "80.1", "num_updates": "30800", "lr": "3e-05", "gnorm": "111.293", "loss_scale": "16", "train_wall": "341", "gb_free": "71.3", "wall": "54346"}
[2024-07-04 06:10:12,270][train_inner][INFO] - {"epoch": 24, "update": 23.913, "loss": "78.049", "ntokens": "14754.8", "nsentences": "78.92", "nll_loss": "0.417", "wps": "8437.4", "ups": "0.57", "wpb": "14754.8", "bsz": "78.9", "num_updates": "31000", "lr": "3e-05", "gnorm": "108.123", "loss_scale": "16", "train_wall": "349", "gb_free": "72.2", "wall": "54696"}
[2024-07-04 06:13:25,745][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 06:13:25,815][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 06:14:05,325][dev-other][INFO] - {"epoch": 24, "dev-other_loss": "23.297", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.248", "dev-other_uer": "3.775", "dev-other_wer": "9.9", "dev-other_raw_wer": "9.9", "dev-other_wps": "6960.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "31113", "dev-other_best_wer": "9.9"}
[2024-07-04 06:14:05,327][fairseq_cli.train][INFO] - end of epoch 24 (average epoch stats below)
[2024-07-04 06:14:05,333][train][INFO] - {"epoch": 24, "train_loss": "78.87", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.427", "train_wps": "8438.9", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "31113", "train_lr": "3e-05", "train_gnorm": "109.109", "train_loss_scale": "16", "train_train_wall": "2233", "train_gb_free": "70.4", "train_wall": "54929"}
[2024-07-04 06:14:05,335][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 06:14:06,206][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 06:14:06,212][fairseq.trainer][INFO] - begin training epoch 25
[2024-07-04 06:14:06,212][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 06:16:37,880][train_inner][INFO] - {"epoch": 25, "update": 24.067, "loss": "76.162", "ntokens": "14786.2", "nsentences": "79.92", "nll_loss": "0.412", "wps": "7670.4", "ups": "0.52", "wpb": "14786.2", "bsz": "79.9", "num_updates": "31200", "lr": "3e-05", "gnorm": "108.991", "loss_scale": "16", "train_wall": "344", "gb_free": "72.8", "wall": "55081"}
[2024-07-04 06:22:19,954][train_inner][INFO] - {"epoch": 25, "update": 24.221, "loss": "78.184", "ntokens": "14889.1", "nsentences": "79.51", "nll_loss": "0.418", "wps": "8707.1", "ups": "0.58", "wpb": "14889.1", "bsz": "79.5", "num_updates": "31400", "lr": "3e-05", "gnorm": "109.895", "loss_scale": "16", "train_wall": "341", "gb_free": "72.5", "wall": "55423"}
[2024-07-04 06:28:01,221][train_inner][INFO] - {"epoch": 25, "update": 24.375, "loss": "75.972", "ntokens": "14888.8", "nsentences": "82.16", "nll_loss": "0.419", "wps": "8725.9", "ups": "0.59", "wpb": "14888.8", "bsz": "82.2", "num_updates": "31600", "lr": "3e-05", "gnorm": "107.497", "loss_scale": "16", "train_wall": "341", "gb_free": "71.3", "wall": "55765"}
[2024-07-04 06:33:47,223][train_inner][INFO] - {"epoch": 25, "update": 24.53, "loss": "78.918", "ntokens": "14780.5", "nsentences": "80.24", "nll_loss": "0.428", "wps": "8544", "ups": "0.58", "wpb": "14780.5", "bsz": "80.2", "num_updates": "31800", "lr": "3e-05", "gnorm": "110.258", "loss_scale": "16", "train_wall": "345", "gb_free": "71.8", "wall": "56111"}
[2024-07-04 06:39:32,268][train_inner][INFO] - {"epoch": 25, "update": 24.684, "loss": "80.766", "ntokens": "14934", "nsentences": "80.84", "nll_loss": "0.437", "wps": "8658.1", "ups": "0.58", "wpb": "14934", "bsz": "80.8", "num_updates": "32000", "lr": "3e-05", "gnorm": "108.325", "loss_scale": "16", "train_wall": "344", "gb_free": "72.3", "wall": "56456"}
[2024-07-04 06:45:17,475][train_inner][INFO] - {"epoch": 25, "update": 24.838, "loss": "79.82", "ntokens": "14697", "nsentences": "79.28", "nll_loss": "0.431", "wps": "8516.9", "ups": "0.58", "wpb": "14697", "bsz": "79.3", "num_updates": "32200", "lr": "3e-05", "gnorm": "109.16", "loss_scale": "16", "train_wall": "345", "gb_free": "72.6", "wall": "56801"}
[2024-07-04 06:51:00,212][train_inner][INFO] - {"epoch": 25, "update": 24.992, "loss": "81.616", "ntokens": "14784.2", "nsentences": "78.6", "nll_loss": "0.434", "wps": "8627.4", "ups": "0.58", "wpb": "14784.2", "bsz": "78.6", "num_updates": "32400", "lr": "3e-05", "gnorm": "110.705", "loss_scale": "16", "train_wall": "342", "gb_free": "71.7", "wall": "57144"}
[2024-07-04 06:51:16,857][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 06:51:16,859][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 06:51:56,489][dev-other][INFO] - {"epoch": 25, "dev-other_loss": "23.728", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.252", "dev-other_uer": "3.838", "dev-other_wer": "10.034", "dev-other_raw_wer": "10.034", "dev-other_wps": "6955.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "32410", "dev-other_best_wer": "10.026"}
[2024-07-04 06:51:56,491][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 25 @ 32410 updates
[2024-07-04 06:51:56,493][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_last.pt
[2024-07-04 06:51:58,878][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_last.pt
[2024-07-04 06:51:58,909][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_last.pt (epoch 25 @ 32410 updates, score 10.034) (writing took 2.417265330441296 seconds)
[2024-07-04 06:51:58,909][fairseq_cli.train][INFO] - end of epoch 25 (average epoch stats below)
[2024-07-04 06:51:59,000][train][INFO] - {"epoch": 25, "train_loss": "78.763", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.426", "train_wps": "8456", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "32410", "train_lr": "3e-05", "train_gnorm": "109.186", "train_loss_scale": "16", "train_train_wall": "2226", "train_gb_free": "72.5", "train_wall": "57202"}
[2024-07-04 06:51:59,002][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 06:51:59,315][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 06:51:59,319][fairseq.trainer][INFO] - begin training epoch 26
[2024-07-04 06:51:59,319][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 06:57:31,142][train_inner][INFO] - {"epoch": 26, "update": 25.146, "loss": "76.79", "ntokens": "14867.7", "nsentences": "80.28", "nll_loss": "0.415", "wps": "7606.5", "ups": "0.51", "wpb": "14867.7", "bsz": "80.3", "num_updates": "32600", "lr": "3e-05", "gnorm": "107.158", "loss_scale": "16", "train_wall": "348", "gb_free": "70.8", "wall": "57534"}
[2024-07-04 07:03:12,672][train_inner][INFO] - {"epoch": 26, "update": 25.301, "loss": "79.137", "ntokens": "14887.6", "nsentences": "80.6", "nll_loss": "0.428", "wps": "8720.1", "ups": "0.59", "wpb": "14887.6", "bsz": "80.6", "num_updates": "32800", "lr": "3e-05", "gnorm": "109.262", "loss_scale": "32", "train_wall": "341", "gb_free": "72", "wall": "57876"}
[2024-07-04 07:04:29,517][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-04 07:08:55,585][train_inner][INFO] - {"epoch": 26, "update": 25.456, "loss": "78.476", "ntokens": "14765.7", "nsentences": "79.96", "nll_loss": "0.425", "wps": "8613.8", "ups": "0.58", "wpb": "14765.7", "bsz": "80", "num_updates": "33000", "lr": "3e-05", "gnorm": "109.499", "loss_scale": "16", "train_wall": "342", "gb_free": "73.4", "wall": "58219"}
[2024-07-04 07:14:34,784][train_inner][INFO] - {"epoch": 26, "update": 25.61, "loss": "75.431", "ntokens": "14776", "nsentences": "80.68", "nll_loss": "0.412", "wps": "8714", "ups": "0.59", "wpb": "14776", "bsz": "80.7", "num_updates": "33200", "lr": "3e-05", "gnorm": "108.007", "loss_scale": "16", "train_wall": "339", "gb_free": "72.4", "wall": "58558"}
[2024-07-04 07:20:23,899][train_inner][INFO] - {"epoch": 26, "update": 25.764, "loss": "75.294", "ntokens": "14808.8", "nsentences": "79.92", "nll_loss": "0.406", "wps": "8485.8", "ups": "0.57", "wpb": "14808.8", "bsz": "79.9", "num_updates": "33400", "lr": "3e-05", "gnorm": "106.74", "loss_scale": "16", "train_wall": "348", "gb_free": "72.2", "wall": "58907"}
[2024-07-04 07:22:57,855][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-04 07:26:09,458][train_inner][INFO] - {"epoch": 26, "update": 25.919, "loss": "76.637", "ntokens": "14896.8", "nsentences": "81.08", "nll_loss": "0.417", "wps": "8622.2", "ups": "0.58", "wpb": "14896.8", "bsz": "81.1", "num_updates": "33600", "lr": "3e-05", "gnorm": "107.681", "loss_scale": "8", "train_wall": "345", "gb_free": "71", "wall": "59253"}
[2024-07-04 07:29:11,818][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 07:29:11,886][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 07:29:51,533][dev-other][INFO] - {"epoch": 26, "dev-other_loss": "23.022", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.245", "dev-other_uer": "3.79", "dev-other_wer": "9.955", "dev-other_raw_wer": "9.955", "dev-other_wps": "6943.3", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "33705", "dev-other_best_wer": "9.955"}
[2024-07-04 07:29:51,534][fairseq_cli.train][INFO] - end of epoch 26 (average epoch stats below)
[2024-07-04 07:29:51,541][train][INFO] - {"epoch": 26, "train_loss": "77.095", "train_ntokens": "14824", "train_nsentences": "80.2162", "train_nll_loss": "0.417", "train_wps": "8447.4", "train_ups": "0.57", "train_wpb": "14824", "train_bsz": "80.2", "train_num_updates": "33705", "train_lr": "3e-05", "train_gnorm": "107.93", "train_loss_scale": "8", "train_train_wall": "2228", "train_gb_free": "71.5", "train_wall": "59475"}
[2024-07-04 07:29:51,543][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 07:29:52,395][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 07:29:52,418][fairseq.trainer][INFO] - begin training epoch 27
[2024-07-04 07:29:52,419][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 07:32:41,636][train_inner][INFO] - {"epoch": 27, "update": 26.073, "loss": "77.563", "ntokens": "14756.1", "nsentences": "78.6", "nll_loss": "0.413", "wps": "7526.8", "ups": "0.51", "wpb": "14756.1", "bsz": "78.6", "num_updates": "33800", "lr": "3e-05", "gnorm": "106.463", "loss_scale": "8", "train_wall": "351", "gb_free": "72.5", "wall": "59645"}
[2024-07-04 07:38:26,982][train_inner][INFO] - {"epoch": 27, "update": 26.227, "loss": "75.883", "ntokens": "14895", "nsentences": "81.08", "nll_loss": "0.413", "wps": "8628", "ups": "0.58", "wpb": "14895", "bsz": "81.1", "num_updates": "34000", "lr": "3e-05", "gnorm": "106.986", "loss_scale": "8", "train_wall": "345", "gb_free": "72.7", "wall": "59990"}
[2024-07-04 07:44:16,106][train_inner][INFO] - {"epoch": 27, "update": 26.382, "loss": "77.941", "ntokens": "14909.8", "nsentences": "82.39", "nll_loss": "0.431", "wps": "8543.1", "ups": "0.57", "wpb": "14909.8", "bsz": "82.4", "num_updates": "34200", "lr": "3e-05", "gnorm": "107.243", "loss_scale": "8", "train_wall": "348", "gb_free": "71.9", "wall": "60339"}
[2024-07-04 07:50:05,788][train_inner][INFO] - {"epoch": 27, "update": 26.536, "loss": "75.683", "ntokens": "14861.3", "nsentences": "79.68", "nll_loss": "0.406", "wps": "8502.1", "ups": "0.57", "wpb": "14861.3", "bsz": "79.7", "num_updates": "34400", "lr": "3e-05", "gnorm": "106.987", "loss_scale": "8", "train_wall": "349", "gb_free": "72.2", "wall": "60689"}
[2024-07-04 07:55:58,748][train_inner][INFO] - {"epoch": 27, "update": 26.69, "loss": "78.236", "ntokens": "14726.9", "nsentences": "78.96", "nll_loss": "0.419", "wps": "8346.8", "ups": "0.57", "wpb": "14726.9", "bsz": "79", "num_updates": "34600", "lr": "3e-05", "gnorm": "109.945", "loss_scale": "8", "train_wall": "352", "gb_free": "71.8", "wall": "61042"}
[2024-07-04 08:01:43,593][train_inner][INFO] - {"epoch": 27, "update": 26.844, "loss": "76.874", "ntokens": "14804.7", "nsentences": "81.08", "nll_loss": "0.421", "wps": "8588.4", "ups": "0.58", "wpb": "14804.7", "bsz": "81.1", "num_updates": "34800", "lr": "3e-05", "gnorm": "108.953", "loss_scale": "8", "train_wall": "344", "gb_free": "71.6", "wall": "61387"}
[2024-07-04 08:07:36,062][train_inner][INFO] - {"epoch": 27, "update": 26.998, "loss": "75.654", "ntokens": "14746.9", "nsentences": "78.92", "nll_loss": "0.405", "wps": "8368", "ups": "0.57", "wpb": "14746.9", "bsz": "78.9", "num_updates": "35000", "lr": "3e-05", "gnorm": "106.243", "loss_scale": "8", "train_wall": "352", "gb_free": "72.3", "wall": "61739"}
[2024-07-04 08:07:39,810][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 08:07:39,811][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 08:08:19,184][dev-other][INFO] - {"epoch": 27, "dev-other_loss": "24.334", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.259", "dev-other_uer": "3.795", "dev-other_wer": "9.933", "dev-other_raw_wer": "9.933", "dev-other_wps": "6990.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "35002", "dev-other_best_wer": "9.933"}
[2024-07-04 08:08:19,186][fairseq_cli.train][INFO] - end of epoch 27 (average epoch stats below)
[2024-07-04 08:08:19,193][train][INFO] - {"epoch": 27, "train_loss": "76.698", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.415", "train_wps": "8331.1", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "35002", "train_lr": "3e-05", "train_gnorm": "107.654", "train_loss_scale": "8", "train_train_wall": "2263", "train_gb_free": "71.1", "train_wall": "61783"}
[2024-07-04 08:08:19,196][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 08:08:20,087][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 08:08:20,094][fairseq.trainer][INFO] - begin training epoch 28
[2024-07-04 08:08:20,095][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 08:13:59,134][train_inner][INFO] - {"epoch": 28, "update": 27.153, "loss": "81.152", "ntokens": "14821.9", "nsentences": "78.36", "nll_loss": "0.429", "wps": "7739.9", "ups": "0.52", "wpb": "14821.9", "bsz": "78.4", "num_updates": "35200", "lr": "3e-05", "gnorm": "111.693", "loss_scale": "8", "train_wall": "342", "gb_free": "72.1", "wall": "62122"}
[2024-07-04 08:19:40,079][train_inner][INFO] - {"epoch": 28, "update": 27.307, "loss": "75.527", "ntokens": "14708.4", "nsentences": "79.96", "nll_loss": "0.411", "wps": "8629.7", "ups": "0.59", "wpb": "14708.4", "bsz": "80", "num_updates": "35400", "lr": "3e-05", "gnorm": "108.355", "loss_scale": "8", "train_wall": "340", "gb_free": "72", "wall": "62463"}
[2024-07-04 08:25:23,874][train_inner][INFO] - {"epoch": 28, "update": 27.461, "loss": "76.168", "ntokens": "14942.7", "nsentences": "82.36", "nll_loss": "0.42", "wps": "8694.5", "ups": "0.58", "wpb": "14942.7", "bsz": "82.4", "num_updates": "35600", "lr": "3e-05", "gnorm": "104.171", "loss_scale": "16", "train_wall": "343", "gb_free": "71.6", "wall": "62807"}
[2024-07-04 08:31:15,205][train_inner][INFO] - {"epoch": 28, "update": 27.615, "loss": "73.867", "ntokens": "14946.8", "nsentences": "82.2", "nll_loss": "0.406", "wps": "8510.3", "ups": "0.57", "wpb": "14946.8", "bsz": "82.2", "num_updates": "35800", "lr": "3e-05", "gnorm": "104.988", "loss_scale": "16", "train_wall": "351", "gb_free": "70.6", "wall": "63158"}
[2024-07-04 08:37:04,296][train_inner][INFO] - {"epoch": 28, "update": 27.769, "loss": "75.545", "ntokens": "14911.4", "nsentences": "81.16", "nll_loss": "0.411", "wps": "8545.6", "ups": "0.57", "wpb": "14911.4", "bsz": "81.2", "num_updates": "36000", "lr": "3e-05", "gnorm": "104.859", "loss_scale": "16", "train_wall": "348", "gb_free": "72.5", "wall": "63508"}
[2024-07-04 08:41:21,689][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-04 08:42:54,320][train_inner][INFO] - {"epoch": 28, "update": 27.924, "loss": "76.4", "ntokens": "14667.8", "nsentences": "77.64", "nll_loss": "0.404", "wps": "8383.5", "ups": "0.57", "wpb": "14667.8", "bsz": "77.6", "num_updates": "36200", "lr": "3e-05", "gnorm": "110.764", "loss_scale": "8", "train_wall": "349", "gb_free": "72.8", "wall": "63858"}
[2024-07-04 08:45:44,070][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 08:45:44,082][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 08:46:23,532][dev-other][INFO] - {"epoch": 28, "dev-other_loss": "23.484", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.25", "dev-other_uer": "3.78", "dev-other_wer": "9.843", "dev-other_raw_wer": "9.843", "dev-other_wps": "6978.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "36298", "dev-other_best_wer": "9.843"}
[2024-07-04 08:46:23,533][fairseq_cli.train][INFO] - end of epoch 28 (average epoch stats below)
[2024-07-04 08:46:23,585][train][INFO] - {"epoch": 28, "train_loss": "76.324", "train_ntokens": "14820.5", "train_nsentences": "80.1667", "train_nll_loss": "0.413", "train_wps": "8408.3", "train_ups": "0.57", "train_wpb": "14820.5", "train_bsz": "80.2", "train_num_updates": "36298", "train_lr": "3e-05", "train_gnorm": "107.337", "train_loss_scale": "8", "train_train_wall": "2240", "train_gb_free": "71.8", "train_wall": "64067"}
[2024-07-04 08:46:23,587][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 08:46:24,418][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 08:46:24,421][fairseq.trainer][INFO] - begin training epoch 29
[2024-07-04 08:46:24,422][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 08:49:23,113][train_inner][INFO] - {"epoch": 29, "update": 28.079, "loss": "74.827", "ntokens": "14714", "nsentences": "80.28", "nll_loss": "0.408", "wps": "7570.9", "ups": "0.51", "wpb": "14714", "bsz": "80.3", "num_updates": "36400", "lr": "3e-05", "gnorm": "105.492", "loss_scale": "8", "train_wall": "348", "gb_free": "72.5", "wall": "64246"}
[2024-07-04 08:55:08,250][train_inner][INFO] - {"epoch": 29, "update": 28.233, "loss": "75.755", "ntokens": "14758.2", "nsentences": "79.6", "nll_loss": "0.409", "wps": "8562.8", "ups": "0.58", "wpb": "14758.2", "bsz": "79.6", "num_updates": "36600", "lr": "3e-05", "gnorm": "107.321", "loss_scale": "8", "train_wall": "344", "gb_free": "71.7", "wall": "64591"}
[2024-07-04 09:01:19,692][train_inner][INFO] - {"epoch": 29, "update": 28.387, "loss": "74.199", "ntokens": "14863.2", "nsentences": "81.24", "nll_loss": "0.406", "wps": "8629.6", "ups": "0.58", "wpb": "14863.2", "bsz": "81.2", "num_updates": "36800", "lr": "3e-05", "gnorm": "106.415", "loss_scale": "8", "train_wall": "344", "gb_free": "71.9", "wall": "64937"}
[2024-07-04 09:07:06,984][train_inner][INFO] - {"epoch": 29, "update": 28.541, "loss": "78.631", "ntokens": "14922.1", "nsentences": "79.91", "nll_loss": "0.421", "wps": "8596", "ups": "0.58", "wpb": "14922.1", "bsz": "79.9", "num_updates": "37000", "lr": "3e-05", "gnorm": "108.297", "loss_scale": "8", "train_wall": "347", "gb_free": "72.3", "wall": "65310"}
[2024-07-04 09:12:51,358][train_inner][INFO] - {"epoch": 29, "update": 28.695, "loss": "76.549", "ntokens": "14778.6", "nsentences": "79.84", "nll_loss": "0.414", "wps": "8584.5", "ups": "0.58", "wpb": "14778.6", "bsz": "79.8", "num_updates": "37200", "lr": "3e-05", "gnorm": "107.748", "loss_scale": "8", "train_wall": "344", "gb_free": "71.9", "wall": "65655"}
[2024-07-04 09:18:34,446][train_inner][INFO] - {"epoch": 29, "update": 28.85, "loss": "75.645", "ntokens": "14870.6", "nsentences": "80.2", "nll_loss": "0.408", "wps": "8670.7", "ups": "0.58", "wpb": "14870.6", "bsz": "80.2", "num_updates": "37400", "lr": "3e-05", "gnorm": "107.158", "loss_scale": "8", "train_wall": "342", "gb_free": "70.9", "wall": "65998"}
[2024-07-04 09:24:06,750][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 09:24:06,812][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 09:24:46,226][dev-other][INFO] - {"epoch": 29, "dev-other_loss": "23.422", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.249", "dev-other_uer": "3.745", "dev-other_wer": "9.78", "dev-other_raw_wer": "9.78", "dev-other_wps": "6962.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "37595", "dev-other_best_wer": "9.78"}
[2024-07-04 09:24:46,227][fairseq_cli.train][INFO] - end of epoch 29 (average epoch stats below)
[2024-07-04 09:24:46,231][train][INFO] - {"epoch": 29, "train_loss": "76.396", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.413", "train_wps": "8349.2", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "37595", "train_lr": "3e-05", "train_gnorm": "107.523", "train_loss_scale": "8", "train_train_wall": "2231", "train_gb_free": "72.1", "train_wall": "66370"}
[2024-07-04 09:24:46,234][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 09:24:47,206][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 09:24:47,221][fairseq.trainer][INFO] - begin training epoch 30
[2024-07-04 09:24:47,223][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 09:24:56,796][train_inner][INFO] - {"epoch": 30, "update": 29.004, "loss": "78.907", "ntokens": "14765.8", "nsentences": "79.28", "nll_loss": "0.424", "wps": "7723.8", "ups": "0.52", "wpb": "14765.8", "bsz": "79.3", "num_updates": "37600", "lr": "3e-05", "gnorm": "109.556", "loss_scale": "8", "train_wall": "341", "gb_free": "71.7", "wall": "66380"}
[2024-07-04 09:30:43,231][train_inner][INFO] - {"epoch": 30, "update": 29.158, "loss": "74.57", "ntokens": "14899.8", "nsentences": "81.16", "nll_loss": "0.406", "wps": "8603.5", "ups": "0.58", "wpb": "14899.8", "bsz": "81.2", "num_updates": "37800", "lr": "3e-05", "gnorm": "106.019", "loss_scale": "8", "train_wall": "346", "gb_free": "70.8", "wall": "66727"}
[2024-07-04 09:36:25,504][train_inner][INFO] - {"epoch": 30, "update": 29.312, "loss": "73.815", "ntokens": "14805.4", "nsentences": "80.48", "nll_loss": "0.401", "wps": "8653.4", "ups": "0.58", "wpb": "14805.4", "bsz": "80.5", "num_updates": "38000", "lr": "3e-05", "gnorm": "107.95", "loss_scale": "8", "train_wall": "342", "gb_free": "72.2", "wall": "67069"}
[2024-07-04 09:42:05,573][train_inner][INFO] - {"epoch": 30, "update": 29.466, "loss": "78.359", "ntokens": "14769.9", "nsentences": "77.96", "nll_loss": "0.414", "wps": "8688.2", "ups": "0.59", "wpb": "14769.9", "bsz": "78", "num_updates": "38200", "lr": "3e-05", "gnorm": "109.843", "loss_scale": "16", "train_wall": "339", "gb_free": "72.8", "wall": "67409"}
[2024-07-04 09:48:00,695][train_inner][INFO] - {"epoch": 30, "update": 29.621, "loss": "72.951", "ntokens": "14747.6", "nsentences": "78.92", "nll_loss": "0.39", "wps": "8307.5", "ups": "0.56", "wpb": "14747.6", "bsz": "78.9", "num_updates": "38400", "lr": "3e-05", "gnorm": "104.951", "loss_scale": "16", "train_wall": "354", "gb_free": "72.2", "wall": "67764"}
[2024-07-04 09:48:24,855][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-04 09:53:47,001][train_inner][INFO] - {"epoch": 30, "update": 29.776, "loss": "76.698", "ntokens": "14934.4", "nsentences": "80.36", "nll_loss": "0.413", "wps": "8627.8", "ups": "0.58", "wpb": "14934.4", "bsz": "80.4", "num_updates": "38600", "lr": "3e-05", "gnorm": "110.655", "loss_scale": "8", "train_wall": "346", "gb_free": "72", "wall": "68110"}
[2024-07-04 09:59:32,022][train_inner][INFO] - {"epoch": 30, "update": 29.93, "loss": "75.656", "ntokens": "14769.3", "nsentences": "80.2", "nll_loss": "0.411", "wps": "8563.1", "ups": "0.58", "wpb": "14769.3", "bsz": "80.2", "num_updates": "38800", "lr": "3e-05", "gnorm": "107.812", "loss_scale": "8", "train_wall": "344", "gb_free": "72.5", "wall": "68455"}
[2024-07-04 10:02:06,394][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 10:02:06,463][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 10:02:45,589][dev-other][INFO] - {"epoch": 30, "dev-other_loss": "23.355", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.248", "dev-other_uer": "3.769", "dev-other_wer": "9.875", "dev-other_raw_wer": "9.875", "dev-other_wps": "7024.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "38891", "dev-other_best_wer": "9.875"}
[2024-07-04 10:02:45,592][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 30 @ 38891 updates
[2024-07-04 10:02:45,593][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt
[2024-07-04 10:02:47,873][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt
[2024-07-04 10:02:48,545][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt (epoch 30 @ 38891 updates, score 9.875) (writing took 2.953228219412267 seconds)
[2024-07-04 10:02:48,545][fairseq_cli.train][INFO] - end of epoch 30 (average epoch stats below)
[2024-07-04 10:02:48,550][train][INFO] - {"epoch": 30, "train_loss": "75.137", "train_ntokens": "14821.8", "train_nsentences": "80.1975", "train_nll_loss": "0.407", "train_wps": "8416.5", "train_ups": "0.57", "train_wpb": "14821.8", "train_bsz": "80.2", "train_num_updates": "38891", "train_lr": "3e-05", "train_gnorm": "107.581", "train_loss_scale": "8", "train_train_wall": "2235", "train_gb_free": "71.9", "train_wall": "68652"}
[2024-07-04 10:02:48,553][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 10:02:48,956][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 10:02:48,962][fairseq.trainer][INFO] - begin training epoch 31
[2024-07-04 10:02:48,962][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 10:06:00,939][train_inner][INFO] - {"epoch": 31, "update": 30.084, "loss": "71.537", "ntokens": "14836.2", "nsentences": "84.04", "nll_loss": "0.405", "wps": "7631.1", "ups": "0.51", "wpb": "14836.2", "bsz": "84", "num_updates": "39000", "lr": "3e-05", "gnorm": "102.694", "loss_scale": "8", "train_wall": "346", "gb_free": "72", "wall": "68844"}
[2024-07-04 10:11:49,868][train_inner][INFO] - {"epoch": 31, "update": 30.238, "loss": "73.919", "ntokens": "14744.8", "nsentences": "80.12", "nll_loss": "0.402", "wps": "8453.7", "ups": "0.57", "wpb": "14744.8", "bsz": "80.1", "num_updates": "39200", "lr": "3e-05", "gnorm": "107.456", "loss_scale": "8", "train_wall": "348", "gb_free": "72.5", "wall": "69193"}
[2024-07-04 10:17:33,198][train_inner][INFO] - {"epoch": 31, "update": 30.392, "loss": "77.998", "ntokens": "14812.9", "nsentences": "79", "nll_loss": "0.416", "wps": "8630.1", "ups": "0.58", "wpb": "14812.9", "bsz": "79", "num_updates": "39400", "lr": "3e-05", "gnorm": "110.855", "loss_scale": "8", "train_wall": "343", "gb_free": "72.2", "wall": "69537"}
[2024-07-04 10:23:16,072][train_inner][INFO] - {"epoch": 31, "update": 30.547, "loss": "75.498", "ntokens": "14914.6", "nsentences": "80.76", "nll_loss": "0.409", "wps": "8701.6", "ups": "0.58", "wpb": "14914.6", "bsz": "80.8", "num_updates": "39600", "lr": "3e-05", "gnorm": "107.913", "loss_scale": "8", "train_wall": "342", "gb_free": "72.2", "wall": "69879"}
[2024-07-04 10:29:02,377][train_inner][INFO] - {"epoch": 31, "update": 30.701, "loss": "75.546", "ntokens": "14850.5", "nsentences": "79.15", "nll_loss": "0.403", "wps": "8578.3", "ups": "0.58", "wpb": "14850.5", "bsz": "79.2", "num_updates": "39800", "lr": "3e-05", "gnorm": "107.317", "loss_scale": "8", "train_wall": "346", "gb_free": "71.2", "wall": "70226"}
[2024-07-04 10:34:43,975][train_inner][INFO] - {"epoch": 31, "update": 30.855, "loss": "74.364", "ntokens": "14768.8", "nsentences": "79.68", "nll_loss": "0.401", "wps": "8647.2", "ups": "0.59", "wpb": "14768.8", "bsz": "79.7", "num_updates": "40000", "lr": "3e-05", "gnorm": "108.057", "loss_scale": "8", "train_wall": "341", "gb_free": "72", "wall": "70567"}
[2024-07-04 10:40:09,926][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 10:40:09,992][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 10:40:49,476][dev-other][INFO] - {"epoch": 31, "dev-other_loss": "23.816", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.253", "dev-other_uer": "3.8", "dev-other_wer": "9.969", "dev-other_raw_wer": "9.969", "dev-other_wps": "6951.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "40188", "dev-other_best_wer": "9.875"}
[2024-07-04 10:40:49,483][fairseq_cli.train][INFO] - end of epoch 31 (average epoch stats below)
[2024-07-04 10:40:49,490][train][INFO] - {"epoch": 31, "train_loss": "74.93", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.405", "train_wps": "8428.7", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "40188", "train_lr": "2.95806e-05", "train_gnorm": "107.692", "train_loss_scale": "8", "train_train_wall": "2237", "train_gb_free": "71.8", "train_wall": "70933"}
[2024-07-04 10:40:49,493][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 10:40:50,383][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 10:40:50,387][fairseq.trainer][INFO] - begin training epoch 32
[2024-07-04 10:40:50,388][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 10:41:13,157][train_inner][INFO] - {"epoch": 32, "update": 31.009, "loss": "74.893", "ntokens": "14844.1", "nsentences": "80.72", "nll_loss": "0.407", "wps": "7629.8", "ups": "0.51", "wpb": "14844.1", "bsz": "80.7", "num_updates": "40200", "lr": "2.9554e-05", "gnorm": "107.64", "loss_scale": "8", "train_wall": "348", "gb_free": "71.5", "wall": "70956"}
[2024-07-04 10:47:02,472][train_inner][INFO] - {"epoch": 32, "update": 31.163, "loss": "73.053", "ntokens": "14843.3", "nsentences": "80.03", "nll_loss": "0.394", "wps": "8500.1", "ups": "0.57", "wpb": "14843.3", "bsz": "80", "num_updates": "40400", "lr": "2.91146e-05", "gnorm": "104.736", "loss_scale": "8", "train_wall": "349", "gb_free": "72.6", "wall": "71306"}
[2024-07-04 10:52:54,082][train_inner][INFO] - {"epoch": 32, "update": 31.318, "loss": "69.43", "ntokens": "14872.4", "nsentences": "82.52", "nll_loss": "0.385", "wps": "8460.1", "ups": "0.57", "wpb": "14872.4", "bsz": "82.5", "num_updates": "40600", "lr": "2.86818e-05", "gnorm": "101.865", "loss_scale": "16", "train_wall": "351", "gb_free": "72.9", "wall": "71657"}
[2024-07-04 10:58:39,812][train_inner][INFO] - {"epoch": 32, "update": 31.472, "loss": "74.284", "ntokens": "14875.6", "nsentences": "81.08", "nll_loss": "0.405", "wps": "8607.1", "ups": "0.58", "wpb": "14875.6", "bsz": "81.1", "num_updates": "40800", "lr": "2.82553e-05", "gnorm": "107.421", "loss_scale": "16", "train_wall": "345", "gb_free": "70.4", "wall": "72003"}
[2024-07-04 11:04:27,392][train_inner][INFO] - {"epoch": 32, "update": 31.626, "loss": "73.41", "ntokens": "14871.4", "nsentences": "80.88", "nll_loss": "0.399", "wps": "8557.4", "ups": "0.58", "wpb": "14871.4", "bsz": "80.9", "num_updates": "41000", "lr": "2.78353e-05", "gnorm": "106.407", "loss_scale": "16", "train_wall": "347", "gb_free": "72.2", "wall": "72351"}
[2024-07-04 11:10:14,429][train_inner][INFO] - {"epoch": 32, "update": 31.78, "loss": "75.102", "ntokens": "14810.2", "nsentences": "79.12", "nll_loss": "0.401", "wps": "8535.4", "ups": "0.58", "wpb": "14810.2", "bsz": "79.1", "num_updates": "41200", "lr": "2.74214e-05", "gnorm": "105.346", "loss_scale": "16", "train_wall": "346", "gb_free": "71.8", "wall": "72698"}
[2024-07-04 11:15:56,645][train_inner][INFO] - {"epoch": 32, "update": 31.934, "loss": "78.301", "ntokens": "14689.4", "nsentences": "77.88", "nll_loss": "0.415", "wps": "8586.6", "ups": "0.58", "wpb": "14689.4", "bsz": "77.9", "num_updates": "41400", "lr": "2.70138e-05", "gnorm": "110.933", "loss_scale": "16", "train_wall": "342", "gb_free": "71.4", "wall": "73040"}
[2024-07-04 11:18:22,081][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 11:18:22,086][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 11:19:02,056][dev-other][INFO] - {"epoch": 32, "dev-other_loss": "23.856", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.254", "dev-other_uer": "3.778", "dev-other_wer": "9.772", "dev-other_raw_wer": "9.772", "dev-other_wps": "6884.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "41485", "dev-other_best_wer": "9.772"}
[2024-07-04 11:19:02,057][fairseq_cli.train][INFO] - end of epoch 32 (average epoch stats below)
[2024-07-04 11:19:02,065][train][INFO] - {"epoch": 32, "train_loss": "74.249", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.402", "train_wps": "8385.9", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "41485", "train_lr": "2.68423e-05", "train_gnorm": "106.272", "train_loss_scale": "16", "train_train_wall": "2247", "train_gb_free": "71.8", "train_wall": "73225"}
[2024-07-04 11:19:02,068][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 11:19:02,999][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 11:19:03,005][fairseq.trainer][INFO] - begin training epoch 33
[2024-07-04 11:19:03,006][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 11:22:19,204][train_inner][INFO] - {"epoch": 33, "update": 32.089, "loss": "76.878", "ntokens": "14716.3", "nsentences": "79.68", "nll_loss": "0.416", "wps": "7693.9", "ups": "0.52", "wpb": "14716.3", "bsz": "79.7", "num_updates": "41600", "lr": "2.66122e-05", "gnorm": "109.009", "loss_scale": "16", "train_wall": "341", "gb_free": "71.2", "wall": "73423"}
[2024-07-04 11:28:03,694][train_inner][INFO] - {"epoch": 33, "update": 32.243, "loss": "73.466", "ntokens": "14803.8", "nsentences": "79.8", "nll_loss": "0.396", "wps": "8596.1", "ups": "0.58", "wpb": "14803.8", "bsz": "79.8", "num_updates": "41800", "lr": "2.62165e-05", "gnorm": "109.157", "loss_scale": "16", "train_wall": "344", "gb_free": "70.4", "wall": "73767"}
[2024-07-04 11:33:48,226][train_inner][INFO] - {"epoch": 33, "update": 32.397, "loss": "72.878", "ntokens": "14941.7", "nsentences": "83.16", "nll_loss": "0.406", "wps": "8675.3", "ups": "0.58", "wpb": "14941.7", "bsz": "83.2", "num_updates": "42000", "lr": "2.58267e-05", "gnorm": "104.113", "loss_scale": "16", "train_wall": "344", "gb_free": "72.7", "wall": "74112"}
[2024-07-04 11:39:32,032][train_inner][INFO] - {"epoch": 33, "update": 32.551, "loss": "73.558", "ntokens": "14851.2", "nsentences": "79.72", "nll_loss": "0.395", "wps": "8641.2", "ups": "0.58", "wpb": "14851.2", "bsz": "79.7", "num_updates": "42200", "lr": "2.54428e-05", "gnorm": "106.985", "loss_scale": "16", "train_wall": "343", "gb_free": "71.6", "wall": "74455"}
[2024-07-04 11:45:13,243][train_inner][INFO] - {"epoch": 33, "update": 32.705, "loss": "77.2", "ntokens": "14862.4", "nsentences": "80.72", "nll_loss": "0.419", "wps": "8713.5", "ups": "0.59", "wpb": "14862.4", "bsz": "80.7", "num_updates": "42400", "lr": "2.50645e-05", "gnorm": "107.601", "loss_scale": "16", "train_wall": "341", "gb_free": "71.9", "wall": "74797"}
[2024-07-04 11:50:56,885][train_inner][INFO] - {"epoch": 33, "update": 32.86, "loss": "76.028", "ntokens": "14689.3", "nsentences": "77.56", "nll_loss": "0.401", "wps": "8551.1", "ups": "0.58", "wpb": "14689.3", "bsz": "77.6", "num_updates": "42600", "lr": "2.46919e-05", "gnorm": "109.908", "loss_scale": "32", "train_wall": "343", "gb_free": "71.4", "wall": "75140"}
[2024-07-04 11:56:06,542][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 11:56:06,609][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 11:56:46,016][dev-other][INFO] - {"epoch": 33, "dev-other_loss": "23.571", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.251", "dev-other_uer": "3.775", "dev-other_wer": "9.727", "dev-other_raw_wer": "9.727", "dev-other_wps": "6977.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "42782", "dev-other_best_wer": "9.727"}
[2024-07-04 11:56:46,018][fairseq_cli.train][INFO] - end of epoch 33 (average epoch stats below)
[2024-07-04 11:56:46,022][train][INFO] - {"epoch": 33, "train_loss": "74.668", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.404", "train_wps": "8491.9", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "42782", "train_lr": "2.43576e-05", "train_gnorm": "107.852", "train_loss_scale": "32", "train_train_wall": "2219", "train_gb_free": "72.3", "train_wall": "75489"}
[2024-07-04 11:56:46,025][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 11:56:46,954][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 11:56:46,958][fairseq.trainer][INFO] - begin training epoch 34
[2024-07-04 11:56:46,959][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 11:56:57,152][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-04 11:57:18,696][train_inner][INFO] - {"epoch": 34, "update": 33.015, "loss": "74.297", "ntokens": "14898.2", "nsentences": "81.31", "nll_loss": "0.405", "wps": "7805.5", "ups": "0.52", "wpb": "14898.2", "bsz": "81.3", "num_updates": "42800", "lr": "2.43248e-05", "gnorm": "108.193", "loss_scale": "16", "train_wall": "341", "gb_free": "70.6", "wall": "75522"}
[2024-07-04 12:03:01,585][train_inner][INFO] - {"epoch": 34, "update": 33.169, "loss": "74.05", "ntokens": "14685", "nsentences": "80.24", "nll_loss": "0.405", "wps": "8565.6", "ups": "0.58", "wpb": "14685", "bsz": "80.2", "num_updates": "43000", "lr": "2.39632e-05", "gnorm": "108.36", "loss_scale": "16", "train_wall": "342", "gb_free": "73.1", "wall": "75865"}
[2024-07-04 12:08:50,778][train_inner][INFO] - {"epoch": 34, "update": 33.323, "loss": "73.424", "ntokens": "14917.3", "nsentences": "79.4", "nll_loss": "0.391", "wps": "8544.1", "ups": "0.57", "wpb": "14917.3", "bsz": "79.4", "num_updates": "43200", "lr": "2.36069e-05", "gnorm": "107.125", "loss_scale": "16", "train_wall": "349", "gb_free": "72.8", "wall": "76214"}
[2024-07-04 12:10:59,136][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-04 12:14:38,338][train_inner][INFO] - {"epoch": 34, "update": 33.478, "loss": "72.227", "ntokens": "14885.3", "nsentences": "80.76", "nll_loss": "0.392", "wps": "8567.4", "ups": "0.58", "wpb": "14885.3", "bsz": "80.8", "num_updates": "43400", "lr": "2.32559e-05", "gnorm": "105.225", "loss_scale": "8", "train_wall": "347", "gb_free": "73.4", "wall": "76562"}
[2024-07-04 12:20:21,862][train_inner][INFO] - {"epoch": 34, "update": 33.632, "loss": "75.319", "ntokens": "14843.7", "nsentences": "79.16", "nll_loss": "0.402", "wps": "8644.5", "ups": "0.58", "wpb": "14843.7", "bsz": "79.2", "num_updates": "43600", "lr": "2.29102e-05", "gnorm": "108.419", "loss_scale": "8", "train_wall": "343", "gb_free": "71", "wall": "76905"}
[2024-07-04 12:26:03,205][train_inner][INFO] - {"epoch": 34, "update": 33.786, "loss": "74.539", "ntokens": "14818.5", "nsentences": "80.48", "nll_loss": "0.405", "wps": "8683.3", "ups": "0.59", "wpb": "14818.5", "bsz": "80.5", "num_updates": "43800", "lr": "2.25696e-05", "gnorm": "106.147", "loss_scale": "8", "train_wall": "341", "gb_free": "72.4", "wall": "77247"}
[2024-07-04 12:31:48,315][train_inner][INFO] - {"epoch": 34, "update": 33.941, "loss": "72.191", "ntokens": "14762.1", "nsentences": "79.52", "nll_loss": "0.389", "wps": "8555.3", "ups": "0.58", "wpb": "14762.1", "bsz": "79.5", "num_updates": "44000", "lr": "2.2234e-05", "gnorm": "107.271", "loss_scale": "8", "train_wall": "345", "gb_free": "71.9", "wall": "77592"}
[2024-07-04 12:34:01,482][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 12:34:01,553][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 12:34:40,886][dev-other][INFO] - {"epoch": 34, "dev-other_loss": "23.85", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.254", "dev-other_uer": "3.758", "dev-other_wer": "9.8", "dev-other_raw_wer": "9.8", "dev-other_wps": "6982.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "44077", "dev-other_best_wer": "9.8"}
[2024-07-04 12:34:40,887][fairseq_cli.train][INFO] - end of epoch 34 (average epoch stats below)
[2024-07-04 12:34:40,893][train][INFO] - {"epoch": 34, "train_loss": "73.564", "train_ntokens": "14823.1", "train_nsentences": "80.2162", "train_nll_loss": "0.398", "train_wps": "8438.3", "train_ups": "0.57", "train_wpb": "14823.1", "train_bsz": "80.2", "train_num_updates": "44077", "train_lr": "2.21062e-05", "train_gnorm": "106.893", "train_loss_scale": "8", "train_train_wall": "2230", "train_gb_free": "72", "train_wall": "77764"}
[2024-07-04 12:34:40,896][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 12:34:41,795][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 12:34:41,801][fairseq.trainer][INFO] - begin training epoch 35
[2024-07-04 12:34:41,801][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 12:38:13,869][train_inner][INFO] - {"epoch": 35, "update": 34.095, "loss": "72.484", "ntokens": "14876.4", "nsentences": "82.76", "nll_loss": "0.403", "wps": "7718.2", "ups": "0.52", "wpb": "14876.4", "bsz": "82.8", "num_updates": "44200", "lr": "2.19035e-05", "gnorm": "103.972", "loss_scale": "8", "train_wall": "344", "gb_free": "69.6", "wall": "77977"}
[2024-07-04 12:44:01,225][train_inner][INFO] - {"epoch": 35, "update": 34.249, "loss": "74.075", "ntokens": "14774.7", "nsentences": "79.92", "nll_loss": "0.401", "wps": "8508.8", "ups": "0.58", "wpb": "14774.7", "bsz": "79.9", "num_updates": "44400", "lr": "2.15778e-05", "gnorm": "106.068", "loss_scale": "8", "train_wall": "347", "gb_free": "73", "wall": "78325"}
[2024-07-04 12:49:43,416][train_inner][INFO] - {"epoch": 35, "update": 34.403, "loss": "72.835", "ntokens": "14828", "nsentences": "79.4", "nll_loss": "0.39", "wps": "8668.6", "ups": "0.58", "wpb": "14828", "bsz": "79.4", "num_updates": "44600", "lr": "2.1257e-05", "gnorm": "106.364", "loss_scale": "8", "train_wall": "342", "gb_free": "70.6", "wall": "78667"}
[2024-07-04 12:55:26,432][train_inner][INFO] - {"epoch": 35, "update": 34.557, "loss": "74.066", "ntokens": "14900.9", "nsentences": "82.12", "nll_loss": "0.408", "wps": "8688.6", "ups": "0.58", "wpb": "14900.9", "bsz": "82.1", "num_updates": "44800", "lr": "2.0941e-05", "gnorm": "108.101", "loss_scale": "8", "train_wall": "342", "gb_free": "71.2", "wall": "79010"}
[2024-07-04 13:01:11,002][train_inner][INFO] - {"epoch": 35, "update": 34.712, "loss": "75.011", "ntokens": "14688.2", "nsentences": "77.68", "nll_loss": "0.397", "wps": "8525.7", "ups": "0.58", "wpb": "14688.2", "bsz": "77.7", "num_updates": "45000", "lr": "2.06297e-05", "gnorm": "108.25", "loss_scale": "8", "train_wall": "344", "gb_free": "71.8", "wall": "79354"}
[2024-07-04 13:06:52,630][train_inner][INFO] - {"epoch": 35, "update": 34.866, "loss": "73.167", "ntokens": "14848.4", "nsentences": "80.44", "nll_loss": "0.396", "wps": "8695.2", "ups": "0.59", "wpb": "14848.4", "bsz": "80.4", "num_updates": "45200", "lr": "2.0323e-05", "gnorm": "106.731", "loss_scale": "8", "train_wall": "341", "gb_free": "70.5", "wall": "79696"}
[2024-07-04 13:10:35,623][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-04 13:11:55,763][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 13:11:55,822][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 13:12:35,436][dev-other][INFO] - {"epoch": 35, "dev-other_loss": "23.308", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.248", "dev-other_uer": "3.71", "dev-other_wer": "9.61", "dev-other_raw_wer": "9.61", "dev-other_wps": "6939.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "45373", "dev-other_best_wer": "9.61"}
[2024-07-04 13:12:35,439][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 35 @ 45373 updates
[2024-07-04 13:12:35,441][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt
[2024-07-04 13:12:37,657][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt
[2024-07-04 13:12:38,361][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt (epoch 35 @ 45373 updates, score 9.61) (writing took 2.922272521071136 seconds)
[2024-07-04 13:12:38,362][fairseq_cli.train][INFO] - end of epoch 35 (average epoch stats below)
[2024-07-04 13:12:38,366][train][INFO] - {"epoch": 35, "train_loss": "73.472", "train_ntokens": "14821.3", "train_nsentences": "80.1975", "train_nll_loss": "0.398", "train_wps": "8434.1", "train_ups": "0.57", "train_wpb": "14821.3", "train_bsz": "80.2", "train_num_updates": "45373", "train_lr": "2.00614e-05", "train_gnorm": "106.642", "train_loss_scale": "8", "train_train_wall": "2230", "train_gb_free": "72.2", "train_wall": "80042"}
[2024-07-04 13:12:38,368][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 13:12:38,616][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 13:12:38,619][fairseq.trainer][INFO] - begin training epoch 36
[2024-07-04 13:12:38,620][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 13:13:23,760][train_inner][INFO] - {"epoch": 36, "update": 35.021, "loss": "72.852", "ntokens": "14832", "nsentences": "79.64", "nll_loss": "0.391", "wps": "7585.8", "ups": "0.51", "wpb": "14832", "bsz": "79.6", "num_updates": "45400", "lr": "2.00208e-05", "gnorm": "106.981", "loss_scale": "8", "train_wall": "347", "gb_free": "71.8", "wall": "80087"}
[2024-07-04 13:19:10,173][train_inner][INFO] - {"epoch": 36, "update": 35.175, "loss": "72.292", "ntokens": "14866.7", "nsentences": "80.52", "nll_loss": "0.392", "wps": "8583.8", "ups": "0.58", "wpb": "14866.7", "bsz": "80.5", "num_updates": "45600", "lr": "1.97232e-05", "gnorm": "106.755", "loss_scale": "8", "train_wall": "346", "gb_free": "72.7", "wall": "80434"}
[2024-07-04 13:24:49,291][train_inner][INFO] - {"epoch": 36, "update": 35.329, "loss": "74.35", "ntokens": "14833.5", "nsentences": "80.6", "nll_loss": "0.404", "wps": "8750.2", "ups": "0.59", "wpb": "14833.5", "bsz": "80.6", "num_updates": "45800", "lr": "1.943e-05", "gnorm": "108.279", "loss_scale": "8", "train_wall": "338", "gb_free": "72.1", "wall": "80773"}
[2024-07-04 13:30:36,544][train_inner][INFO] - {"epoch": 36, "update": 35.483, "loss": "75.545", "ntokens": "14710", "nsentences": "77.04", "nll_loss": "0.396", "wps": "8473", "ups": "0.58", "wpb": "14710", "bsz": "77", "num_updates": "46000", "lr": "1.91411e-05", "gnorm": "109.314", "loss_scale": "8", "train_wall": "347", "gb_free": "72.6", "wall": "81120"}
[2024-07-04 13:36:26,617][train_inner][INFO] - {"epoch": 36, "update": 35.638, "loss": "72.385", "ntokens": "14873.6", "nsentences": "81", "nll_loss": "0.394", "wps": "8497.6", "ups": "0.57", "wpb": "14873.6", "bsz": "81", "num_updates": "46200", "lr": "1.88565e-05", "gnorm": "105.158", "loss_scale": "8", "train_wall": "349", "gb_free": "73", "wall": "81470"}
[2024-07-04 13:42:15,166][train_inner][INFO] - {"epoch": 36, "update": 35.792, "loss": "70.277", "ntokens": "14887.2", "nsentences": "82.19", "nll_loss": "0.388", "wps": "8542.6", "ups": "0.57", "wpb": "14887.2", "bsz": "82.2", "num_updates": "46400", "lr": "1.85762e-05", "gnorm": "103.763", "loss_scale": "8", "train_wall": "348", "gb_free": "72.4", "wall": "81819"}
[2024-07-04 13:48:03,043][train_inner][INFO] - {"epoch": 36, "update": 35.946, "loss": "71.157", "ntokens": "14742.7", "nsentences": "79.68", "nll_loss": "0.385", "wps": "8478.3", "ups": "0.58", "wpb": "14742.7", "bsz": "79.7", "num_updates": "46600", "lr": "1.83e-05", "gnorm": "106.455", "loss_scale": "8", "train_wall": "347", "gb_free": "72", "wall": "82166"}
[2024-07-04 13:50:03,504][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 13:50:03,566][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 13:50:42,983][dev-other][INFO] - {"epoch": 36, "dev-other_loss": "22.918", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.244", "dev-other_uer": "3.743", "dev-other_wer": "9.757", "dev-other_raw_wer": "9.757", "dev-other_wps": "6966.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "46670", "dev-other_best_wer": "9.61"}
[2024-07-04 13:50:42,985][fairseq_cli.train][INFO] - end of epoch 36 (average epoch stats below)
[2024-07-04 13:50:43,034][train][INFO] - {"epoch": 36, "train_loss": "72.567", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.393", "train_wps": "8415.1", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "46670", "train_lr": "1.82043e-05", "train_gnorm": "106.637", "train_loss_scale": "8", "train_train_wall": "2240", "train_gb_free": "71.4", "train_wall": "82326"}
[2024-07-04 13:50:43,037][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 13:50:43,879][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 13:50:43,895][fairseq.trainer][INFO] - begin training epoch 37
[2024-07-04 13:50:43,895][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 13:54:32,001][train_inner][INFO] - {"epoch": 37, "update": 36.1, "loss": "71.085", "ntokens": "14952.4", "nsentences": "81.72", "nll_loss": "0.389", "wps": "7689.4", "ups": "0.51", "wpb": "14952.4", "bsz": "81.7", "num_updates": "46800", "lr": "1.80279e-05", "gnorm": "104.214", "loss_scale": "8", "train_wall": "348", "gb_free": "71.3", "wall": "82555"}
[2024-07-04 14:00:20,577][train_inner][INFO] - {"epoch": 37, "update": 36.254, "loss": "75.928", "ntokens": "14727.9", "nsentences": "79.31", "nll_loss": "0.409", "wps": "8450.6", "ups": "0.57", "wpb": "14727.9", "bsz": "79.3", "num_updates": "47000", "lr": "1.77599e-05", "gnorm": "109.225", "loss_scale": "8", "train_wall": "348", "gb_free": "71.5", "wall": "82904"}
[2024-07-04 14:06:06,239][train_inner][INFO] - {"epoch": 37, "update": 36.409, "loss": "70.797", "ntokens": "14723.9", "nsentences": "80.76", "nll_loss": "0.388", "wps": "8519.5", "ups": "0.58", "wpb": "14723.9", "bsz": "80.8", "num_updates": "47200", "lr": "1.74959e-05", "gnorm": "106.787", "loss_scale": "8", "train_wall": "345", "gb_free": "71.4", "wall": "83250"}
[2024-07-04 14:11:46,313][train_inner][INFO] - {"epoch": 37, "update": 36.563, "loss": "74.411", "ntokens": "14843.5", "nsentences": "80.24", "nll_loss": "0.402", "wps": "8731.5", "ups": "0.59", "wpb": "14843.5", "bsz": "80.2", "num_updates": "47400", "lr": "1.72358e-05", "gnorm": "108.08", "loss_scale": "16", "train_wall": "339", "gb_free": "71.5", "wall": "83590"}
[2024-07-04 14:17:33,266][train_inner][INFO] - {"epoch": 37, "update": 36.717, "loss": "72.278", "ntokens": "14845.7", "nsentences": "79.88", "nll_loss": "0.389", "wps": "8559.5", "ups": "0.58", "wpb": "14845.7", "bsz": "79.9", "num_updates": "47600", "lr": "1.69795e-05", "gnorm": "107.72", "loss_scale": "16", "train_wall": "346", "gb_free": "71.2", "wall": "83937"}
[2024-07-04 14:23:14,428][train_inner][INFO] - {"epoch": 37, "update": 36.871, "loss": "74.504", "ntokens": "14799", "nsentences": "79.68", "nll_loss": "0.401", "wps": "8675.9", "ups": "0.59", "wpb": "14799", "bsz": "79.7", "num_updates": "47800", "lr": "1.67271e-05", "gnorm": "107.799", "loss_scale": "16", "train_wall": "341", "gb_free": "72.9", "wall": "84278"}
[2024-07-04 14:28:03,925][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 14:28:03,946][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 14:28:43,566][dev-other][INFO] - {"epoch": 37, "dev-other_loss": "23.574", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.251", "dev-other_uer": "3.723", "dev-other_wer": "9.643", "dev-other_raw_wer": "9.643", "dev-other_wps": "6979.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "47967", "dev-other_best_wer": "9.61"}
[2024-07-04 14:28:43,567][fairseq_cli.train][INFO] - end of epoch 37 (average epoch stats below)
[2024-07-04 14:28:43,572][train][INFO] - {"epoch": 37, "train_loss": "73.175", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.396", "train_wps": "8430.2", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "47967", "train_lr": "1.65192e-05", "train_gnorm": "107.402", "train_loss_scale": "16", "train_train_wall": "2236", "train_gb_free": "71.3", "train_wall": "84607"}
[2024-07-04 14:28:43,575][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 14:28:44,492][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 14:28:44,506][fairseq.trainer][INFO] - begin training epoch 38
[2024-07-04 14:28:44,506][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 14:29:39,234][train_inner][INFO] - {"epoch": 38, "update": 37.025, "loss": "73.077", "ntokens": "14858.1", "nsentences": "79.88", "nll_loss": "0.393", "wps": "7722.5", "ups": "0.52", "wpb": "14858.1", "bsz": "79.9", "num_updates": "48000", "lr": "1.64784e-05", "gnorm": "107.701", "loss_scale": "16", "train_wall": "343", "gb_free": "72.8", "wall": "84663"}
[2024-07-04 14:35:23,488][train_inner][INFO] - {"epoch": 38, "update": 37.18, "loss": "73.085", "ntokens": "14782.7", "nsentences": "80.16", "nll_loss": "0.396", "wps": "8589.7", "ups": "0.58", "wpb": "14782.7", "bsz": "80.2", "num_updates": "48200", "lr": "1.62334e-05", "gnorm": "107.227", "loss_scale": "16", "train_wall": "344", "gb_free": "72.4", "wall": "85007"}
[2024-07-04 14:41:16,656][train_inner][INFO] - {"epoch": 38, "update": 37.334, "loss": "72.43", "ntokens": "14906.2", "nsentences": "80", "nll_loss": "0.389", "wps": "8441.7", "ups": "0.57", "wpb": "14906.2", "bsz": "80", "num_updates": "48400", "lr": "1.59921e-05", "gnorm": "104.291", "loss_scale": "16", "train_wall": "353", "gb_free": "72.1", "wall": "85360"}
[2024-07-04 14:44:41,917][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-04 14:47:05,730][train_inner][INFO] - {"epoch": 38, "update": 37.489, "loss": "70.387", "ntokens": "14845.4", "nsentences": "80.12", "nll_loss": "0.38", "wps": "8505.9", "ups": "0.57", "wpb": "14845.4", "bsz": "80.1", "num_updates": "48600", "lr": "1.57543e-05", "gnorm": "105.328", "loss_scale": "8", "train_wall": "348", "gb_free": "71.4", "wall": "85709"}
[2024-07-04 14:52:45,024][train_inner][INFO] - {"epoch": 38, "update": 37.643, "loss": "75.484", "ntokens": "14824", "nsentences": "79.48", "nll_loss": "0.405", "wps": "8738.7", "ups": "0.59", "wpb": "14824", "bsz": "79.5", "num_updates": "48800", "lr": "1.55201e-05", "gnorm": "111.707", "loss_scale": "8", "train_wall": "339", "gb_free": "71.6", "wall": "86048"}
[2024-07-04 14:58:35,705][train_inner][INFO] - {"epoch": 38, "update": 37.797, "loss": "71.701", "ntokens": "14797.5", "nsentences": "81.36", "nll_loss": "0.394", "wps": "8441.4", "ups": "0.57", "wpb": "14797.5", "bsz": "81.4", "num_updates": "49000", "lr": "1.52894e-05", "gnorm": "104.766", "loss_scale": "8", "train_wall": "350", "gb_free": "69.8", "wall": "86399"}
[2024-07-04 15:04:21,059][train_inner][INFO] - {"epoch": 38, "update": 37.951, "loss": "71.225", "ntokens": "14799.2", "nsentences": "80.36", "nll_loss": "0.387", "wps": "8572.2", "ups": "0.58", "wpb": "14799.2", "bsz": "80.4", "num_updates": "49200", "lr": "1.50621e-05", "gnorm": "106.739", "loss_scale": "8", "train_wall": "345", "gb_free": "72.5", "wall": "86744"}
[2024-07-04 15:06:09,886][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 15:06:09,891][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 15:06:49,665][dev-other][INFO] - {"epoch": 38, "dev-other_loss": "23.428", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.249", "dev-other_uer": "3.757", "dev-other_wer": "9.761", "dev-other_raw_wer": "9.761", "dev-other_wps": "6936.3", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "49263", "dev-other_best_wer": "9.61"}
[2024-07-04 15:06:49,667][fairseq_cli.train][INFO] - end of epoch 38 (average epoch stats below)
[2024-07-04 15:06:49,674][train][INFO] - {"epoch": 38, "train_loss": "72.377", "train_ntokens": "14821.7", "train_nsentences": "80.2037", "train_nll_loss": "0.392", "train_wps": "8402.5", "train_ups": "0.57", "train_wpb": "14821.7", "train_bsz": "80.2", "train_num_updates": "49263", "train_lr": "1.49912e-05", "train_gnorm": "106.764", "train_loss_scale": "8", "train_train_wall": "2241", "train_gb_free": "72.4", "train_wall": "86893"}
[2024-07-04 15:06:49,688][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 15:06:50,642][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 15:06:50,649][fairseq.trainer][INFO] - begin training epoch 39
[2024-07-04 15:06:50,649][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 15:10:50,400][train_inner][INFO] - {"epoch": 39, "update": 38.106, "loss": "72.563", "ntokens": "14834.6", "nsentences": "80.15", "nll_loss": "0.392", "wps": "7620.6", "ups": "0.51", "wpb": "14834.6", "bsz": "80.2", "num_updates": "49400", "lr": "1.48381e-05", "gnorm": "107.993", "loss_scale": "8", "train_wall": "348", "gb_free": "72", "wall": "87134"}
[2024-07-04 15:16:42,135][train_inner][INFO] - {"epoch": 39, "update": 38.26, "loss": "70.312", "ntokens": "14748.1", "nsentences": "80.56", "nll_loss": "0.384", "wps": "8386.2", "ups": "0.57", "wpb": "14748.1", "bsz": "80.6", "num_updates": "49600", "lr": "1.46175e-05", "gnorm": "105.841", "loss_scale": "8", "train_wall": "351", "gb_free": "72.8", "wall": "87485"}
[2024-07-04 15:22:24,073][train_inner][INFO] - {"epoch": 39, "update": 38.414, "loss": "71.219", "ntokens": "14803.8", "nsentences": "80.4", "nll_loss": "0.387", "wps": "8659.4", "ups": "0.58", "wpb": "14803.8", "bsz": "80.4", "num_updates": "49800", "lr": "1.44002e-05", "gnorm": "106.252", "loss_scale": "8", "train_wall": "341", "gb_free": "72", "wall": "87827"}
[2024-07-04 15:28:03,080][train_inner][INFO] - {"epoch": 39, "update": 38.568, "loss": "74.163", "ntokens": "14863.6", "nsentences": "80.52", "nll_loss": "0.402", "wps": "8769.7", "ups": "0.59", "wpb": "14863.6", "bsz": "80.5", "num_updates": "50000", "lr": "1.41861e-05", "gnorm": "108.458", "loss_scale": "8", "train_wall": "338", "gb_free": "72.4", "wall": "88166"}
[2024-07-04 15:33:52,440][train_inner][INFO] - {"epoch": 39, "update": 38.722, "loss": "69.408", "ntokens": "14911.3", "nsentences": "81.12", "nll_loss": "0.378", "wps": "8538", "ups": "0.57", "wpb": "14911.3", "bsz": "81.1", "num_updates": "50200", "lr": "1.39752e-05", "gnorm": "103.114", "loss_scale": "8", "train_wall": "349", "gb_free": "71.9", "wall": "88516"}
[2024-07-04 15:39:35,281][train_inner][INFO] - {"epoch": 39, "update": 38.877, "loss": "73.839", "ntokens": "14789.4", "nsentences": "78.72", "nll_loss": "0.393", "wps": "8628", "ups": "0.58", "wpb": "14789.4", "bsz": "78.7", "num_updates": "50400", "lr": "1.37674e-05", "gnorm": "110.247", "loss_scale": "8", "train_wall": "342", "gb_free": "72.1", "wall": "88859"}
[2024-07-04 15:44:08,351][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 15:44:08,393][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 15:44:47,687][dev-other][INFO] - {"epoch": 39, "dev-other_loss": "23.93", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.254", "dev-other_uer": "3.778", "dev-other_wer": "9.712", "dev-other_raw_wer": "9.712", "dev-other_wps": "6999", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "50560", "dev-other_best_wer": "9.61"}
[2024-07-04 15:44:47,688][fairseq_cli.train][INFO] - end of epoch 39 (average epoch stats below)
[2024-07-04 15:44:47,692][train][INFO] - {"epoch": 39, "train_loss": "72.64", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.393", "train_wps": "8439.5", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "50560", "train_lr": "1.36035e-05", "train_gnorm": "107.564", "train_loss_scale": "8", "train_train_wall": "2234", "train_gb_free": "72.5", "train_wall": "89171"}
[2024-07-04 15:44:47,694][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 15:44:48,594][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 15:44:48,621][fairseq.trainer][INFO] - begin training epoch 40
[2024-07-04 15:44:48,621][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 15:45:59,602][train_inner][INFO] - {"epoch": 40, "update": 39.031, "loss": "74.937", "ntokens": "14830.8", "nsentences": "80.88", "nll_loss": "0.409", "wps": "7718.5", "ups": "0.52", "wpb": "14830.8", "bsz": "80.9", "num_updates": "50600", "lr": "1.35628e-05", "gnorm": "109.062", "loss_scale": "16", "train_wall": "343", "gb_free": "72.2", "wall": "89243"}
[2024-07-04 15:51:53,591][train_inner][INFO] - {"epoch": 40, "update": 39.185, "loss": "69.701", "ntokens": "14921.2", "nsentences": "82.04", "nll_loss": "0.383", "wps": "8431.2", "ups": "0.57", "wpb": "14921.2", "bsz": "82", "num_updates": "50800", "lr": "1.33611e-05", "gnorm": "104.014", "loss_scale": "16", "train_wall": "353", "gb_free": "72.6", "wall": "89597"}
[2024-07-04 15:57:43,702][train_inner][INFO] - {"epoch": 40, "update": 39.339, "loss": "72.556", "ntokens": "14804", "nsentences": "79.36", "nll_loss": "0.389", "wps": "8457.2", "ups": "0.57", "wpb": "14804", "bsz": "79.4", "num_updates": "51000", "lr": "1.31625e-05", "gnorm": "106.646", "loss_scale": "16", "train_wall": "350", "gb_free": "71.5", "wall": "89947"}
[2024-07-04 16:03:35,120][train_inner][INFO] - {"epoch": 40, "update": 39.493, "loss": "74.175", "ntokens": "14867.6", "nsentences": "79.36", "nll_loss": "0.396", "wps": "8461.8", "ups": "0.57", "wpb": "14867.6", "bsz": "79.4", "num_updates": "51200", "lr": "1.29668e-05", "gnorm": "108.078", "loss_scale": "16", "train_wall": "351", "gb_free": "72.1", "wall": "90298"}
[2024-07-04 16:04:36,320][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-04 16:09:23,046][train_inner][INFO] - {"epoch": 40, "update": 39.648, "loss": "71.097", "ntokens": "14788.6", "nsentences": "79.76", "nll_loss": "0.383", "wps": "8501.3", "ups": "0.57", "wpb": "14788.6", "bsz": "79.8", "num_updates": "51400", "lr": "1.2774e-05", "gnorm": "106.895", "loss_scale": "8", "train_wall": "347", "gb_free": "72", "wall": "90646"}
[2024-07-04 16:15:15,806][train_inner][INFO] - {"epoch": 40, "update": 39.803, "loss": "71.613", "ntokens": "14788.8", "nsentences": "79.36", "nll_loss": "0.384", "wps": "8385", "ups": "0.57", "wpb": "14788.8", "bsz": "79.4", "num_updates": "51600", "lr": "1.25841e-05", "gnorm": "105.515", "loss_scale": "8", "train_wall": "352", "gb_free": "71.6", "wall": "90999"}
[2024-07-04 16:20:51,463][train_inner][INFO] - {"epoch": 40, "update": 39.957, "loss": "74.438", "ntokens": "14766.8", "nsentences": "80.08", "nll_loss": "0.404", "wps": "8799.1", "ups": "0.6", "wpb": "14766.8", "bsz": "80.1", "num_updates": "51800", "lr": "1.2397e-05", "gnorm": "109.097", "loss_scale": "8", "train_wall": "335", "gb_free": "73.1", "wall": "91335"}
[2024-07-04 16:22:29,331][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 16:22:29,364][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 16:23:09,144][dev-other][INFO] - {"epoch": 40, "dev-other_loss": "23.911", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.254", "dev-other_uer": "3.726", "dev-other_wer": "9.576", "dev-other_raw_wer": "9.576", "dev-other_wps": "6932.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "51856", "dev-other_best_wer": "9.576"}
[2024-07-04 16:23:09,157][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 40 @ 51856 updates
[2024-07-04 16:23:09,159][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt
[2024-07-04 16:23:11,278][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt
[2024-07-04 16:23:11,938][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt (epoch 40 @ 51856 updates, score 9.576) (writing took 2.7808030769228935 seconds)
[2024-07-04 16:23:11,938][fairseq_cli.train][INFO] - end of epoch 40 (average epoch stats below)
[2024-07-04 16:23:11,943][train][INFO] - {"epoch": 40, "train_loss": "71.862", "train_ntokens": "14821.2", "train_nsentences": "80.1852", "train_nll_loss": "0.389", "train_wps": "8336", "train_ups": "0.56", "train_wpb": "14821.2", "train_bsz": "80.2", "train_num_updates": "51856", "train_lr": "1.23451e-05", "train_gnorm": "106.485", "train_loss_scale": "8", "train_train_wall": "2256", "train_gb_free": "72.5", "train_wall": "91475"}
[2024-07-04 16:23:11,944][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 16:23:12,299][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 16:23:12,312][fairseq.trainer][INFO] - begin training epoch 41
[2024-07-04 16:23:12,312][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 16:27:20,085][train_inner][INFO] - {"epoch": 41, "update": 40.111, "loss": "69.13", "ntokens": "14864.9", "nsentences": "81.64", "nll_loss": "0.38", "wps": "7650.3", "ups": "0.51", "wpb": "14864.9", "bsz": "81.6", "num_updates": "52000", "lr": "1.22127e-05", "gnorm": "105.589", "loss_scale": "8", "train_wall": "345", "gb_free": "73.3", "wall": "91723"}
[2024-07-04 16:33:06,499][train_inner][INFO] - {"epoch": 41, "update": 40.265, "loss": "67.322", "ntokens": "14802", "nsentences": "81.48", "nll_loss": "0.371", "wps": "8546", "ups": "0.58", "wpb": "14802", "bsz": "81.5", "num_updates": "52200", "lr": "1.20311e-05", "gnorm": "104.226", "loss_scale": "8", "train_wall": "346", "gb_free": "72.4", "wall": "92070"}
[2024-07-04 16:38:51,030][train_inner][INFO] - {"epoch": 41, "update": 40.419, "loss": "71.919", "ntokens": "14839.9", "nsentences": "79.8", "nll_loss": "0.387", "wps": "8615", "ups": "0.58", "wpb": "14839.9", "bsz": "79.8", "num_updates": "52400", "lr": "1.18523e-05", "gnorm": "107.342", "loss_scale": "8", "train_wall": "344", "gb_free": "72.2", "wall": "92414"}
[2024-07-04 16:44:37,399][train_inner][INFO] - {"epoch": 41, "update": 40.574, "loss": "69.502", "ntokens": "14882", "nsentences": "81.36", "nll_loss": "0.38", "wps": "8593.4", "ups": "0.58", "wpb": "14882", "bsz": "81.4", "num_updates": "52600", "lr": "1.16761e-05", "gnorm": "104.713", "loss_scale": "8", "train_wall": "346", "gb_free": "71.4", "wall": "92761"}
[2024-07-04 16:50:19,739][train_inner][INFO] - {"epoch": 41, "update": 40.728, "loss": "72.957", "ntokens": "14895.5", "nsentences": "81", "nll_loss": "0.397", "wps": "8702.4", "ups": "0.58", "wpb": "14895.5", "bsz": "81", "num_updates": "52800", "lr": "1.15025e-05", "gnorm": "110.684", "loss_scale": "8", "train_wall": "342", "gb_free": "72.8", "wall": "93103"}
[2024-07-04 16:56:04,709][train_inner][INFO] - {"epoch": 41, "update": 40.882, "loss": "74.068", "ntokens": "14756.2", "nsentences": "78.04", "nll_loss": "0.392", "wps": "8555.3", "ups": "0.58", "wpb": "14756.2", "bsz": "78", "num_updates": "53000", "lr": "1.13315e-05", "gnorm": "109.461", "loss_scale": "8", "train_wall": "344", "gb_free": "72.2", "wall": "93448"}
[2024-07-04 17:00:34,853][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 17:00:35,175][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 17:01:13,984][dev-other][INFO] - {"epoch": 41, "dev-other_loss": "23.375", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.248", "dev-other_uer": "3.729", "dev-other_wer": "9.602", "dev-other_raw_wer": "9.602", "dev-other_wps": "7007.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "53153", "dev-other_best_wer": "9.576"}
[2024-07-04 17:01:13,985][fairseq_cli.train][INFO] - end of epoch 41 (average epoch stats below)
[2024-07-04 17:01:13,989][train][INFO] - {"epoch": 41, "train_loss": "71.059", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.384", "train_wps": "8424.6", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "53153", "train_lr": "1.12024e-05", "train_gnorm": "106.958", "train_loss_scale": "8", "train_train_wall": "2238", "train_gb_free": "72.8", "train_wall": "93757"}
[2024-07-04 17:01:13,992][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 17:01:14,890][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 17:01:14,901][fairseq.trainer][INFO] - begin training epoch 42
[2024-07-04 17:01:14,902][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 17:02:33,624][train_inner][INFO] - {"epoch": 42, "update": 41.036, "loss": "72.084", "ntokens": "14728.5", "nsentences": "78.87", "nll_loss": "0.386", "wps": "7574.3", "ups": "0.51", "wpb": "14728.5", "bsz": "78.9", "num_updates": "53200", "lr": "1.1163e-05", "gnorm": "106.324", "loss_scale": "8", "train_wall": "348", "gb_free": "71.9", "wall": "93837"}
[2024-07-04 17:08:17,450][train_inner][INFO] - {"epoch": 42, "update": 41.19, "loss": "72.184", "ntokens": "14804.5", "nsentences": "80.36", "nll_loss": "0.392", "wps": "8611.8", "ups": "0.58", "wpb": "14804.5", "bsz": "80.4", "num_updates": "53400", "lr": "1.09971e-05", "gnorm": "106.896", "loss_scale": "16", "train_wall": "343", "gb_free": "72.3", "wall": "94181"}
[2024-07-04 17:14:00,408][train_inner][INFO] - {"epoch": 42, "update": 41.345, "loss": "72.376", "ntokens": "14860.6", "nsentences": "79.56", "nll_loss": "0.387", "wps": "8666.3", "ups": "0.58", "wpb": "14860.6", "bsz": "79.6", "num_updates": "53600", "lr": "1.08336e-05", "gnorm": "108.108", "loss_scale": "16", "train_wall": "342", "gb_free": "71.3", "wall": "94524"}
[2024-07-04 17:19:42,505][train_inner][INFO] - {"epoch": 42, "update": 41.499, "loss": "70.366", "ntokens": "14700.9", "nsentences": "80.68", "nll_loss": "0.386", "wps": "8596.4", "ups": "0.58", "wpb": "14700.9", "bsz": "80.7", "num_updates": "53800", "lr": "1.06725e-05", "gnorm": "106.164", "loss_scale": "16", "train_wall": "341", "gb_free": "70.7", "wall": "94866"}
[2024-07-04 17:20:52,109][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-04 17:25:37,855][train_inner][INFO] - {"epoch": 42, "update": 41.654, "loss": "69.485", "ntokens": "14930.9", "nsentences": "79.76", "nll_loss": "0.371", "wps": "8404.3", "ups": "0.56", "wpb": "14930.9", "bsz": "79.8", "num_updates": "54000", "lr": "1.05138e-05", "gnorm": "102.618", "loss_scale": "8", "train_wall": "355", "gb_free": "72.4", "wall": "95221"}
[2024-07-04 17:31:26,770][train_inner][INFO] - {"epoch": 42, "update": 41.808, "loss": "70.502", "ntokens": "14795.6", "nsentences": "78.88", "nll_loss": "0.376", "wps": "8482.8", "ups": "0.57", "wpb": "14795.6", "bsz": "78.9", "num_updates": "54200", "lr": "1.03575e-05", "gnorm": "106.402", "loss_scale": "8", "train_wall": "348", "gb_free": "72.5", "wall": "95570"}
[2024-07-04 17:37:17,595][train_inner][INFO] - {"epoch": 42, "update": 41.962, "loss": "68.47", "ntokens": "14833.2", "nsentences": "81.2", "nll_loss": "0.375", "wps": "8456.7", "ups": "0.57", "wpb": "14833.2", "bsz": "81.2", "num_updates": "54400", "lr": "1.02035e-05", "gnorm": "103.714", "loss_scale": "8", "train_wall": "350", "gb_free": "73", "wall": "95921"}
[2024-07-04 17:38:43,444][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 17:38:43,513][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 17:39:22,749][dev-other][INFO] - {"epoch": 42, "dev-other_loss": "23.602", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.251", "dev-other_uer": "3.726", "dev-other_wer": "9.588", "dev-other_raw_wer": "9.588", "dev-other_wps": "6999.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "54449", "dev-other_best_wer": "9.576"}
[2024-07-04 17:39:22,750][fairseq_cli.train][INFO] - end of epoch 42 (average epoch stats below)
[2024-07-04 17:39:22,754][train][INFO] - {"epoch": 42, "train_loss": "70.842", "train_ntokens": "14823", "train_nsentences": "80.2037", "train_nll_loss": "0.383", "train_wps": "8393.4", "train_ups": "0.57", "train_wpb": "14823", "train_bsz": "80.2", "train_num_updates": "54449", "train_lr": "1.01662e-05", "train_gnorm": "105.638", "train_loss_scale": "8", "train_train_wall": "2244", "train_gb_free": "71.5", "train_wall": "96046"}
[2024-07-04 17:39:22,756][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 17:39:23,643][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 17:39:23,647][fairseq.trainer][INFO] - begin training epoch 43
[2024-07-04 17:39:23,647][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 17:43:49,168][train_inner][INFO] - {"epoch": 43, "update": 42.116, "loss": "71.93", "ntokens": "14787.4", "nsentences": "79.12", "nll_loss": "0.385", "wps": "7554.1", "ups": "0.51", "wpb": "14787.4", "bsz": "79.1", "num_updates": "54600", "lr": "1.00518e-05", "gnorm": "105.349", "loss_scale": "8", "train_wall": "350", "gb_free": "71.3", "wall": "96312"}
[2024-07-04 17:49:34,220][train_inner][INFO] - {"epoch": 43, "update": 42.271, "loss": "70.153", "ntokens": "14909.2", "nsentences": "82.4", "nll_loss": "0.388", "wps": "8643.8", "ups": "0.58", "wpb": "14909.2", "bsz": "82.4", "num_updates": "54800", "lr": "9.90239e-06", "gnorm": "104.183", "loss_scale": "8", "train_wall": "344", "gb_free": "72", "wall": "96657"}
[2024-07-04 17:55:13,458][train_inner][INFO] - {"epoch": 43, "update": 42.425, "loss": "72.604", "ntokens": "14936.4", "nsentences": "80.8", "nll_loss": "0.393", "wps": "8808", "ups": "0.59", "wpb": "14936.4", "bsz": "80.8", "num_updates": "55000", "lr": "9.75517e-06", "gnorm": "106.97", "loss_scale": "8", "train_wall": "339", "gb_free": "72.3", "wall": "96997"}
[2024-07-04 18:01:03,362][train_inner][INFO] - {"epoch": 43, "update": 42.579, "loss": "70.844", "ntokens": "14756.9", "nsentences": "78.87", "nll_loss": "0.379", "wps": "8436.8", "ups": "0.57", "wpb": "14756.9", "bsz": "78.9", "num_updates": "55200", "lr": "9.61014e-06", "gnorm": "106.393", "loss_scale": "8", "train_wall": "349", "gb_free": "71.8", "wall": "97347"}
[2024-07-04 18:06:46,543][train_inner][INFO] - {"epoch": 43, "update": 42.733, "loss": "71.349", "ntokens": "14787.9", "nsentences": "81.48", "nll_loss": "0.393", "wps": "8618.4", "ups": "0.58", "wpb": "14787.9", "bsz": "81.5", "num_updates": "55400", "lr": "9.46727e-06", "gnorm": "106.723", "loss_scale": "8", "train_wall": "343", "gb_free": "71.3", "wall": "97690"}
[2024-07-04 18:12:37,112][train_inner][INFO] - {"epoch": 43, "update": 42.887, "loss": "68.67", "ntokens": "14779.1", "nsentences": "79.36", "nll_loss": "0.369", "wps": "8431.7", "ups": "0.57", "wpb": "14779.1", "bsz": "79.4", "num_updates": "55600", "lr": "9.32652e-06", "gnorm": "105.609", "loss_scale": "8", "train_wall": "350", "gb_free": "71.3", "wall": "98040"}
[2024-07-04 18:16:48,613][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 18:16:48,677][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 18:17:27,571][dev-other][INFO] - {"epoch": 43, "dev-other_loss": "23.979", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.255", "dev-other_uer": "3.758", "dev-other_wer": "9.688", "dev-other_raw_wer": "9.688", "dev-other_wps": "7071.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "55746", "dev-other_best_wer": "9.576"}
[2024-07-04 18:17:27,572][fairseq_cli.train][INFO] - end of epoch 43 (average epoch stats below)
[2024-07-04 18:17:27,577][train][INFO] - {"epoch": 43, "train_loss": "70.973", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.384", "train_wps": "8414.4", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "55746", "train_lr": "9.22509e-06", "train_gnorm": "106.119", "train_loss_scale": "8", "train_train_wall": "2241", "train_gb_free": "71", "train_wall": "98331"}
[2024-07-04 18:17:27,580][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 18:17:28,431][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 18:17:28,436][fairseq.trainer][INFO] - begin training epoch 44
[2024-07-04 18:17:28,436][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 18:19:05,220][train_inner][INFO] - {"epoch": 44, "update": 43.042, "loss": "72.276", "ntokens": "14707.3", "nsentences": "79.07", "nll_loss": "0.389", "wps": "7580.3", "ups": "0.52", "wpb": "14707.3", "bsz": "79.1", "num_updates": "55800", "lr": "9.18786e-06", "gnorm": "106.76", "loss_scale": "8", "train_wall": "348", "gb_free": "72.5", "wall": "98428"}
[2024-07-04 18:24:52,020][train_inner][INFO] - {"epoch": 44, "update": 43.196, "loss": "69.639", "ntokens": "14792.9", "nsentences": "79.24", "nll_loss": "0.373", "wps": "8532", "ups": "0.58", "wpb": "14792.9", "bsz": "79.2", "num_updates": "56000", "lr": "9.05126e-06", "gnorm": "108.128", "loss_scale": "16", "train_wall": "346", "gb_free": "70.6", "wall": "98775"}
[2024-07-04 18:30:34,779][train_inner][INFO] - {"epoch": 44, "update": 43.35, "loss": "71.206", "ntokens": "14928", "nsentences": "80.68", "nll_loss": "0.385", "wps": "8712.3", "ups": "0.58", "wpb": "14928", "bsz": "80.7", "num_updates": "56200", "lr": "8.9167e-06", "gnorm": "105.634", "loss_scale": "16", "train_wall": "342", "gb_free": "71.4", "wall": "99118"}
[2024-07-04 18:36:26,212][train_inner][INFO] - {"epoch": 44, "update": 43.504, "loss": "69.649", "ntokens": "14766.4", "nsentences": "79.84", "nll_loss": "0.377", "wps": "8404", "ups": "0.57", "wpb": "14766.4", "bsz": "79.8", "num_updates": "56400", "lr": "8.78413e-06", "gnorm": "104.218", "loss_scale": "16", "train_wall": "351", "gb_free": "72", "wall": "99470"}
[2024-07-04 18:42:17,317][train_inner][INFO] - {"epoch": 44, "update": 43.658, "loss": "65.924", "ntokens": "14917.1", "nsentences": "83.2", "nll_loss": "0.368", "wps": "8497.4", "ups": "0.57", "wpb": "14917.1", "bsz": "83.2", "num_updates": "56600", "lr": "8.65354e-06", "gnorm": "100.964", "loss_scale": "16", "train_wall": "351", "gb_free": "72.3", "wall": "99821"}
[2024-07-04 18:48:00,134][train_inner][INFO] - {"epoch": 44, "update": 43.813, "loss": "71.206", "ntokens": "14831.7", "nsentences": "79.72", "nll_loss": "0.383", "wps": "8654.5", "ups": "0.58", "wpb": "14831.7", "bsz": "79.7", "num_updates": "56800", "lr": "8.52489e-06", "gnorm": "107.304", "loss_scale": "16", "train_wall": "342", "gb_free": "72", "wall": "100163"}
[2024-07-04 18:53:50,544][train_inner][INFO] - {"epoch": 44, "update": 43.967, "loss": "69.703", "ntokens": "14763.5", "nsentences": "79.04", "nll_loss": "0.373", "wps": "8426.7", "ups": "0.57", "wpb": "14763.5", "bsz": "79", "num_updates": "57000", "lr": "8.39815e-06", "gnorm": "106.172", "loss_scale": "16", "train_wall": "350", "gb_free": "73", "wall": "100514"}
[2024-07-04 18:55:07,187][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 18:55:07,236][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 18:55:45,942][dev-other][INFO] - {"epoch": 44, "dev-other_loss": "23.794", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.253", "dev-other_uer": "3.75", "dev-other_wer": "9.674", "dev-other_raw_wer": "9.674", "dev-other_wps": "7097.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "57043", "dev-other_best_wer": "9.576"}
[2024-07-04 18:55:45,943][fairseq_cli.train][INFO] - end of epoch 44 (average epoch stats below)
[2024-07-04 18:55:45,947][train][INFO] - {"epoch": 44, "train_loss": "69.457", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.376", "train_wps": "8364.8", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "57043", "train_lr": "8.37115e-06", "train_gnorm": "105.287", "train_loss_scale": "16", "train_train_wall": "2255", "train_gb_free": "72.7", "train_wall": "100629"}
[2024-07-04 18:55:45,949][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 18:55:46,814][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 18:55:46,817][fairseq.trainer][INFO] - begin training epoch 45
[2024-07-04 18:55:46,817][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 19:00:19,531][train_inner][INFO] - {"epoch": 45, "update": 44.121, "loss": "70.031", "ntokens": "14867.4", "nsentences": "81.24", "nll_loss": "0.383", "wps": "7645.6", "ups": "0.51", "wpb": "14867.4", "bsz": "81.2", "num_updates": "57200", "lr": "8.27329e-06", "gnorm": "105.503", "loss_scale": "16", "train_wall": "349", "gb_free": "72.1", "wall": "100903"}
[2024-07-04 19:04:38,217][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-04 19:06:04,112][train_inner][INFO] - {"epoch": 45, "update": 44.276, "loss": "70.003", "ntokens": "14791.3", "nsentences": "79.88", "nll_loss": "0.378", "wps": "8587.1", "ups": "0.58", "wpb": "14791.3", "bsz": "79.9", "num_updates": "57400", "lr": "8.15029e-06", "gnorm": "107.484", "loss_scale": "8", "train_wall": "344", "gb_free": "71.8", "wall": "101247"}
[2024-07-04 19:11:48,714][train_inner][INFO] - {"epoch": 45, "update": 44.43, "loss": "70.201", "ntokens": "14779.7", "nsentences": "79.12", "nll_loss": "0.376", "wps": "8579.5", "ups": "0.58", "wpb": "14779.7", "bsz": "79.1", "num_updates": "57600", "lr": "8.02912e-06", "gnorm": "107.708", "loss_scale": "8", "train_wall": "344", "gb_free": "71.2", "wall": "101592"}
[2024-07-04 19:17:32,367][train_inner][INFO] - {"epoch": 45, "update": 44.584, "loss": "71.434", "ntokens": "14852.3", "nsentences": "80.48", "nll_loss": "0.387", "wps": "8645.4", "ups": "0.58", "wpb": "14852.3", "bsz": "80.5", "num_updates": "57800", "lr": "7.90975e-06", "gnorm": "106.89", "loss_scale": "8", "train_wall": "343", "gb_free": "73.3", "wall": "101936"}
[2024-07-04 19:23:18,571][train_inner][INFO] - {"epoch": 45, "update": 44.739, "loss": "71.68", "ntokens": "14758.9", "nsentences": "79.04", "nll_loss": "0.384", "wps": "8526.3", "ups": "0.58", "wpb": "14758.9", "bsz": "79", "num_updates": "58000", "lr": "7.79216e-06", "gnorm": "106.324", "loss_scale": "8", "train_wall": "346", "gb_free": "71.5", "wall": "102282"}
[2024-07-04 19:29:05,366][train_inner][INFO] - {"epoch": 45, "update": 44.893, "loss": "67.761", "ntokens": "14956.9", "nsentences": "82.68", "nll_loss": "0.375", "wps": "8626", "ups": "0.58", "wpb": "14956.9", "bsz": "82.7", "num_updates": "58200", "lr": "7.67631e-06", "gnorm": "104.2", "loss_scale": "8", "train_wall": "346", "gb_free": "69.5", "wall": "102629"}
[2024-07-04 19:33:05,824][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 19:33:05,886][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 19:33:45,249][dev-other][INFO] - {"epoch": 45, "dev-other_loss": "23", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.244", "dev-other_uer": "3.692", "dev-other_wer": "9.568", "dev-other_raw_wer": "9.568", "dev-other_wps": "6986.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "58339", "dev-other_best_wer": "9.568"}
[2024-07-04 19:33:45,251][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 45 @ 58339 updates
[2024-07-04 19:33:45,253][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt
[2024-07-04 19:33:47,658][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt
[2024-07-04 19:33:48,225][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt (epoch 45 @ 58339 updates, score 9.568) (writing took 2.9738660706207156 seconds)
[2024-07-04 19:33:48,226][fairseq_cli.train][INFO] - end of epoch 45 (average epoch stats below)
[2024-07-04 19:33:48,230][train][INFO] - {"epoch": 45, "train_loss": "70.383", "train_ntokens": "14822", "train_nsentences": "80.2037", "train_nll_loss": "0.381", "train_wps": "8416.7", "train_ups": "0.57", "train_wpb": "14822", "train_bsz": "80.2", "train_num_updates": "58339", "train_lr": "7.59681e-06", "train_gnorm": "106.469", "train_loss_scale": "8", "train_train_wall": "2235", "train_gb_free": "72.5", "train_wall": "102912"}
[2024-07-04 19:33:48,232][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 19:33:48,529][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 19:33:48,533][fairseq.trainer][INFO] - begin training epoch 46
[2024-07-04 19:33:48,533][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 19:35:37,157][train_inner][INFO] - {"epoch": 46, "update": 45.047, "loss": "69.477", "ntokens": "14717.6", "nsentences": "77.88", "nll_loss": "0.368", "wps": "7514.5", "ups": "0.51", "wpb": "14717.6", "bsz": "77.9", "num_updates": "58400", "lr": "7.56219e-06", "gnorm": "106.81", "loss_scale": "8", "train_wall": "348", "gb_free": "71.2", "wall": "103020"}
[2024-07-04 19:41:27,173][train_inner][INFO] - {"epoch": 46, "update": 45.201, "loss": "68.458", "ntokens": "14847.6", "nsentences": "80.63", "nll_loss": "0.372", "wps": "8485.6", "ups": "0.57", "wpb": "14847.6", "bsz": "80.6", "num_updates": "58600", "lr": "7.44976e-06", "gnorm": "102.864", "loss_scale": "8", "train_wall": "349", "gb_free": "71.8", "wall": "103370"}
[2024-07-04 19:47:20,231][train_inner][INFO] - {"epoch": 46, "update": 45.355, "loss": "68.642", "ntokens": "14808.2", "nsentences": "79.6", "nll_loss": "0.369", "wps": "8390.1", "ups": "0.57", "wpb": "14808.2", "bsz": "79.6", "num_updates": "58800", "lr": "7.339e-06", "gnorm": "103.908", "loss_scale": "8", "train_wall": "352", "gb_free": "71.8", "wall": "103724"}
[2024-07-04 19:53:02,668][train_inner][INFO] - {"epoch": 46, "update": 45.51, "loss": "67.242", "ntokens": "14865.9", "nsentences": "83.04", "nll_loss": "0.376", "wps": "8682.7", "ups": "0.58", "wpb": "14865.9", "bsz": "83", "num_updates": "59000", "lr": "7.2299e-06", "gnorm": "103.43", "loss_scale": "8", "train_wall": "342", "gb_free": "71.6", "wall": "104066"}
[2024-07-04 19:58:55,321][train_inner][INFO] - {"epoch": 46, "update": 45.664, "loss": "69.988", "ntokens": "14813.1", "nsentences": "79.96", "nll_loss": "0.378", "wps": "8401.1", "ups": "0.57", "wpb": "14813.1", "bsz": "80", "num_updates": "59200", "lr": "7.12241e-06", "gnorm": "104.449", "loss_scale": "8", "train_wall": "352", "gb_free": "71.7", "wall": "104419"}
[2024-07-04 20:04:37,941][train_inner][INFO] - {"epoch": 46, "update": 45.818, "loss": "72.017", "ntokens": "14881.6", "nsentences": "79.76", "nll_loss": "0.386", "wps": "8687.2", "ups": "0.58", "wpb": "14881.6", "bsz": "79.8", "num_updates": "59400", "lr": "7.01652e-06", "gnorm": "108.505", "loss_scale": "16", "train_wall": "342", "gb_free": "72.5", "wall": "104761"}
[2024-07-04 20:10:21,133][train_inner][INFO] - {"epoch": 46, "update": 45.972, "loss": "69.646", "ntokens": "14755.1", "nsentences": "79.64", "nll_loss": "0.376", "wps": "8600.9", "ups": "0.58", "wpb": "14755.1", "bsz": "79.6", "num_updates": "59600", "lr": "6.9122e-06", "gnorm": "106.919", "loss_scale": "16", "train_wall": "343", "gb_free": "71", "wall": "105104"}
[2024-07-04 20:11:24,377][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 20:11:24,379][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 20:12:03,679][dev-other][INFO] - {"epoch": 46, "dev-other_loss": "23.293", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.248", "dev-other_uer": "3.692", "dev-other_wer": "9.57", "dev-other_raw_wer": "9.57", "dev-other_wps": "7001.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "59636", "dev-other_best_wer": "9.568"}
[2024-07-04 20:12:03,680][fairseq_cli.train][INFO] - end of epoch 46 (average epoch stats below)
[2024-07-04 20:12:03,735][train][INFO] - {"epoch": 46, "train_loss": "69.209", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.374", "train_wps": "8375.4", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "59636", "train_lr": "6.89359e-06", "train_gnorm": "105.209", "train_loss_scale": "16", "train_train_wall": "2252", "train_gb_free": "72", "train_wall": "105207"}
[2024-07-04 20:12:03,737][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 20:12:04,704][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 20:12:04,710][fairseq.trainer][INFO] - begin training epoch 47
[2024-07-04 20:12:04,710][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 20:16:48,449][train_inner][INFO] - {"epoch": 47, "update": 46.126, "loss": "69.505", "ntokens": "14871.6", "nsentences": "81", "nll_loss": "0.379", "wps": "7681.1", "ups": "0.52", "wpb": "14871.6", "bsz": "81", "num_updates": "59800", "lr": "6.80944e-06", "gnorm": "104.746", "loss_scale": "16", "train_wall": "346", "gb_free": "72.1", "wall": "105492"}
[2024-07-04 20:22:35,376][train_inner][INFO] - {"epoch": 47, "update": 46.281, "loss": "69.542", "ntokens": "14863.2", "nsentences": "79.8", "nll_loss": "0.373", "wps": "8570.4", "ups": "0.58", "wpb": "14863.2", "bsz": "79.8", "num_updates": "60000", "lr": "6.7082e-06", "gnorm": "106.175", "loss_scale": "16", "train_wall": "346", "gb_free": "71.3", "wall": "105839"}
[2024-07-04 20:28:22,760][train_inner][INFO] - {"epoch": 47, "update": 46.435, "loss": "68.354", "ntokens": "14780.8", "nsentences": "80.6", "nll_loss": "0.373", "wps": "8511.6", "ups": "0.58", "wpb": "14780.8", "bsz": "80.6", "num_updates": "60200", "lr": "6.60847e-06", "gnorm": "106.335", "loss_scale": "16", "train_wall": "347", "gb_free": "71.4", "wall": "106186"}
[2024-07-04 20:34:06,990][train_inner][INFO] - {"epoch": 47, "update": 46.589, "loss": "71.636", "ntokens": "14917.8", "nsentences": "80.96", "nll_loss": "0.389", "wps": "8669.8", "ups": "0.58", "wpb": "14917.8", "bsz": "81", "num_updates": "60400", "lr": "6.51022e-06", "gnorm": "107.454", "loss_scale": "16", "train_wall": "344", "gb_free": "72.1", "wall": "106530"}
[2024-07-04 20:39:57,560][train_inner][INFO] - {"epoch": 47, "update": 46.743, "loss": "69.842", "ntokens": "14705.1", "nsentences": "77.56", "nll_loss": "0.368", "wps": "8389.6", "ups": "0.57", "wpb": "14705.1", "bsz": "77.6", "num_updates": "60600", "lr": "6.41344e-06", "gnorm": "106.769", "loss_scale": "16", "train_wall": "350", "gb_free": "72.3", "wall": "106881"}
[2024-07-04 20:45:44,797][train_inner][INFO] - {"epoch": 47, "update": 46.897, "loss": "69.525", "ntokens": "14799.9", "nsentences": "81.2", "nll_loss": "0.381", "wps": "8526", "ups": "0.58", "wpb": "14799.9", "bsz": "81.2", "num_updates": "60800", "lr": "6.31809e-06", "gnorm": "103.411", "loss_scale": "16", "train_wall": "347", "gb_free": "72.4", "wall": "107228"}
[2024-07-04 20:47:19,002][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-04 20:49:33,202][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 20:49:33,206][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 20:50:12,041][dev-other][INFO] - {"epoch": 47, "dev-other_loss": "23.332", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.248", "dev-other_uer": "3.715", "dev-other_wer": "9.633", "dev-other_raw_wer": "9.633", "dev-other_wps": "7083.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "60932", "dev-other_best_wer": "9.568"}
[2024-07-04 20:50:12,042][fairseq_cli.train][INFO] - end of epoch 47 (average epoch stats below)
[2024-07-04 20:50:12,045][train][INFO] - {"epoch": 47, "train_loss": "70.015", "train_ntokens": "14824.1", "train_nsentences": "80.2083", "train_nll_loss": "0.379", "train_wps": "8395.7", "train_ups": "0.57", "train_wpb": "14824.1", "train_bsz": "80.2", "train_num_updates": "60932", "train_lr": "6.25594e-06", "train_gnorm": "105.936", "train_loss_scale": "8", "train_train_wall": "2244", "train_gb_free": "70.7", "train_wall": "107495"}
[2024-07-04 20:50:12,046][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 20:50:12,959][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 20:50:12,998][fairseq.trainer][INFO] - begin training epoch 48
[2024-07-04 20:50:12,999][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 20:52:10,371][train_inner][INFO] - {"epoch": 48, "update": 47.052, "loss": "71.995", "ntokens": "14844.8", "nsentences": "79.99", "nll_loss": "0.388", "wps": "7701.4", "ups": "0.52", "wpb": "14844.8", "bsz": "80", "num_updates": "61000", "lr": "6.22416e-06", "gnorm": "108.011", "loss_scale": "8", "train_wall": "345", "gb_free": "71.7", "wall": "107614"}
[2024-07-04 20:58:00,297][train_inner][INFO] - {"epoch": 48, "update": 47.207, "loss": "69.675", "ntokens": "14824.7", "nsentences": "80.48", "nll_loss": "0.378", "wps": "8474.6", "ups": "0.57", "wpb": "14824.7", "bsz": "80.5", "num_updates": "61200", "lr": "6.13162e-06", "gnorm": "104.079", "loss_scale": "8", "train_wall": "349", "gb_free": "72.3", "wall": "107964"}
[2024-07-04 21:03:48,975][train_inner][INFO] - {"epoch": 48, "update": 47.361, "loss": "69.662", "ntokens": "14813.1", "nsentences": "79.28", "nll_loss": "0.373", "wps": "8498.7", "ups": "0.57", "wpb": "14813.1", "bsz": "79.3", "num_updates": "61400", "lr": "6.04046e-06", "gnorm": "104.993", "loss_scale": "8", "train_wall": "348", "gb_free": "71.3", "wall": "108312"}
[2024-07-04 21:09:39,933][train_inner][INFO] - {"epoch": 48, "update": 47.515, "loss": "70.477", "ntokens": "14694.5", "nsentences": "79.07", "nll_loss": "0.379", "wps": "8374.4", "ups": "0.57", "wpb": "14694.5", "bsz": "79.1", "num_updates": "61600", "lr": "5.95066e-06", "gnorm": "105.868", "loss_scale": "8", "train_wall": "350", "gb_free": "70.2", "wall": "108663"}
[2024-07-04 21:15:24,900][train_inner][INFO] - {"epoch": 48, "update": 47.669, "loss": "68.507", "ntokens": "14915.3", "nsentences": "81.84", "nll_loss": "0.376", "wps": "8649.2", "ups": "0.58", "wpb": "14915.3", "bsz": "81.8", "num_updates": "61800", "lr": "5.86219e-06", "gnorm": "105.999", "loss_scale": "8", "train_wall": "344", "gb_free": "71.9", "wall": "109008"}
[2024-07-04 21:21:06,244][train_inner][INFO] - {"epoch": 48, "update": 47.823, "loss": "72.74", "ntokens": "14784.4", "nsentences": "79.28", "nll_loss": "0.39", "wps": "8664.5", "ups": "0.59", "wpb": "14784.4", "bsz": "79.3", "num_updates": "62000", "lr": "5.77504e-06", "gnorm": "109.637", "loss_scale": "8", "train_wall": "341", "gb_free": "73.1", "wall": "109350"}
[2024-07-04 21:26:50,235][train_inner][INFO] - {"epoch": 48, "update": 47.978, "loss": "70.546", "ntokens": "14913.8", "nsentences": "81.76", "nll_loss": "0.387", "wps": "8672.8", "ups": "0.58", "wpb": "14913.8", "bsz": "81.8", "num_updates": "62200", "lr": "5.68918e-06", "gnorm": "105.093", "loss_scale": "8", "train_wall": "343", "gb_free": "73.6", "wall": "109694"}
[2024-07-04 21:27:40,484][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 21:27:40,485][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 21:28:19,642][dev-other][INFO] - {"epoch": 48, "dev-other_loss": "23.304", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.248", "dev-other_uer": "3.702", "dev-other_wer": "9.549", "dev-other_raw_wer": "9.549", "dev-other_wps": "7017.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "62229", "dev-other_best_wer": "9.549"}
[2024-07-04 21:28:19,643][fairseq_cli.train][INFO] - end of epoch 48 (average epoch stats below)
[2024-07-04 21:28:19,646][train][INFO] - {"epoch": 48, "train_loss": "70.397", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.381", "train_wps": "8404.1", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "62229", "train_lr": "5.67684e-06", "train_gnorm": "106.157", "train_loss_scale": "8", "train_train_wall": "2243", "train_gb_free": "71.7", "train_wall": "109783"}
[2024-07-04 21:28:19,649][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 21:28:20,600][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 21:28:20,606][fairseq.trainer][INFO] - begin training epoch 49
[2024-07-04 21:28:20,606][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 21:33:17,516][train_inner][INFO] - {"epoch": 49, "update": 48.132, "loss": "70.977", "ntokens": "14817", "nsentences": "79.32", "nll_loss": "0.38", "wps": "7652", "ups": "0.52", "wpb": "14817", "bsz": "79.3", "num_updates": "62400", "lr": "5.6046e-06", "gnorm": "106.357", "loss_scale": "8", "train_wall": "346", "gb_free": "72.6", "wall": "110081"}
[2024-07-04 21:39:03,986][train_inner][INFO] - {"epoch": 49, "update": 48.286, "loss": "68.682", "ntokens": "14868.9", "nsentences": "80.87", "nll_loss": "0.374", "wps": "8585", "ups": "0.58", "wpb": "14868.9", "bsz": "80.9", "num_updates": "62600", "lr": "5.52127e-06", "gnorm": "105.419", "loss_scale": "8", "train_wall": "346", "gb_free": "69.2", "wall": "110427"}
[2024-07-04 21:44:46,432][train_inner][INFO] - {"epoch": 49, "update": 48.44, "loss": "68.311", "ntokens": "14746.2", "nsentences": "81.2", "nll_loss": "0.376", "wps": "8612.9", "ups": "0.58", "wpb": "14746.2", "bsz": "81.2", "num_updates": "62800", "lr": "5.43919e-06", "gnorm": "105.461", "loss_scale": "8", "train_wall": "342", "gb_free": "72.3", "wall": "110770"}
[2024-07-04 21:50:30,285][train_inner][INFO] - {"epoch": 49, "update": 48.594, "loss": "68.011", "ntokens": "14928.8", "nsentences": "82.04", "nll_loss": "0.374", "wps": "8685", "ups": "0.58", "wpb": "14928.8", "bsz": "82", "num_updates": "63000", "lr": "5.35832e-06", "gnorm": "105.513", "loss_scale": "16", "train_wall": "343", "gb_free": "72.7", "wall": "111114"}
[2024-07-04 21:56:13,714][train_inner][INFO] - {"epoch": 49, "update": 48.749, "loss": "69.014", "ntokens": "14831", "nsentences": "80.48", "nll_loss": "0.374", "wps": "8637.3", "ups": "0.58", "wpb": "14831", "bsz": "80.5", "num_updates": "63200", "lr": "5.27866e-06", "gnorm": "105.293", "loss_scale": "16", "train_wall": "343", "gb_free": "69.5", "wall": "111457"}
[2024-07-04 22:01:54,291][train_inner][INFO] - {"epoch": 49, "update": 48.903, "loss": "73.437", "ntokens": "14784.2", "nsentences": "77.92", "nll_loss": "0.387", "wps": "8683.3", "ups": "0.59", "wpb": "14784.2", "bsz": "77.9", "num_updates": "63400", "lr": "5.20018e-06", "gnorm": "109.104", "loss_scale": "16", "train_wall": "340", "gb_free": "72.1", "wall": "111798"}
[2024-07-04 22:05:26,320][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 22:05:26,327][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 22:06:05,146][dev-other][INFO] - {"epoch": 49, "dev-other_loss": "23.351", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.248", "dev-other_uer": "3.732", "dev-other_wer": "9.584", "dev-other_raw_wer": "9.584", "dev-other_wps": "7131.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "63526", "dev-other_best_wer": "9.568"}
[2024-07-04 22:06:05,147][fairseq_cli.train][INFO] - end of epoch 49 (average epoch stats below)
[2024-07-04 22:06:05,152][train][INFO] - {"epoch": 49, "train_loss": "69.891", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.378", "train_wps": "8486.1", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "63526", "train_lr": "5.15134e-06", "train_gnorm": "106.652", "train_loss_scale": "16", "train_train_wall": "2222", "train_gb_free": "72.7", "train_wall": "112048"}
[2024-07-04 22:06:05,154][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 22:06:06,133][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 22:06:06,138][fairseq.trainer][INFO] - begin training epoch 50
[2024-07-04 22:06:06,139][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 22:08:14,954][train_inner][INFO] - {"epoch": 50, "update": 49.057, "loss": "71.309", "ntokens": "14767", "nsentences": "78.72", "nll_loss": "0.38", "wps": "7760.1", "ups": "0.53", "wpb": "14767", "bsz": "78.7", "num_updates": "63600", "lr": "5.12287e-06", "gnorm": "108.477", "loss_scale": "16", "train_wall": "340", "gb_free": "70.6", "wall": "112178"}
[2024-07-04 22:13:55,253][train_inner][INFO] - {"epoch": 50, "update": 49.211, "loss": "74.575", "ntokens": "14829.3", "nsentences": "79.36", "nll_loss": "0.399", "wps": "8717.6", "ups": "0.59", "wpb": "14829.3", "bsz": "79.4", "num_updates": "63800", "lr": "5.04671e-06", "gnorm": "109.502", "loss_scale": "16", "train_wall": "340", "gb_free": "71.4", "wall": "112519"}
[2024-07-04 22:19:45,497][train_inner][INFO] - {"epoch": 50, "update": 49.365, "loss": "68.758", "ntokens": "14719.7", "nsentences": "79.56", "nll_loss": "0.372", "wps": "8407.2", "ups": "0.57", "wpb": "14719.7", "bsz": "79.6", "num_updates": "64000", "lr": "4.97168e-06", "gnorm": "106.159", "loss_scale": "16", "train_wall": "350", "gb_free": "71.9", "wall": "112869"}
[2024-07-04 22:20:45,712][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-04 22:25:24,984][train_inner][INFO] - {"epoch": 50, "update": 49.52, "loss": "69.649", "ntokens": "15020.7", "nsentences": "83.56", "nll_loss": "0.387", "wps": "8850.9", "ups": "0.59", "wpb": "15020.7", "bsz": "83.6", "num_updates": "64200", "lr": "4.89777e-06", "gnorm": "106.722", "loss_scale": "8", "train_wall": "339", "gb_free": "70.8", "wall": "113208"}
[2024-07-04 22:31:13,244][train_inner][INFO] - {"epoch": 50, "update": 49.675, "loss": "67.578", "ntokens": "14888.8", "nsentences": "82.56", "nll_loss": "0.375", "wps": "8550.7", "ups": "0.57", "wpb": "14888.8", "bsz": "82.6", "num_updates": "64400", "lr": "4.82495e-06", "gnorm": "102.661", "loss_scale": "8", "train_wall": "348", "gb_free": "70.7", "wall": "113557"}
[2024-07-04 22:37:02,025][train_inner][INFO] - {"epoch": 50, "update": 49.829, "loss": "71.23", "ntokens": "14689.9", "nsentences": "77.28", "nll_loss": "0.375", "wps": "8425.1", "ups": "0.57", "wpb": "14689.9", "bsz": "77.3", "num_updates": "64600", "lr": "4.75322e-06", "gnorm": "109.17", "loss_scale": "8", "train_wall": "348", "gb_free": "72.2", "wall": "113905"}
[2024-07-04 22:42:46,804][train_inner][INFO] - {"epoch": 50, "update": 49.983, "loss": "70.641", "ntokens": "14774.8", "nsentences": "79.16", "nll_loss": "0.378", "wps": "8572.6", "ups": "0.58", "wpb": "14774.8", "bsz": "79.2", "num_updates": "64800", "lr": "4.68255e-06", "gnorm": "106.663", "loss_scale": "8", "train_wall": "344", "gb_free": "72.2", "wall": "114250"}
[2024-07-04 22:43:24,329][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 22:43:24,330][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 22:44:03,494][dev-other][INFO] - {"epoch": 50, "dev-other_loss": "23.52", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.25", "dev-other_uer": "3.755", "dev-other_wer": "9.674", "dev-other_raw_wer": "9.674", "dev-other_wps": "7026.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "64822", "dev-other_best_wer": "9.568"}
[2024-07-04 22:44:03,496][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 50 @ 64822 updates
[2024-07-04 22:44:03,498][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_last.pt
[2024-07-04 22:44:05,987][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_last.pt
[2024-07-04 22:44:06,008][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_last.pt (epoch 50 @ 64822 updates, score 9.674) (writing took 2.5116079738363624 seconds)
[2024-07-04 22:44:06,009][fairseq_cli.train][INFO] - end of epoch 50 (average epoch stats below)
[2024-07-04 22:44:06,032][train][INFO] - {"epoch": 50, "train_loss": "70.235", "train_ntokens": "14823.1", "train_nsentences": "80.2099", "train_nll_loss": "0.38", "train_wps": "8422.6", "train_ups": "0.57", "train_wpb": "14823.1", "train_bsz": "80.2", "train_num_updates": "64822", "train_lr": "4.67484e-06", "train_gnorm": "106.602", "train_loss_scale": "8", "train_train_wall": "2234", "train_gb_free": "71.8", "train_wall": "114329"}
[2024-07-04 22:44:06,034][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 22:44:06,367][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 22:44:06,370][fairseq.trainer][INFO] - begin training epoch 51
[2024-07-04 22:44:06,370][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 22:49:14,135][train_inner][INFO] - {"epoch": 51, "update": 50.137, "loss": "70.744", "ntokens": "14811.1", "nsentences": "80.51", "nll_loss": "0.385", "wps": "7649.2", "ups": "0.52", "wpb": "14811.1", "bsz": "80.5", "num_updates": "65000", "lr": "4.61294e-06", "gnorm": "105.849", "loss_scale": "8", "train_wall": "345", "gb_free": "72.9", "wall": "114637"}
[2024-07-04 22:54:55,439][train_inner][INFO] - {"epoch": 51, "update": 50.291, "loss": "72.014", "ntokens": "14757.2", "nsentences": "79.24", "nll_loss": "0.387", "wps": "8647.7", "ups": "0.59", "wpb": "14757.2", "bsz": "79.2", "num_updates": "65200", "lr": "4.54436e-06", "gnorm": "108.584", "loss_scale": "8", "train_wall": "341", "gb_free": "72.1", "wall": "114979"}
[2024-07-04 23:00:45,311][train_inner][INFO] - {"epoch": 51, "update": 50.446, "loss": "69.566", "ntokens": "14753.5", "nsentences": "79.76", "nll_loss": "0.376", "wps": "8434.1", "ups": "0.57", "wpb": "14753.5", "bsz": "79.8", "num_updates": "65400", "lr": "4.47679e-06", "gnorm": "108.289", "loss_scale": "8", "train_wall": "349", "gb_free": "73.6", "wall": "115329"}
[2024-07-04 23:06:26,808][train_inner][INFO] - {"epoch": 51, "update": 50.6, "loss": "69.564", "ntokens": "14857.7", "nsentences": "80.24", "nll_loss": "0.376", "wps": "8703.3", "ups": "0.59", "wpb": "14857.7", "bsz": "80.2", "num_updates": "65600", "lr": "4.41024e-06", "gnorm": "107.243", "loss_scale": "8", "train_wall": "341", "gb_free": "70.5", "wall": "115670"}
[2024-07-04 23:12:15,138][train_inner][INFO] - {"epoch": 51, "update": 50.754, "loss": "67.773", "ntokens": "14972.5", "nsentences": "82.52", "nll_loss": "0.374", "wps": "8598.4", "ups": "0.57", "wpb": "14972.5", "bsz": "82.5", "num_updates": "65800", "lr": "4.34467e-06", "gnorm": "104.026", "loss_scale": "8", "train_wall": "348", "gb_free": "70.1", "wall": "116018"}
[2024-07-04 23:17:56,462][train_inner][INFO] - {"epoch": 51, "update": 50.908, "loss": "70.363", "ntokens": "14809.6", "nsentences": "78.68", "nll_loss": "0.374", "wps": "8679.6", "ups": "0.59", "wpb": "14809.6", "bsz": "78.7", "num_updates": "66000", "lr": "4.28008e-06", "gnorm": "106.885", "loss_scale": "8", "train_wall": "341", "gb_free": "71.2", "wall": "116360"}
[2024-07-04 23:21:25,265][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 23:21:25,337][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 23:22:04,614][dev-other][INFO] - {"epoch": 51, "dev-other_loss": "23.53", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.25", "dev-other_uer": "3.668", "dev-other_wer": "9.504", "dev-other_raw_wer": "9.504", "dev-other_wps": "7004.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "66119", "dev-other_best_wer": "9.504"}
[2024-07-04 23:22:04,626][fairseq_cli.train][INFO] - end of epoch 51 (average epoch stats below)
[2024-07-04 23:22:04,632][train][INFO] - {"epoch": 51, "train_loss": "69.591", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.377", "train_wps": "8437.3", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "66119", "train_lr": "4.2421e-06", "train_gnorm": "106.479", "train_loss_scale": "16", "train_train_wall": "2235", "train_gb_free": "71.8", "train_wall": "116608"}
[2024-07-04 23:22:04,635][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-04 23:22:05,580][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-04 23:22:05,586][fairseq.trainer][INFO] - begin training epoch 52
[2024-07-04 23:22:05,586][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-04 23:24:22,862][train_inner][INFO] - {"epoch": 52, "update": 51.062, "loss": "66.325", "ntokens": "14784.8", "nsentences": "80.16", "nll_loss": "0.36", "wps": "7652.9", "ups": "0.52", "wpb": "14784.8", "bsz": "80.2", "num_updates": "66200", "lr": "4.21645e-06", "gnorm": "105.422", "loss_scale": "16", "train_wall": "345", "gb_free": "72", "wall": "116746"}
[2024-07-04 23:30:07,036][train_inner][INFO] - {"epoch": 52, "update": 51.217, "loss": "71.789", "ntokens": "14820.4", "nsentences": "77.95", "nll_loss": "0.378", "wps": "8613.8", "ups": "0.58", "wpb": "14820.4", "bsz": "78", "num_updates": "66400", "lr": "4.15376e-06", "gnorm": "108.943", "loss_scale": "16", "train_wall": "344", "gb_free": "71.7", "wall": "117090"}
[2024-07-04 23:35:54,708][train_inner][INFO] - {"epoch": 52, "update": 51.371, "loss": "68.818", "ntokens": "14886.8", "nsentences": "81.48", "nll_loss": "0.377", "wps": "8563.9", "ups": "0.58", "wpb": "14886.8", "bsz": "81.5", "num_updates": "66600", "lr": "4.09201e-06", "gnorm": "103.997", "loss_scale": "16", "train_wall": "347", "gb_free": "72.1", "wall": "117438"}
[2024-07-04 23:41:39,712][train_inner][INFO] - {"epoch": 52, "update": 51.525, "loss": "69.78", "ntokens": "14786.9", "nsentences": "80.36", "nll_loss": "0.379", "wps": "8574", "ups": "0.58", "wpb": "14786.9", "bsz": "80.4", "num_updates": "66800", "lr": "4.03117e-06", "gnorm": "105.888", "loss_scale": "16", "train_wall": "344", "gb_free": "71.6", "wall": "117783"}
[2024-07-04 23:47:26,031][train_inner][INFO] - {"epoch": 52, "update": 51.679, "loss": "67.231", "ntokens": "14806", "nsentences": "81.4", "nll_loss": "0.37", "wps": "8552.4", "ups": "0.58", "wpb": "14806", "bsz": "81.4", "num_updates": "67000", "lr": "3.97124e-06", "gnorm": "104.057", "loss_scale": "16", "train_wall": "346", "gb_free": "72.6", "wall": "118129"}
[2024-07-04 23:53:10,336][train_inner][INFO] - {"epoch": 52, "update": 51.833, "loss": "70.041", "ntokens": "14847.7", "nsentences": "80.72", "nll_loss": "0.381", "wps": "8625.4", "ups": "0.58", "wpb": "14847.7", "bsz": "80.7", "num_updates": "67200", "lr": "3.9122e-06", "gnorm": "105.205", "loss_scale": "16", "train_wall": "344", "gb_free": "69.5", "wall": "118474"}
[2024-07-04 23:58:55,734][train_inner][INFO] - {"epoch": 52, "update": 51.988, "loss": "71.447", "ntokens": "14773.5", "nsentences": "79.44", "nll_loss": "0.384", "wps": "8554.8", "ups": "0.58", "wpb": "14773.5", "bsz": "79.4", "num_updates": "67400", "lr": "3.85404e-06", "gnorm": "106.653", "loss_scale": "16", "train_wall": "345", "gb_free": "71.9", "wall": "118819"}
[2024-07-04 23:59:24,925][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-04 23:59:24,926][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 00:00:04,132][dev-other][INFO] - {"epoch": 52, "dev-other_loss": "22.955", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.244", "dev-other_uer": "3.677", "dev-other_wer": "9.509", "dev-other_raw_wer": "9.509", "dev-other_wps": "7044.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "67416", "dev-other_best_wer": "9.509"}
[2024-07-05 00:00:04,133][fairseq_cli.train][INFO] - end of epoch 52 (average epoch stats below)
[2024-07-05 00:00:04,149][train][INFO] - {"epoch": 52, "train_loss": "69.645", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.377", "train_wps": "8434", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "67416", "train_lr": "3.84942e-06", "train_gnorm": "105.873", "train_loss_scale": "16", "train_train_wall": "2235", "train_gb_free": "71", "train_wall": "118887"}
[2024-07-05 00:00:04,152][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 00:00:04,991][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 00:00:04,996][fairseq.trainer][INFO] - begin training epoch 53
[2024-07-05 00:00:04,997][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 00:05:22,681][train_inner][INFO] - {"epoch": 53, "update": 52.142, "loss": "68.927", "ntokens": "14946.7", "nsentences": "80.56", "nll_loss": "0.372", "wps": "7726.7", "ups": "0.52", "wpb": "14946.7", "bsz": "80.6", "num_updates": "67600", "lr": "3.79674e-06", "gnorm": "103.39", "loss_scale": "16", "train_wall": "346", "gb_free": "73.1", "wall": "119206"}
[2024-07-05 00:11:14,956][train_inner][INFO] - {"epoch": 53, "update": 52.296, "loss": "65.854", "ntokens": "14812", "nsentences": "81.28", "nll_loss": "0.361", "wps": "8410.9", "ups": "0.57", "wpb": "14812", "bsz": "81.3", "num_updates": "67800", "lr": "3.74029e-06", "gnorm": "102.26", "loss_scale": "16", "train_wall": "352", "gb_free": "71.8", "wall": "119558"}
[2024-07-05 00:12:05,969][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-05 00:16:57,100][train_inner][INFO] - {"epoch": 53, "update": 52.451, "loss": "71.648", "ntokens": "14880.8", "nsentences": "80.44", "nll_loss": "0.387", "wps": "8700.3", "ups": "0.58", "wpb": "14880.8", "bsz": "80.4", "num_updates": "68000", "lr": "3.68468e-06", "gnorm": "109.024", "loss_scale": "8", "train_wall": "341", "gb_free": "71.6", "wall": "119900"}
[2024-07-05 00:22:39,153][train_inner][INFO] - {"epoch": 53, "update": 52.605, "loss": "72.262", "ntokens": "14828.9", "nsentences": "78.96", "nll_loss": "0.385", "wps": "8672", "ups": "0.58", "wpb": "14828.9", "bsz": "79", "num_updates": "68200", "lr": "3.6299e-06", "gnorm": "108.487", "loss_scale": "8", "train_wall": "341", "gb_free": "71.2", "wall": "120242"}
[2024-07-05 00:28:23,919][train_inner][INFO] - {"epoch": 53, "update": 52.759, "loss": "68.28", "ntokens": "14766.7", "nsentences": "79.32", "nll_loss": "0.367", "wps": "8566.4", "ups": "0.58", "wpb": "14766.7", "bsz": "79.3", "num_updates": "68400", "lr": "3.57594e-06", "gnorm": "107.996", "loss_scale": "8", "train_wall": "344", "gb_free": "70.9", "wall": "120587"}
[2024-07-05 00:34:10,976][train_inner][INFO] - {"epoch": 53, "update": 52.914, "loss": "68.091", "ntokens": "14798.6", "nsentences": "80.79", "nll_loss": "0.372", "wps": "8529.6", "ups": "0.58", "wpb": "14798.6", "bsz": "80.8", "num_updates": "68600", "lr": "3.52277e-06", "gnorm": "104.548", "loss_scale": "8", "train_wall": "346", "gb_free": "70.9", "wall": "120934"}
[2024-07-05 00:37:23,484][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 00:37:23,491][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 00:38:02,603][dev-other][INFO] - {"epoch": 53, "dev-other_loss": "23.169", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.246", "dev-other_uer": "3.702", "dev-other_wer": "9.557", "dev-other_raw_wer": "9.557", "dev-other_wps": "7057.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "68712", "dev-other_best_wer": "9.557"}
[2024-07-05 00:38:02,604][fairseq_cli.train][INFO] - end of epoch 53 (average epoch stats below)
[2024-07-05 00:38:02,609][train][INFO] - {"epoch": 53, "train_loss": "69.178", "train_ntokens": "14821.7", "train_nsentences": "80.1898", "train_nll_loss": "0.374", "train_wps": "8430.7", "train_ups": "0.57", "train_wpb": "14821.7", "train_bsz": "80.2", "train_num_updates": "68712", "train_lr": "3.49335e-06", "train_gnorm": "106.071", "train_loss_scale": "8", "train_train_wall": "2234", "train_gb_free": "72.1", "train_wall": "121166"}
[2024-07-05 00:38:02,612][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 00:38:03,581][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 00:38:03,594][fairseq.trainer][INFO] - begin training epoch 54
[2024-07-05 00:38:03,594][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 00:40:35,553][train_inner][INFO] - {"epoch": 54, "update": 53.068, "loss": "69.633", "ntokens": "14713.4", "nsentences": "79.84", "nll_loss": "0.378", "wps": "7653.6", "ups": "0.52", "wpb": "14713.4", "bsz": "79.8", "num_updates": "68800", "lr": "3.4704e-06", "gnorm": "106.91", "loss_scale": "8", "train_wall": "344", "gb_free": "71.6", "wall": "121319"}
[2024-07-05 00:46:16,345][train_inner][INFO] - {"epoch": 54, "update": 53.222, "loss": "72.406", "ntokens": "14809.9", "nsentences": "78.07", "nll_loss": "0.382", "wps": "8694", "ups": "0.59", "wpb": "14809.9", "bsz": "78.1", "num_updates": "69000", "lr": "3.41881e-06", "gnorm": "109.996", "loss_scale": "8", "train_wall": "340", "gb_free": "71.7", "wall": "121660"}
[2024-07-05 00:52:00,677][train_inner][INFO] - {"epoch": 54, "update": 53.376, "loss": "69.687", "ntokens": "14791.9", "nsentences": "81.04", "nll_loss": "0.382", "wps": "8592.2", "ups": "0.58", "wpb": "14791.9", "bsz": "81", "num_updates": "69200", "lr": "3.36798e-06", "gnorm": "109.702", "loss_scale": "8", "train_wall": "344", "gb_free": "72.7", "wall": "122004"}
[2024-07-05 00:57:48,076][train_inner][INFO] - {"epoch": 54, "update": 53.53, "loss": "70.069", "ntokens": "14903.9", "nsentences": "80.36", "nll_loss": "0.378", "wps": "8580.4", "ups": "0.58", "wpb": "14903.9", "bsz": "80.4", "num_updates": "69400", "lr": "3.31791e-06", "gnorm": "106.221", "loss_scale": "8", "train_wall": "347", "gb_free": "73", "wall": "122351"}
[2024-07-05 01:03:36,912][train_inner][INFO] - {"epoch": 54, "update": 53.685, "loss": "69.044", "ntokens": "14822.7", "nsentences": "80.32", "nll_loss": "0.374", "wps": "8500.2", "ups": "0.57", "wpb": "14822.7", "bsz": "80.3", "num_updates": "69600", "lr": "3.26858e-06", "gnorm": "105.044", "loss_scale": "8", "train_wall": "348", "gb_free": "71.7", "wall": "122700"}
[2024-07-05 01:09:22,918][train_inner][INFO] - {"epoch": 54, "update": 53.839, "loss": "68.355", "ntokens": "14784.8", "nsentences": "80.32", "nll_loss": "0.371", "wps": "8547.8", "ups": "0.58", "wpb": "14784.8", "bsz": "80.3", "num_updates": "69800", "lr": "3.21999e-06", "gnorm": "104.97", "loss_scale": "8", "train_wall": "345", "gb_free": "72.1", "wall": "123046"}
[2024-07-05 01:15:12,643][train_inner][INFO] - {"epoch": 54, "update": 53.993, "loss": "67.49", "ntokens": "14870.5", "nsentences": "81.24", "nll_loss": "0.369", "wps": "8504.5", "ups": "0.57", "wpb": "14870.5", "bsz": "81.2", "num_updates": "70000", "lr": "3.17211e-06", "gnorm": "105.099", "loss_scale": "16", "train_wall": "349", "gb_free": "72", "wall": "123396"}
[2024-07-05 01:15:28,834][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 01:15:28,835][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 01:16:07,999][dev-other][INFO] - {"epoch": 54, "dev-other_loss": "23.299", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.248", "dev-other_uer": "3.678", "dev-other_wer": "9.525", "dev-other_raw_wer": "9.525", "dev-other_wps": "7031.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "70009", "dev-other_best_wer": "9.525"}
[2024-07-05 01:16:08,000][fairseq_cli.train][INFO] - end of epoch 54 (average epoch stats below)
[2024-07-05 01:16:08,005][train][INFO] - {"epoch": 54, "train_loss": "69.546", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.376", "train_wps": "8412.2", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "70009", "train_lr": "3.16998e-06", "train_gnorm": "106.87", "train_loss_scale": "16", "train_train_wall": "2241", "train_gb_free": "72.2", "train_wall": "123451"}
[2024-07-05 01:16:08,007][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 01:16:09,022][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 01:16:09,028][fairseq.trainer][INFO] - begin training epoch 55
[2024-07-05 01:16:09,028][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 01:21:37,760][train_inner][INFO] - {"epoch": 55, "update": 54.147, "loss": "65.542", "ntokens": "14846", "nsentences": "82.44", "nll_loss": "0.364", "wps": "7710", "ups": "0.52", "wpb": "14846", "bsz": "82.4", "num_updates": "70200", "lr": "3.12495e-06", "gnorm": "103.982", "loss_scale": "16", "train_wall": "344", "gb_free": "71.4", "wall": "123781"}
[2024-07-05 01:25:21,227][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-05 01:27:29,166][train_inner][INFO] - {"epoch": 55, "update": 54.302, "loss": "70.343", "ntokens": "14846.8", "nsentences": "78.96", "nll_loss": "0.374", "wps": "8451.4", "ups": "0.57", "wpb": "14846.8", "bsz": "79", "num_updates": "70400", "lr": "3.0785e-06", "gnorm": "106.067", "loss_scale": "8", "train_wall": "351", "gb_free": "72.2", "wall": "124132"}
[2024-07-05 01:33:14,297][train_inner][INFO] - {"epoch": 55, "update": 54.456, "loss": "66.287", "ntokens": "14879.2", "nsentences": "81.84", "nll_loss": "0.365", "wps": "8622.6", "ups": "0.58", "wpb": "14879.2", "bsz": "81.8", "num_updates": "70600", "lr": "3.03273e-06", "gnorm": "105.304", "loss_scale": "8", "train_wall": "345", "gb_free": "72.8", "wall": "124478"}
[2024-07-05 01:39:02,194][train_inner][INFO] - {"epoch": 55, "update": 54.611, "loss": "71.312", "ntokens": "14773.9", "nsentences": "77.12", "nll_loss": "0.372", "wps": "8494.8", "ups": "0.57", "wpb": "14773.9", "bsz": "77.1", "num_updates": "70800", "lr": "2.98764e-06", "gnorm": "109.046", "loss_scale": "8", "train_wall": "347", "gb_free": "72.8", "wall": "124825"}
[2024-07-05 01:44:44,411][train_inner][INFO] - {"epoch": 55, "update": 54.765, "loss": "67.025", "ntokens": "14875.5", "nsentences": "82.08", "nll_loss": "0.37", "wps": "8695.3", "ups": "0.58", "wpb": "14875.5", "bsz": "82.1", "num_updates": "71000", "lr": "2.94322e-06", "gnorm": "103.915", "loss_scale": "8", "train_wall": "342", "gb_free": "70.2", "wall": "125168"}
[2024-07-05 01:50:31,014][train_inner][INFO] - {"epoch": 55, "update": 54.919, "loss": "70.515", "ntokens": "14702.1", "nsentences": "78.6", "nll_loss": "0.377", "wps": "8485.5", "ups": "0.58", "wpb": "14702.1", "bsz": "78.6", "num_updates": "71200", "lr": "2.89946e-06", "gnorm": "108.752", "loss_scale": "8", "train_wall": "346", "gb_free": "72.5", "wall": "125514"}
[2024-07-05 01:53:34,654][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 01:53:34,723][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 01:54:14,522][dev-other][INFO] - {"epoch": 55, "dev-other_loss": "24.097", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.256", "dev-other_uer": "3.72", "dev-other_wer": "9.557", "dev-other_raw_wer": "9.557", "dev-other_wps": "6907.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "71305", "dev-other_best_wer": "9.557"}
[2024-07-05 01:54:14,525][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 55 @ 71305 updates
[2024-07-05 01:54:14,526][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt
[2024-07-05 01:54:16,861][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt
[2024-07-05 01:54:17,429][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt (epoch 55 @ 71305 updates, score 9.557) (writing took 2.903805600479245 seconds)
[2024-07-05 01:54:17,429][fairseq_cli.train][INFO] - end of epoch 55 (average epoch stats below)
[2024-07-05 01:54:17,433][train][INFO] - {"epoch": 55, "train_loss": "68.498", "train_ntokens": "14822.6", "train_nsentences": "80.1852", "train_nll_loss": "0.371", "train_wps": "8390.8", "train_ups": "0.57", "train_wpb": "14822.6", "train_bsz": "80.2", "train_num_updates": "71305", "train_lr": "2.87675e-06", "train_gnorm": "106.22", "train_loss_scale": "8", "train_train_wall": "2241", "train_gb_free": "72.6", "train_wall": "125741"}
[2024-07-05 01:54:17,435][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 01:54:17,819][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 01:54:17,824][fairseq.trainer][INFO] - begin training epoch 56
[2024-07-05 01:54:17,824][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 01:57:05,652][train_inner][INFO] - {"epoch": 56, "update": 55.073, "loss": "65.951", "ntokens": "14849.4", "nsentences": "82.16", "nll_loss": "0.365", "wps": "7525.8", "ups": "0.51", "wpb": "14849.4", "bsz": "82.2", "num_updates": "71400", "lr": "2.85636e-06", "gnorm": "103.365", "loss_scale": "8", "train_wall": "351", "gb_free": "72.4", "wall": "125909"}
[2024-07-05 02:02:54,744][train_inner][INFO] - {"epoch": 56, "update": 55.227, "loss": "67.297", "ntokens": "14872.7", "nsentences": "79.6", "nll_loss": "0.36", "wps": "8521.5", "ups": "0.57", "wpb": "14872.7", "bsz": "79.6", "num_updates": "71600", "lr": "2.81389e-06", "gnorm": "105.139", "loss_scale": "8", "train_wall": "348", "gb_free": "72.3", "wall": "126258"}
[2024-07-05 02:08:39,186][train_inner][INFO] - {"epoch": 56, "update": 55.382, "loss": "68.565", "ntokens": "14884.6", "nsentences": "82.32", "nll_loss": "0.379", "wps": "8645.7", "ups": "0.58", "wpb": "14884.6", "bsz": "82.3", "num_updates": "71800", "lr": "2.77206e-06", "gnorm": "103.565", "loss_scale": "8", "train_wall": "344", "gb_free": "70.7", "wall": "126602"}
[2024-07-05 02:14:30,375][train_inner][INFO] - {"epoch": 56, "update": 55.536, "loss": "68.473", "ntokens": "14773.6", "nsentences": "78.12", "nll_loss": "0.362", "wps": "8413.7", "ups": "0.57", "wpb": "14773.6", "bsz": "78.1", "num_updates": "72000", "lr": "2.73085e-06", "gnorm": "106.075", "loss_scale": "8", "train_wall": "351", "gb_free": "71.4", "wall": "126954"}
[2024-07-05 02:20:18,091][train_inner][INFO] - {"epoch": 56, "update": 55.69, "loss": "70.927", "ntokens": "14802.6", "nsentences": "79.44", "nll_loss": "0.381", "wps": "8515.7", "ups": "0.58", "wpb": "14802.6", "bsz": "79.4", "num_updates": "72200", "lr": "2.69025e-06", "gnorm": "106.337", "loss_scale": "8", "train_wall": "347", "gb_free": "72.8", "wall": "127301"}
[2024-07-05 02:26:03,064][train_inner][INFO] - {"epoch": 56, "update": 55.844, "loss": "68.387", "ntokens": "14840.6", "nsentences": "80.64", "nll_loss": "0.372", "wps": "8605.5", "ups": "0.58", "wpb": "14840.6", "bsz": "80.6", "num_updates": "72400", "lr": "2.65025e-06", "gnorm": "107.191", "loss_scale": "16", "train_wall": "344", "gb_free": "72.8", "wall": "127646"}
[2024-07-05 02:29:22,534][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-05 02:31:54,968][train_inner][INFO] - {"epoch": 56, "update": 55.999, "loss": "67.758", "ntokens": "14761.4", "nsentences": "79.48", "nll_loss": "0.365", "wps": "8389.7", "ups": "0.57", "wpb": "14761.4", "bsz": "79.5", "num_updates": "72600", "lr": "2.61085e-06", "gnorm": "105.767", "loss_scale": "8", "train_wall": "351", "gb_free": "71.5", "wall": "127998"}
[2024-07-05 02:31:56,852][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 02:31:56,852][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 02:32:36,657][dev-other][INFO] - {"epoch": 56, "dev-other_loss": "23.651", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.251", "dev-other_uer": "3.732", "dev-other_wer": "9.639", "dev-other_raw_wer": "9.639", "dev-other_wps": "6923.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "72601", "dev-other_best_wer": "9.557"}
[2024-07-05 02:32:36,658][fairseq_cli.train][INFO] - end of epoch 56 (average epoch stats below)
[2024-07-05 02:32:36,673][train][INFO] - {"epoch": 56, "train_loss": "68.176", "train_ntokens": "14822.8", "train_nsentences": "80.2037", "train_nll_loss": "0.369", "train_wps": "8355.2", "train_ups": "0.56", "train_wpb": "14822.8", "train_bsz": "80.2", "train_num_updates": "72601", "train_lr": "2.61065e-06", "train_gnorm": "105.307", "train_loss_scale": "8", "train_train_wall": "2255", "train_gb_free": "72.2", "train_wall": "128040"}
[2024-07-05 02:32:36,675][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 02:32:37,501][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 02:32:37,507][fairseq.trainer][INFO] - begin training epoch 57
[2024-07-05 02:32:37,507][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 02:38:24,107][train_inner][INFO] - {"epoch": 57, "update": 56.153, "loss": "72.571", "ntokens": "14830.8", "nsentences": "79.08", "nll_loss": "0.387", "wps": "7622.6", "ups": "0.51", "wpb": "14830.8", "bsz": "79.1", "num_updates": "72800", "lr": "2.57203e-06", "gnorm": "105.993", "loss_scale": "8", "train_wall": "348", "gb_free": "71.9", "wall": "128387"}
[2024-07-05 02:44:10,463][train_inner][INFO] - {"epoch": 57, "update": 56.308, "loss": "66.878", "ntokens": "14866.2", "nsentences": "82.07", "nll_loss": "0.369", "wps": "8584.6", "ups": "0.58", "wpb": "14866.2", "bsz": "82.1", "num_updates": "73000", "lr": "2.5338e-06", "gnorm": "104.571", "loss_scale": "8", "train_wall": "346", "gb_free": "72.2", "wall": "128734"}
[2024-07-05 02:49:57,815][train_inner][INFO] - {"epoch": 57, "update": 56.462, "loss": "68.523", "ntokens": "14762.3", "nsentences": "81", "nll_loss": "0.376", "wps": "8501.6", "ups": "0.58", "wpb": "14762.3", "bsz": "81", "num_updates": "73200", "lr": "2.49613e-06", "gnorm": "104.474", "loss_scale": "8", "train_wall": "347", "gb_free": "72.6", "wall": "129081"}
[2024-07-05 02:55:43,973][train_inner][INFO] - {"epoch": 57, "update": 56.616, "loss": "69.204", "ntokens": "14825.8", "nsentences": "79.92", "nll_loss": "0.373", "wps": "8567.7", "ups": "0.58", "wpb": "14825.8", "bsz": "79.9", "num_updates": "73400", "lr": "2.45902e-06", "gnorm": "106.036", "loss_scale": "8", "train_wall": "345", "gb_free": "71.3", "wall": "129427"}
[2024-07-05 03:01:20,506][train_inner][INFO] - {"epoch": 57, "update": 56.77, "loss": "70.05", "ntokens": "14833.6", "nsentences": "80.8", "nll_loss": "0.382", "wps": "8815.8", "ups": "0.59", "wpb": "14833.6", "bsz": "80.8", "num_updates": "73600", "lr": "2.42246e-06", "gnorm": "106.586", "loss_scale": "8", "train_wall": "336", "gb_free": "72.5", "wall": "129764"}
[2024-07-05 03:07:09,111][train_inner][INFO] - {"epoch": 57, "update": 56.924, "loss": "70.46", "ntokens": "14784.4", "nsentences": "77.92", "nll_loss": "0.371", "wps": "8483.9", "ups": "0.57", "wpb": "14784.4", "bsz": "77.9", "num_updates": "73800", "lr": "2.38644e-06", "gnorm": "108.829", "loss_scale": "8", "train_wall": "348", "gb_free": "72.1", "wall": "130112"}
[2024-07-05 03:09:50,815][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 03:09:50,887][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 03:10:30,365][dev-other][INFO] - {"epoch": 57, "dev-other_loss": "23.719", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.252", "dev-other_uer": "3.659", "dev-other_wer": "9.5", "dev-other_raw_wer": "9.5", "dev-other_wps": "6944.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "73898", "dev-other_best_wer": "9.5"}
[2024-07-05 03:10:30,367][fairseq_cli.train][INFO] - end of epoch 57 (average epoch stats below)
[2024-07-05 03:10:30,387][train][INFO] - {"epoch": 57, "train_loss": "69.654", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.377", "train_wps": "8455.5", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "73898", "train_lr": "2.36899e-06", "train_gnorm": "106.33", "train_loss_scale": "8", "train_train_wall": "2229", "train_gb_free": "72.1", "train_wall": "130314"}
[2024-07-05 03:10:30,390][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 03:10:31,262][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 03:10:31,265][fairseq.trainer][INFO] - begin training epoch 58
[2024-07-05 03:10:31,265][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 03:13:33,355][train_inner][INFO] - {"epoch": 58, "update": 57.079, "loss": "68.453", "ntokens": "14864.1", "nsentences": "79.84", "nll_loss": "0.368", "wps": "7738.4", "ups": "0.52", "wpb": "14864.1", "bsz": "79.8", "num_updates": "74000", "lr": "2.35096e-06", "gnorm": "106.947", "loss_scale": "8", "train_wall": "343", "gb_free": "71.4", "wall": "130497"}
[2024-07-05 03:19:14,492][train_inner][INFO] - {"epoch": 58, "update": 57.233, "loss": "71.6", "ntokens": "14793.2", "nsentences": "80.96", "nll_loss": "0.392", "wps": "8673.2", "ups": "0.59", "wpb": "14793.2", "bsz": "81", "num_updates": "74200", "lr": "2.31601e-06", "gnorm": "106.618", "loss_scale": "8", "train_wall": "341", "gb_free": "70.2", "wall": "130838"}
[2024-07-05 03:24:54,146][train_inner][INFO] - {"epoch": 58, "update": 57.387, "loss": "67.538", "ntokens": "14878.5", "nsentences": "81.32", "nll_loss": "0.369", "wps": "8761.6", "ups": "0.59", "wpb": "14878.5", "bsz": "81.3", "num_updates": "74400", "lr": "2.28158e-06", "gnorm": "105.994", "loss_scale": "8", "train_wall": "339", "gb_free": "72.5", "wall": "131177"}
[2024-07-05 03:30:34,927][train_inner][INFO] - {"epoch": 58, "update": 57.541, "loss": "71.234", "ntokens": "14903.6", "nsentences": "80.84", "nll_loss": "0.386", "wps": "8748.8", "ups": "0.59", "wpb": "14903.6", "bsz": "80.8", "num_updates": "74600", "lr": "2.24766e-06", "gnorm": "109.629", "loss_scale": "16", "train_wall": "340", "gb_free": "73.3", "wall": "131518"}
[2024-07-05 03:36:25,605][train_inner][INFO] - {"epoch": 58, "update": 57.695, "loss": "69.329", "ntokens": "14779.9", "nsentences": "78.84", "nll_loss": "0.37", "wps": "8430.9", "ups": "0.57", "wpb": "14779.9", "bsz": "78.8", "num_updates": "74800", "lr": "2.21424e-06", "gnorm": "106.509", "loss_scale": "16", "train_wall": "350", "gb_free": "71.7", "wall": "131869"}
[2024-07-05 03:42:06,115][train_inner][INFO] - {"epoch": 58, "update": 57.85, "loss": "71.691", "ntokens": "14766.4", "nsentences": "79", "nll_loss": "0.384", "wps": "8674.9", "ups": "0.59", "wpb": "14766.4", "bsz": "79", "num_updates": "75000", "lr": "2.18132e-06", "gnorm": "109.166", "loss_scale": "16", "train_wall": "340", "gb_free": "72.3", "wall": "132209"}
[2024-07-05 03:46:32,311][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-05 03:47:47,647][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 03:47:47,719][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 03:48:27,498][dev-other][INFO] - {"epoch": 58, "dev-other_loss": "23.316", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.248", "dev-other_uer": "3.69", "dev-other_wer": "9.56", "dev-other_raw_wer": "9.56", "dev-other_wps": "6905.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "75194", "dev-other_best_wer": "9.557"}
[2024-07-05 03:48:27,506][fairseq_cli.train][INFO] - end of epoch 58 (average epoch stats below)
[2024-07-05 03:48:27,514][train][INFO] - {"epoch": 58, "train_loss": "69.32", "train_ntokens": "14822.7", "train_nsentences": "80.2099", "train_nll_loss": "0.375", "train_wps": "8436.2", "train_ups": "0.57", "train_wpb": "14822.7", "train_bsz": "80.2", "train_num_updates": "75194", "train_lr": "2.14986e-06", "train_gnorm": "106.833", "train_loss_scale": "8", "train_train_wall": "2232", "train_gb_free": "72", "train_wall": "132591"}
[2024-07-05 03:48:27,517][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 03:48:28,405][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 03:48:28,411][fairseq.trainer][INFO] - begin training epoch 59
[2024-07-05 03:48:28,411][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 03:48:39,847][train_inner][INFO] - {"epoch": 59, "update": 58.005, "loss": "66.004", "ntokens": "14828.9", "nsentences": "81.48", "nll_loss": "0.363", "wps": "7532.8", "ups": "0.51", "wpb": "14828.9", "bsz": "81.5", "num_updates": "75200", "lr": "2.14889e-06", "gnorm": "103.677", "loss_scale": "8", "train_wall": "352", "gb_free": "70.8", "wall": "132603"}
[2024-07-05 03:54:31,496][train_inner][INFO] - {"epoch": 59, "update": 58.159, "loss": "68.3", "ntokens": "14741.5", "nsentences": "78.96", "nll_loss": "0.366", "wps": "8385.8", "ups": "0.57", "wpb": "14741.5", "bsz": "79", "num_updates": "75400", "lr": "2.11695e-06", "gnorm": "105.558", "loss_scale": "8", "train_wall": "351", "gb_free": "70.1", "wall": "132955"}
[2024-07-05 04:00:12,119][train_inner][INFO] - {"epoch": 59, "update": 58.313, "loss": "70.299", "ntokens": "14771.5", "nsentences": "77.92", "nll_loss": "0.371", "wps": "8675.2", "ups": "0.59", "wpb": "14771.5", "bsz": "77.9", "num_updates": "75600", "lr": "2.08547e-06", "gnorm": "109.2", "loss_scale": "8", "train_wall": "340", "gb_free": "70.9", "wall": "133295"}
[2024-07-05 04:05:55,116][train_inner][INFO] - {"epoch": 59, "update": 58.467, "loss": "68.104", "ntokens": "14853.2", "nsentences": "81.32", "nll_loss": "0.373", "wps": "8661.1", "ups": "0.58", "wpb": "14853.2", "bsz": "81.3", "num_updates": "75800", "lr": "2.05447e-06", "gnorm": "106.072", "loss_scale": "8", "train_wall": "342", "gb_free": "71.2", "wall": "133638"}
[2024-07-05 04:11:41,535][train_inner][INFO] - {"epoch": 59, "update": 58.621, "loss": "67.859", "ntokens": "14875.9", "nsentences": "80.83", "nll_loss": "0.369", "wps": "8590.1", "ups": "0.58", "wpb": "14875.9", "bsz": "80.8", "num_updates": "76000", "lr": "2.02392e-06", "gnorm": "107.077", "loss_scale": "8", "train_wall": "346", "gb_free": "71.7", "wall": "133985"}
[2024-07-05 04:17:25,686][train_inner][INFO] - {"epoch": 59, "update": 58.776, "loss": "71.05", "ntokens": "14789.4", "nsentences": "80.52", "nll_loss": "0.387", "wps": "8595.1", "ups": "0.58", "wpb": "14789.4", "bsz": "80.5", "num_updates": "76200", "lr": "1.99383e-06", "gnorm": "107.122", "loss_scale": "8", "train_wall": "344", "gb_free": "72.8", "wall": "134329"}
[2024-07-05 04:23:11,362][train_inner][INFO] - {"epoch": 59, "update": 58.93, "loss": "67.199", "ntokens": "14882.2", "nsentences": "81.52", "nll_loss": "0.368", "wps": "8612.4", "ups": "0.58", "wpb": "14882.2", "bsz": "81.5", "num_updates": "76400", "lr": "1.96419e-06", "gnorm": "104.85", "loss_scale": "8", "train_wall": "345", "gb_free": "71.5", "wall": "134675"}
[2024-07-05 04:25:47,655][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 04:25:47,718][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 04:26:27,706][dev-other][INFO] - {"epoch": 59, "dev-other_loss": "23.521", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.25", "dev-other_uer": "3.722", "dev-other_wer": "9.594", "dev-other_raw_wer": "9.594", "dev-other_wps": "6922.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "76491", "dev-other_best_wer": "9.557"}
[2024-07-05 04:26:27,707][fairseq_cli.train][INFO] - end of epoch 59 (average epoch stats below)
[2024-07-05 04:26:27,711][train][INFO] - {"epoch": 59, "train_loss": "68.953", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.373", "train_wps": "8431.4", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "76491", "train_lr": "1.95085e-06", "train_gnorm": "106.752", "train_loss_scale": "8", "train_train_wall": "2235", "train_gb_free": "72.4", "train_wall": "134871"}
[2024-07-05 04:26:27,714][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 04:26:28,686][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 04:26:28,708][fairseq.trainer][INFO] - begin training epoch 60
[2024-07-05 04:26:28,708][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 04:29:42,077][train_inner][INFO] - {"epoch": 60, "update": 59.084, "loss": "67.863", "ntokens": "14855.2", "nsentences": "79.96", "nll_loss": "0.365", "wps": "7604.4", "ups": "0.51", "wpb": "14855.2", "bsz": "80", "num_updates": "76600", "lr": "1.93499e-06", "gnorm": "106.057", "loss_scale": "8", "train_wall": "349", "gb_free": "71.7", "wall": "135065"}
[2024-07-05 04:35:25,008][train_inner][INFO] - {"epoch": 60, "update": 59.238, "loss": "66.109", "ntokens": "14826.1", "nsentences": "81.8", "nll_loss": "0.365", "wps": "8648.5", "ups": "0.58", "wpb": "14826.1", "bsz": "81.8", "num_updates": "76800", "lr": "1.90622e-06", "gnorm": "104.873", "loss_scale": "8", "train_wall": "342", "gb_free": "72.4", "wall": "135408"}
[2024-07-05 04:41:13,324][train_inner][INFO] - {"epoch": 60, "update": 59.392, "loss": "67.729", "ntokens": "14860.5", "nsentences": "81.32", "nll_loss": "0.371", "wps": "8533", "ups": "0.57", "wpb": "14860.5", "bsz": "81.3", "num_updates": "77000", "lr": "1.87788e-06", "gnorm": "105.322", "loss_scale": "8", "train_wall": "348", "gb_free": "72.2", "wall": "135757"}
[2024-07-05 04:47:04,091][train_inner][INFO] - {"epoch": 60, "update": 59.547, "loss": "68.312", "ntokens": "14830.3", "nsentences": "79.16", "nll_loss": "0.365", "wps": "8457.4", "ups": "0.57", "wpb": "14830.3", "bsz": "79.2", "num_updates": "77200", "lr": "1.84996e-06", "gnorm": "105.77", "loss_scale": "16", "train_wall": "350", "gb_free": "72.6", "wall": "136107"}
[2024-07-05 04:51:03,336][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-05 04:52:56,644][train_inner][INFO] - {"epoch": 60, "update": 59.702, "loss": "67.667", "ntokens": "14804", "nsentences": "79.6", "nll_loss": "0.364", "wps": "8400.1", "ups": "0.57", "wpb": "14804", "bsz": "79.6", "num_updates": "77400", "lr": "1.82246e-06", "gnorm": "104.267", "loss_scale": "8", "train_wall": "352", "gb_free": "71.6", "wall": "136460"}
[2024-07-05 04:58:42,354][train_inner][INFO] - {"epoch": 60, "update": 59.856, "loss": "67.763", "ntokens": "14840.6", "nsentences": "80.04", "nll_loss": "0.365", "wps": "8587.4", "ups": "0.58", "wpb": "14840.6", "bsz": "80", "num_updates": "77600", "lr": "1.79537e-06", "gnorm": "105.246", "loss_scale": "8", "train_wall": "345", "gb_free": "71.6", "wall": "136806"}
[2024-07-05 05:04:06,897][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 05:04:06,965][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 05:04:46,254][dev-other][INFO] - {"epoch": 60, "dev-other_loss": "23.75", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.252", "dev-other_uer": "3.701", "dev-other_wer": "9.527", "dev-other_raw_wer": "9.527", "dev-other_wps": "6996.3", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "77787", "dev-other_best_wer": "9.527"}
[2024-07-05 05:04:46,257][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 60 @ 77787 updates
[2024-07-05 05:04:46,258][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt
[2024-07-05 05:04:48,752][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt
[2024-07-05 05:04:49,260][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_best.pt (epoch 60 @ 77787 updates, score 9.527) (writing took 3.0031759310513735 seconds)
[2024-07-05 05:04:49,261][fairseq_cli.train][INFO] - end of epoch 60 (average epoch stats below)
[2024-07-05 05:04:49,265][train][INFO] - {"epoch": 60, "train_loss": "67.548", "train_ntokens": "14821.9", "train_nsentences": "80.2037", "train_nll_loss": "0.366", "train_wps": "8346.2", "train_ups": "0.56", "train_wpb": "14821.9", "train_bsz": "80.2", "train_num_updates": "77787", "train_lr": "1.7704e-06", "train_gnorm": "104.977", "train_loss_scale": "8", "train_train_wall": "2254", "train_gb_free": "71.9", "train_wall": "137173"}
[2024-07-05 05:04:49,267][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 05:04:49,687][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 05:04:49,693][fairseq.trainer][INFO] - begin training epoch 61
[2024-07-05 05:04:49,693][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 05:05:11,348][train_inner][INFO] - {"epoch": 61, "update": 60.01, "loss": "68.577", "ntokens": "14733.4", "nsentences": "80", "nll_loss": "0.372", "wps": "7576.4", "ups": "0.51", "wpb": "14733.4", "bsz": "80", "num_updates": "77800", "lr": "1.76867e-06", "gnorm": "104.71", "loss_scale": "8", "train_wall": "345", "gb_free": "69.8", "wall": "137195"}
[2024-07-05 05:10:59,099][train_inner][INFO] - {"epoch": 61, "update": 60.164, "loss": "70.332", "ntokens": "14798.6", "nsentences": "78.44", "nll_loss": "0.373", "wps": "8511.4", "ups": "0.58", "wpb": "14798.6", "bsz": "78.4", "num_updates": "78000", "lr": "1.74238e-06", "gnorm": "107.095", "loss_scale": "8", "train_wall": "347", "gb_free": "71.5", "wall": "137542"}
[2024-07-05 05:16:41,438][train_inner][INFO] - {"epoch": 61, "update": 60.318, "loss": "69.314", "ntokens": "14781", "nsentences": "79.52", "nll_loss": "0.373", "wps": "8637.3", "ups": "0.58", "wpb": "14781", "bsz": "79.5", "num_updates": "78200", "lr": "1.71648e-06", "gnorm": "108.014", "loss_scale": "8", "train_wall": "342", "gb_free": "72.4", "wall": "137885"}
[2024-07-05 05:22:24,418][train_inner][INFO] - {"epoch": 61, "update": 60.473, "loss": "68.646", "ntokens": "14873.1", "nsentences": "80.56", "nll_loss": "0.372", "wps": "8674.7", "ups": "0.58", "wpb": "14873.1", "bsz": "80.6", "num_updates": "78400", "lr": "1.69096e-06", "gnorm": "106.581", "loss_scale": "8", "train_wall": "342", "gb_free": "71", "wall": "138228"}
[2024-07-05 05:28:07,740][train_inner][INFO] - {"epoch": 61, "update": 60.627, "loss": "66.843", "ntokens": "14849.5", "nsentences": "81.44", "nll_loss": "0.367", "wps": "8652.4", "ups": "0.58", "wpb": "14849.5", "bsz": "81.4", "num_updates": "78600", "lr": "1.66582e-06", "gnorm": "104.583", "loss_scale": "8", "train_wall": "343", "gb_free": "73.1", "wall": "138571"}
[2024-07-05 05:33:55,012][train_inner][INFO] - {"epoch": 61, "update": 60.781, "loss": "68.806", "ntokens": "14826.6", "nsentences": "80.2", "nll_loss": "0.372", "wps": "8541.1", "ups": "0.58", "wpb": "14826.6", "bsz": "80.2", "num_updates": "78800", "lr": "1.64105e-06", "gnorm": "105", "loss_scale": "8", "train_wall": "347", "gb_free": "71.4", "wall": "138918"}
[2024-07-05 05:39:42,799][train_inner][INFO] - {"epoch": 61, "update": 60.935, "loss": "69.57", "ntokens": "14791.4", "nsentences": "79.11", "nll_loss": "0.372", "wps": "8507.8", "ups": "0.58", "wpb": "14791.4", "bsz": "79.1", "num_updates": "79000", "lr": "1.61665e-06", "gnorm": "107.269", "loss_scale": "8", "train_wall": "347", "gb_free": "71.8", "wall": "139266"}
[2024-07-05 05:42:04,901][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 05:42:04,906][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 05:42:44,399][dev-other][INFO] - {"epoch": 61, "dev-other_loss": "23.585", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.251", "dev-other_uer": "3.704", "dev-other_wer": "9.545", "dev-other_raw_wer": "9.545", "dev-other_wps": "6962.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "79084", "dev-other_best_wer": "9.527"}
[2024-07-05 05:42:44,400][fairseq_cli.train][INFO] - end of epoch 61 (average epoch stats below)
[2024-07-05 05:42:44,404][train][INFO] - {"epoch": 61, "train_loss": "69.216", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.374", "train_wps": "8450.2", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "79084", "train_lr": "1.60652e-06", "train_gnorm": "106.485", "train_loss_scale": "8", "train_train_wall": "2231", "train_gb_free": "71.7", "train_wall": "139448"}
[2024-07-05 05:42:44,406][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 05:42:45,371][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 05:42:45,390][fairseq.trainer][INFO] - begin training epoch 62
[2024-07-05 05:42:45,391][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 05:46:05,069][train_inner][INFO] - {"epoch": 62, "update": 61.089, "loss": "72.385", "ntokens": "14813.3", "nsentences": "80.32", "nll_loss": "0.392", "wps": "7750.4", "ups": "0.52", "wpb": "14813.3", "bsz": "80.3", "num_updates": "79200", "lr": "1.59262e-06", "gnorm": "108.845", "loss_scale": "8", "train_wall": "341", "gb_free": "72.8", "wall": "139648"}
[2024-07-05 05:51:50,160][train_inner][INFO] - {"epoch": 62, "update": 61.244, "loss": "68.393", "ntokens": "14854.6", "nsentences": "80.92", "nll_loss": "0.373", "wps": "8609.7", "ups": "0.58", "wpb": "14854.6", "bsz": "80.9", "num_updates": "79400", "lr": "1.56894e-06", "gnorm": "107.114", "loss_scale": "16", "train_wall": "344", "gb_free": "71.4", "wall": "139993"}
[2024-07-05 05:57:31,650][train_inner][INFO] - {"epoch": 62, "update": 61.398, "loss": "72.432", "ntokens": "14852.5", "nsentences": "80.16", "nll_loss": "0.391", "wps": "8698.9", "ups": "0.59", "wpb": "14852.5", "bsz": "80.2", "num_updates": "79600", "lr": "1.54562e-06", "gnorm": "108.139", "loss_scale": "16", "train_wall": "341", "gb_free": "71.1", "wall": "140335"}
[2024-07-05 06:03:18,271][train_inner][INFO] - {"epoch": 62, "update": 61.552, "loss": "69.655", "ntokens": "14775.5", "nsentences": "79.32", "nll_loss": "0.374", "wps": "8525.7", "ups": "0.58", "wpb": "14775.5", "bsz": "79.3", "num_updates": "79800", "lr": "1.52264e-06", "gnorm": "106.677", "loss_scale": "16", "train_wall": "346", "gb_free": "72.2", "wall": "140682"}
[2024-07-05 06:09:04,414][train_inner][INFO] - {"epoch": 62, "update": 61.706, "loss": "66.834", "ntokens": "14830.9", "nsentences": "81.32", "nll_loss": "0.366", "wps": "8569.5", "ups": "0.58", "wpb": "14830.9", "bsz": "81.3", "num_updates": "80000", "lr": "1.5e-06", "gnorm": "106.285", "loss_scale": "16", "train_wall": "346", "gb_free": "71.9", "wall": "141028"}
[2024-07-05 06:09:04,417][fairseq_cli.train][INFO] - Stopping training due to num_updates: 80000 >= max_update: 80000
[2024-07-05 06:09:04,417][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 06:09:04,418][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 06:09:44,031][dev-other][INFO] - {"epoch": 62, "dev-other_loss": "23.869", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.254", "dev-other_uer": "3.739", "dev-other_wer": "9.606", "dev-other_raw_wer": "9.606", "dev-other_wps": "6963.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "80000", "dev-other_best_wer": "9.527"}
[2024-07-05 06:09:44,034][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 62 @ 80000 updates
[2024-07-05 06:09:44,036][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_last.pt
[2024-07-05 06:09:45,156][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_last.pt
[2024-07-05 06:09:45,167][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune/checkpoint_last.pt (epoch 62 @ 80000 updates, score 9.606) (writing took 1.132440222427249 seconds)
[2024-07-05 06:09:45,171][fairseq_cli.train][INFO] - end of epoch 62 (average epoch stats below)
[2024-07-05 06:09:45,347][train][INFO] - {"epoch": 62, "train_loss": "69.453", "train_ntokens": "14821.3", "train_nsentences": "80.1921", "train_nll_loss": "0.376", "train_wps": "8376.5", "train_ups": "0.57", "train_wpb": "14821.3", "train_bsz": "80.2", "train_num_updates": "80000", "train_lr": "1.5e-06", "train_gnorm": "107.263", "train_loss_scale": "16", "train_train_wall": "1576", "train_gb_free": "71.9", "train_wall": "141069"}
[2024-07-05 06:09:45,347][fairseq_cli.train][INFO] - done training in 141027.5 seconds
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
fine tune base t-hubert model  using train-other-500 supervision data
[2024-07-05 06:10:03,015][fairseq.distributed.utils][INFO] - Rank 0, device_id: 0
2024-07-05 06:10:09 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:23948
2024-07-05 06:10:09 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:23948
2024-07-05 06:10:09 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:23948
2024-07-05 06:10:09 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2024-07-05 06:10:09 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:23948
2024-07-05 06:10:09 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2024-07-05 06:10:10 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2024-07-05 06:10:10 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2024-07-05 06:10:10 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-07-05 06:10:10 | INFO | fairseq.distributed.utils | initialized host pgpu18 as rank 0
2024-07-05 06:10:10 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-07-05 06:10:10 | INFO | fairseq.distributed.utils | initialized host pgpu18 as rank 3
2024-07-05 06:10:10 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-07-05 06:10:10 | INFO | fairseq.distributed.utils | initialized host pgpu18 as rank 1
2024-07-05 06:10:10 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-07-05 06:10:10 | INFO | fairseq.distributed.utils | initialized host pgpu18 as rank 2
[2024-07-05 06:10:13,321][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/mntcephfs/lab_data/maduo/exp//finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/t-hubert', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:23948', 'distributed_port': 23948, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3200000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train-other-500', 'valid_subset': 'dev-other', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3200000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 80000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [2], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/mntcephfs/lab_data/maduo/exp//finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'wer', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'hubert_ctc', 'w2v_path': '/mntcephfs/lab_data/maduo/exp//pretrain/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update/checkpoint_298_400000.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.1, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_embed_dim': 768, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 0, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'normalize': False, 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'w2v_args': None, 'autoregressive': False}, 'task': {'_name': 'hubert_pretraining', 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'fine_tuning': True, 'labels': ['ltr'], 'label_dir': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'label_rate': -1.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': None, 'min_sample_size': None, 'single_target': True, 'random_crop': True, 'pad_audio': False}, 'criterion': {'_name': 'ctc', 'zero_infinity': True, 'sentence_avg': True, 'post_process': 'letter', 'wer_kenlm_model': None, 'wer_lexicon': None, 'wer_lm_weight': 2.0, 'wer_word_score': -1.0, 'wer_sil_weight': 0.0, 'wer_args': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05], 'amsgrad': False}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 8000, 'hold_steps': 32000, 'decay_steps': 40000, 'phase_ratio': None, 'init_lr_scale': 0.01, 'final_lr_scale': 0.05, 'max_update': 80000.0, 'lr': [3e-05]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': '/mntcephfs/lab_data/maduo/exp//pretrain/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update/finetune.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-07-05 06:10:13,326][fairseq.tasks.hubert_pretraining][INFO] - current directory is /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/t-hubert
[2024-07-05 06:10:13,326][fairseq.tasks.hubert_pretraining][INFO] - HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'fine_tuning': True, 'labels': ['ltr'], 'label_dir': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'label_rate': -1.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': None, 'min_sample_size': None, 'single_target': True, 'random_crop': True, 'pad_audio': False}
[2024-07-05 06:10:13,332][fairseq.models.hubert.hubert_asr][INFO] - cfg: {'_name': 'hubert_ctc', 'w2v_path': '/mntcephfs/lab_data/maduo/exp//pretrain/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update/checkpoint_298_400000.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.1, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_embed_dim': 768, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 0, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'normalize': False, 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'w2v_args': None, 'autoregressive': False}, task: <fairseq.tasks.hubert_pretraining.HubertPretrainingTask object at 0x155407561700>
[2024-07-05 06:10:13,333][fairseq.models.hubert.hubert_asr][INFO] - mdddd:::/mntcephfs/lab_data/maduo/exp//pretrain/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update/checkpoint_298_400000.pt
[2024-07-05 06:10:16,743][fairseq.tasks.hubert_pretraining][INFO] - current directory is /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/t-hubert
[2024-07-05 06:10:16,743][fairseq.tasks.hubert_pretraining][INFO] - HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'fine_tuning': False, 'labels': ['phncode', 'km'], 'label_dir': '/mntcephfs/lab_data/maduo/datasets/format/librispeech//offical_hubert_codes_and_librispeech_frame_monophncode_using_wav2vec-u2_model', 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
[2024-07-05 06:10:16,752][fairseq.models.hubert.hubert2][INFO] - HubertModel2 Config: {'_name': 'ils_hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'attention_type': 'rel_attention', 'weighted_sum': False, 'predict_layers': '[7,12]', 'separate_label_embeds': True, 'separate_layer_targets': False, 'km4_bpekm7_km12': False, 'bpekm7_km12': False, 'phnkm6_km12': False, 'phnkm7_km12': True, 'km4_phnkm6_km12': False, 'km4_phnkm7_km12': False}
[2024-07-05 06:10:17,286][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-05 06:10:17,373][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-05 06:10:17,460][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-05 06:10:17,559][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-05 06:10:17,646][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-05 06:10:17,734][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-05 06:10:17,822][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-05 06:10:17,909][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-05 06:10:17,997][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-05 06:10:18,084][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-05 06:10:18,172][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-05 06:10:18,259][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-05 06:10:19,266][fairseq.models.hubert.ils_hubert][INFO] - HubertModel Config: {'_name': 'ils_hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'attention_type': 'rel_attention', 'weighted_sum': False, 'predict_layers': '[7,12]', 'separate_label_embeds': True, 'separate_layer_targets': False, 'km4_bpekm7_km12': False, 'bpekm7_km12': False, 'phnkm6_km12': False, 'phnkm7_km12': True, 'km4_phnkm6_km12': False, 'km4_phnkm7_km12': False}
[2024-07-05 06:10:22,864][fairseq_cli.train][INFO] - HubertCtc(
  (w2v_encoder): HubertEncoder(
    (w2v_model): ILSHubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention2(
              (dropout_module): FairseqDropout()
              (relative_attention_bias): Embedding(320, 12)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1-11): 11 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention2(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (proj): Linear(in_features=768, out_features=32, bias=True)
  )
)
[2024-07-05 06:10:22,866][fairseq_cli.train][INFO] - task: HubertPretrainingTask
[2024-07-05 06:10:22,866][fairseq_cli.train][INFO] - model: HubertCtc
[2024-07-05 06:10:22,867][fairseq_cli.train][INFO] - criterion: CtcCriterion
[2024-07-05 06:10:22,868][fairseq_cli.train][INFO] - num. shared model params: 94,400,160 (num. trained: 94,400,160)
[2024-07-05 06:10:22,868][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-07-05 06:10:22,872][fairseq.data.audio.hubert_dataset][INFO] - max_keep=None, min_keep=None, loaded 2864, skipped 0 short and 0 long, longest-loaded=562480, shortest-loaded=17040
[2024-07-05 06:10:22,874][fairseq.data.audio.hubert_dataset][INFO] - /mntcephfs/lab_data/maduo/datasets/format/librispeech//dev-other.ltr is sequence label. skipped
[2024-07-05 06:10:22,874][fairseq.data.audio.hubert_dataset][INFO] - pad_audio=False, random_crop=True, normalize=False, max_sample_size=9223372036854775807
[2024-07-05 06:10:25,199][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:2 to store for rank: 0
[2024-07-05 06:10:25,250][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
[2024-07-05 06:10:25,251][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
[2024-07-05 06:10:25,252][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
[2024-07-05 06:10:25,252][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
[2024-07-05 06:10:25,252][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
[2024-07-05 06:10:25,252][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
[2024-07-05 06:10:25,252][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
[2024-07-05 06:10:25,252][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
[2024-07-05 06:10:25,889][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2024-07-05 06:10:25,889][fairseq.utils][INFO] - rank   0: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A100-SXM4-80GB                   
[2024-07-05 06:10:25,889][fairseq.utils][INFO] - rank   1: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A100-SXM4-80GB                   
[2024-07-05 06:10:25,889][fairseq.utils][INFO] - rank   2: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A100-SXM4-80GB                   
[2024-07-05 06:10:25,889][fairseq.utils][INFO] - rank   3: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A100-SXM4-80GB                   
[2024-07-05 06:10:25,889][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2024-07-05 06:10:25,889][fairseq_cli.train][INFO] - training on 4 devices (GPUs/TPUs)
[2024-07-05 06:10:25,889][fairseq_cli.train][INFO] - max tokens per device = 3200000 and max sentences per device = None
[2024-07-05 06:10:25,890][fairseq.trainer][INFO] - Preparing to load checkpoint /mntcephfs/lab_data/maduo/exp//finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune/checkpoint_last.pt
[2024-07-05 06:10:25,890][fairseq.trainer][INFO] - No existing checkpoint found /mntcephfs/lab_data/maduo/exp//finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune/checkpoint_last.pt
[2024-07-05 06:10:25,890][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-07-05 06:10:25,992][fairseq.data.audio.hubert_dataset][INFO] - max_keep=None, min_keep=None, loaded 148688, skipped 0 short and 0 long, longest-loaded=446720, shortest-loaded=13280
[2024-07-05 06:10:26,168][fairseq.data.audio.hubert_dataset][INFO] - /mntcephfs/lab_data/maduo/datasets/format/librispeech//train-other-500.ltr is sequence label. skipped
[2024-07-05 06:10:26,168][fairseq.data.audio.hubert_dataset][INFO] - pad_audio=False, random_crop=True, normalize=False, max_sample_size=9223372036854775807
[2024-07-05 06:10:26,234][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 06:10:26,235][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2024-07-05 06:10:26,235][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = False
[2024-07-05 06:10:26,235][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2024-07-05 06:10:27,613][fairseq_cli.train][INFO] - begin dry-run validation on "dev-other" subset
[2024-07-05 06:10:27,615][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 06:10:27,616][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2024-07-05 06:10:27,616][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = False
[2024-07-05 06:10:27,616][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2024-07-05 06:11:06,425][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-05 06:11:06,431][fairseq.trainer][INFO] - begin training epoch 1
[2024-07-05 06:11:06,432][fairseq_cli.train][INFO] - Start iterating over samples
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
[2024-07-05 06:11:45,812][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2024-07-05 06:11:47,847][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2024-07-05 06:11:49,161][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-05 06:12:08,762][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-05 06:15:11,190][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-07-05 06:17:54,907][train_inner][INFO] - {"epoch": 1, "update": 0.117, "loss": "2114.76", "ntokens": "14500.3", "nsentences": "81.96", "nll_loss": "11.953", "wps": "7946.5", "ups": "0.55", "wpb": "14500.3", "bsz": "82", "num_updates": "200", "lr": "1.0425e-06", "gnorm": "1441.38", "loss_scale": "4", "train_wall": "372", "gb_free": "72.5", "wall": "449"}
[2024-07-05 06:18:46,571][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-07-05 06:23:47,243][train_inner][INFO] - {"epoch": 1, "update": 0.232, "loss": "1114.12", "ntokens": "14572.8", "nsentences": "85.28", "nll_loss": "6.52", "wps": "8274.9", "ups": "0.57", "wpb": "14572.8", "bsz": "85.3", "num_updates": "400", "lr": "1.785e-06", "gnorm": "1704.64", "loss_scale": "2", "train_wall": "352", "gb_free": "72.3", "wall": "801"}
[2024-07-05 06:29:38,766][train_inner][INFO] - {"epoch": 1, "update": 0.346, "loss": "784.019", "ntokens": "14587.4", "nsentences": "83.96", "nll_loss": "4.513", "wps": "8301.4", "ups": "0.57", "wpb": "14587.4", "bsz": "84", "num_updates": "600", "lr": "2.5275e-06", "gnorm": "562.171", "loss_scale": "2", "train_wall": "351", "gb_free": "71", "wall": "1153"}
[2024-07-05 06:35:27,553][train_inner][INFO] - {"epoch": 1, "update": 0.46, "loss": "716.216", "ntokens": "14451.4", "nsentences": "85.16", "nll_loss": "4.221", "wps": "8289", "ups": "0.57", "wpb": "14451.4", "bsz": "85.2", "num_updates": "800", "lr": "3.27e-06", "gnorm": "239.876", "loss_scale": "2", "train_wall": "348", "gb_free": "71.7", "wall": "1502"}
[2024-07-05 06:41:12,874][train_inner][INFO] - {"epoch": 1, "update": 0.574, "loss": "717.57", "ntokens": "14630.2", "nsentences": "84.995", "nll_loss": "4.169", "wps": "8475.5", "ups": "0.58", "wpb": "14630.2", "bsz": "85", "num_updates": "1000", "lr": "4.0125e-06", "gnorm": "187.266", "loss_scale": "2", "train_wall": "345", "gb_free": "71.1", "wall": "1847"}
[2024-07-05 06:47:06,004][train_inner][INFO] - {"epoch": 1, "update": 0.688, "loss": "707.969", "ntokens": "14641.4", "nsentences": "86.04", "nll_loss": "4.16", "wps": "8292.7", "ups": "0.57", "wpb": "14641.4", "bsz": "86", "num_updates": "1200", "lr": "4.755e-06", "gnorm": "182.933", "loss_scale": "2", "train_wall": "352", "gb_free": "69.8", "wall": "2200"}
[2024-07-05 06:52:47,126][train_inner][INFO] - {"epoch": 1, "update": 0.803, "loss": "700.188", "ntokens": "14638.5", "nsentences": "86.24", "nll_loss": "4.125", "wps": "8584.5", "ups": "0.59", "wpb": "14638.5", "bsz": "86.2", "num_updates": "1400", "lr": "5.4975e-06", "gnorm": "153.42", "loss_scale": "2", "train_wall": "340", "gb_free": "71", "wall": "2541"}
[2024-07-05 06:58:36,196][train_inner][INFO] - {"epoch": 1, "update": 0.917, "loss": "707.438", "ntokens": "14559.6", "nsentences": "85.08", "nll_loss": "4.134", "wps": "8343.7", "ups": "0.57", "wpb": "14559.6", "bsz": "85.1", "num_updates": "1600", "lr": "6.24e-06", "gnorm": "161.902", "loss_scale": "2", "train_wall": "348", "gb_free": "71.2", "wall": "2890"}
[2024-07-05 07:02:47,523][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 07:02:47,532][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 07:03:27,233][dev-other][INFO] - {"epoch": 1, "dev-other_loss": "390.099", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "4.147", "dev-other_uer": "100", "dev-other_wer": "100", "dev-other_raw_wer": "100", "dev-other_wps": "6937.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "1746"}
[2024-07-05 07:03:27,234][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2024-07-05 07:03:27,261][train][INFO] - {"epoch": 1, "train_loss": "920.277", "train_ntokens": "14575.9", "train_nsentences": "84.8242", "train_nll_loss": "5.356", "train_wps": "8216.8", "train_ups": "0.56", "train_wpb": "14575.9", "train_bsz": "84.8", "train_num_updates": "1746", "train_lr": "6.78202e-06", "train_gnorm": "541.825", "train_loss_scale": "2", "train_train_wall": "3059", "train_gb_free": "72.4", "train_wall": "3181"}
[2024-07-05 07:03:27,264][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 07:03:28,247][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-05 07:03:28,250][fairseq.trainer][INFO] - begin training epoch 2
[2024-07-05 07:03:28,250][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 07:05:04,667][train_inner][INFO] - {"epoch": 2, "update": 1.031, "loss": "712.442", "ntokens": "14603.5", "nsentences": "84.36", "nll_loss": "4.116", "wps": "7518.7", "ups": "0.51", "wpb": "14603.5", "bsz": "84.4", "num_updates": "1800", "lr": "6.9825e-06", "gnorm": "140.718", "loss_scale": "2", "train_wall": "347", "gb_free": "71.7", "wall": "3279"}
[2024-07-05 07:10:50,393][train_inner][INFO] - {"epoch": 2, "update": 1.145, "loss": "695.063", "ntokens": "14613.4", "nsentences": "85.96", "nll_loss": "4.089", "wps": "8455.6", "ups": "0.58", "wpb": "14613.4", "bsz": "86", "num_updates": "2000", "lr": "7.725e-06", "gnorm": "189.448", "loss_scale": "2", "train_wall": "345", "gb_free": "72.8", "wall": "3624"}
[2024-07-05 07:16:37,573][train_inner][INFO] - {"epoch": 2, "update": 1.259, "loss": "665.958", "ntokens": "14514.7", "nsentences": "83.36", "nll_loss": "3.825", "wps": "8363.2", "ups": "0.58", "wpb": "14514.7", "bsz": "83.4", "num_updates": "2200", "lr": "8.4675e-06", "gnorm": "217.952", "loss_scale": "2", "train_wall": "346", "gb_free": "71.5", "wall": "3972"}
[2024-07-05 07:22:30,231][train_inner][INFO] - {"epoch": 2, "update": 1.373, "loss": "553.237", "ntokens": "14604.7", "nsentences": "85.76", "nll_loss": "3.249", "wps": "8284.6", "ups": "0.57", "wpb": "14604.7", "bsz": "85.8", "num_updates": "2400", "lr": "9.21e-06", "gnorm": "236.8", "loss_scale": "4", "train_wall": "352", "gb_free": "72.1", "wall": "4324"}
[2024-07-05 07:28:12,416][train_inner][INFO] - {"epoch": 2, "update": 1.487, "loss": "462.648", "ntokens": "14632.7", "nsentences": "85.68", "nll_loss": "2.709", "wps": "8552.8", "ups": "0.58", "wpb": "14632.7", "bsz": "85.7", "num_updates": "2600", "lr": "9.9525e-06", "gnorm": "204.736", "loss_scale": "4", "train_wall": "342", "gb_free": "70.3", "wall": "4667"}
[2024-07-05 07:34:01,548][train_inner][INFO] - {"epoch": 2, "update": 1.602, "loss": "386.632", "ntokens": "14464", "nsentences": "82.12", "nll_loss": "2.195", "wps": "8287.4", "ups": "0.57", "wpb": "14464", "bsz": "82.1", "num_updates": "2800", "lr": "1.0695e-05", "gnorm": "181.649", "loss_scale": "4", "train_wall": "348", "gb_free": "70.5", "wall": "5016"}
[2024-07-05 07:39:44,678][train_inner][INFO] - {"epoch": 2, "update": 1.716, "loss": "316.174", "ntokens": "14597.6", "nsentences": "86.12", "nll_loss": "1.865", "wps": "8509.4", "ups": "0.58", "wpb": "14597.6", "bsz": "86.1", "num_updates": "3000", "lr": "1.14375e-05", "gnorm": "164.061", "loss_scale": "4", "train_wall": "342", "gb_free": "71.3", "wall": "5359"}
[2024-07-05 07:45:25,094][train_inner][INFO] - {"epoch": 2, "update": 1.83, "loss": "283.814", "ntokens": "14655.6", "nsentences": "85.36", "nll_loss": "1.653", "wps": "8611.8", "ups": "0.59", "wpb": "14655.6", "bsz": "85.4", "num_updates": "3200", "lr": "1.218e-05", "gnorm": "160.322", "loss_scale": "4", "train_wall": "340", "gb_free": "70.6", "wall": "5699"}
[2024-07-05 07:51:10,306][train_inner][INFO] - {"epoch": 2, "update": 1.944, "loss": "258.559", "ntokens": "14617.5", "nsentences": "86.155", "nll_loss": "1.524", "wps": "8470.6", "ups": "0.58", "wpb": "14617.5", "bsz": "86.2", "num_updates": "3400", "lr": "1.29225e-05", "gnorm": "169.699", "loss_scale": "4", "train_wall": "345", "gb_free": "72.3", "wall": "6044"}
[2024-07-05 07:53:57,188][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 07:53:57,263][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 07:54:37,037][dev-other][INFO] - {"epoch": 2, "dev-other_loss": "62.479", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.664", "dev-other_uer": "12.415", "dev-other_wer": "39.677", "dev-other_raw_wer": "39.677", "dev-other_wps": "6916.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "3498"}
[2024-07-05 07:54:37,038][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2024-07-05 07:54:37,043][train][INFO] - {"epoch": 2, "train_loss": "448.981", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "2.614", "train_wps": "8319.8", "train_ups": "0.57", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "3498", "train_lr": "1.32863e-05", "train_gnorm": "187.56", "train_loss_scale": "4", "train_train_wall": "3023", "train_gb_free": "72.3", "train_wall": "6251"}
[2024-07-05 07:54:37,045][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 07:54:38,060][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-05 07:54:38,070][fairseq.trainer][INFO] - begin training epoch 3
[2024-07-05 07:54:38,071][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 07:57:36,257][train_inner][INFO] - {"epoch": 3, "update": 2.058, "loss": "233.878", "ntokens": "14446.3", "nsentences": "83.12", "nll_loss": "1.346", "wps": "7486.3", "ups": "0.52", "wpb": "14446.3", "bsz": "83.1", "num_updates": "3600", "lr": "1.3665e-05", "gnorm": "151.6", "loss_scale": "4", "train_wall": "344", "gb_free": "72.1", "wall": "6430"}
[2024-07-05 08:03:23,622][train_inner][INFO] - {"epoch": 3, "update": 2.172, "loss": "219.522", "ntokens": "14487.2", "nsentences": "83.555", "nll_loss": "1.266", "wps": "8343.2", "ups": "0.58", "wpb": "14487.2", "bsz": "83.6", "num_updates": "3800", "lr": "1.44075e-05", "gnorm": "146.744", "loss_scale": "4", "train_wall": "347", "gb_free": "71.2", "wall": "6778"}
[2024-07-05 08:09:06,639][train_inner][INFO] - {"epoch": 3, "update": 2.287, "loss": "204.014", "ntokens": "14601.4", "nsentences": "84.76", "nll_loss": "1.184", "wps": "8515.5", "ups": "0.58", "wpb": "14601.4", "bsz": "84.8", "num_updates": "4000", "lr": "1.515e-05", "gnorm": "142.918", "loss_scale": "4", "train_wall": "342", "gb_free": "73.2", "wall": "7121"}
[2024-07-05 08:14:54,299][train_inner][INFO] - {"epoch": 3, "update": 2.401, "loss": "196.486", "ntokens": "14583", "nsentences": "82.72", "nll_loss": "1.115", "wps": "8391", "ups": "0.58", "wpb": "14583", "bsz": "82.7", "num_updates": "4200", "lr": "1.58925e-05", "gnorm": "146.066", "loss_scale": "4", "train_wall": "347", "gb_free": "72.4", "wall": "7468"}
[2024-07-05 08:20:36,146][train_inner][INFO] - {"epoch": 3, "update": 2.515, "loss": "171.016", "ntokens": "14769.3", "nsentences": "90.96", "nll_loss": "1.053", "wps": "8642.7", "ups": "0.59", "wpb": "14769.3", "bsz": "91", "num_updates": "4400", "lr": "1.6635e-05", "gnorm": "139.284", "loss_scale": "8", "train_wall": "341", "gb_free": "72.7", "wall": "7810"}
[2024-07-05 08:26:20,251][train_inner][INFO] - {"epoch": 3, "update": 2.629, "loss": "174.983", "ntokens": "14663.8", "nsentences": "87.28", "nll_loss": "1.042", "wps": "8523.2", "ups": "0.58", "wpb": "14663.8", "bsz": "87.3", "num_updates": "4600", "lr": "1.73775e-05", "gnorm": "144.331", "loss_scale": "8", "train_wall": "344", "gb_free": "69.8", "wall": "8154"}
[2024-07-05 08:32:06,275][train_inner][INFO] - {"epoch": 3, "update": 2.743, "loss": "165.844", "ntokens": "14571.4", "nsentences": "84.24", "nll_loss": "0.959", "wps": "8423.9", "ups": "0.58", "wpb": "14571.4", "bsz": "84.2", "num_updates": "4800", "lr": "1.812e-05", "gnorm": "136.531", "loss_scale": "8", "train_wall": "345", "gb_free": "71.8", "wall": "8500"}
[2024-07-05 08:37:47,793][train_inner][INFO] - {"epoch": 3, "update": 2.857, "loss": "174.629", "ntokens": "14453.2", "nsentences": "83", "nll_loss": "1.003", "wps": "8465.6", "ups": "0.59", "wpb": "14453.2", "bsz": "83", "num_updates": "5000", "lr": "1.88625e-05", "gnorm": "144.947", "loss_scale": "8", "train_wall": "341", "gb_free": "72.5", "wall": "8842"}
[2024-07-05 08:43:35,520][train_inner][INFO] - {"epoch": 3, "update": 2.971, "loss": "155.483", "ntokens": "14591.2", "nsentences": "83.64", "nll_loss": "0.891", "wps": "8394", "ups": "0.58", "wpb": "14591.2", "bsz": "83.6", "num_updates": "5200", "lr": "1.9605e-05", "gnorm": "136.227", "loss_scale": "8", "train_wall": "347", "gb_free": "72.4", "wall": "9190"}
[2024-07-05 08:45:02,052][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 08:45:02,113][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 08:45:41,240][dev-other][INFO] - {"epoch": 3, "dev-other_loss": "34.729", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.369", "dev-other_uer": "6.507", "dev-other_wer": "20.356", "dev-other_raw_wer": "20.356", "dev-other_wps": "7030", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "5250"}
[2024-07-05 08:45:41,241][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)
[2024-07-05 08:45:41,244][train][INFO] - {"epoch": 3, "train_loss": "184.214", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "1.072", "train_wps": "8334.9", "train_ups": "0.57", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "5250", "train_lr": "1.97906e-05", "train_gnorm": "142.524", "train_loss_scale": "8", "train_train_wall": "3018", "train_gb_free": "72.4", "train_wall": "9315"}
[2024-07-05 08:45:41,247][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 08:45:42,257][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-05 08:45:42,272][fairseq.trainer][INFO] - begin training epoch 4
[2024-07-05 08:45:42,272][fairseq_cli.train][INFO] - Start iterating over samples
slurmstepd: error: *** JOB 167438 ON pgpu18 CANCELLED AT 2024-07-05T08:48:57 ***
