Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple
Requirement already satisfied: ninja in /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages (1.11.1)
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/setuptools/dist.py:490: UserWarning: Normalizing 'V1.0.0' to '1.0.0'
  warnings.warn(tmpl.format(**locals()))
running build_ext
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/utils/cpp_extension.py:398: UserWarning: There are no /cm/local/apps/gcc/11.2.0/bin/g++ version bounds defined for CUDA version 11.8
  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')
cythoning fairseq/data/data_utils_fast.pyx to fairseq/data/data_utils_fast.cpp
cythoning fairseq/data/token_block_utils_fast.pyx to fairseq/data/token_block_utils_fast.cpp
building 'fairseq.libbleu' extension
Emitting ninja build file /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
/cm/local/apps/gcc/11.2.0/bin/g++ -pthread -B /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/compiler_compat -shared -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/libbleu/libbleu.o /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/libbleu/module.o -o build/lib.linux-x86_64-3.9/fairseq/libbleu.cpython-39-x86_64-linux-gnu.so
building 'fairseq.data.data_utils_fast' extension
Emitting ninja build file /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/1] /cm/local/apps/gcc/11.2.0/bin/g++ -MMD -MF /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/data/data_utils_fast.o.d -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -fPIC -O2 -isystem /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: -fPIC -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/numpy/core/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/numpy/core/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include/python3.9 -c -c /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/data/data_utils_fast.cpp -o /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/data/data_utils_fast.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=data_utils_fast -D_GLIBCXX_USE_CXX11_ABI=0
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h:1948,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h:12,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h:5,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/data/data_utils_fast.cpp:760:
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: warning: #warning "Using deprecated NumPy API, disable it with " "#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION" [-Wcpp]
   17 | #warning "Using deprecated NumPy API, disable it with " \
      |  ^~~~~~~
/cm/local/apps/gcc/11.2.0/bin/g++ -pthread -B /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/compiler_compat -shared -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/data/data_utils_fast.o -o build/lib.linux-x86_64-3.9/fairseq/data/data_utils_fast.cpython-39-x86_64-linux-gnu.so
building 'fairseq.data.token_block_utils_fast' extension
Emitting ninja build file /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/1] /cm/local/apps/gcc/11.2.0/bin/g++ -MMD -MF /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/data/token_block_utils_fast.o.d -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -fPIC -O2 -isystem /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: -fPIC -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/numpy/core/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/numpy/core/include -I/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/include/python3.9 -c -c /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/data/token_block_utils_fast.cpp -o /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/data/token_block_utils_fast.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=token_block_utils_fast -D_GLIBCXX_USE_CXX11_ABI=0
In file included from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h:1948,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h:12,
                 from /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h:5,
                 from /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/data/token_block_utils_fast.cpp:761:
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: warning: #warning "Using deprecated NumPy API, disable it with " "#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION" [-Wcpp]
   17 | #warning "Using deprecated NumPy API, disable it with " \
      |  ^~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/data/token_block_utils_fast.cpp: In function ‘PyArrayObject* __pyx_f_7fairseq_4data_22token_block_utils_fast__get_slice_indices_fast(PyArrayObject*, PyObject*, int, int, int)’:
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/data/token_block_utils_fast.cpp:3469:36: warning: comparison of integer expressions of different signedness: ‘__pyx_t_7fairseq_4data_22token_block_utils_fast_DTYPE_t’ {aka ‘long int’} and ‘size_t’ {aka ‘long unsigned int’} [-Wsign-compare]
 3469 |       __pyx_t_4 = ((__pyx_v_sz_idx < __pyx_t_10) != 0);
      |                     ~~~~~~~~~~~~~~~^~~~~~~~~~~~
/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/fairseq/data/token_block_utils_fast.cpp:3664:36: warning: comparison of integer expressions of different signedness: ‘__pyx_t_7fairseq_4data_22token_block_utils_fast_DTYPE_t’ {aka ‘long int’} and ‘size_t’ {aka ‘long unsigned int’} [-Wsign-compare]
 3664 |       __pyx_t_3 = ((__pyx_v_sz_idx < __pyx_t_10) != 0);
      |                     ~~~~~~~~~~~~~~~^~~~~~~~~~~~
/cm/local/apps/gcc/11.2.0/bin/g++ -pthread -B /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/compiler_compat -shared -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/data/token_block_utils_fast.o -o build/lib.linux-x86_64-3.9/fairseq/data/token_block_utils_fast.cpython-39-x86_64-linux-gnu.so
building 'fairseq.libbase' extension
Emitting ninja build file /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
/cm/local/apps/gcc/11.2.0/bin/g++ -pthread -B /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/compiler_compat -shared -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/libbase/balanced_assignment.o -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.9/fairseq/libbase.cpython-39-x86_64-linux-gnu.so
building 'fairseq.libnat' extension
Emitting ninja build file /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
/cm/local/apps/gcc/11.2.0/bin/g++ -pthread -B /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/compiler_compat -shared -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/libnat/edit_dist.o -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.9/fairseq/libnat.cpython-39-x86_64-linux-gnu.so
building 'alignment_train_cpu_binding' extension
Emitting ninja build file /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
/cm/local/apps/gcc/11.2.0/bin/g++ -pthread -B /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/compiler_compat -shared -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/examples/operators/alignment_train_cpu.o -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.9/alignment_train_cpu_binding.cpython-39-x86_64-linux-gnu.so
building 'fairseq.libnat_cuda' extension
Emitting ninja build file /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
/cm/local/apps/gcc/11.2.0/bin/g++ -pthread -B /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/compiler_compat -shared -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/libnat_cuda/binding.o /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/libnat_cuda/edit_dist.o -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.9/fairseq/libnat_cuda.cpython-39-x86_64-linux-gnu.so
building 'fairseq.ngram_repeat_block_cuda' extension
Emitting ninja build file /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
/cm/local/apps/gcc/11.2.0/bin/g++ -pthread -B /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/compiler_compat -shared -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/cuda/ngram_repeat_block_cuda.o /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/fairseq/clib/cuda/ngram_repeat_block_cuda_kernel.o -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.9/fairseq/ngram_repeat_block_cuda.cpython-39-x86_64-linux-gnu.so
building 'alignment_train_cuda_binding' extension
Emitting ninja build file /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/build.ninja...
Compiling objects...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
/cm/local/apps/gcc/11.2.0/bin/g++ -pthread -B /mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/compiler_compat -shared -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -Wl,-rpath-link,/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib -I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include:-I/mntnfs/lee_data1/maduo/installed/cuda-11.8.0/include//targets/x86_64-linux/include: /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/examples/operators/alignment_train_cuda.o /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/build/temp.linux-x86_64-3.9/examples/operators/alignment_train_kernel.o -L/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.9/alignment_train_cuda_binding.cpython-39-x86_64-linux-gnu.so
copying build/lib.linux-x86_64-3.9/fairseq/libbleu.cpython-39-x86_64-linux-gnu.so -> fairseq
copying build/lib.linux-x86_64-3.9/fairseq/data/data_utils_fast.cpython-39-x86_64-linux-gnu.so -> fairseq/data
copying build/lib.linux-x86_64-3.9/fairseq/data/token_block_utils_fast.cpython-39-x86_64-linux-gnu.so -> fairseq/data
copying build/lib.linux-x86_64-3.9/fairseq/libbase.cpython-39-x86_64-linux-gnu.so -> fairseq
copying build/lib.linux-x86_64-3.9/fairseq/libnat.cpython-39-x86_64-linux-gnu.so -> fairseq
copying build/lib.linux-x86_64-3.9/alignment_train_cpu_binding.cpython-39-x86_64-linux-gnu.so -> 
copying build/lib.linux-x86_64-3.9/fairseq/libnat_cuda.cpython-39-x86_64-linux-gnu.so -> fairseq
copying build/lib.linux-x86_64-3.9/fairseq/ngram_repeat_block_cuda.cpython-39-x86_64-linux-gnu.so -> fairseq
copying build/lib.linux-x86_64-3.9/alignment_train_cuda_binding.cpython-39-x86_64-linux-gnu.so -> 
fine tune base t-hubert model  using train-clean-360 supervision data
[2024-07-05 08:49:43,629][fairseq.distributed.utils][INFO] - Rank 0, device_id: 0
2024-07-05 08:49:48 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:28610
2024-07-05 08:49:48 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:28610
2024-07-05 08:49:48 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:28610
2024-07-05 08:49:48 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:28610
2024-07-05 08:49:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2024-07-05 08:49:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2024-07-05 08:49:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2024-07-05 08:49:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2024-07-05 08:49:49 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-07-05 08:49:49 | INFO | fairseq.distributed.utils | initialized host pgpu13 as rank 0
2024-07-05 08:49:49 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-07-05 08:49:49 | INFO | fairseq.distributed.utils | initialized host pgpu13 as rank 3
2024-07-05 08:49:49 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-07-05 08:49:49 | INFO | fairseq.distributed.utils | initialized host pgpu13 as rank 1
2024-07-05 08:49:49 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-07-05 08:49:49 | INFO | fairseq.distributed.utils | initialized host pgpu13 as rank 2
[2024-07-05 08:49:55,295][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/t-hubert', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:28610', 'distributed_port': 28610, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3200000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train-clean-360', 'valid_subset': 'dev-other', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3200000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 100000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [2], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'wer', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'hubert_ctc', 'w2v_path': '/mntcephfs/lab_data/maduo/exp/pretrain/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update/checkpoint_298_400000.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.1, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_embed_dim': 768, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 0, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'normalize': False, 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'w2v_args': None, 'autoregressive': False}, 'task': {'_name': 'hubert_pretraining', 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'fine_tuning': True, 'labels': ['ltr'], 'label_dir': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'label_rate': -1.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': None, 'min_sample_size': None, 'single_target': True, 'random_crop': True, 'pad_audio': False}, 'criterion': {'_name': 'ctc', 'zero_infinity': True, 'sentence_avg': True, 'post_process': 'letter', 'wer_kenlm_model': None, 'wer_lexicon': None, 'wer_lm_weight': 2.0, 'wer_word_score': -1.0, 'wer_sil_weight': 0.0, 'wer_args': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05], 'amsgrad': False}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 40000, 'decay_steps': 50000, 'phase_ratio': None, 'init_lr_scale': 0.01, 'final_lr_scale': 0.05, 'max_update': 100000.0, 'lr': [3e-05]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': '/mntcephfs/lab_data/maduo/exp/pretrain/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update/finetune.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-07-05 08:49:55,298][fairseq.tasks.hubert_pretraining][INFO] - current directory is /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/t-hubert
[2024-07-05 08:49:55,298][fairseq.tasks.hubert_pretraining][INFO] - HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'fine_tuning': True, 'labels': ['ltr'], 'label_dir': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'label_rate': -1.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': None, 'min_sample_size': None, 'single_target': True, 'random_crop': True, 'pad_audio': False}
[2024-07-05 08:49:55,301][fairseq.models.hubert.hubert_asr][INFO] - cfg: {'_name': 'hubert_ctc', 'w2v_path': '/mntcephfs/lab_data/maduo/exp/pretrain/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update/checkpoint_298_400000.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.1, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_embed_dim': 768, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 0, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'normalize': False, 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'w2v_args': None, 'autoregressive': False}, task: <fairseq.tasks.hubert_pretraining.HubertPretrainingTask object at 0x1554074f3070>
[2024-07-05 08:49:55,302][fairseq.models.hubert.hubert_asr][INFO] - mdddd:::/mntcephfs/lab_data/maduo/exp/pretrain/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update/checkpoint_298_400000.pt
[2024-07-05 08:49:58,941][fairseq.tasks.hubert_pretraining][INFO] - current directory is /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/t-hubert
[2024-07-05 08:49:58,941][fairseq.tasks.hubert_pretraining][INFO] - HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'fine_tuning': False, 'labels': ['phncode', 'km'], 'label_dir': '/mntcephfs/lab_data/maduo/datasets/format/librispeech//offical_hubert_codes_and_librispeech_frame_monophncode_using_wav2vec-u2_model', 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
[2024-07-05 08:49:58,949][fairseq.models.hubert.hubert2][INFO] - HubertModel2 Config: {'_name': 'ils_hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'attention_type': 'rel_attention', 'weighted_sum': False, 'predict_layers': '[7,12]', 'separate_label_embeds': True, 'separate_layer_targets': False, 'km4_bpekm7_km12': False, 'bpekm7_km12': False, 'phnkm6_km12': False, 'phnkm7_km12': True, 'km4_phnkm6_km12': False, 'km4_phnkm7_km12': False}
[2024-07-05 08:49:59,157][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-05 08:49:59,227][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-05 08:49:59,399][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-05 08:49:59,448][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-05 08:49:59,498][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-05 08:49:59,547][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-05 08:49:59,596][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-05 08:49:59,645][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-05 08:49:59,695][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-05 08:49:59,744][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-05 08:49:59,793][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-05 08:49:59,843][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-05 08:50:00,344][fairseq.models.hubert.ils_hubert][INFO] - HubertModel Config: {'_name': 'ils_hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'attention_type': 'rel_attention', 'weighted_sum': False, 'predict_layers': '[7,12]', 'separate_label_embeds': True, 'separate_layer_targets': False, 'km4_bpekm7_km12': False, 'bpekm7_km12': False, 'phnkm6_km12': False, 'phnkm7_km12': True, 'km4_phnkm6_km12': False, 'km4_phnkm7_km12': False}
[2024-07-05 08:50:04,127][fairseq_cli.train][INFO] - HubertCtc(
  (w2v_encoder): HubertEncoder(
    (w2v_model): ILSHubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention2(
              (dropout_module): FairseqDropout()
              (relative_attention_bias): Embedding(320, 12)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1-11): 11 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention2(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (proj): Linear(in_features=768, out_features=32, bias=True)
  )
)
[2024-07-05 08:50:04,142][fairseq_cli.train][INFO] - task: HubertPretrainingTask
[2024-07-05 08:50:04,142][fairseq_cli.train][INFO] - model: HubertCtc
[2024-07-05 08:50:04,142][fairseq_cli.train][INFO] - criterion: CtcCriterion
[2024-07-05 08:50:04,143][fairseq_cli.train][INFO] - num. shared model params: 94,400,160 (num. trained: 94,400,160)
[2024-07-05 08:50:04,144][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-07-05 08:50:04,148][fairseq.data.audio.hubert_dataset][INFO] - max_keep=None, min_keep=None, loaded 2864, skipped 0 short and 0 long, longest-loaded=562480, shortest-loaded=17040
[2024-07-05 08:50:04,149][fairseq.data.audio.hubert_dataset][INFO] - /mntcephfs/lab_data/maduo/datasets/format/librispeech//dev-other.ltr is sequence label. skipped
[2024-07-05 08:50:04,150][fairseq.data.audio.hubert_dataset][INFO] - pad_audio=False, random_crop=True, normalize=False, max_sample_size=9223372036854775807
[2024-07-05 08:50:07,667][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:2 to store for rank: 0
[2024-07-05 08:50:07,698][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
[2024-07-05 08:50:07,698][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
[2024-07-05 08:50:07,698][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
[2024-07-05 08:50:07,698][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
[2024-07-05 08:50:07,698][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
[2024-07-05 08:50:07,698][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
[2024-07-05 08:50:07,698][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
[2024-07-05 08:50:07,698][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
[2024-07-05 08:50:08,318][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2024-07-05 08:50:08,318][fairseq.utils][INFO] - rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
[2024-07-05 08:50:08,318][fairseq.utils][INFO] - rank   1: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
[2024-07-05 08:50:08,318][fairseq.utils][INFO] - rank   2: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
[2024-07-05 08:50:08,318][fairseq.utils][INFO] - rank   3: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
[2024-07-05 08:50:08,318][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2024-07-05 08:50:08,318][fairseq_cli.train][INFO] - training on 4 devices (GPUs/TPUs)
[2024-07-05 08:50:08,318][fairseq_cli.train][INFO] - max tokens per device = 3200000 and max sentences per device = None
[2024-07-05 08:50:08,319][fairseq.trainer][INFO] - Preparing to load checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_last.pt
[2024-07-05 08:50:08,319][fairseq.trainer][INFO] - No existing checkpoint found /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_last.pt
[2024-07-05 08:50:08,319][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-07-05 08:50:08,399][fairseq.data.audio.hubert_dataset][INFO] - max_keep=None, min_keep=None, loaded 104014, skipped 0 short and 0 long, longest-loaded=475760, shortest-loaded=17040
[2024-07-05 08:50:08,529][fairseq.data.audio.hubert_dataset][INFO] - /mntcephfs/lab_data/maduo/datasets/format/librispeech//train-clean-360.ltr is sequence label. skipped
[2024-07-05 08:50:08,530][fairseq.data.audio.hubert_dataset][INFO] - pad_audio=False, random_crop=True, normalize=False, max_sample_size=9223372036854775807
[2024-07-05 08:50:08,644][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 08:50:08,645][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2024-07-05 08:50:08,645][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = False
[2024-07-05 08:50:08,645][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2024-07-05 08:50:09,499][fairseq_cli.train][INFO] - begin dry-run validation on "dev-other" subset
[2024-07-05 08:50:09,500][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 08:50:09,501][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2024-07-05 08:50:09,501][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = False
[2024-07-05 08:50:09,501][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2024-07-05 08:50:34,160][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 08:50:34,163][fairseq.trainer][INFO] - begin training epoch 1
[2024-07-05 08:50:34,164][fairseq_cli.train][INFO] - Start iterating over samples
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
[2024-07-05 08:51:04,445][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2024-07-05 08:51:06,416][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2024-07-05 08:51:08,403][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-05 08:51:38,945][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-05 08:54:34,876][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-07-05 08:57:14,277][train_inner][INFO] - {"epoch": 1, "update": 0.158, "loss": "2162.51", "ntokens": "14758", "nsentences": "79.84", "nll_loss": "11.699", "wps": "8055.1", "ups": "0.55", "wpb": "14758", "bsz": "79.8", "num_updates": "200", "lr": "8.94e-07", "gnorm": "1403.75", "loss_scale": "4", "train_wall": "377", "gb_free": "31.1", "wall": "426"}
[2024-07-05 08:58:55,605][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-07-05 09:03:04,138][train_inner][INFO] - {"epoch": 1, "update": 0.313, "loss": "1329.02", "ntokens": "14833.5", "nsentences": "79.88", "nll_loss": "7.157", "wps": "8482.4", "ups": "0.57", "wpb": "14833.5", "bsz": "79.9", "num_updates": "400", "lr": "1.488e-06", "gnorm": "1970.58", "loss_scale": "2", "train_wall": "349", "gb_free": "32.8", "wall": "776"}
[2024-07-05 09:08:50,332][train_inner][INFO] - {"epoch": 1, "update": 0.467, "loss": "843.169", "ntokens": "14870", "nsentences": "80.83", "nll_loss": "4.583", "wps": "8592.3", "ups": "0.58", "wpb": "14870", "bsz": "80.8", "num_updates": "600", "lr": "2.082e-06", "gnorm": "605.376", "loss_scale": "2", "train_wall": "346", "gb_free": "31.8", "wall": "1122"}
[2024-07-05 09:14:26,917][train_inner][INFO] - {"epoch": 1, "update": 0.621, "loss": "787.046", "ntokens": "14854.8", "nsentences": "80.16", "nll_loss": "4.247", "wps": "8828.6", "ups": "0.59", "wpb": "14854.8", "bsz": "80.2", "num_updates": "800", "lr": "2.676e-06", "gnorm": "283.259", "loss_scale": "2", "train_wall": "336", "gb_free": "32.1", "wall": "1459"}
[2024-07-05 09:20:30,782][train_inner][INFO] - {"epoch": 1, "update": 0.776, "loss": "770.82", "ntokens": "14798.3", "nsentences": "80.52", "nll_loss": "4.194", "wps": "8135.7", "ups": "0.55", "wpb": "14798.3", "bsz": "80.5", "num_updates": "1000", "lr": "3.27e-06", "gnorm": "229.063", "loss_scale": "2", "train_wall": "363", "gb_free": "32.1", "wall": "1822"}
[2024-07-05 09:26:19,319][train_inner][INFO] - {"epoch": 1, "update": 0.93, "loss": "765.98", "ntokens": "14840.1", "nsentences": "80.48", "nll_loss": "4.154", "wps": "8516", "ups": "0.57", "wpb": "14840.1", "bsz": "80.5", "num_updates": "1200", "lr": "3.864e-06", "gnorm": "164.241", "loss_scale": "2", "train_wall": "348", "gb_free": "31.6", "wall": "2171"}
[2024-07-05 09:29:00,282][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 09:29:00,344][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 09:29:32,564][dev-other][INFO] - {"epoch": 1, "dev-other_loss": "393.849", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "4.187", "dev-other_uer": "100", "dev-other_wer": "100", "dev-other_raw_wer": "100", "dev-other_wps": "8663.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "1291"}
[2024-07-05 09:29:32,565][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2024-07-05 09:29:32,579][train][INFO] - {"epoch": 1, "train_loss": "1084.9", "train_ntokens": "14821.7", "train_nsentences": "80.1844", "train_nll_loss": "5.869", "train_wps": "8302.6", "train_ups": "0.56", "train_wpb": "14821.7", "train_bsz": "80.2", "train_num_updates": "1291", "train_lr": "4.13427e-06", "train_gnorm": "733.677", "train_loss_scale": "2", "train_train_wall": "2279", "train_gb_free": "31.6", "train_wall": "2364"}
[2024-07-05 09:29:32,581][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 09:29:33,165][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 09:29:33,168][fairseq.trainer][INFO] - begin training epoch 2
[2024-07-05 09:29:33,169][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 09:32:32,998][train_inner][INFO] - {"epoch": 2, "update": 1.084, "loss": "758.307", "ntokens": "14764.8", "nsentences": "80.56", "nll_loss": "4.137", "wps": "7902.7", "ups": "0.54", "wpb": "14764.8", "bsz": "80.6", "num_updates": "1400", "lr": "4.458e-06", "gnorm": "167.255", "loss_scale": "2", "train_wall": "340", "gb_free": "31.5", "wall": "2545"}
[2024-07-05 09:38:25,532][train_inner][INFO] - {"epoch": 2, "update": 1.238, "loss": "758.794", "ntokens": "14796.5", "nsentences": "80.32", "nll_loss": "4.119", "wps": "8396.1", "ups": "0.57", "wpb": "14796.5", "bsz": "80.3", "num_updates": "1600", "lr": "5.052e-06", "gnorm": "184.084", "loss_scale": "2", "train_wall": "352", "gb_free": "32.1", "wall": "2897"}
[2024-07-05 09:44:11,892][train_inner][INFO] - {"epoch": 2, "update": 1.392, "loss": "783.043", "ntokens": "14753.5", "nsentences": "77.44", "nll_loss": "4.11", "wps": "8520.9", "ups": "0.58", "wpb": "14753.5", "bsz": "77.4", "num_updates": "1800", "lr": "5.646e-06", "gnorm": "160.817", "loss_scale": "2", "train_wall": "346", "gb_free": "33.1", "wall": "3244"}
[2024-07-05 09:50:05,521][train_inner][INFO] - {"epoch": 2, "update": 1.547, "loss": "758.935", "ntokens": "14894.3", "nsentences": "80.6", "nll_loss": "4.107", "wps": "8425", "ups": "0.57", "wpb": "14894.3", "bsz": "80.6", "num_updates": "2000", "lr": "6.24e-06", "gnorm": "181.655", "loss_scale": "2", "train_wall": "353", "gb_free": "32.9", "wall": "3597"}
[2024-07-05 09:55:52,294][train_inner][INFO] - {"epoch": 2, "update": 1.701, "loss": "738.281", "ntokens": "14738.6", "nsentences": "80", "nll_loss": "4.007", "wps": "8500.6", "ups": "0.58", "wpb": "14738.6", "bsz": "80", "num_updates": "2200", "lr": "6.834e-06", "gnorm": "217.989", "loss_scale": "2", "train_wall": "346", "gb_free": "31.2", "wall": "3944"}
[2024-07-05 10:01:35,099][train_inner][INFO] - {"epoch": 2, "update": 1.855, "loss": "665.931", "ntokens": "14914.9", "nsentences": "81.59", "nll_loss": "3.643", "wps": "8703.2", "ups": "0.58", "wpb": "14914.9", "bsz": "81.6", "num_updates": "2400", "lr": "7.428e-06", "gnorm": "205.877", "loss_scale": "4", "train_wall": "342", "gb_free": "32.2", "wall": "4287"}
[2024-07-05 10:07:05,905][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 10:07:05,968][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 10:07:37,907][dev-other][INFO] - {"epoch": 2, "dev-other_loss": "200.579", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "2.132", "dev-other_uer": "49.965", "dev-other_wer": "90.006", "dev-other_raw_wer": "90.006", "dev-other_wps": "8737.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "2588"}
[2024-07-05 10:07:37,908][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2024-07-05 10:07:37,912][train][INFO] - {"epoch": 2, "train_loss": "716.767", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "3.878", "train_wps": "8412.5", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "2588", "train_lr": "7.98636e-06", "train_gnorm": "194.129", "train_loss_scale": "4", "train_train_wall": "2249", "train_gb_free": "32.4", "train_wall": "4650"}
[2024-07-05 10:07:37,914][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 10:07:38,507][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 10:07:38,511][fairseq.trainer][INFO] - begin training epoch 3
[2024-07-05 10:07:38,511][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 10:08:00,197][train_inner][INFO] - {"epoch": 3, "update": 2.009, "loss": "568.324", "ntokens": "14884", "nsentences": "80.44", "nll_loss": "3.071", "wps": "7731.3", "ups": "0.52", "wpb": "14884", "bsz": "80.4", "num_updates": "2600", "lr": "8.022e-06", "gnorm": "234.548", "loss_scale": "4", "train_wall": "352", "gb_free": "32.1", "wall": "4672"}
[2024-07-05 10:13:57,817][train_inner][INFO] - {"epoch": 3, "update": 2.163, "loss": "457.634", "ntokens": "14750.2", "nsentences": "79.95", "nll_loss": "2.48", "wps": "8249.2", "ups": "0.56", "wpb": "14750.2", "bsz": "80", "num_updates": "2800", "lr": "8.616e-06", "gnorm": "209.754", "loss_scale": "4", "train_wall": "357", "gb_free": "32", "wall": "5029"}
[2024-07-05 10:19:37,938][train_inner][INFO] - {"epoch": 3, "update": 2.318, "loss": "377.367", "ntokens": "14892", "nsentences": "79.68", "nll_loss": "2.019", "wps": "8759.3", "ups": "0.59", "wpb": "14892", "bsz": "79.7", "num_updates": "3000", "lr": "9.21e-06", "gnorm": "188.764", "loss_scale": "4", "train_wall": "339", "gb_free": "32.5", "wall": "5370"}
[2024-07-05 10:25:31,620][train_inner][INFO] - {"epoch": 3, "update": 2.472, "loss": "321.024", "ntokens": "14901.6", "nsentences": "82.8", "nll_loss": "1.784", "wps": "8426.8", "ups": "0.57", "wpb": "14901.6", "bsz": "82.8", "num_updates": "3200", "lr": "9.804e-06", "gnorm": "197.246", "loss_scale": "4", "train_wall": "353", "gb_free": "32.7", "wall": "5723"}
[2024-07-05 10:31:19,215][train_inner][INFO] - {"epoch": 3, "update": 2.626, "loss": "294.445", "ntokens": "14864", "nsentences": "80.48", "nll_loss": "1.594", "wps": "8554", "ups": "0.58", "wpb": "14864", "bsz": "80.5", "num_updates": "3400", "lr": "1.0398e-05", "gnorm": "167.826", "loss_scale": "4", "train_wall": "347", "gb_free": "32.8", "wall": "6071"}
[2024-07-05 10:37:09,061][train_inner][INFO] - {"epoch": 3, "update": 2.78, "loss": "259.221", "ntokens": "14783.6", "nsentences": "80", "nll_loss": "1.403", "wps": "8451.7", "ups": "0.57", "wpb": "14783.6", "bsz": "80", "num_updates": "3600", "lr": "1.0992e-05", "gnorm": "152.639", "loss_scale": "4", "train_wall": "349", "gb_free": "30.9", "wall": "6421"}
[2024-07-05 10:42:58,317][train_inner][INFO] - {"epoch": 3, "update": 2.934, "loss": "232.738", "ntokens": "14794.2", "nsentences": "79.6", "nll_loss": "1.252", "wps": "8472", "ups": "0.57", "wpb": "14794.2", "bsz": "79.6", "num_updates": "3800", "lr": "1.1586e-05", "gnorm": "140.609", "loss_scale": "4", "train_wall": "349", "gb_free": "31.8", "wall": "6770"}
[2024-07-05 10:45:34,178][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 10:45:34,183][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 10:46:06,185][dev-other][INFO] - {"epoch": 3, "dev-other_loss": "61.235", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.651", "dev-other_uer": "11.57", "dev-other_wer": "37.219", "dev-other_raw_wer": "37.219", "dev-other_wps": "8735.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "3885"}
[2024-07-05 10:46:06,186][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)
[2024-07-05 10:46:06,197][train][INFO] - {"epoch": 3, "train_loss": "319.077", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "1.726", "train_wps": "8328.9", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "3885", "train_lr": "1.18385e-05", "train_gnorm": "174.652", "train_loss_scale": "4", "train_train_wall": "2272", "train_gb_free": "32.1", "train_wall": "6958"}
[2024-07-05 10:46:06,199][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 10:46:06,788][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 10:46:06,792][fairseq.trainer][INFO] - begin training epoch 4
[2024-07-05 10:46:06,792][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 10:49:26,632][train_inner][INFO] - {"epoch": 4, "update": 3.089, "loss": "211.978", "ntokens": "14789", "nsentences": "81.04", "nll_loss": "1.162", "wps": "7618.2", "ups": "0.52", "wpb": "14789", "bsz": "81", "num_updates": "4000", "lr": "1.218e-05", "gnorm": "141.409", "loss_scale": "4", "train_wall": "355", "gb_free": "31.7", "wall": "7158"}
[2024-07-05 10:55:13,672][train_inner][INFO] - {"epoch": 4, "update": 3.243, "loss": "202.357", "ntokens": "14845.6", "nsentences": "80.83", "nll_loss": "1.102", "wps": "8555.8", "ups": "0.58", "wpb": "14845.6", "bsz": "80.8", "num_updates": "4200", "lr": "1.2774e-05", "gnorm": "142.025", "loss_scale": "4", "train_wall": "346", "gb_free": "30.9", "wall": "7505"}
[2024-07-05 11:01:06,010][train_inner][INFO] - {"epoch": 4, "update": 3.397, "loss": "195.967", "ntokens": "14822.1", "nsentences": "81.72", "nll_loss": "1.08", "wps": "8413.9", "ups": "0.57", "wpb": "14822.1", "bsz": "81.7", "num_updates": "4400", "lr": "1.3368e-05", "gnorm": "150.536", "loss_scale": "8", "train_wall": "352", "gb_free": "31.2", "wall": "7858"}
[2024-07-05 11:06:56,620][train_inner][INFO] - {"epoch": 4, "update": 3.551, "loss": "186.623", "ntokens": "14828.2", "nsentences": "79.56", "nll_loss": "1.001", "wps": "8458.7", "ups": "0.57", "wpb": "14828.2", "bsz": "79.6", "num_updates": "4600", "lr": "1.3962e-05", "gnorm": "149.607", "loss_scale": "8", "train_wall": "350", "gb_free": "32.3", "wall": "8208"}
[2024-07-05 11:12:46,092][train_inner][INFO] - {"epoch": 4, "update": 3.705, "loss": "174.312", "ntokens": "14749.7", "nsentences": "78.36", "nll_loss": "0.926", "wps": "8441.3", "ups": "0.57", "wpb": "14749.7", "bsz": "78.4", "num_updates": "4800", "lr": "1.4556e-05", "gnorm": "136.34", "loss_scale": "8", "train_wall": "349", "gb_free": "30.1", "wall": "8558"}
[2024-07-05 11:18:35,196][train_inner][INFO] - {"epoch": 4, "update": 3.86, "loss": "177.713", "ntokens": "14782.4", "nsentences": "77.24", "nll_loss": "0.929", "wps": "8469", "ups": "0.57", "wpb": "14782.4", "bsz": "77.2", "num_updates": "5000", "lr": "1.515e-05", "gnorm": "140.876", "loss_scale": "8", "train_wall": "349", "gb_free": "30.4", "wall": "8907"}
[2024-07-05 11:23:48,121][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 11:23:48,204][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 11:24:19,932][dev-other][INFO] - {"epoch": 4, "dev-other_loss": "39.341", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.418", "dev-other_uer": "7.519", "dev-other_wer": "23.852", "dev-other_raw_wer": "23.852", "dev-other_wps": "8778.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "5182"}
[2024-07-05 11:24:19,933][fairseq_cli.train][INFO] - end of epoch 4 (average epoch stats below)
[2024-07-05 11:24:19,936][train][INFO] - {"epoch": 4, "train_loss": "185.736", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "1.005", "train_wps": "8381.6", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "5182", "train_lr": "1.56905e-05", "train_gnorm": "142.104", "train_loss_scale": "8", "train_train_wall": "2258", "train_gb_free": "32.1", "train_wall": "9252"}
[2024-07-05 11:24:19,937][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 11:24:20,602][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 11:24:20,607][fairseq.trainer][INFO] - begin training epoch 5
[2024-07-05 11:24:20,607][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 11:24:51,971][train_inner][INFO] - {"epoch": 5, "update": 4.014, "loss": "163.122", "ntokens": "14881", "nsentences": "80.72", "nll_loss": "0.885", "wps": "7900.6", "ups": "0.53", "wpb": "14881", "bsz": "80.7", "num_updates": "5200", "lr": "1.5744e-05", "gnorm": "134.546", "loss_scale": "8", "train_wall": "344", "gb_free": "32.1", "wall": "9284"}
[2024-07-05 11:30:36,861][train_inner][INFO] - {"epoch": 5, "update": 4.168, "loss": "157.92", "ntokens": "14801.8", "nsentences": "79.4", "nll_loss": "0.847", "wps": "8583.7", "ups": "0.58", "wpb": "14801.8", "bsz": "79.4", "num_updates": "5400", "lr": "1.6338e-05", "gnorm": "135.018", "loss_scale": "8", "train_wall": "344", "gb_free": "32.5", "wall": "9629"}
[2024-07-05 11:36:28,052][train_inner][INFO] - {"epoch": 5, "update": 4.322, "loss": "149.075", "ntokens": "14793.7", "nsentences": "79.76", "nll_loss": "0.804", "wps": "8426.5", "ups": "0.57", "wpb": "14793.7", "bsz": "79.8", "num_updates": "5600", "lr": "1.6932e-05", "gnorm": "129.988", "loss_scale": "8", "train_wall": "351", "gb_free": "30.7", "wall": "9980"}
[2024-07-05 11:42:21,246][train_inner][INFO] - {"epoch": 5, "update": 4.476, "loss": "137.662", "ntokens": "14858.6", "nsentences": "82.12", "nll_loss": "0.761", "wps": "8415.6", "ups": "0.57", "wpb": "14858.6", "bsz": "82.1", "num_updates": "5800", "lr": "1.7526e-05", "gnorm": "121.144", "loss_scale": "8", "train_wall": "353", "gb_free": "33.1", "wall": "10333"}
[2024-07-05 11:48:07,730][train_inner][INFO] - {"epoch": 5, "update": 4.631, "loss": "140.109", "ntokens": "14887.3", "nsentences": "80.08", "nll_loss": "0.754", "wps": "8595", "ups": "0.58", "wpb": "14887.3", "bsz": "80.1", "num_updates": "6000", "lr": "1.812e-05", "gnorm": "124.673", "loss_scale": "8", "train_wall": "346", "gb_free": "32.1", "wall": "10679"}
[2024-07-05 11:53:51,168][train_inner][INFO] - {"epoch": 5, "update": 4.785, "loss": "137.952", "ntokens": "14866.3", "nsentences": "80.64", "nll_loss": "0.748", "wps": "8659.3", "ups": "0.58", "wpb": "14866.3", "bsz": "80.6", "num_updates": "6200", "lr": "1.8714e-05", "gnorm": "125.613", "loss_scale": "8", "train_wall": "343", "gb_free": "31.3", "wall": "11023"}
[2024-07-05 11:59:36,068][train_inner][INFO] - {"epoch": 5, "update": 4.939, "loss": "136.975", "ntokens": "14738.8", "nsentences": "79.99", "nll_loss": "0.743", "wps": "8549.6", "ups": "0.58", "wpb": "14738.8", "bsz": "80", "num_updates": "6400", "lr": "1.9308e-05", "gnorm": "132.959", "loss_scale": "16", "train_wall": "344", "gb_free": "31.8", "wall": "11368"}
[2024-07-05 12:02:01,482][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 12:02:01,582][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 12:02:33,788][dev-other][INFO] - {"epoch": 5, "dev-other_loss": "31.743", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.337", "dev-other_uer": "5.562", "dev-other_wer": "16.704", "dev-other_raw_wer": "16.704", "dev-other_wps": "8733.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "6479"}
[2024-07-05 12:02:33,790][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 6479 updates
[2024-07-05 12:02:33,791][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt
[2024-07-05 12:02:35,869][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt
[2024-07-05 12:02:36,429][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt (epoch 5 @ 6479 updates, score 16.704) (writing took 2.63882252946496 seconds)
[2024-07-05 12:02:36,429][fairseq_cli.train][INFO] - end of epoch 5 (average epoch stats below)
[2024-07-05 12:02:36,548][train][INFO] - {"epoch": 5, "train_loss": "141.971", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.768", "train_wps": "8371.6", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "6479", "train_lr": "1.95426e-05", "train_gnorm": "127.722", "train_loss_scale": "16", "train_train_wall": "2257", "train_gb_free": "32.3", "train_wall": "11548"}
[2024-07-05 12:02:36,549][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 12:02:36,772][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 12:02:36,775][fairseq.trainer][INFO] - begin training epoch 6
[2024-07-05 12:02:36,776][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 12:06:13,350][train_inner][INFO] - {"epoch": 6, "update": 5.093, "loss": "127.48", "ntokens": "14735.3", "nsentences": "79.32", "nll_loss": "0.686", "wps": "7419.2", "ups": "0.5", "wpb": "14735.3", "bsz": "79.3", "num_updates": "6600", "lr": "1.9902e-05", "gnorm": "122.783", "loss_scale": "16", "train_wall": "361", "gb_free": "31.8", "wall": "11765"}
[2024-07-05 12:12:02,811][train_inner][INFO] - {"epoch": 6, "update": 5.247, "loss": "130.508", "ntokens": "14934.5", "nsentences": "80.88", "nll_loss": "0.707", "wps": "8547.6", "ups": "0.57", "wpb": "14934.5", "bsz": "80.9", "num_updates": "6800", "lr": "2.0496e-05", "gnorm": "123.205", "loss_scale": "16", "train_wall": "349", "gb_free": "32.1", "wall": "12114"}
[2024-07-05 12:17:53,824][train_inner][INFO] - {"epoch": 6, "update": 5.402, "loss": "123.481", "ntokens": "14834.2", "nsentences": "80.56", "nll_loss": "0.671", "wps": "8452.6", "ups": "0.57", "wpb": "14834.2", "bsz": "80.6", "num_updates": "7000", "lr": "2.109e-05", "gnorm": "122.617", "loss_scale": "16", "train_wall": "350", "gb_free": "31.6", "wall": "12465"}
[2024-07-05 12:23:48,795][train_inner][INFO] - {"epoch": 6, "update": 5.556, "loss": "117.25", "ntokens": "14904.6", "nsentences": "81.28", "nll_loss": "0.639", "wps": "8397.8", "ups": "0.56", "wpb": "14904.6", "bsz": "81.3", "num_updates": "7200", "lr": "2.1684e-05", "gnorm": "118.228", "loss_scale": "16", "train_wall": "354", "gb_free": "31", "wall": "12820"}
[2024-07-05 12:29:38,200][train_inner][INFO] - {"epoch": 6, "update": 5.71, "loss": "124.791", "ntokens": "14780.6", "nsentences": "78.75", "nll_loss": "0.665", "wps": "8462", "ups": "0.57", "wpb": "14780.6", "bsz": "78.8", "num_updates": "7400", "lr": "2.2278e-05", "gnorm": "125.425", "loss_scale": "16", "train_wall": "349", "gb_free": "32.4", "wall": "13170"}
[2024-07-05 12:29:56,414][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-05 12:35:34,474][train_inner][INFO] - {"epoch": 6, "update": 5.865, "loss": "114.34", "ntokens": "14695.3", "nsentences": "79.32", "nll_loss": "0.617", "wps": "8249.7", "ups": "0.56", "wpb": "14695.3", "bsz": "79.3", "num_updates": "7600", "lr": "2.2872e-05", "gnorm": "118.409", "loss_scale": "8", "train_wall": "356", "gb_free": "32.6", "wall": "13526"}
[2024-07-05 12:40:43,892][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 12:40:43,953][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 12:41:15,827][dev-other][INFO] - {"epoch": 6, "dev-other_loss": "29.181", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.31", "dev-other_uer": "4.937", "dev-other_wer": "14.117", "dev-other_raw_wer": "14.117", "dev-other_wps": "8738.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "7775", "dev-other_best_wer": "14.117"}
[2024-07-05 12:41:15,828][fairseq_cli.train][INFO] - end of epoch 6 (average epoch stats below)
[2024-07-05 12:41:15,848][train][INFO] - {"epoch": 6, "train_loss": "122.094", "train_ntokens": "14822.1", "train_nsentences": "80.1775", "train_nll_loss": "0.66", "train_wps": "8282.5", "train_ups": "0.56", "train_wpb": "14822.1", "train_bsz": "80.2", "train_num_updates": "7775", "train_lr": "2.33917e-05", "train_gnorm": "121.811", "train_loss_scale": "8", "train_train_wall": "2283", "train_gb_free": "32.1", "train_wall": "13868"}
[2024-07-05 12:41:15,850][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 12:41:16,460][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 12:41:16,463][fairseq.trainer][INFO] - begin training epoch 7
[2024-07-05 12:41:16,463][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 12:42:01,029][train_inner][INFO] - {"epoch": 7, "update": 6.019, "loss": "115.299", "ntokens": "14826.9", "nsentences": "80.64", "nll_loss": "0.627", "wps": "7671.5", "ups": "0.52", "wpb": "14826.9", "bsz": "80.6", "num_updates": "7800", "lr": "2.3466e-05", "gnorm": "120.493", "loss_scale": "8", "train_wall": "353", "gb_free": "32.3", "wall": "13913"}
[2024-07-05 12:47:56,265][train_inner][INFO] - {"epoch": 7, "update": 6.173, "loss": "112.27", "ntokens": "14845.6", "nsentences": "79.64", "nll_loss": "0.602", "wps": "8358.3", "ups": "0.56", "wpb": "14845.6", "bsz": "79.6", "num_updates": "8000", "lr": "2.406e-05", "gnorm": "119.004", "loss_scale": "8", "train_wall": "355", "gb_free": "31.6", "wall": "14268"}
[2024-07-05 12:53:41,571][train_inner][INFO] - {"epoch": 7, "update": 6.328, "loss": "114.413", "ntokens": "14828.1", "nsentences": "81.03", "nll_loss": "0.625", "wps": "8590.2", "ups": "0.58", "wpb": "14828.1", "bsz": "81", "num_updates": "8200", "lr": "2.4654e-05", "gnorm": "122.044", "loss_scale": "8", "train_wall": "345", "gb_free": "32.1", "wall": "14613"}
[2024-07-05 12:59:31,833][train_inner][INFO] - {"epoch": 7, "update": 6.482, "loss": "119.333", "ntokens": "14722.9", "nsentences": "79.04", "nll_loss": "0.641", "wps": "8407.2", "ups": "0.57", "wpb": "14722.9", "bsz": "79", "num_updates": "8400", "lr": "2.5248e-05", "gnorm": "129.299", "loss_scale": "8", "train_wall": "350", "gb_free": "32.2", "wall": "14964"}
[2024-07-05 13:05:19,881][train_inner][INFO] - {"epoch": 7, "update": 6.636, "loss": "111.15", "ntokens": "14884.9", "nsentences": "80.28", "nll_loss": "0.599", "wps": "8553.6", "ups": "0.57", "wpb": "14884.9", "bsz": "80.3", "num_updates": "8600", "lr": "2.5842e-05", "gnorm": "122.036", "loss_scale": "8", "train_wall": "348", "gb_free": "30.6", "wall": "15312"}
[2024-07-05 13:10:56,544][train_inner][INFO] - {"epoch": 7, "update": 6.79, "loss": "114.748", "ntokens": "14798.2", "nsentences": "80.84", "nll_loss": "0.627", "wps": "8792.9", "ups": "0.59", "wpb": "14798.2", "bsz": "80.8", "num_updates": "8800", "lr": "2.6436e-05", "gnorm": "123.006", "loss_scale": "8", "train_wall": "336", "gb_free": "33.2", "wall": "15648"}
[2024-07-05 13:16:53,276][train_inner][INFO] - {"epoch": 7, "update": 6.944, "loss": "110.076", "ntokens": "14861.1", "nsentences": "79.36", "nll_loss": "0.588", "wps": "8332.4", "ups": "0.56", "wpb": "14861.1", "bsz": "79.4", "num_updates": "9000", "lr": "2.703e-05", "gnorm": "120.007", "loss_scale": "8", "train_wall": "356", "gb_free": "32.9", "wall": "16005"}
[2024-07-05 13:19:06,353][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 13:19:06,359][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 13:19:38,887][dev-other][INFO] - {"epoch": 7, "dev-other_loss": "26.683", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.284", "dev-other_uer": "4.574", "dev-other_wer": "12.837", "dev-other_raw_wer": "12.837", "dev-other_wps": "8606.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "9072", "dev-other_best_wer": "12.837"}
[2024-07-05 13:19:38,888][fairseq_cli.train][INFO] - end of epoch 7 (average epoch stats below)
[2024-07-05 13:19:38,891][train][INFO] - {"epoch": 7, "train_loss": "112.888", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.611", "train_wps": "8347.8", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "9072", "train_lr": "2.72438e-05", "train_gnorm": "121.845", "train_loss_scale": "8", "train_train_wall": "2266", "train_gb_free": "33", "train_wall": "16171"}
[2024-07-05 13:19:38,893][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 13:19:39,501][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 13:19:39,504][fairseq.trainer][INFO] - begin training epoch 8
[2024-07-05 13:19:39,504][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 13:23:21,948][train_inner][INFO] - {"epoch": 8, "update": 7.099, "loss": "107.373", "ntokens": "14875", "nsentences": "81.07", "nll_loss": "0.585", "wps": "7654.4", "ups": "0.51", "wpb": "14875", "bsz": "81.1", "num_updates": "9200", "lr": "2.7624e-05", "gnorm": "121.163", "loss_scale": "8", "train_wall": "355", "gb_free": "32.2", "wall": "16394"}
[2024-07-05 13:29:15,204][train_inner][INFO] - {"epoch": 8, "update": 7.253, "loss": "110.746", "ntokens": "14769.9", "nsentences": "80.48", "nll_loss": "0.603", "wps": "8363.8", "ups": "0.57", "wpb": "14769.9", "bsz": "80.5", "num_updates": "9400", "lr": "2.8218e-05", "gnorm": "123.913", "loss_scale": "8", "train_wall": "353", "gb_free": "32.3", "wall": "16747"}
[2024-07-05 13:35:03,862][train_inner][INFO] - {"epoch": 8, "update": 7.407, "loss": "107.11", "ntokens": "14881.9", "nsentences": "79.96", "nll_loss": "0.575", "wps": "8537", "ups": "0.57", "wpb": "14881.9", "bsz": "80", "num_updates": "9600", "lr": "2.8812e-05", "gnorm": "119.502", "loss_scale": "16", "train_wall": "348", "gb_free": "32.6", "wall": "17096"}
[2024-07-05 13:40:57,385][train_inner][INFO] - {"epoch": 8, "update": 7.561, "loss": "103.608", "ntokens": "14861.9", "nsentences": "81.8", "nll_loss": "0.57", "wps": "8408.7", "ups": "0.57", "wpb": "14861.9", "bsz": "81.8", "num_updates": "9800", "lr": "2.9406e-05", "gnorm": "117.203", "loss_scale": "16", "train_wall": "353", "gb_free": "31.5", "wall": "17449"}
[2024-07-05 13:43:56,514][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-05 13:46:49,223][train_inner][INFO] - {"epoch": 8, "update": 7.716, "loss": "104.918", "ntokens": "14757.6", "nsentences": "79.64", "nll_loss": "0.566", "wps": "8396.4", "ups": "0.57", "wpb": "14757.6", "bsz": "79.6", "num_updates": "10000", "lr": "3e-05", "gnorm": "119.648", "loss_scale": "8", "train_wall": "351", "gb_free": "31.4", "wall": "17801"}
[2024-07-05 13:52:37,116][train_inner][INFO] - {"epoch": 8, "update": 7.87, "loss": "107.194", "ntokens": "14804.5", "nsentences": "77.6", "nll_loss": "0.562", "wps": "8511.2", "ups": "0.57", "wpb": "14804.6", "bsz": "77.6", "num_updates": "10200", "lr": "3e-05", "gnorm": "121.186", "loss_scale": "8", "train_wall": "347", "gb_free": "32.5", "wall": "18149"}
[2024-07-05 13:57:37,365][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 13:57:37,371][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 13:58:09,754][dev-other][INFO] - {"epoch": 8, "dev-other_loss": "25.388", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.27", "dev-other_uer": "4.334", "dev-other_wer": "12.044", "dev-other_raw_wer": "12.044", "dev-other_wps": "8657.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "10368", "dev-other_best_wer": "12.044"}
[2024-07-05 13:58:09,755][fairseq_cli.train][INFO] - end of epoch 8 (average epoch stats below)
[2024-07-05 13:58:09,877][train][INFO] - {"epoch": 8, "train_loss": "106.382", "train_ntokens": "14822.3", "train_nsentences": "80.196", "train_nll_loss": "0.576", "train_wps": "8312.8", "train_ups": "0.56", "train_wpb": "14822.3", "train_bsz": "80.2", "train_num_updates": "10368", "train_lr": "3e-05", "train_gnorm": "120.537", "train_loss_scale": "8", "train_train_wall": "2274", "train_gb_free": "32.2", "train_wall": "18481"}
[2024-07-05 13:58:09,878][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 13:58:10,326][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 13:58:10,331][fairseq.trainer][INFO] - begin training epoch 9
[2024-07-05 13:58:10,331][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 13:59:05,858][train_inner][INFO] - {"epoch": 9, "update": 8.025, "loss": "100.595", "ntokens": "14858.6", "nsentences": "82.08", "nll_loss": "0.556", "wps": "7650.8", "ups": "0.51", "wpb": "14858.6", "bsz": "82.1", "num_updates": "10400", "lr": "3e-05", "gnorm": "116.31", "loss_scale": "8", "train_wall": "355", "gb_free": "33.2", "wall": "18537"}
[2024-07-05 14:04:51,019][train_inner][INFO] - {"epoch": 9, "update": 8.179, "loss": "109.836", "ntokens": "14664.5", "nsentences": "77.88", "nll_loss": "0.583", "wps": "8501.2", "ups": "0.58", "wpb": "14664.5", "bsz": "77.9", "num_updates": "10600", "lr": "3e-05", "gnorm": "128.497", "loss_scale": "8", "train_wall": "344", "gb_free": "32.4", "wall": "18883"}
[2024-07-05 14:10:45,939][train_inner][INFO] - {"epoch": 9, "update": 8.333, "loss": "100.096", "ntokens": "14892.3", "nsentences": "81.39", "nll_loss": "0.547", "wps": "8401", "ups": "0.56", "wpb": "14892.3", "bsz": "81.4", "num_updates": "10800", "lr": "3e-05", "gnorm": "119.669", "loss_scale": "8", "train_wall": "354", "gb_free": "31.9", "wall": "19237"}
[2024-07-05 14:16:33,744][train_inner][INFO] - {"epoch": 9, "update": 8.487, "loss": "100.943", "ntokens": "14798.2", "nsentences": "80.72", "nll_loss": "0.551", "wps": "8509.7", "ups": "0.58", "wpb": "14798.2", "bsz": "80.7", "num_updates": "11000", "lr": "3e-05", "gnorm": "117.522", "loss_scale": "8", "train_wall": "347", "gb_free": "32.5", "wall": "19585"}
[2024-07-05 14:22:20,615][train_inner][INFO] - {"epoch": 9, "update": 8.641, "loss": "101.912", "ntokens": "14831.8", "nsentences": "79.24", "nll_loss": "0.544", "wps": "8553.4", "ups": "0.58", "wpb": "14831.8", "bsz": "79.2", "num_updates": "11200", "lr": "3e-05", "gnorm": "118.973", "loss_scale": "8", "train_wall": "346", "gb_free": "32.2", "wall": "19932"}
[2024-07-05 14:28:14,444][train_inner][INFO] - {"epoch": 9, "update": 8.796, "loss": "99.482", "ntokens": "14866.8", "nsentences": "80.16", "nll_loss": "0.536", "wps": "8415", "ups": "0.57", "wpb": "14866.8", "bsz": "80.2", "num_updates": "11400", "lr": "3e-05", "gnorm": "115.419", "loss_scale": "8", "train_wall": "353", "gb_free": "33", "wall": "20286"}
[2024-07-05 14:34:01,542][train_inner][INFO] - {"epoch": 9, "update": 8.95, "loss": "102.805", "ntokens": "14894.2", "nsentences": "81.64", "nll_loss": "0.564", "wps": "8583.9", "ups": "0.58", "wpb": "14894.2", "bsz": "81.6", "num_updates": "11600", "lr": "3e-05", "gnorm": "119.223", "loss_scale": "8", "train_wall": "346", "gb_free": "33", "wall": "20633"}
[2024-07-05 14:35:56,379][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 14:35:56,383][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 14:36:28,508][dev-other][INFO] - {"epoch": 9, "dev-other_loss": "24.836", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.264", "dev-other_uer": "4.172", "dev-other_wer": "11.531", "dev-other_raw_wer": "11.531", "dev-other_wps": "8699.3", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "11665", "dev-other_best_wer": "11.531"}
[2024-07-05 14:36:28,527][fairseq_cli.train][INFO] - end of epoch 9 (average epoch stats below)
[2024-07-05 14:36:28,535][train][INFO] - {"epoch": 9, "train_loss": "102.076", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.552", "train_wps": "8363.7", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "11665", "train_lr": "3e-05", "train_gnorm": "119.424", "train_loss_scale": "8", "train_train_wall": "2261", "train_gb_free": "32.5", "train_wall": "20780"}
[2024-07-05 14:36:28,537][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 14:36:29,156][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 14:36:29,159][fairseq.trainer][INFO] - begin training epoch 10
[2024-07-05 14:36:29,159][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 14:40:18,173][train_inner][INFO] - {"epoch": 10, "update": 9.104, "loss": "101.045", "ntokens": "14744.6", "nsentences": "79.96", "nll_loss": "0.548", "wps": "7831", "ups": "0.53", "wpb": "14744.6", "bsz": "80", "num_updates": "11800", "lr": "3e-05", "gnorm": "119.015", "loss_scale": "8", "train_wall": "343", "gb_free": "31.8", "wall": "21010"}
[2024-07-05 14:46:14,161][train_inner][INFO] - {"epoch": 10, "update": 9.258, "loss": "95.757", "ntokens": "14831.2", "nsentences": "79.64", "nll_loss": "0.514", "wps": "8333.7", "ups": "0.56", "wpb": "14831.2", "bsz": "79.6", "num_updates": "12000", "lr": "3e-05", "gnorm": "115.153", "loss_scale": "16", "train_wall": "355", "gb_free": "33.3", "wall": "21366"}
[2024-07-05 14:52:00,231][train_inner][INFO] - {"epoch": 10, "update": 9.412, "loss": "100.117", "ntokens": "14798.2", "nsentences": "80.64", "nll_loss": "0.546", "wps": "8554.2", "ups": "0.58", "wpb": "14798.2", "bsz": "80.6", "num_updates": "12200", "lr": "3e-05", "gnorm": "117.543", "loss_scale": "16", "train_wall": "345", "gb_free": "32.5", "wall": "21712"}
[2024-07-05 14:57:44,635][train_inner][INFO] - {"epoch": 10, "update": 9.567, "loss": "93.044", "ntokens": "14881.5", "nsentences": "81.96", "nll_loss": "0.512", "wps": "8643.3", "ups": "0.58", "wpb": "14881.5", "bsz": "82", "num_updates": "12400", "lr": "3e-05", "gnorm": "113.745", "loss_scale": "16", "train_wall": "344", "gb_free": "31.5", "wall": "22056"}
[2024-07-05 15:03:33,914][train_inner][INFO] - {"epoch": 10, "update": 9.721, "loss": "96.804", "ntokens": "14823.3", "nsentences": "80.6", "nll_loss": "0.526", "wps": "8488.1", "ups": "0.57", "wpb": "14823.3", "bsz": "80.6", "num_updates": "12600", "lr": "3e-05", "gnorm": "116.867", "loss_scale": "16", "train_wall": "349", "gb_free": "32.7", "wall": "22406"}
[2024-07-05 15:09:29,180][train_inner][INFO] - {"epoch": 10, "update": 9.875, "loss": "101.673", "ntokens": "14865.7", "nsentences": "78.75", "nll_loss": "0.539", "wps": "8370.2", "ups": "0.56", "wpb": "14865.7", "bsz": "78.8", "num_updates": "12800", "lr": "3e-05", "gnorm": "119.313", "loss_scale": "16", "train_wall": "355", "gb_free": "30.9", "wall": "22761"}
[2024-07-05 15:10:07,625][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-05 15:14:10,874][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 15:14:10,879][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 15:14:43,188][dev-other][INFO] - {"epoch": 10, "dev-other_loss": "23.774", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.253", "dev-other_uer": "4.101", "dev-other_wer": "11.3", "dev-other_raw_wer": "11.3", "dev-other_wps": "8700.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "12961", "dev-other_best_wer": "11.3"}
[2024-07-05 15:14:43,189][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 10 @ 12961 updates
[2024-07-05 15:14:43,190][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt
[2024-07-05 15:14:44,658][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt
[2024-07-05 15:14:45,103][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt (epoch 10 @ 12961 updates, score 11.3) (writing took 1.9134177081286907 seconds)
[2024-07-05 15:14:45,103][fairseq_cli.train][INFO] - end of epoch 10 (average epoch stats below)
[2024-07-05 15:14:45,111][train][INFO] - {"epoch": 10, "train_loss": "98.195", "train_ntokens": "14822.5", "train_nsentences": "80.1898", "train_nll_loss": "0.531", "train_wps": "8364.6", "train_ups": "0.56", "train_wpb": "14822.5", "train_bsz": "80.2", "train_num_updates": "12961", "train_lr": "3e-05", "train_gnorm": "116.927", "train_loss_scale": "8", "train_train_wall": "2258", "train_gb_free": "31.9", "train_wall": "23077"}
[2024-07-05 15:14:45,113][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 15:14:45,375][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 15:14:45,379][fairseq.trainer][INFO] - begin training epoch 11
[2024-07-05 15:14:45,379][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 15:15:53,159][train_inner][INFO] - {"epoch": 11, "update": 10.03, "loss": "97.261", "ntokens": "14792.6", "nsentences": "79.72", "nll_loss": "0.524", "wps": "7706.7", "ups": "0.52", "wpb": "14792.6", "bsz": "79.7", "num_updates": "13000", "lr": "3e-05", "gnorm": "115.527", "loss_scale": "8", "train_wall": "349", "gb_free": "30.9", "wall": "23145"}
[2024-07-05 15:21:42,394][train_inner][INFO] - {"epoch": 11, "update": 10.184, "loss": "92.938", "ntokens": "14820.8", "nsentences": "79.64", "nll_loss": "0.499", "wps": "8489.4", "ups": "0.57", "wpb": "14820.8", "bsz": "79.6", "num_updates": "13200", "lr": "3e-05", "gnorm": "116.066", "loss_scale": "8", "train_wall": "349", "gb_free": "30.5", "wall": "23494"}
[2024-07-05 15:27:33,109][train_inner][INFO] - {"epoch": 11, "update": 10.338, "loss": "93.714", "ntokens": "14731.7", "nsentences": "79.56", "nll_loss": "0.506", "wps": "8401.4", "ups": "0.57", "wpb": "14731.7", "bsz": "79.6", "num_updates": "13400", "lr": "3e-05", "gnorm": "114.347", "loss_scale": "8", "train_wall": "350", "gb_free": "31.5", "wall": "23845"}
[2024-07-05 15:33:22,583][train_inner][INFO] - {"epoch": 11, "update": 10.493, "loss": "94.558", "ntokens": "14827.6", "nsentences": "79.96", "nll_loss": "0.51", "wps": "8487.3", "ups": "0.57", "wpb": "14827.6", "bsz": "80", "num_updates": "13600", "lr": "3e-05", "gnorm": "114.297", "loss_scale": "8", "train_wall": "349", "gb_free": "33", "wall": "24194"}
[2024-07-05 15:39:17,378][train_inner][INFO] - {"epoch": 11, "update": 10.647, "loss": "95.745", "ntokens": "14830.8", "nsentences": "80.28", "nll_loss": "0.518", "wps": "8360.9", "ups": "0.56", "wpb": "14830.8", "bsz": "80.3", "num_updates": "13800", "lr": "3e-05", "gnorm": "119.6", "loss_scale": "8", "train_wall": "354", "gb_free": "32.3", "wall": "24549"}
[2024-07-05 15:45:18,728][train_inner][INFO] - {"epoch": 11, "update": 10.801, "loss": "92.675", "ntokens": "14811.8", "nsentences": "81.28", "nll_loss": "0.509", "wps": "8199.4", "ups": "0.55", "wpb": "14811.8", "bsz": "81.3", "num_updates": "14000", "lr": "3e-05", "gnorm": "112.537", "loss_scale": "8", "train_wall": "361", "gb_free": "32.1", "wall": "24910"}
[2024-07-05 15:51:05,435][train_inner][INFO] - {"epoch": 11, "update": 10.955, "loss": "93.565", "ntokens": "14901.4", "nsentences": "80.91", "nll_loss": "0.508", "wps": "8604.5", "ups": "0.58", "wpb": "14901.4", "bsz": "80.9", "num_updates": "14200", "lr": "3e-05", "gnorm": "115.176", "loss_scale": "8", "train_wall": "346", "gb_free": "32", "wall": "25257"}
[2024-07-05 15:52:46,831][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 15:52:46,869][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 15:53:19,230][dev-other][INFO] - {"epoch": 11, "dev-other_loss": "24.215", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.257", "dev-other_uer": "4.047", "dev-other_wer": "11.06", "dev-other_raw_wer": "11.06", "dev-other_wps": "8656.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "14258", "dev-other_best_wer": "11.06"}
[2024-07-05 15:53:19,230][fairseq_cli.train][INFO] - end of epoch 11 (average epoch stats below)
[2024-07-05 15:53:19,234][train][INFO] - {"epoch": 11, "train_loss": "93.743", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.507", "train_wps": "8307.8", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "14258", "train_lr": "3e-05", "train_gnorm": "115.252", "train_loss_scale": "8", "train_train_wall": "2277", "train_gb_free": "32.6", "train_wall": "25391"}
[2024-07-05 15:53:19,235][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 15:53:19,729][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 15:53:19,735][fairseq.trainer][INFO] - begin training epoch 12
[2024-07-05 15:53:19,735][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 15:57:26,340][train_inner][INFO] - {"epoch": 12, "update": 11.109, "loss": "89.544", "ntokens": "14846.9", "nsentences": "80.36", "nll_loss": "0.485", "wps": "7799.4", "ups": "0.53", "wpb": "14846.9", "bsz": "80.4", "num_updates": "14400", "lr": "3e-05", "gnorm": "113.945", "loss_scale": "8", "train_wall": "347", "gb_free": "33.1", "wall": "25638"}
[2024-07-05 16:03:15,746][train_inner][INFO] - {"epoch": 12, "update": 11.264, "loss": "93.759", "ntokens": "14701.4", "nsentences": "77.96", "nll_loss": "0.497", "wps": "8418.5", "ups": "0.57", "wpb": "14701.4", "bsz": "78", "num_updates": "14600", "lr": "3e-05", "gnorm": "116.839", "loss_scale": "8", "train_wall": "349", "gb_free": "33.3", "wall": "25987"}
[2024-07-05 16:09:09,279][train_inner][INFO] - {"epoch": 12, "update": 11.418, "loss": "95.093", "ntokens": "14749.1", "nsentences": "78.48", "nll_loss": "0.506", "wps": "8345.4", "ups": "0.57", "wpb": "14749.1", "bsz": "78.5", "num_updates": "14800", "lr": "3e-05", "gnorm": "115.275", "loss_scale": "8", "train_wall": "353", "gb_free": "31.9", "wall": "26341"}
[2024-07-05 16:15:01,275][train_inner][INFO] - {"epoch": 12, "update": 11.572, "loss": "88.413", "ntokens": "14817.5", "nsentences": "80.64", "nll_loss": "0.481", "wps": "8420.9", "ups": "0.57", "wpb": "14817.5", "bsz": "80.6", "num_updates": "15000", "lr": "3e-05", "gnorm": "112.237", "loss_scale": "16", "train_wall": "351", "gb_free": "32.7", "wall": "26693"}
[2024-07-05 16:20:48,608][train_inner][INFO] - {"epoch": 12, "update": 11.726, "loss": "92.155", "ntokens": "14916", "nsentences": "81.36", "nll_loss": "0.503", "wps": "8590.6", "ups": "0.58", "wpb": "14916", "bsz": "81.4", "num_updates": "15200", "lr": "3e-05", "gnorm": "112.91", "loss_scale": "16", "train_wall": "347", "gb_free": "33.1", "wall": "27040"}
[2024-07-05 16:26:35,828][train_inner][INFO] - {"epoch": 12, "update": 11.88, "loss": "88.628", "ntokens": "14929.6", "nsentences": "82.04", "nll_loss": "0.487", "wps": "8601.3", "ups": "0.58", "wpb": "14929.6", "bsz": "82", "num_updates": "15400", "lr": "3e-05", "gnorm": "109.992", "loss_scale": "16", "train_wall": "347", "gb_free": "32.7", "wall": "27387"}
[2024-07-05 16:31:06,514][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 16:31:06,566][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 16:31:38,532][dev-other][INFO] - {"epoch": 12, "dev-other_loss": "24.339", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.259", "dev-other_uer": "3.995", "dev-other_wer": "10.852", "dev-other_raw_wer": "10.852", "dev-other_wps": "8730.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "15555", "dev-other_best_wer": "10.852"}
[2024-07-05 16:31:38,533][fairseq_cli.train][INFO] - end of epoch 12 (average epoch stats below)
[2024-07-05 16:31:38,537][train][INFO] - {"epoch": 12, "train_loss": "91.501", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.495", "train_wps": "8361.4", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "15555", "train_lr": "3e-05", "train_gnorm": "113.764", "train_loss_scale": "16", "train_train_wall": "2262", "train_gb_free": "30.3", "train_wall": "27690"}
[2024-07-05 16:31:38,539][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 16:31:39,146][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 16:31:39,155][fairseq.trainer][INFO] - begin training epoch 13
[2024-07-05 16:31:39,155][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 16:33:01,080][train_inner][INFO] - {"epoch": 13, "update": 12.035, "loss": "93.471", "ntokens": "14858.2", "nsentences": "79.46", "nll_loss": "0.5", "wps": "7714.9", "ups": "0.52", "wpb": "14858.2", "bsz": "79.5", "num_updates": "15600", "lr": "3e-05", "gnorm": "115.15", "loss_scale": "16", "train_wall": "352", "gb_free": "32.1", "wall": "27773"}
[2024-07-05 16:38:53,953][train_inner][INFO] - {"epoch": 13, "update": 12.189, "loss": "87.498", "ntokens": "14808.4", "nsentences": "81.28", "nll_loss": "0.48", "wps": "8394.9", "ups": "0.57", "wpb": "14808.4", "bsz": "81.3", "num_updates": "15800", "lr": "3e-05", "gnorm": "114.372", "loss_scale": "16", "train_wall": "352", "gb_free": "31.3", "wall": "28126"}
[2024-07-05 16:44:43,155][train_inner][INFO] - {"epoch": 13, "update": 12.343, "loss": "90.551", "ntokens": "14827.1", "nsentences": "80.16", "nll_loss": "0.49", "wps": "8492.3", "ups": "0.57", "wpb": "14827.1", "bsz": "80.2", "num_updates": "16000", "lr": "3e-05", "gnorm": "112.709", "loss_scale": "16", "train_wall": "349", "gb_free": "32.4", "wall": "28475"}
[2024-07-05 16:50:37,404][train_inner][INFO] - {"epoch": 13, "update": 12.497, "loss": "90.114", "ntokens": "14822.5", "nsentences": "79.12", "nll_loss": "0.481", "wps": "8370.3", "ups": "0.56", "wpb": "14822.5", "bsz": "79.1", "num_updates": "16200", "lr": "3e-05", "gnorm": "111.565", "loss_scale": "16", "train_wall": "354", "gb_free": "31.9", "wall": "28829"}
[2024-07-05 16:56:26,460][train_inner][INFO] - {"epoch": 13, "update": 12.652, "loss": "88.126", "ntokens": "14856.6", "nsentences": "81.28", "nll_loss": "0.482", "wps": "8513", "ups": "0.57", "wpb": "14856.6", "bsz": "81.3", "num_updates": "16400", "lr": "3e-05", "gnorm": "112.065", "loss_scale": "16", "train_wall": "348", "gb_free": "33", "wall": "29178"}
[2024-07-05 17:02:08,747][train_inner][INFO] - {"epoch": 13, "update": 12.806, "loss": "89.574", "ntokens": "14799.2", "nsentences": "79.52", "nll_loss": "0.481", "wps": "8649", "ups": "0.58", "wpb": "14799.2", "bsz": "79.5", "num_updates": "16600", "lr": "3e-05", "gnorm": "114.725", "loss_scale": "16", "train_wall": "342", "gb_free": "32.6", "wall": "29520"}
[2024-07-05 17:08:02,235][train_inner][INFO] - {"epoch": 13, "update": 12.96, "loss": "91.482", "ntokens": "14788.7", "nsentences": "80.88", "nll_loss": "0.5", "wps": "8368.9", "ups": "0.57", "wpb": "14788.7", "bsz": "80.9", "num_updates": "16800", "lr": "3e-05", "gnorm": "113.948", "loss_scale": "16", "train_wall": "353", "gb_free": "30.1", "wall": "29874"}
[2024-07-05 17:09:31,567][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 17:09:31,579][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 17:10:03,768][dev-other][INFO] - {"epoch": 13, "dev-other_loss": "23.99", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.255", "dev-other_uer": "3.98", "dev-other_wer": "10.801", "dev-other_raw_wer": "10.801", "dev-other_wps": "8673.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "16852", "dev-other_best_wer": "10.801"}
[2024-07-05 17:10:03,769][fairseq_cli.train][INFO] - end of epoch 13 (average epoch stats below)
[2024-07-05 17:10:03,776][train][INFO] - {"epoch": 13, "train_loss": "89.701", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.485", "train_wps": "8339.8", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "16852", "train_lr": "3e-05", "train_gnorm": "113.227", "train_loss_scale": "16", "train_train_wall": "2268", "train_gb_free": "31.8", "train_wall": "29995"}
[2024-07-05 17:10:03,778][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 17:10:04,381][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 17:10:04,385][fairseq.trainer][INFO] - begin training epoch 14
[2024-07-05 17:10:04,385][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 17:13:38,500][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-05 17:14:23,693][train_inner][INFO] - {"epoch": 14, "update": 13.115, "loss": "92.084", "ntokens": "14705.5", "nsentences": "77.6", "nll_loss": "0.486", "wps": "7711.4", "ups": "0.52", "wpb": "14705.5", "bsz": "77.6", "num_updates": "17000", "lr": "3e-05", "gnorm": "116.3", "loss_scale": "16", "train_wall": "348", "gb_free": "30", "wall": "30255"}
[2024-07-05 17:20:15,053][train_inner][INFO] - {"epoch": 14, "update": 13.269, "loss": "89.741", "ntokens": "14848.9", "nsentences": "79.6", "nll_loss": "0.481", "wps": "8453.8", "ups": "0.57", "wpb": "14848.9", "bsz": "79.6", "num_updates": "17200", "lr": "3e-05", "gnorm": "114.592", "loss_scale": "16", "train_wall": "351", "gb_free": "32.9", "wall": "30607"}
[2024-07-05 17:26:02,510][train_inner][INFO] - {"epoch": 14, "update": 13.423, "loss": "88.829", "ntokens": "14809.1", "nsentences": "79.92", "nll_loss": "0.479", "wps": "8526.8", "ups": "0.58", "wpb": "14809.1", "bsz": "79.9", "num_updates": "17400", "lr": "3e-05", "gnorm": "112.404", "loss_scale": "16", "train_wall": "347", "gb_free": "32", "wall": "30954"}
[2024-07-05 17:31:58,303][train_inner][INFO] - {"epoch": 14, "update": 13.577, "loss": "89.784", "ntokens": "14749.1", "nsentences": "79.35", "nll_loss": "0.483", "wps": "8294.1", "ups": "0.56", "wpb": "14749.1", "bsz": "79.4", "num_updates": "17600", "lr": "3e-05", "gnorm": "111.821", "loss_scale": "16", "train_wall": "355", "gb_free": "30.1", "wall": "31310"}
[2024-07-05 17:37:49,214][train_inner][INFO] - {"epoch": 14, "update": 13.732, "loss": "89.102", "ntokens": "14860.4", "nsentences": "81.48", "nll_loss": "0.489", "wps": "8471.4", "ups": "0.57", "wpb": "14860.4", "bsz": "81.5", "num_updates": "17800", "lr": "3e-05", "gnorm": "115.709", "loss_scale": "16", "train_wall": "350", "gb_free": "31.9", "wall": "31661"}
[2024-07-05 17:43:40,117][train_inner][INFO] - {"epoch": 14, "update": 13.886, "loss": "84.327", "ntokens": "14860.8", "nsentences": "81.64", "nll_loss": "0.463", "wps": "8471.8", "ups": "0.57", "wpb": "14860.8", "bsz": "81.6", "num_updates": "18000", "lr": "3e-05", "gnorm": "109.945", "loss_scale": "16", "train_wall": "350", "gb_free": "31.6", "wall": "32012"}
[2024-07-05 17:47:58,406][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 17:47:58,478][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 17:48:30,593][dev-other][INFO] - {"epoch": 14, "dev-other_loss": "24.043", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.256", "dev-other_uer": "3.913", "dev-other_wer": "10.442", "dev-other_raw_wer": "10.442", "dev-other_wps": "8723.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "18148", "dev-other_best_wer": "10.442"}
[2024-07-05 17:48:30,594][fairseq_cli.train][INFO] - end of epoch 14 (average epoch stats below)
[2024-07-05 17:48:30,605][train][INFO] - {"epoch": 14, "train_loss": "88.692", "train_ntokens": "14823.4", "train_nsentences": "80.1898", "train_nll_loss": "0.48", "train_wps": "8328", "train_ups": "0.56", "train_wpb": "14823.4", "train_bsz": "80.2", "train_num_updates": "18148", "train_lr": "3e-05", "train_gnorm": "112.973", "train_loss_scale": "16", "train_train_wall": "2270", "train_gb_free": "32.3", "train_wall": "32302"}
[2024-07-05 17:48:30,606][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 17:48:31,211][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 17:48:31,214][fairseq.trainer][INFO] - begin training epoch 15
[2024-07-05 17:48:31,215][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 17:50:03,402][train_inner][INFO] - {"epoch": 15, "update": 14.04, "loss": "87.257", "ntokens": "14906.5", "nsentences": "80.6", "nll_loss": "0.472", "wps": "7779.8", "ups": "0.52", "wpb": "14906.5", "bsz": "80.6", "num_updates": "18200", "lr": "3e-05", "gnorm": "110.143", "loss_scale": "16", "train_wall": "349", "gb_free": "32", "wall": "32395"}
[2024-07-05 17:55:58,458][train_inner][INFO] - {"epoch": 15, "update": 14.194, "loss": "85.018", "ntokens": "14875.6", "nsentences": "79.88", "nll_loss": "0.457", "wps": "8381.6", "ups": "0.56", "wpb": "14875.6", "bsz": "79.9", "num_updates": "18400", "lr": "3e-05", "gnorm": "109.943", "loss_scale": "16", "train_wall": "354", "gb_free": "32.7", "wall": "32750"}
[2024-07-05 18:01:49,534][train_inner][INFO] - {"epoch": 15, "update": 14.348, "loss": "87.585", "ntokens": "14726.1", "nsentences": "78.28", "nll_loss": "0.466", "wps": "8390.8", "ups": "0.57", "wpb": "14726.1", "bsz": "78.3", "num_updates": "18600", "lr": "3e-05", "gnorm": "112.62", "loss_scale": "16", "train_wall": "350", "gb_free": "32.6", "wall": "33101"}
[2024-07-05 18:06:56,530][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-05 18:07:39,514][train_inner][INFO] - {"epoch": 15, "update": 14.503, "loss": "84.171", "ntokens": "14870.1", "nsentences": "82.51", "nll_loss": "0.467", "wps": "8499.3", "ups": "0.57", "wpb": "14870.1", "bsz": "82.5", "num_updates": "18800", "lr": "3e-05", "gnorm": "109.081", "loss_scale": "8", "train_wall": "349", "gb_free": "31.6", "wall": "33451"}
[2024-07-05 18:13:26,041][train_inner][INFO] - {"epoch": 15, "update": 14.658, "loss": "87.781", "ntokens": "14799.3", "nsentences": "80.4", "nll_loss": "0.477", "wps": "8543.2", "ups": "0.58", "wpb": "14799.3", "bsz": "80.4", "num_updates": "19000", "lr": "3e-05", "gnorm": "112.204", "loss_scale": "8", "train_wall": "346", "gb_free": "32.6", "wall": "33798"}
[2024-07-05 18:19:25,925][train_inner][INFO] - {"epoch": 15, "update": 14.812, "loss": "85.35", "ntokens": "14840.8", "nsentences": "79.8", "nll_loss": "0.459", "wps": "8249.2", "ups": "0.56", "wpb": "14840.8", "bsz": "79.8", "num_updates": "19200", "lr": "3e-05", "gnorm": "111.504", "loss_scale": "8", "train_wall": "359", "gb_free": "33", "wall": "34158"}
[2024-07-05 18:25:20,018][train_inner][INFO] - {"epoch": 15, "update": 14.966, "loss": "84.006", "ntokens": "14850.3", "nsentences": "81.24", "nll_loss": "0.46", "wps": "8389.5", "ups": "0.56", "wpb": "14850.3", "bsz": "81.2", "num_updates": "19400", "lr": "3e-05", "gnorm": "110.353", "loss_scale": "8", "train_wall": "353", "gb_free": "32.7", "wall": "34512"}
[2024-07-05 18:26:40,928][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 18:26:40,983][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 18:27:13,191][dev-other][INFO] - {"epoch": 15, "dev-other_loss": "24.138", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.257", "dev-other_uer": "3.956", "dev-other_wer": "10.642", "dev-other_raw_wer": "10.642", "dev-other_wps": "8675", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "19444", "dev-other_best_wer": "10.642"}
[2024-07-05 18:27:13,202][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 15 @ 19444 updates
[2024-07-05 18:27:13,203][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt
[2024-07-05 18:27:14,837][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt
[2024-07-05 18:27:15,370][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt (epoch 15 @ 19444 updates, score 10.642) (writing took 2.1684636250138283 seconds)
[2024-07-05 18:27:15,370][fairseq_cli.train][INFO] - end of epoch 15 (average epoch stats below)
[2024-07-05 18:27:15,374][train][INFO] - {"epoch": 15, "train_loss": "85.565", "train_ntokens": "14822.8", "train_nsentences": "80.196", "train_nll_loss": "0.463", "train_wps": "8263.3", "train_ups": "0.56", "train_wpb": "14822.8", "train_bsz": "80.2", "train_num_updates": "19444", "train_lr": "3e-05", "train_gnorm": "110.942", "train_loss_scale": "8", "train_train_wall": "2285", "train_gb_free": "32.5", "train_wall": "34627"}
[2024-07-05 18:27:15,376][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 18:27:15,599][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 18:27:15,602][fairseq.trainer][INFO] - begin training epoch 16
[2024-07-05 18:27:15,602][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 18:31:55,300][train_inner][INFO] - {"epoch": 16, "update": 15.12, "loss": "86.293", "ntokens": "14809.7", "nsentences": "79.56", "nll_loss": "0.464", "wps": "7494.5", "ups": "0.51", "wpb": "14809.7", "bsz": "79.6", "num_updates": "19600", "lr": "3e-05", "gnorm": "115.281", "loss_scale": "8", "train_wall": "360", "gb_free": "32.4", "wall": "34907"}
[2024-07-05 18:37:52,619][train_inner][INFO] - {"epoch": 16, "update": 15.274, "loss": "85.637", "ntokens": "14744.1", "nsentences": "78.59", "nll_loss": "0.456", "wps": "8254.1", "ups": "0.56", "wpb": "14744.1", "bsz": "78.6", "num_updates": "19800", "lr": "3e-05", "gnorm": "112.037", "loss_scale": "8", "train_wall": "357", "gb_free": "31.4", "wall": "35264"}
[2024-07-05 18:43:46,940][train_inner][INFO] - {"epoch": 16, "update": 15.429, "loss": "83.761", "ntokens": "14897.4", "nsentences": "81.56", "nll_loss": "0.459", "wps": "8409.7", "ups": "0.56", "wpb": "14897.4", "bsz": "81.6", "num_updates": "20000", "lr": "3e-05", "gnorm": "108.318", "loss_scale": "8", "train_wall": "354", "gb_free": "33.2", "wall": "35619"}
[2024-07-05 18:49:36,838][train_inner][INFO] - {"epoch": 16, "update": 15.583, "loss": "86.128", "ntokens": "14799.8", "nsentences": "80.24", "nll_loss": "0.467", "wps": "8459.7", "ups": "0.57", "wpb": "14799.8", "bsz": "80.2", "num_updates": "20200", "lr": "3e-05", "gnorm": "113.247", "loss_scale": "8", "train_wall": "349", "gb_free": "32.6", "wall": "35969"}
[2024-07-05 18:55:26,483][train_inner][INFO] - {"epoch": 16, "update": 15.737, "loss": "87.216", "ntokens": "14847.4", "nsentences": "79.48", "nll_loss": "0.467", "wps": "8494.6", "ups": "0.57", "wpb": "14847.4", "bsz": "79.5", "num_updates": "20400", "lr": "3e-05", "gnorm": "111.199", "loss_scale": "8", "train_wall": "349", "gb_free": "32.4", "wall": "36318"}
[2024-07-05 19:01:20,402][train_inner][INFO] - {"epoch": 16, "update": 15.891, "loss": "83.432", "ntokens": "14751.3", "nsentences": "79.68", "nll_loss": "0.451", "wps": "8338", "ups": "0.57", "wpb": "14751.3", "bsz": "79.7", "num_updates": "20600", "lr": "3e-05", "gnorm": "110.764", "loss_scale": "8", "train_wall": "353", "gb_free": "32.7", "wall": "36672"}
[2024-07-05 19:05:23,612][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 19:05:23,667][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 19:05:55,704][dev-other][INFO] - {"epoch": 16, "dev-other_loss": "24.064", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.256", "dev-other_uer": "3.885", "dev-other_wer": "10.409", "dev-other_raw_wer": "10.409", "dev-other_wps": "8706.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "20741", "dev-other_best_wer": "10.409"}
[2024-07-05 19:05:55,704][fairseq_cli.train][INFO] - end of epoch 16 (average epoch stats below)
[2024-07-05 19:05:55,721][train][INFO] - {"epoch": 16, "train_loss": "85.162", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.461", "train_wps": "8285.6", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "20741", "train_lr": "3e-05", "train_gnorm": "111.778", "train_loss_scale": "8", "train_train_wall": "2284", "train_gb_free": "31.7", "train_wall": "36947"}
[2024-07-05 19:05:55,722][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 19:05:56,320][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 19:05:56,324][fairseq.trainer][INFO] - begin training epoch 17
[2024-07-05 19:05:56,324][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 19:07:36,727][train_inner][INFO] - {"epoch": 17, "update": 16.045, "loss": "83.527", "ntokens": "14896.9", "nsentences": "81.92", "nll_loss": "0.459", "wps": "7917.2", "ups": "0.53", "wpb": "14896.9", "bsz": "81.9", "num_updates": "20800", "lr": "3e-05", "gnorm": "111.346", "loss_scale": "8", "train_wall": "343", "gb_free": "33.5", "wall": "37048"}
[2024-07-05 19:08:43,666][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-05 19:13:34,748][train_inner][INFO] - {"epoch": 17, "update": 16.2, "loss": "84.94", "ntokens": "14903.2", "nsentences": "80.2", "nll_loss": "0.457", "wps": "8327.1", "ups": "0.56", "wpb": "14903.2", "bsz": "80.2", "num_updates": "21000", "lr": "3e-05", "gnorm": "109.557", "loss_scale": "8", "train_wall": "357", "gb_free": "31.5", "wall": "37406"}
[2024-07-05 19:19:29,729][train_inner][INFO] - {"epoch": 17, "update": 16.355, "loss": "84.32", "ntokens": "14738.9", "nsentences": "79.2", "nll_loss": "0.453", "wps": "8305.6", "ups": "0.56", "wpb": "14738.9", "bsz": "79.2", "num_updates": "21200", "lr": "3e-05", "gnorm": "109.861", "loss_scale": "8", "train_wall": "354", "gb_free": "32.6", "wall": "37761"}
[2024-07-05 19:25:15,150][train_inner][INFO] - {"epoch": 17, "update": 16.509, "loss": "83.532", "ntokens": "14874.7", "nsentences": "80.84", "nll_loss": "0.454", "wps": "8612.6", "ups": "0.58", "wpb": "14874.7", "bsz": "80.8", "num_updates": "21400", "lr": "3e-05", "gnorm": "109.637", "loss_scale": "8", "train_wall": "345", "gb_free": "33.1", "wall": "38107"}
[2024-07-05 19:31:08,865][train_inner][INFO] - {"epoch": 17, "update": 16.663, "loss": "80.965", "ntokens": "14922.1", "nsentences": "81.92", "nll_loss": "0.444", "wps": "8437.8", "ups": "0.57", "wpb": "14922.1", "bsz": "81.9", "num_updates": "21600", "lr": "3e-05", "gnorm": "105.837", "loss_scale": "8", "train_wall": "353", "gb_free": "31.3", "wall": "38461"}
[2024-07-05 19:36:54,773][train_inner][INFO] - {"epoch": 17, "update": 16.817, "loss": "86.737", "ntokens": "14692.8", "nsentences": "79.64", "nll_loss": "0.47", "wps": "8495.6", "ups": "0.58", "wpb": "14692.8", "bsz": "79.6", "num_updates": "21800", "lr": "3e-05", "gnorm": "114.044", "loss_scale": "8", "train_wall": "345", "gb_free": "32.2", "wall": "38806"}
[2024-07-05 19:42:46,412][train_inner][INFO] - {"epoch": 17, "update": 16.971, "loss": "86.518", "ntokens": "14797.6", "nsentences": "79.43", "nll_loss": "0.464", "wps": "8416.8", "ups": "0.57", "wpb": "14797.6", "bsz": "79.4", "num_updates": "22000", "lr": "3e-05", "gnorm": "112.307", "loss_scale": "8", "train_wall": "351", "gb_free": "33.1", "wall": "39158"}
[2024-07-05 19:43:47,657][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 19:43:47,658][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 19:44:19,792][dev-other][INFO] - {"epoch": 17, "dev-other_loss": "23.205", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.247", "dev-other_uer": "3.868", "dev-other_wer": "10.442", "dev-other_raw_wer": "10.442", "dev-other_wps": "8707.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "22037", "dev-other_best_wer": "10.442"}
[2024-07-05 19:44:19,793][fairseq_cli.train][INFO] - end of epoch 17 (average epoch stats below)
[2024-07-05 19:44:19,802][train][INFO] - {"epoch": 17, "train_loss": "84.649", "train_ntokens": "14823.7", "train_nsentences": "80.2083", "train_nll_loss": "0.458", "train_wps": "8338.1", "train_ups": "0.56", "train_wpb": "14823.7", "train_bsz": "80.2", "train_num_updates": "22037", "train_lr": "3e-05", "train_gnorm": "110.502", "train_loss_scale": "8", "train_train_wall": "2267", "train_gb_free": "33.5", "train_wall": "39251"}
[2024-07-05 19:44:19,804][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 19:44:20,400][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 19:44:20,404][fairseq.trainer][INFO] - begin training epoch 18
[2024-07-05 19:44:20,404][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 19:49:10,947][train_inner][INFO] - {"epoch": 18, "update": 17.126, "loss": "82.928", "ntokens": "14859.4", "nsentences": "78.88", "nll_loss": "0.44", "wps": "7729.2", "ups": "0.52", "wpb": "14859.4", "bsz": "78.9", "num_updates": "22200", "lr": "3e-05", "gnorm": "110.532", "loss_scale": "8", "train_wall": "351", "gb_free": "32.3", "wall": "39543"}
[2024-07-05 19:55:05,529][train_inner][INFO] - {"epoch": 18, "update": 17.28, "loss": "83.462", "ntokens": "14829.1", "nsentences": "80.11", "nll_loss": "0.451", "wps": "8365.1", "ups": "0.56", "wpb": "14829.1", "bsz": "80.1", "num_updates": "22400", "lr": "3e-05", "gnorm": "108.315", "loss_scale": "8", "train_wall": "354", "gb_free": "32", "wall": "39897"}
[2024-07-05 20:00:48,864][train_inner][INFO] - {"epoch": 18, "update": 17.434, "loss": "83.565", "ntokens": "14839.3", "nsentences": "81.48", "nll_loss": "0.459", "wps": "8645.1", "ups": "0.58", "wpb": "14839.3", "bsz": "81.5", "num_updates": "22600", "lr": "3e-05", "gnorm": "109.497", "loss_scale": "8", "train_wall": "343", "gb_free": "32", "wall": "40241"}
[2024-07-05 20:06:42,404][train_inner][INFO] - {"epoch": 18, "update": 17.588, "loss": "83.731", "ntokens": "14935.4", "nsentences": "81.48", "nll_loss": "0.457", "wps": "8449.3", "ups": "0.57", "wpb": "14935.4", "bsz": "81.5", "num_updates": "22800", "lr": "3e-05", "gnorm": "111.612", "loss_scale": "8", "train_wall": "353", "gb_free": "32.4", "wall": "40594"}
[2024-07-05 20:12:29,042][train_inner][INFO] - {"epoch": 18, "update": 17.742, "loss": "88.728", "ntokens": "14737.7", "nsentences": "78.48", "nll_loss": "0.472", "wps": "8504", "ups": "0.58", "wpb": "14737.7", "bsz": "78.5", "num_updates": "23000", "lr": "3e-05", "gnorm": "115.599", "loss_scale": "16", "train_wall": "346", "gb_free": "32.6", "wall": "40941"}
[2024-07-05 20:18:15,526][train_inner][INFO] - {"epoch": 18, "update": 17.897, "loss": "82.392", "ntokens": "14760.2", "nsentences": "80.64", "nll_loss": "0.45", "wps": "8520.2", "ups": "0.58", "wpb": "14760.2", "bsz": "80.6", "num_updates": "23200", "lr": "3e-05", "gnorm": "110.337", "loss_scale": "16", "train_wall": "346", "gb_free": "33.5", "wall": "41287"}
[2024-07-05 20:22:11,791][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 20:22:11,835][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 20:22:43,807][dev-other][INFO] - {"epoch": 18, "dev-other_loss": "23.39", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.249", "dev-other_uer": "3.767", "dev-other_wer": "10.037", "dev-other_raw_wer": "10.037", "dev-other_wps": "8744.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "23334", "dev-other_best_wer": "10.037"}
[2024-07-05 20:22:43,807][fairseq_cli.train][INFO] - end of epoch 18 (average epoch stats below)
[2024-07-05 20:22:43,814][train][INFO] - {"epoch": 18, "train_loss": "83.837", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.454", "train_wps": "8344.3", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "23334", "train_lr": "3e-05", "train_gnorm": "110.725", "train_loss_scale": "16", "train_train_wall": "2268", "train_gb_free": "33.6", "train_wall": "41555"}
[2024-07-05 20:22:43,816][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 20:22:44,394][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 20:22:44,397][fairseq.trainer][INFO] - begin training epoch 19
[2024-07-05 20:22:44,398][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 20:24:41,559][train_inner][INFO] - {"epoch": 19, "update": 18.051, "loss": "81.072", "ntokens": "14863.9", "nsentences": "81.19", "nll_loss": "0.443", "wps": "7701", "ups": "0.52", "wpb": "14863.9", "bsz": "81.2", "num_updates": "23400", "lr": "3e-05", "gnorm": "108.159", "loss_scale": "16", "train_wall": "353", "gb_free": "32.2", "wall": "41673"}
[2024-07-05 20:30:33,273][train_inner][INFO] - {"epoch": 19, "update": 18.205, "loss": "80.985", "ntokens": "14800.5", "nsentences": "79.88", "nll_loss": "0.437", "wps": "8416.4", "ups": "0.57", "wpb": "14800.5", "bsz": "79.9", "num_updates": "23600", "lr": "3e-05", "gnorm": "110.24", "loss_scale": "16", "train_wall": "351", "gb_free": "32.3", "wall": "42025"}
[2024-07-05 20:36:32,102][train_inner][INFO] - {"epoch": 19, "update": 18.359, "loss": "78.639", "ntokens": "14855.7", "nsentences": "80.64", "nll_loss": "0.427", "wps": "8280.4", "ups": "0.56", "wpb": "14855.7", "bsz": "80.6", "num_updates": "23800", "lr": "3e-05", "gnorm": "107.643", "loss_scale": "16", "train_wall": "358", "gb_free": "33.5", "wall": "42384"}
[2024-07-05 20:42:23,818][train_inner][INFO] - {"epoch": 19, "update": 18.513, "loss": "82.894", "ntokens": "14774.6", "nsentences": "79.36", "nll_loss": "0.445", "wps": "8403.1", "ups": "0.57", "wpb": "14774.6", "bsz": "79.4", "num_updates": "24000", "lr": "3e-05", "gnorm": "109.167", "loss_scale": "16", "train_wall": "351", "gb_free": "31.3", "wall": "42735"}
[2024-07-05 20:48:10,838][train_inner][INFO] - {"epoch": 19, "update": 18.668, "loss": "82.636", "ntokens": "14753.9", "nsentences": "79.6", "nll_loss": "0.446", "wps": "8505.4", "ups": "0.58", "wpb": "14753.9", "bsz": "79.6", "num_updates": "24200", "lr": "3e-05", "gnorm": "110.146", "loss_scale": "16", "train_wall": "346", "gb_free": "33.7", "wall": "43082"}
[2024-07-05 20:54:00,791][train_inner][INFO] - {"epoch": 19, "update": 18.822, "loss": "82.642", "ntokens": "14915.3", "nsentences": "81.28", "nll_loss": "0.45", "wps": "8527.8", "ups": "0.57", "wpb": "14915.3", "bsz": "81.3", "num_updates": "24400", "lr": "3e-05", "gnorm": "110.53", "loss_scale": "16", "train_wall": "349", "gb_free": "31.6", "wall": "43432"}
[2024-07-05 20:59:56,639][train_inner][INFO] - {"epoch": 19, "update": 18.976, "loss": "81.531", "ntokens": "14741", "nsentences": "79.16", "nll_loss": "0.438", "wps": "8285.7", "ups": "0.56", "wpb": "14741", "bsz": "79.2", "num_updates": "24600", "lr": "3e-05", "gnorm": "110.008", "loss_scale": "16", "train_wall": "355", "gb_free": "31.9", "wall": "43788"}
[2024-07-05 21:00:52,163][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 21:00:52,164][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 21:01:24,335][dev-other][INFO] - {"epoch": 19, "dev-other_loss": "24.064", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.256", "dev-other_uer": "3.748", "dev-other_wer": "9.967", "dev-other_raw_wer": "9.967", "dev-other_wps": "8694.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "24631", "dev-other_best_wer": "9.967"}
[2024-07-05 21:01:24,354][fairseq_cli.train][INFO] - end of epoch 19 (average epoch stats below)
[2024-07-05 21:01:24,363][train][INFO] - {"epoch": 19, "train_loss": "81.315", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.44", "train_wps": "8284.8", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "24631", "train_lr": "3e-05", "train_gnorm": "109.216", "train_loss_scale": "16", "train_train_wall": "2284", "train_gb_free": "31.9", "train_wall": "43876"}
[2024-07-05 21:01:24,364][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 21:01:24,950][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 21:01:24,955][fairseq.trainer][INFO] - begin training epoch 20
[2024-07-05 21:01:24,956][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 21:04:58,317][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-05 21:06:23,064][train_inner][INFO] - {"epoch": 20, "update": 19.131, "loss": "79.081", "ntokens": "14860", "nsentences": "81.72", "nll_loss": "0.435", "wps": "7691.3", "ups": "0.52", "wpb": "14860", "bsz": "81.7", "num_updates": "24800", "lr": "3e-05", "gnorm": "106.442", "loss_scale": "8", "train_wall": "353", "gb_free": "32.9", "wall": "44175"}
[2024-07-05 21:12:20,072][train_inner][INFO] - {"epoch": 20, "update": 19.285, "loss": "81.449", "ntokens": "14829.4", "nsentences": "80.6", "nll_loss": "0.443", "wps": "8309.5", "ups": "0.56", "wpb": "14829.4", "bsz": "80.6", "num_updates": "25000", "lr": "3e-05", "gnorm": "108.608", "loss_scale": "8", "train_wall": "356", "gb_free": "31.9", "wall": "44532"}
[2024-07-05 21:18:16,153][train_inner][INFO] - {"epoch": 20, "update": 19.439, "loss": "79.57", "ntokens": "14837.3", "nsentences": "81.84", "nll_loss": "0.439", "wps": "8335.3", "ups": "0.56", "wpb": "14837.3", "bsz": "81.8", "num_updates": "25200", "lr": "3e-05", "gnorm": "106.39", "loss_scale": "8", "train_wall": "355", "gb_free": "31.1", "wall": "44888"}
[2024-07-05 21:24:10,161][train_inner][INFO] - {"epoch": 20, "update": 19.594, "loss": "81.829", "ntokens": "14682.6", "nsentences": "77.43", "nll_loss": "0.432", "wps": "8296.6", "ups": "0.57", "wpb": "14682.6", "bsz": "77.4", "num_updates": "25400", "lr": "3e-05", "gnorm": "112.866", "loss_scale": "8", "train_wall": "353", "gb_free": "31.2", "wall": "45242"}
[2024-07-05 21:29:57,318][train_inner][INFO] - {"epoch": 20, "update": 19.748, "loss": "84.753", "ntokens": "14869.8", "nsentences": "80.76", "nll_loss": "0.46", "wps": "8568.5", "ups": "0.58", "wpb": "14869.8", "bsz": "80.8", "num_updates": "25600", "lr": "3e-05", "gnorm": "110.497", "loss_scale": "8", "train_wall": "347", "gb_free": "31.9", "wall": "45589"}
[2024-07-05 21:35:50,851][train_inner][INFO] - {"epoch": 20, "update": 19.902, "loss": "81.771", "ntokens": "14897.9", "nsentences": "80.44", "nll_loss": "0.442", "wps": "8428.2", "ups": "0.57", "wpb": "14897.9", "bsz": "80.4", "num_updates": "25800", "lr": "3e-05", "gnorm": "108.64", "loss_scale": "8", "train_wall": "353", "gb_free": "31.9", "wall": "45943"}
[2024-07-05 21:39:34,892][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 21:39:34,947][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 21:40:07,051][dev-other][INFO] - {"epoch": 20, "dev-other_loss": "23.208", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.247", "dev-other_uer": "3.775", "dev-other_wer": "10.061", "dev-other_raw_wer": "10.061", "dev-other_wps": "8682.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "25927", "dev-other_best_wer": "10.061"}
[2024-07-05 21:40:07,053][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 20 @ 25927 updates
[2024-07-05 21:40:07,054][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt
[2024-07-05 21:40:09,065][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt
[2024-07-05 21:40:09,574][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt (epoch 20 @ 25927 updates, score 10.061) (writing took 2.521777883172035 seconds)
[2024-07-05 21:40:09,575][fairseq_cli.train][INFO] - end of epoch 20 (average epoch stats below)
[2024-07-05 21:40:09,580][train][INFO] - {"epoch": 20, "train_loss": "81.526", "train_ntokens": "14823.1", "train_nsentences": "80.2022", "train_nll_loss": "0.441", "train_wps": "8261.9", "train_ups": "0.56", "train_wpb": "14823.1", "train_bsz": "80.2", "train_num_updates": "25927", "train_lr": "3e-05", "train_gnorm": "109.125", "train_loss_scale": "8", "train_train_wall": "2286", "train_gb_free": "31.8", "train_wall": "46201"}
[2024-07-05 21:40:09,581][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 21:40:09,808][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 21:40:09,812][fairseq.trainer][INFO] - begin training epoch 21
[2024-07-05 21:40:09,812][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 21:42:18,416][train_inner][INFO] - {"epoch": 21, "update": 20.056, "loss": "84.417", "ntokens": "14784.2", "nsentences": "78.68", "nll_loss": "0.449", "wps": "7629.4", "ups": "0.52", "wpb": "14784.2", "bsz": "78.7", "num_updates": "26000", "lr": "3e-05", "gnorm": "112.398", "loss_scale": "8", "train_wall": "352", "gb_free": "32.1", "wall": "46330"}
[2024-07-05 21:48:04,913][train_inner][INFO] - {"epoch": 21, "update": 20.21, "loss": "81.278", "ntokens": "14834.2", "nsentences": "81", "nll_loss": "0.444", "wps": "8562.9", "ups": "0.58", "wpb": "14834.2", "bsz": "81", "num_updates": "26200", "lr": "3e-05", "gnorm": "109.285", "loss_scale": "8", "train_wall": "346", "gb_free": "33.1", "wall": "46677"}
[2024-07-05 21:54:00,381][train_inner][INFO] - {"epoch": 21, "update": 20.365, "loss": "79.013", "ntokens": "14862", "nsentences": "79.84", "nll_loss": "0.424", "wps": "8366.9", "ups": "0.56", "wpb": "14862", "bsz": "79.8", "num_updates": "26400", "lr": "3e-05", "gnorm": "108.029", "loss_scale": "8", "train_wall": "355", "gb_free": "31.1", "wall": "47032"}
[2024-07-05 21:59:58,786][train_inner][INFO] - {"epoch": 21, "update": 20.519, "loss": "80.064", "ntokens": "14807.8", "nsentences": "79.19", "nll_loss": "0.428", "wps": "8264.7", "ups": "0.56", "wpb": "14807.8", "bsz": "79.2", "num_updates": "26600", "lr": "3e-05", "gnorm": "108.085", "loss_scale": "8", "train_wall": "358", "gb_free": "32.8", "wall": "47390"}
[2024-07-05 22:05:55,846][train_inner][INFO] - {"epoch": 21, "update": 20.673, "loss": "77.099", "ntokens": "14806.8", "nsentences": "80.36", "nll_loss": "0.418", "wps": "8294", "ups": "0.56", "wpb": "14806.8", "bsz": "80.4", "num_updates": "26800", "lr": "3e-05", "gnorm": "105.579", "loss_scale": "16", "train_wall": "356", "gb_free": "32.2", "wall": "47748"}
[2024-07-05 22:11:42,698][train_inner][INFO] - {"epoch": 21, "update": 20.827, "loss": "82.11", "ntokens": "14762.6", "nsentences": "80.28", "nll_loss": "0.447", "wps": "8513.9", "ups": "0.58", "wpb": "14762.6", "bsz": "80.3", "num_updates": "27000", "lr": "3e-05", "gnorm": "110.638", "loss_scale": "16", "train_wall": "346", "gb_free": "31.7", "wall": "48094"}
[2024-07-05 22:17:36,095][train_inner][INFO] - {"epoch": 21, "update": 20.981, "loss": "78.039", "ntokens": "14900.7", "nsentences": "81.4", "nll_loss": "0.426", "wps": "8434.6", "ups": "0.57", "wpb": "14900.7", "bsz": "81.4", "num_updates": "27200", "lr": "3e-05", "gnorm": "106.591", "loss_scale": "16", "train_wall": "353", "gb_free": "31.8", "wall": "48448"}
[2024-07-05 22:18:18,691][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 22:18:18,692][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 22:18:50,799][dev-other][INFO] - {"epoch": 21, "dev-other_loss": "23.385", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.249", "dev-other_uer": "3.826", "dev-other_wer": "10.155", "dev-other_raw_wer": "10.155", "dev-other_wps": "8724.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "27224", "dev-other_best_wer": "10.061"}
[2024-07-05 22:18:50,799][fairseq_cli.train][INFO] - end of epoch 21 (average epoch stats below)
[2024-07-05 22:18:50,804][train][INFO] - {"epoch": 21, "train_loss": "80.239", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.434", "train_wps": "8282.4", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "27224", "train_lr": "3e-05", "train_gnorm": "108.592", "train_loss_scale": "16", "train_train_wall": "2285", "train_gb_free": "30", "train_wall": "48522"}
[2024-07-05 22:18:50,805][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 22:18:51,397][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 22:18:51,400][fairseq.trainer][INFO] - begin training epoch 22
[2024-07-05 22:18:51,400][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 22:24:01,160][train_inner][INFO] - {"epoch": 22, "update": 21.136, "loss": "79.506", "ntokens": "14829.2", "nsentences": "80.32", "nll_loss": "0.431", "wps": "7702.4", "ups": "0.52", "wpb": "14829.2", "bsz": "80.3", "num_updates": "27400", "lr": "3e-05", "gnorm": "108.209", "loss_scale": "16", "train_wall": "352", "gb_free": "33.5", "wall": "48833"}
[2024-07-05 22:29:51,971][train_inner][INFO] - {"epoch": 22, "update": 21.29, "loss": "79.744", "ntokens": "14826.2", "nsentences": "80.4", "nll_loss": "0.432", "wps": "8454.2", "ups": "0.57", "wpb": "14826.2", "bsz": "80.4", "num_updates": "27600", "lr": "3e-05", "gnorm": "109.58", "loss_scale": "16", "train_wall": "350", "gb_free": "30.9", "wall": "49184"}
[2024-07-05 22:35:33,730][train_inner][INFO] - {"epoch": 22, "update": 21.444, "loss": "80.255", "ntokens": "14793.5", "nsentences": "80.67", "nll_loss": "0.438", "wps": "8657.5", "ups": "0.59", "wpb": "14793.5", "bsz": "80.7", "num_updates": "27800", "lr": "3e-05", "gnorm": "110.414", "loss_scale": "16", "train_wall": "341", "gb_free": "32.9", "wall": "49525"}
[2024-07-05 22:41:23,081][train_inner][INFO] - {"epoch": 22, "update": 21.598, "loss": "79.322", "ntokens": "14776.9", "nsentences": "80.04", "nll_loss": "0.43", "wps": "8461.1", "ups": "0.57", "wpb": "14776.9", "bsz": "80", "num_updates": "28000", "lr": "3e-05", "gnorm": "109.047", "loss_scale": "16", "train_wall": "349", "gb_free": "32.9", "wall": "49875"}
[2024-07-05 22:47:22,535][train_inner][INFO] - {"epoch": 22, "update": 21.753, "loss": "82.049", "ntokens": "14857.9", "nsentences": "79.28", "nll_loss": "0.438", "wps": "8268.5", "ups": "0.56", "wpb": "14857.9", "bsz": "79.3", "num_updates": "28200", "lr": "3e-05", "gnorm": "110.932", "loss_scale": "16", "train_wall": "359", "gb_free": "31.9", "wall": "50234"}
[2024-07-05 22:53:11,807][train_inner][INFO] - {"epoch": 22, "update": 21.907, "loss": "82.868", "ntokens": "14854.1", "nsentences": "80.68", "nll_loss": "0.45", "wps": "8507.9", "ups": "0.57", "wpb": "14854.1", "bsz": "80.7", "num_updates": "28400", "lr": "3e-05", "gnorm": "112.19", "loss_scale": "16", "train_wall": "349", "gb_free": "33.1", "wall": "50583"}
[2024-07-05 22:56:37,105][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 22:56:37,167][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 22:57:09,294][dev-other][INFO] - {"epoch": 22, "dev-other_loss": "23.077", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.245", "dev-other_uer": "3.768", "dev-other_wer": "10.036", "dev-other_raw_wer": "10.036", "dev-other_wps": "8686.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "28521", "dev-other_best_wer": "10.036"}
[2024-07-05 22:57:09,295][fairseq_cli.train][INFO] - end of epoch 22 (average epoch stats below)
[2024-07-05 22:57:09,300][train][INFO] - {"epoch": 22, "train_loss": "80.962", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.438", "train_wps": "8364.3", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "28521", "train_lr": "3e-05", "train_gnorm": "110.341", "train_loss_scale": "16", "train_train_wall": "2262", "train_gb_free": "31.4", "train_wall": "50821"}
[2024-07-05 22:57:09,302][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 22:57:09,903][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 22:57:09,907][fairseq.trainer][INFO] - begin training epoch 23
[2024-07-05 22:57:09,907][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 22:58:32,028][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-05 22:59:33,432][train_inner][INFO] - {"epoch": 23, "update": 22.062, "loss": "83.425", "ntokens": "14899", "nsentences": "79.64", "nll_loss": "0.446", "wps": "7808.4", "ups": "0.52", "wpb": "14899", "bsz": "79.6", "num_updates": "28600", "lr": "3e-05", "gnorm": "110.402", "loss_scale": "8", "train_wall": "348", "gb_free": "31.6", "wall": "50965"}
[2024-07-05 23:05:22,283][train_inner][INFO] - {"epoch": 23, "update": 22.216, "loss": "82.407", "ntokens": "14672.4", "nsentences": "78.64", "nll_loss": "0.442", "wps": "8413.4", "ups": "0.57", "wpb": "14672.4", "bsz": "78.6", "num_updates": "28800", "lr": "3e-05", "gnorm": "113.117", "loss_scale": "8", "train_wall": "348", "gb_free": "31.5", "wall": "51314"}
[2024-07-05 23:11:11,704][train_inner][INFO] - {"epoch": 23, "update": 22.37, "loss": "80.405", "ntokens": "14826", "nsentences": "78.64", "nll_loss": "0.426", "wps": "8487.8", "ups": "0.57", "wpb": "14826", "bsz": "78.6", "num_updates": "29000", "lr": "3e-05", "gnorm": "111.111", "loss_scale": "8", "train_wall": "349", "gb_free": "32.4", "wall": "51663"}
[2024-07-05 23:16:57,352][train_inner][INFO] - {"epoch": 23, "update": 22.524, "loss": "78.447", "ntokens": "14874.3", "nsentences": "81.2", "nll_loss": "0.428", "wps": "8608.5", "ups": "0.58", "wpb": "14874.3", "bsz": "81.2", "num_updates": "29200", "lr": "3e-05", "gnorm": "108.301", "loss_scale": "8", "train_wall": "345", "gb_free": "32.3", "wall": "52009"}
[2024-07-05 23:22:46,907][train_inner][INFO] - {"epoch": 23, "update": 22.678, "loss": "79.022", "ntokens": "14835.7", "nsentences": "80.76", "nll_loss": "0.43", "wps": "8489.9", "ups": "0.57", "wpb": "14835.7", "bsz": "80.8", "num_updates": "29400", "lr": "3e-05", "gnorm": "108.719", "loss_scale": "8", "train_wall": "349", "gb_free": "32.3", "wall": "52359"}
[2024-07-05 23:28:41,121][train_inner][INFO] - {"epoch": 23, "update": 22.833, "loss": "78.054", "ntokens": "14798.6", "nsentences": "80.08", "nll_loss": "0.422", "wps": "8357.5", "ups": "0.56", "wpb": "14798.6", "bsz": "80.1", "num_updates": "29600", "lr": "3e-05", "gnorm": "106.487", "loss_scale": "8", "train_wall": "354", "gb_free": "32", "wall": "52713"}
[2024-07-05 23:34:29,846][train_inner][INFO] - {"epoch": 23, "update": 22.987, "loss": "79.33", "ntokens": "14832.3", "nsentences": "81.48", "nll_loss": "0.436", "wps": "8508.2", "ups": "0.57", "wpb": "14832.3", "bsz": "81.5", "num_updates": "29800", "lr": "3e-05", "gnorm": "108.565", "loss_scale": "8", "train_wall": "348", "gb_free": "32.1", "wall": "53061"}
[2024-07-05 23:34:59,254][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-05 23:34:59,255][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 23:35:31,506][dev-other][INFO] - {"epoch": 23, "dev-other_loss": "23.839", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.253", "dev-other_uer": "3.826", "dev-other_wer": "10.142", "dev-other_raw_wer": "10.142", "dev-other_wps": "8672", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "29817", "dev-other_best_wer": "10.061"}
[2024-07-05 23:35:31,506][fairseq_cli.train][INFO] - end of epoch 23 (average epoch stats below)
[2024-07-05 23:35:31,516][train][INFO] - {"epoch": 23, "train_loss": "79.602", "train_ntokens": "14821.3", "train_nsentences": "80.1728", "train_nll_loss": "0.431", "train_wps": "8343.5", "train_ups": "0.56", "train_wpb": "14821.3", "train_bsz": "80.2", "train_num_updates": "29817", "train_lr": "3e-05", "train_gnorm": "109.173", "train_loss_scale": "8", "train_train_wall": "2265", "train_gb_free": "32.4", "train_wall": "53123"}
[2024-07-05 23:35:31,518][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-05 23:35:32,109][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-05 23:35:32,113][fairseq.trainer][INFO] - begin training epoch 24
[2024-07-05 23:35:32,113][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-05 23:40:47,498][train_inner][INFO] - {"epoch": 24, "update": 23.141, "loss": "79.27", "ntokens": "14818.3", "nsentences": "81.63", "nll_loss": "0.437", "wps": "7847.9", "ups": "0.53", "wpb": "14818.3", "bsz": "81.6", "num_updates": "30000", "lr": "3e-05", "gnorm": "110.141", "loss_scale": "8", "train_wall": "344", "gb_free": "30.8", "wall": "53439"}
[2024-07-05 23:46:43,361][train_inner][INFO] - {"epoch": 24, "update": 23.295, "loss": "78.394", "ntokens": "14694.5", "nsentences": "78.96", "nll_loss": "0.421", "wps": "8258.7", "ups": "0.56", "wpb": "14694.5", "bsz": "79", "num_updates": "30200", "lr": "3e-05", "gnorm": "110.134", "loss_scale": "8", "train_wall": "355", "gb_free": "32.1", "wall": "53795"}
[2024-07-05 23:52:31,524][train_inner][INFO] - {"epoch": 24, "update": 23.449, "loss": "80.206", "ntokens": "14871", "nsentences": "80.44", "nll_loss": "0.434", "wps": "8544.4", "ups": "0.57", "wpb": "14871", "bsz": "80.4", "num_updates": "30400", "lr": "3e-05", "gnorm": "108.068", "loss_scale": "8", "train_wall": "348", "gb_free": "29.8", "wall": "54143"}
[2024-07-05 23:58:28,419][train_inner][INFO] - {"epoch": 24, "update": 23.604, "loss": "77.232", "ntokens": "14927.6", "nsentences": "81.64", "nll_loss": "0.422", "wps": "8366.8", "ups": "0.56", "wpb": "14927.6", "bsz": "81.6", "num_updates": "30600", "lr": "3e-05", "gnorm": "105.225", "loss_scale": "8", "train_wall": "356", "gb_free": "32.5", "wall": "54500"}
[2024-07-06 00:04:13,293][train_inner][INFO] - {"epoch": 24, "update": 23.758, "loss": "81.464", "ntokens": "14885.7", "nsentences": "80.16", "nll_loss": "0.439", "wps": "8632.8", "ups": "0.58", "wpb": "14885.7", "bsz": "80.2", "num_updates": "30800", "lr": "3e-05", "gnorm": "112.308", "loss_scale": "16", "train_wall": "344", "gb_free": "30.6", "wall": "54845"}
[2024-07-06 00:10:10,755][train_inner][INFO] - {"epoch": 24, "update": 23.912, "loss": "79.044", "ntokens": "14756.8", "nsentences": "78.88", "nll_loss": "0.423", "wps": "8258.2", "ups": "0.56", "wpb": "14756.8", "bsz": "78.9", "num_updates": "31000", "lr": "3e-05", "gnorm": "107.759", "loss_scale": "16", "train_wall": "357", "gb_free": "32.5", "wall": "55202"}
[2024-07-06 00:13:28,624][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 00:13:28,629][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 00:14:00,708][dev-other][INFO] - {"epoch": 24, "dev-other_loss": "23.92", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.254", "dev-other_uer": "3.856", "dev-other_wer": "10.157", "dev-other_raw_wer": "10.157", "dev-other_wps": "8722.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "31114", "dev-other_best_wer": "10.061"}
[2024-07-06 00:14:00,708][fairseq_cli.train][INFO] - end of epoch 24 (average epoch stats below)
[2024-07-06 00:14:00,713][train][INFO] - {"epoch": 24, "train_loss": "79.301", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.429", "train_wps": "8325.5", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "31114", "train_lr": "3e-05", "train_gnorm": "109.066", "train_loss_scale": "16", "train_train_wall": "2273", "train_gb_free": "30.6", "train_wall": "55432"}
[2024-07-06 00:14:00,715][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 00:14:01,313][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 00:14:01,317][fairseq.trainer][INFO] - begin training epoch 25
[2024-07-06 00:14:01,318][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 00:16:33,310][train_inner][INFO] - {"epoch": 25, "update": 24.066, "loss": "76.904", "ntokens": "14781.9", "nsentences": "79.92", "nll_loss": "0.416", "wps": "7729.4", "ups": "0.52", "wpb": "14781.9", "bsz": "79.9", "num_updates": "31200", "lr": "3e-05", "gnorm": "109.023", "loss_scale": "16", "train_wall": "349", "gb_free": "32.7", "wall": "55585"}
[2024-07-06 00:22:20,131][train_inner][INFO] - {"epoch": 25, "update": 24.221, "loss": "79.591", "ntokens": "14881", "nsentences": "79.31", "nll_loss": "0.424", "wps": "8583.4", "ups": "0.58", "wpb": "14881", "bsz": "79.3", "num_updates": "31400", "lr": "3e-05", "gnorm": "110.593", "loss_scale": "16", "train_wall": "346", "gb_free": "33.8", "wall": "55932"}
[2024-07-06 00:28:05,298][train_inner][INFO] - {"epoch": 25, "update": 24.375, "loss": "76.446", "ntokens": "14897.2", "nsentences": "82.36", "nll_loss": "0.423", "wps": "8632.7", "ups": "0.58", "wpb": "14897.2", "bsz": "82.4", "num_updates": "31600", "lr": "3e-05", "gnorm": "106.799", "loss_scale": "16", "train_wall": "345", "gb_free": "31.2", "wall": "56277"}
[2024-07-06 00:33:55,902][train_inner][INFO] - {"epoch": 25, "update": 24.529, "loss": "79.488", "ntokens": "14775.4", "nsentences": "80.16", "nll_loss": "0.431", "wps": "8430.1", "ups": "0.57", "wpb": "14775.4", "bsz": "80.2", "num_updates": "31800", "lr": "3e-05", "gnorm": "110.172", "loss_scale": "16", "train_wall": "350", "gb_free": "32.2", "wall": "56628"}
[2024-07-06 00:39:42,987][train_inner][INFO] - {"epoch": 25, "update": 24.683, "loss": "80.389", "ntokens": "14931.4", "nsentences": "80.68", "nll_loss": "0.434", "wps": "8605.9", "ups": "0.58", "wpb": "14931.4", "bsz": "80.7", "num_updates": "32000", "lr": "3e-05", "gnorm": "109.331", "loss_scale": "16", "train_wall": "346", "gb_free": "32.7", "wall": "56975"}
[2024-07-06 00:45:31,570][train_inner][INFO] - {"epoch": 25, "update": 24.837, "loss": "79.836", "ntokens": "14706.6", "nsentences": "79.52", "nll_loss": "0.432", "wps": "8439.8", "ups": "0.57", "wpb": "14706.6", "bsz": "79.5", "num_updates": "32200", "lr": "3e-05", "gnorm": "109.157", "loss_scale": "16", "train_wall": "348", "gb_free": "32.9", "wall": "57323"}
[2024-07-06 00:51:18,277][train_inner][INFO] - {"epoch": 25, "update": 24.992, "loss": "82.01", "ntokens": "14783.3", "nsentences": "78.52", "nll_loss": "0.436", "wps": "8528.3", "ups": "0.58", "wpb": "14783.3", "bsz": "78.5", "num_updates": "32400", "lr": "3e-05", "gnorm": "110.384", "loss_scale": "16", "train_wall": "346", "gb_free": "32.2", "wall": "57670"}
[2024-07-06 00:51:36,719][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 00:51:36,721][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 00:52:08,898][dev-other][INFO] - {"epoch": 25, "dev-other_loss": "23.541", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.25", "dev-other_uer": "3.786", "dev-other_wer": "10.014", "dev-other_raw_wer": "10.014", "dev-other_wps": "8707.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "32411", "dev-other_best_wer": "10.014"}
[2024-07-06 00:52:08,900][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 25 @ 32411 updates
[2024-07-06 00:52:08,901][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt
[2024-07-06 00:52:10,507][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt
[2024-07-06 00:52:11,012][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt (epoch 25 @ 32411 updates, score 10.014) (writing took 2.112569134682417 seconds)
[2024-07-06 00:52:11,013][fairseq_cli.train][INFO] - end of epoch 25 (average epoch stats below)
[2024-07-06 00:52:11,017][train][INFO] - {"epoch": 25, "train_loss": "79.184", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.428", "train_wps": "8394.2", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "32411", "train_lr": "3e-05", "train_gnorm": "109.231", "train_loss_scale": "16", "train_train_wall": "2251", "train_gb_free": "32.8", "train_wall": "57723"}
[2024-07-06 00:52:11,018][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 00:52:11,258][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 00:52:11,261][fairseq.trainer][INFO] - begin training epoch 26
[2024-07-06 00:52:11,261][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 00:57:49,645][train_inner][INFO] - {"epoch": 26, "update": 25.146, "loss": "77.375", "ntokens": "14858.7", "nsentences": "80.24", "nll_loss": "0.418", "wps": "7593.5", "ups": "0.51", "wpb": "14858.7", "bsz": "80.2", "num_updates": "32600", "lr": "3e-05", "gnorm": "107.996", "loss_scale": "16", "train_wall": "356", "gb_free": "32.9", "wall": "58061"}
[2024-07-06 01:03:33,519][train_inner][INFO] - {"epoch": 26, "update": 25.3, "loss": "79.366", "ntokens": "14895.4", "nsentences": "80.72", "nll_loss": "0.43", "wps": "8663.7", "ups": "0.58", "wpb": "14895.4", "bsz": "80.7", "num_updates": "32800", "lr": "3e-05", "gnorm": "109.875", "loss_scale": "32", "train_wall": "343", "gb_free": "32.4", "wall": "58405"}
[2024-07-06 01:05:11,081][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-06 01:09:20,313][train_inner][INFO] - {"epoch": 26, "update": 25.455, "loss": "78.724", "ntokens": "14765.2", "nsentences": "79.84", "nll_loss": "0.426", "wps": "8517.6", "ups": "0.58", "wpb": "14765.2", "bsz": "79.8", "num_updates": "33000", "lr": "3e-05", "gnorm": "110.319", "loss_scale": "16", "train_wall": "346", "gb_free": "32.5", "wall": "58752"}
[2024-07-06 01:15:02,781][train_inner][INFO] - {"epoch": 26, "update": 25.609, "loss": "76.503", "ntokens": "14780", "nsentences": "80.76", "nll_loss": "0.418", "wps": "8637.3", "ups": "0.58", "wpb": "14780", "bsz": "80.8", "num_updates": "33200", "lr": "3e-05", "gnorm": "108.311", "loss_scale": "16", "train_wall": "342", "gb_free": "31.9", "wall": "59094"}
[2024-07-06 01:20:57,997][train_inner][INFO] - {"epoch": 26, "update": 25.763, "loss": "76.156", "ntokens": "14813", "nsentences": "79.96", "nll_loss": "0.411", "wps": "8340.7", "ups": "0.56", "wpb": "14813", "bsz": "80", "num_updates": "33400", "lr": "3e-05", "gnorm": "106.182", "loss_scale": "16", "train_wall": "355", "gb_free": "33", "wall": "59450"}
[2024-07-06 01:23:35,337][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-06 01:26:49,529][train_inner][INFO] - {"epoch": 26, "update": 25.918, "loss": "75.672", "ntokens": "14884.9", "nsentences": "80.96", "nll_loss": "0.412", "wps": "8469.2", "ups": "0.57", "wpb": "14884.9", "bsz": "81", "num_updates": "33600", "lr": "3e-05", "gnorm": "107.276", "loss_scale": "8", "train_wall": "351", "gb_free": "33.1", "wall": "59801"}
[2024-07-06 01:29:56,636][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 01:29:56,709][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 01:30:28,650][dev-other][INFO] - {"epoch": 26, "dev-other_loss": "23.247", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.247", "dev-other_uer": "3.721", "dev-other_wer": "9.763", "dev-other_raw_wer": "9.763", "dev-other_wps": "8734.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "33706", "dev-other_best_wer": "9.763"}
[2024-07-06 01:30:28,650][fairseq_cli.train][INFO] - end of epoch 26 (average epoch stats below)
[2024-07-06 01:30:28,663][train][INFO] - {"epoch": 26, "train_loss": "77.492", "train_ntokens": "14824", "train_nsentences": "80.21", "train_nll_loss": "0.419", "train_wps": "8355.2", "train_ups": "0.56", "train_wpb": "14824", "train_bsz": "80.2", "train_num_updates": "33706", "train_lr": "3e-05", "train_gnorm": "108.254", "train_loss_scale": "8", "train_train_wall": "2261", "train_gb_free": "31.8", "train_wall": "60020"}
[2024-07-06 01:30:28,664][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 01:30:29,279][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 01:30:29,283][fairseq.trainer][INFO] - begin training epoch 27
[2024-07-06 01:30:29,283][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 01:33:19,757][train_inner][INFO] - {"epoch": 27, "update": 26.072, "loss": "77.714", "ntokens": "14763.7", "nsentences": "78.68", "nll_loss": "0.414", "wps": "7568.3", "ups": "0.51", "wpb": "14763.7", "bsz": "78.7", "num_updates": "33800", "lr": "3e-05", "gnorm": "106.44", "loss_scale": "8", "train_wall": "357", "gb_free": "32.1", "wall": "60191"}
[2024-07-06 01:39:13,006][train_inner][INFO] - {"epoch": 27, "update": 26.227, "loss": "75.503", "ntokens": "14894", "nsentences": "81.08", "nll_loss": "0.411", "wps": "8434.3", "ups": "0.57", "wpb": "14894", "bsz": "81.1", "num_updates": "34000", "lr": "3e-05", "gnorm": "106.736", "loss_scale": "8", "train_wall": "353", "gb_free": "32.4", "wall": "60545"}
[2024-07-06 01:45:06,513][train_inner][INFO] - {"epoch": 27, "update": 26.381, "loss": "79.237", "ntokens": "14912.6", "nsentences": "82.43", "nll_loss": "0.438", "wps": "8438.6", "ups": "0.57", "wpb": "14912.6", "bsz": "82.4", "num_updates": "34200", "lr": "3e-05", "gnorm": "108.718", "loss_scale": "8", "train_wall": "353", "gb_free": "32.7", "wall": "60898"}
[2024-07-06 01:51:01,589][train_inner][INFO] - {"epoch": 27, "update": 26.535, "loss": "76.494", "ntokens": "14858", "nsentences": "79.68", "nll_loss": "0.41", "wps": "8370.4", "ups": "0.56", "wpb": "14858", "bsz": "79.7", "num_updates": "34400", "lr": "3e-05", "gnorm": "108.369", "loss_scale": "8", "train_wall": "354", "gb_free": "29.6", "wall": "61253"}
[2024-07-06 01:57:01,716][train_inner][INFO] - {"epoch": 27, "update": 26.689, "loss": "77.764", "ntokens": "14729.5", "nsentences": "78.96", "nll_loss": "0.417", "wps": "8182.1", "ups": "0.56", "wpb": "14729.5", "bsz": "79", "num_updates": "34600", "lr": "3e-05", "gnorm": "108.628", "loss_scale": "8", "train_wall": "359", "gb_free": "31.6", "wall": "61613"}
[2024-07-06 02:02:49,728][train_inner][INFO] - {"epoch": 27, "update": 26.843, "loss": "76.766", "ntokens": "14790.8", "nsentences": "80.84", "nll_loss": "0.42", "wps": "8501.7", "ups": "0.57", "wpb": "14790.8", "bsz": "80.8", "num_updates": "34800", "lr": "3e-05", "gnorm": "107.991", "loss_scale": "8", "train_wall": "347", "gb_free": "32.9", "wall": "61961"}
[2024-07-06 02:08:48,964][train_inner][INFO] - {"epoch": 27, "update": 26.998, "loss": "76.531", "ntokens": "14749.5", "nsentences": "79.04", "nll_loss": "0.41", "wps": "8213.2", "ups": "0.56", "wpb": "14749.5", "bsz": "79", "num_updates": "35000", "lr": "3e-05", "gnorm": "107.156", "loss_scale": "8", "train_wall": "359", "gb_free": "32.8", "wall": "62321"}
[2024-07-06 02:08:54,651][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 02:08:54,652][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 02:09:26,852][dev-other][INFO] - {"epoch": 27, "dev-other_loss": "24.264", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.258", "dev-other_uer": "3.855", "dev-other_wer": "10.138", "dev-other_raw_wer": "10.138", "dev-other_wps": "8669.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "35003", "dev-other_best_wer": "10.014"}
[2024-07-06 02:09:26,853][fairseq_cli.train][INFO] - end of epoch 27 (average epoch stats below)
[2024-07-06 02:09:26,857][train][INFO] - {"epoch": 27, "train_loss": "76.977", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.416", "train_wps": "8222.3", "train_ups": "0.55", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "35003", "train_lr": "3e-05", "train_gnorm": "107.752", "train_loss_scale": "8", "train_train_wall": "2301", "train_gb_free": "31.4", "train_wall": "62359"}
[2024-07-06 02:09:26,858][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 02:09:27,505][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 02:09:27,509][fairseq.trainer][INFO] - begin training epoch 28
[2024-07-06 02:09:27,509][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 02:15:07,272][train_inner][INFO] - {"epoch": 28, "update": 27.152, "loss": "81.006", "ntokens": "14827", "nsentences": "78.36", "nll_loss": "0.428", "wps": "7838.8", "ups": "0.53", "wpb": "14827", "bsz": "78.4", "num_updates": "35200", "lr": "3e-05", "gnorm": "112.225", "loss_scale": "8", "train_wall": "345", "gb_free": "30.5", "wall": "62699"}
[2024-07-06 02:20:52,717][train_inner][INFO] - {"epoch": 28, "update": 27.306, "loss": "75.712", "ntokens": "14714.8", "nsentences": "80.04", "nll_loss": "0.412", "wps": "8519.5", "ups": "0.58", "wpb": "14714.8", "bsz": "80", "num_updates": "35400", "lr": "3e-05", "gnorm": "108.344", "loss_scale": "8", "train_wall": "345", "gb_free": "31.6", "wall": "63044"}
[2024-07-06 02:26:40,662][train_inner][INFO] - {"epoch": 28, "update": 27.46, "loss": "75.907", "ntokens": "14938.2", "nsentences": "82.36", "nll_loss": "0.419", "wps": "8588.4", "ups": "0.57", "wpb": "14938.2", "bsz": "82.4", "num_updates": "35600", "lr": "3e-05", "gnorm": "105.298", "loss_scale": "16", "train_wall": "347", "gb_free": "32.7", "wall": "63392"}
[2024-07-06 02:32:39,184][train_inner][INFO] - {"epoch": 28, "update": 27.614, "loss": "74.148", "ntokens": "14939.2", "nsentences": "82.12", "nll_loss": "0.408", "wps": "8335.4", "ups": "0.56", "wpb": "14939.2", "bsz": "82.1", "num_updates": "35800", "lr": "3e-05", "gnorm": "104.872", "loss_scale": "16", "train_wall": "358", "gb_free": "32.6", "wall": "63751"}
[2024-07-06 02:38:34,078][train_inner][INFO] - {"epoch": 28, "update": 27.769, "loss": "75.964", "ntokens": "14924.6", "nsentences": "81.28", "nll_loss": "0.414", "wps": "8412.2", "ups": "0.56", "wpb": "14924.6", "bsz": "81.3", "num_updates": "36000", "lr": "3e-05", "gnorm": "105.353", "loss_scale": "16", "train_wall": "354", "gb_free": "33.7", "wall": "64106"}
[2024-07-06 02:42:56,038][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-06 02:44:27,371][train_inner][INFO] - {"epoch": 28, "update": 27.924, "loss": "77.452", "ntokens": "14662.1", "nsentences": "77.6", "nll_loss": "0.41", "wps": "8300.5", "ups": "0.57", "wpb": "14662.1", "bsz": "77.6", "num_updates": "36200", "lr": "3e-05", "gnorm": "110.561", "loss_scale": "8", "train_wall": "353", "gb_free": "32.1", "wall": "64459"}
[2024-07-06 02:47:22,279][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 02:47:22,285][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 02:47:54,444][dev-other][INFO] - {"epoch": 28, "dev-other_loss": "23.859", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.254", "dev-other_uer": "3.802", "dev-other_wer": "9.99", "dev-other_raw_wer": "9.99", "dev-other_wps": "8695.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "36299", "dev-other_best_wer": "9.99"}
[2024-07-06 02:47:54,461][fairseq_cli.train][INFO] - end of epoch 28 (average epoch stats below)
[2024-07-06 02:47:54,465][train][INFO] - {"epoch": 28, "train_loss": "76.599", "train_ntokens": "14820.5", "train_nsentences": "80.1667", "train_nll_loss": "0.414", "train_wps": "8323.5", "train_ups": "0.56", "train_wpb": "14820.5", "train_bsz": "80.2", "train_num_updates": "36299", "train_lr": "3e-05", "train_gnorm": "107.721", "train_loss_scale": "8", "train_train_wall": "2271", "train_gb_free": "32.1", "train_wall": "64666"}
[2024-07-06 02:47:54,466][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 02:47:55,052][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 02:47:55,056][fairseq.trainer][INFO] - begin training epoch 29
[2024-07-06 02:47:55,056][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 02:50:57,221][train_inner][INFO] - {"epoch": 29, "update": 28.078, "loss": "75.094", "ntokens": "14715.9", "nsentences": "80.24", "nll_loss": "0.409", "wps": "7550.9", "ups": "0.51", "wpb": "14715.9", "bsz": "80.2", "num_updates": "36400", "lr": "3e-05", "gnorm": "105.717", "loss_scale": "8", "train_wall": "356", "gb_free": "32", "wall": "64849"}
[2024-07-06 02:56:43,330][train_inner][INFO] - {"epoch": 29, "update": 28.232, "loss": "76.368", "ntokens": "14758.4", "nsentences": "79.64", "nll_loss": "0.412", "wps": "8529.9", "ups": "0.58", "wpb": "14758.4", "bsz": "79.6", "num_updates": "36600", "lr": "3e-05", "gnorm": "107.832", "loss_scale": "8", "train_wall": "345", "gb_free": "30.6", "wall": "65195"}
[2024-07-06 03:02:32,423][train_inner][INFO] - {"epoch": 29, "update": 28.386, "loss": "74.236", "ntokens": "14861.2", "nsentences": "81.24", "nll_loss": "0.406", "wps": "8514.5", "ups": "0.57", "wpb": "14861.2", "bsz": "81.2", "num_updates": "36800", "lr": "3e-05", "gnorm": "105.952", "loss_scale": "8", "train_wall": "349", "gb_free": "32.6", "wall": "65544"}
[2024-07-06 03:08:24,817][train_inner][INFO] - {"epoch": 29, "update": 28.54, "loss": "79.228", "ntokens": "14921.2", "nsentences": "79.83", "nll_loss": "0.424", "wps": "8470.1", "ups": "0.57", "wpb": "14921.2", "bsz": "79.8", "num_updates": "37000", "lr": "3e-05", "gnorm": "108.909", "loss_scale": "8", "train_wall": "352", "gb_free": "31.9", "wall": "65896"}
[2024-07-06 03:14:16,380][train_inner][INFO] - {"epoch": 29, "update": 28.695, "loss": "76.116", "ntokens": "14778.3", "nsentences": "79.92", "nll_loss": "0.412", "wps": "8409", "ups": "0.57", "wpb": "14778.3", "bsz": "79.9", "num_updates": "37200", "lr": "3e-05", "gnorm": "107.883", "loss_scale": "8", "train_wall": "351", "gb_free": "32.8", "wall": "66248"}
[2024-07-06 03:20:05,915][train_inner][INFO] - {"epoch": 29, "update": 28.849, "loss": "74.89", "ntokens": "14874.6", "nsentences": "80.16", "nll_loss": "0.404", "wps": "8513.4", "ups": "0.57", "wpb": "14874.6", "bsz": "80.2", "num_updates": "37400", "lr": "3e-05", "gnorm": "105.769", "loss_scale": "8", "train_wall": "349", "gb_free": "33.1", "wall": "66598"}
[2024-07-06 03:25:41,853][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 03:25:41,921][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 03:26:13,926][dev-other][INFO] - {"epoch": 29, "dev-other_loss": "22.813", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.243", "dev-other_uer": "3.733", "dev-other_wer": "9.922", "dev-other_raw_wer": "9.922", "dev-other_wps": "8732.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "37596", "dev-other_best_wer": "9.922"}
[2024-07-06 03:26:13,927][fairseq_cli.train][INFO] - end of epoch 29 (average epoch stats below)
[2024-07-06 03:26:13,934][train][INFO] - {"epoch": 29, "train_loss": "76.289", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.413", "train_wps": "8360.8", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "37596", "train_lr": "3e-05", "train_gnorm": "107.392", "train_loss_scale": "8", "train_train_wall": "2263", "train_gb_free": "32.3", "train_wall": "66966"}
[2024-07-06 03:26:13,936][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 03:26:14,532][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 03:26:14,535][fairseq.trainer][INFO] - begin training epoch 30
[2024-07-06 03:26:14,536][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 03:26:22,496][train_inner][INFO] - {"epoch": 30, "update": 29.003, "loss": "78.094", "ntokens": "14766.9", "nsentences": "79.28", "nll_loss": "0.419", "wps": "7842.9", "ups": "0.53", "wpb": "14766.9", "bsz": "79.3", "num_updates": "37600", "lr": "3e-05", "gnorm": "109.526", "loss_scale": "8", "train_wall": "343", "gb_free": "32.3", "wall": "66974"}
[2024-07-06 03:32:15,799][train_inner][INFO] - {"epoch": 30, "update": 29.157, "loss": "73.586", "ntokens": "14895.7", "nsentences": "81.2", "nll_loss": "0.401", "wps": "8433.8", "ups": "0.57", "wpb": "14895.7", "bsz": "81.2", "num_updates": "37800", "lr": "3e-05", "gnorm": "104.464", "loss_scale": "8", "train_wall": "353", "gb_free": "30.2", "wall": "67327"}
[2024-07-06 03:38:01,107][train_inner][INFO] - {"epoch": 30, "update": 29.311, "loss": "73.869", "ntokens": "14812.3", "nsentences": "80.52", "nll_loss": "0.402", "wps": "8581.5", "ups": "0.58", "wpb": "14812.3", "bsz": "80.5", "num_updates": "38000", "lr": "3e-05", "gnorm": "108.616", "loss_scale": "8", "train_wall": "345", "gb_free": "31.8", "wall": "67673"}
[2024-07-06 03:43:47,396][train_inner][INFO] - {"epoch": 30, "update": 29.466, "loss": "78.768", "ntokens": "14766.8", "nsentences": "77.96", "nll_loss": "0.416", "wps": "8529", "ups": "0.58", "wpb": "14766.8", "bsz": "78", "num_updates": "38200", "lr": "3e-05", "gnorm": "109.318", "loss_scale": "16", "train_wall": "346", "gb_free": "31.7", "wall": "68019"}
[2024-07-06 03:49:48,927][train_inner][INFO] - {"epoch": 30, "update": 29.62, "loss": "73.821", "ntokens": "14737.2", "nsentences": "78.76", "nll_loss": "0.395", "wps": "8154.2", "ups": "0.55", "wpb": "14737.2", "bsz": "78.8", "num_updates": "38400", "lr": "3e-05", "gnorm": "106.709", "loss_scale": "16", "train_wall": "361", "gb_free": "33.2", "wall": "68381"}
[2024-07-06 03:50:14,925][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-06 03:55:36,822][train_inner][INFO] - {"epoch": 30, "update": 29.775, "loss": "76.444", "ntokens": "14940.8", "nsentences": "80.36", "nll_loss": "0.411", "wps": "8589.6", "ups": "0.57", "wpb": "14940.8", "bsz": "80.4", "num_updates": "38600", "lr": "3e-05", "gnorm": "109.88", "loss_scale": "8", "train_wall": "347", "gb_free": "30.1", "wall": "68728"}
[2024-07-06 04:01:27,342][train_inner][INFO] - {"epoch": 30, "update": 29.929, "loss": "75.776", "ntokens": "14773.2", "nsentences": "80.32", "nll_loss": "0.412", "wps": "8430.8", "ups": "0.57", "wpb": "14773.2", "bsz": "80.3", "num_updates": "38800", "lr": "3e-05", "gnorm": "106.868", "loss_scale": "8", "train_wall": "350", "gb_free": "31.2", "wall": "69079"}
[2024-07-06 04:04:06,238][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 04:04:06,310][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 04:04:38,375][dev-other][INFO] - {"epoch": 30, "dev-other_loss": "22.864", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.243", "dev-other_uer": "3.716", "dev-other_wer": "9.824", "dev-other_raw_wer": "9.824", "dev-other_wps": "8717.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "38892", "dev-other_best_wer": "9.824"}
[2024-07-06 04:04:38,377][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 30 @ 38892 updates
[2024-07-06 04:04:38,378][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt
[2024-07-06 04:04:39,961][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt
[2024-07-06 04:04:40,443][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt (epoch 30 @ 38892 updates, score 9.824) (writing took 2.0657798498868942 seconds)
[2024-07-06 04:04:40,443][fairseq_cli.train][INFO] - end of epoch 30 (average epoch stats below)
[2024-07-06 04:04:40,450][train][INFO] - {"epoch": 30, "train_loss": "75.179", "train_ntokens": "14821.8", "train_nsentences": "80.1975", "train_nll_loss": "0.407", "train_wps": "8328.2", "train_ups": "0.56", "train_wpb": "14821.8", "train_bsz": "80.2", "train_num_updates": "38892", "train_lr": "3e-05", "train_gnorm": "107.288", "train_loss_scale": "8", "train_train_wall": "2268", "train_gb_free": "32.2", "train_wall": "69272"}
[2024-07-06 04:04:40,452][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 04:04:40,692][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 04:04:40,695][fairseq.trainer][INFO] - begin training epoch 31
[2024-07-06 04:04:40,695][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 04:07:54,052][train_inner][INFO] - {"epoch": 31, "update": 30.083, "loss": "71.253", "ntokens": "14835", "nsentences": "84.04", "nll_loss": "0.404", "wps": "7673.7", "ups": "0.52", "wpb": "14835", "bsz": "84", "num_updates": "39000", "lr": "3e-05", "gnorm": "101.692", "loss_scale": "8", "train_wall": "352", "gb_free": "31.7", "wall": "69466"}
[2024-07-06 04:13:48,677][train_inner][INFO] - {"epoch": 31, "update": 30.237, "loss": "75.25", "ntokens": "14744.4", "nsentences": "80.12", "nll_loss": "0.409", "wps": "8317.3", "ups": "0.56", "wpb": "14744.4", "bsz": "80.1", "num_updates": "39200", "lr": "3e-05", "gnorm": "108.025", "loss_scale": "8", "train_wall": "354", "gb_free": "32.9", "wall": "69820"}
[2024-07-06 04:19:34,474][train_inner][INFO] - {"epoch": 31, "update": 30.392, "loss": "79.418", "ntokens": "14815.1", "nsentences": "78.96", "nll_loss": "0.423", "wps": "8570.3", "ups": "0.58", "wpb": "14815.1", "bsz": "79", "num_updates": "39400", "lr": "3e-05", "gnorm": "114.105", "loss_scale": "8", "train_wall": "345", "gb_free": "31.8", "wall": "70166"}
[2024-07-06 04:25:23,349][train_inner][INFO] - {"epoch": 31, "update": 30.546, "loss": "75.146", "ntokens": "14916.4", "nsentences": "80.84", "nll_loss": "0.407", "wps": "8551.4", "ups": "0.57", "wpb": "14916.4", "bsz": "80.8", "num_updates": "39600", "lr": "3e-05", "gnorm": "107.729", "loss_scale": "8", "train_wall": "348", "gb_free": "32.5", "wall": "70515"}
[2024-07-06 04:31:15,289][train_inner][INFO] - {"epoch": 31, "update": 30.7, "loss": "76.378", "ntokens": "14848.7", "nsentences": "79.11", "nll_loss": "0.407", "wps": "8440", "ups": "0.57", "wpb": "14848.7", "bsz": "79.1", "num_updates": "39800", "lr": "3e-05", "gnorm": "109.333", "loss_scale": "8", "train_wall": "351", "gb_free": "31.9", "wall": "70867"}
[2024-07-06 04:37:00,647][train_inner][INFO] - {"epoch": 31, "update": 30.854, "loss": "74.954", "ntokens": "14767.5", "nsentences": "79.68", "nll_loss": "0.404", "wps": "8552.6", "ups": "0.58", "wpb": "14767.5", "bsz": "79.7", "num_updates": "40000", "lr": "3e-05", "gnorm": "108.942", "loss_scale": "8", "train_wall": "345", "gb_free": "32", "wall": "71212"}
[2024-07-06 04:42:34,992][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 04:42:35,061][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 04:43:07,421][dev-other][INFO] - {"epoch": 31, "dev-other_loss": "23.846", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.253", "dev-other_uer": "3.703", "dev-other_wer": "9.796", "dev-other_raw_wer": "9.796", "dev-other_wps": "8639.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "40189", "dev-other_best_wer": "9.796"}
[2024-07-06 04:43:07,422][fairseq_cli.train][INFO] - end of epoch 31 (average epoch stats below)
[2024-07-06 04:43:07,427][train][INFO] - {"epoch": 31, "train_loss": "75.43", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.408", "train_wps": "8333.6", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "40189", "train_lr": "3e-05", "train_gnorm": "108.499", "train_loss_scale": "8", "train_train_wall": "2270", "train_gb_free": "32.1", "train_wall": "71579"}
[2024-07-06 04:43:07,429][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 04:43:08,009][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 04:43:08,014][fairseq.trainer][INFO] - begin training epoch 32
[2024-07-06 04:43:08,014][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 04:43:29,386][train_inner][INFO] - {"epoch": 32, "update": 31.008, "loss": "74.482", "ntokens": "14846.5", "nsentences": "80.76", "nll_loss": "0.405", "wps": "7639.7", "ups": "0.51", "wpb": "14846.5", "bsz": "80.8", "num_updates": "40200", "lr": "3e-05", "gnorm": "106.586", "loss_scale": "8", "train_wall": "355", "gb_free": "32.4", "wall": "71601"}
[2024-07-06 04:49:24,008][train_inner][INFO] - {"epoch": 32, "update": 31.163, "loss": "73.848", "ntokens": "14844.6", "nsentences": "80.03", "nll_loss": "0.398", "wps": "8373.7", "ups": "0.56", "wpb": "14844.6", "bsz": "80", "num_updates": "40400", "lr": "3e-05", "gnorm": "105.422", "loss_scale": "8", "train_wall": "354", "gb_free": "32.2", "wall": "71956"}
[2024-07-06 04:55:23,539][train_inner][INFO] - {"epoch": 32, "update": 31.317, "loss": "70.615", "ntokens": "14871.9", "nsentences": "82.52", "nll_loss": "0.392", "wps": "8273.2", "ups": "0.56", "wpb": "14871.9", "bsz": "82.5", "num_updates": "40600", "lr": "3e-05", "gnorm": "102.692", "loss_scale": "16", "train_wall": "359", "gb_free": "32.6", "wall": "72315"}
[2024-07-06 05:01:14,467][train_inner][INFO] - {"epoch": 32, "update": 31.471, "loss": "75.042", "ntokens": "14858.9", "nsentences": "80.92", "nll_loss": "0.409", "wps": "8468.6", "ups": "0.57", "wpb": "14858.9", "bsz": "80.9", "num_updates": "40800", "lr": "3e-05", "gnorm": "107.275", "loss_scale": "16", "train_wall": "350", "gb_free": "29.4", "wall": "72666"}
[2024-07-06 05:07:07,655][train_inner][INFO] - {"epoch": 32, "update": 31.625, "loss": "73.54", "ntokens": "14886.2", "nsentences": "81", "nll_loss": "0.4", "wps": "8430.4", "ups": "0.57", "wpb": "14886.2", "bsz": "81", "num_updates": "41000", "lr": "3e-05", "gnorm": "105.707", "loss_scale": "16", "train_wall": "353", "gb_free": "31.9", "wall": "73019"}
[2024-07-06 05:13:04,341][train_inner][INFO] - {"epoch": 32, "update": 31.779, "loss": "76.078", "ntokens": "14801.4", "nsentences": "79.04", "nll_loss": "0.406", "wps": "8301.7", "ups": "0.56", "wpb": "14801.4", "bsz": "79", "num_updates": "41200", "lr": "3e-05", "gnorm": "105.783", "loss_scale": "16", "train_wall": "356", "gb_free": "30.3", "wall": "73376"}
[2024-07-06 05:18:47,007][train_inner][INFO] - {"epoch": 32, "update": 31.934, "loss": "78.279", "ntokens": "14693.1", "nsentences": "77.92", "nll_loss": "0.415", "wps": "8576", "ups": "0.58", "wpb": "14693.1", "bsz": "77.9", "num_updates": "41400", "lr": "3e-05", "gnorm": "111.141", "loss_scale": "16", "train_wall": "342", "gb_free": "30.1", "wall": "73719"}
[2024-07-06 05:21:17,025][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 05:21:17,090][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 05:21:49,181][dev-other][INFO] - {"epoch": 32, "dev-other_loss": "23.049", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.245", "dev-other_uer": "3.704", "dev-other_wer": "9.672", "dev-other_raw_wer": "9.672", "dev-other_wps": "8701.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "41486", "dev-other_best_wer": "9.672"}
[2024-07-06 05:21:49,182][fairseq_cli.train][INFO] - end of epoch 32 (average epoch stats below)
[2024-07-06 05:21:49,190][train][INFO] - {"epoch": 32, "train_loss": "74.797", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.405", "train_wps": "8280.5", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "41486", "train_lr": "3e-05", "train_gnorm": "106.445", "train_loss_scale": "16", "train_train_wall": "2285", "train_gb_free": "32", "train_wall": "73901"}
[2024-07-06 05:21:49,191][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 05:21:49,788][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 05:21:49,792][fairseq.trainer][INFO] - begin training epoch 33
[2024-07-06 05:21:49,792][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 05:25:07,606][train_inner][INFO] - {"epoch": 33, "update": 32.088, "loss": "76.797", "ntokens": "14714.3", "nsentences": "79.68", "nll_loss": "0.416", "wps": "7733.5", "ups": "0.53", "wpb": "14714.3", "bsz": "79.7", "num_updates": "41600", "lr": "3e-05", "gnorm": "108.817", "loss_scale": "16", "train_wall": "347", "gb_free": "31.8", "wall": "74099"}
[2024-07-06 05:30:56,528][train_inner][INFO] - {"epoch": 33, "update": 32.242, "loss": "74.434", "ntokens": "14793.9", "nsentences": "79.6", "nll_loss": "0.4", "wps": "8480", "ups": "0.57", "wpb": "14793.9", "bsz": "79.6", "num_updates": "41800", "lr": "3e-05", "gnorm": "108.3", "loss_scale": "16", "train_wall": "348", "gb_free": "31.5", "wall": "74448"}
[2024-07-06 05:36:47,663][train_inner][INFO] - {"epoch": 33, "update": 32.396, "loss": "72.988", "ntokens": "14960.3", "nsentences": "83.44", "nll_loss": "0.407", "wps": "8522.9", "ups": "0.57", "wpb": "14960.3", "bsz": "83.4", "num_updates": "42000", "lr": "3e-05", "gnorm": "103.751", "loss_scale": "16", "train_wall": "351", "gb_free": "31.7", "wall": "74799"}
[2024-07-06 05:42:38,275][train_inner][INFO] - {"epoch": 33, "update": 32.551, "loss": "75.02", "ntokens": "14847.7", "nsentences": "79.72", "nll_loss": "0.403", "wps": "8469.9", "ups": "0.57", "wpb": "14847.7", "bsz": "79.7", "num_updates": "42200", "lr": "3e-05", "gnorm": "107.706", "loss_scale": "16", "train_wall": "350", "gb_free": "30.2", "wall": "75150"}
[2024-07-06 05:48:23,859][train_inner][INFO] - {"epoch": 33, "update": 32.705, "loss": "77.513", "ntokens": "14864.8", "nsentences": "80.68", "nll_loss": "0.421", "wps": "8604.5", "ups": "0.58", "wpb": "14864.8", "bsz": "80.7", "num_updates": "42400", "lr": "3e-05", "gnorm": "108.043", "loss_scale": "16", "train_wall": "345", "gb_free": "31.4", "wall": "75495"}
[2024-07-06 05:54:11,927][train_inner][INFO] - {"epoch": 33, "update": 32.859, "loss": "75.778", "ntokens": "14686.8", "nsentences": "77.52", "nll_loss": "0.4", "wps": "8440.7", "ups": "0.57", "wpb": "14686.8", "bsz": "77.5", "num_updates": "42600", "lr": "3e-05", "gnorm": "109.358", "loss_scale": "32", "train_wall": "347", "gb_free": "32.4", "wall": "75844"}
[2024-07-06 05:59:24,512][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 05:59:24,572][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 05:59:56,622][dev-other][INFO] - {"epoch": 33, "dev-other_loss": "23.406", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.249", "dev-other_uer": "3.781", "dev-other_wer": "9.814", "dev-other_raw_wer": "9.814", "dev-other_wps": "8705", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "42783", "dev-other_best_wer": "9.814"}
[2024-07-06 05:59:56,623][fairseq_cli.train][INFO] - end of epoch 33 (average epoch stats below)
[2024-07-06 05:59:56,629][train][INFO] - {"epoch": 33, "train_loss": "75.224", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.407", "train_wps": "8404.7", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "42783", "train_lr": "3e-05", "train_gnorm": "107.866", "train_loss_scale": "32", "train_train_wall": "2251", "train_gb_free": "32.6", "train_wall": "76188"}
[2024-07-06 05:59:56,631][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 05:59:57,227][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 05:59:57,232][fairseq.trainer][INFO] - begin training epoch 34
[2024-07-06 05:59:57,232][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 06:00:07,196][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-06 06:00:26,853][train_inner][INFO] - {"epoch": 34, "update": 33.014, "loss": "75.689", "ntokens": "14897.7", "nsentences": "81.31", "nll_loss": "0.413", "wps": "7948.8", "ups": "0.53", "wpb": "14897.7", "bsz": "81.3", "num_updates": "42800", "lr": "3e-05", "gnorm": "109.671", "loss_scale": "16", "train_wall": "341", "gb_free": "31.7", "wall": "76218"}
[2024-07-06 06:06:16,405][train_inner][INFO] - {"epoch": 34, "update": 33.168, "loss": "75.016", "ntokens": "14686.4", "nsentences": "80.24", "nll_loss": "0.41", "wps": "8404.7", "ups": "0.57", "wpb": "14686.4", "bsz": "80.2", "num_updates": "43000", "lr": "3e-05", "gnorm": "107.547", "loss_scale": "16", "train_wall": "349", "gb_free": "32", "wall": "76568"}
[2024-07-06 06:12:12,391][train_inner][INFO] - {"epoch": 34, "update": 33.322, "loss": "74.245", "ntokens": "14918.5", "nsentences": "79.4", "nll_loss": "0.395", "wps": "8383.3", "ups": "0.56", "wpb": "14918.5", "bsz": "79.4", "num_updates": "43200", "lr": "3e-05", "gnorm": "106.63", "loss_scale": "16", "train_wall": "355", "gb_free": "32.5", "wall": "76924"}
[2024-07-06 06:14:25,289][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-06 06:18:04,416][train_inner][INFO] - {"epoch": 34, "update": 33.477, "loss": "72.707", "ntokens": "14891.7", "nsentences": "80.84", "nll_loss": "0.395", "wps": "8462.8", "ups": "0.57", "wpb": "14891.7", "bsz": "80.8", "num_updates": "43400", "lr": "3e-05", "gnorm": "105.995", "loss_scale": "8", "train_wall": "351", "gb_free": "32.2", "wall": "77276"}
[2024-07-06 06:23:54,294][train_inner][INFO] - {"epoch": 34, "update": 33.631, "loss": "75.72", "ntokens": "14832.1", "nsentences": "79.04", "nll_loss": "0.404", "wps": "8480.4", "ups": "0.57", "wpb": "14832.1", "bsz": "79", "num_updates": "43600", "lr": "3e-05", "gnorm": "109.123", "loss_scale": "8", "train_wall": "349", "gb_free": "29.9", "wall": "77626"}
[2024-07-06 06:29:41,042][train_inner][INFO] - {"epoch": 34, "update": 33.786, "loss": "75.121", "ntokens": "14828.4", "nsentences": "80.6", "nll_loss": "0.408", "wps": "8554.6", "ups": "0.58", "wpb": "14828.4", "bsz": "80.6", "num_updates": "43800", "lr": "3e-05", "gnorm": "107.66", "loss_scale": "8", "train_wall": "346", "gb_free": "32.8", "wall": "77973"}
[2024-07-06 06:35:31,145][train_inner][INFO] - {"epoch": 34, "update": 33.94, "loss": "73.468", "ntokens": "14756.1", "nsentences": "79.52", "nll_loss": "0.396", "wps": "8431.3", "ups": "0.57", "wpb": "14756.1", "bsz": "79.5", "num_updates": "44000", "lr": "3e-05", "gnorm": "107.313", "loss_scale": "8", "train_wall": "349", "gb_free": "31.4", "wall": "78323"}
[2024-07-06 06:37:49,874][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 06:37:49,939][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 06:38:22,174][dev-other][INFO] - {"epoch": 34, "dev-other_loss": "22.917", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.244", "dev-other_uer": "3.723", "dev-other_wer": "9.774", "dev-other_raw_wer": "9.774", "dev-other_wps": "8652.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "44078", "dev-other_best_wer": "9.774"}
[2024-07-06 06:38:22,175][fairseq_cli.train][INFO] - end of epoch 34 (average epoch stats below)
[2024-07-06 06:38:22,184][train][INFO] - {"epoch": 34, "train_loss": "74.334", "train_ntokens": "14823.1", "train_nsentences": "80.2162", "train_nll_loss": "0.402", "train_wps": "8326", "train_ups": "0.56", "train_wpb": "14823.1", "train_bsz": "80.2", "train_num_updates": "44078", "train_lr": "3e-05", "train_gnorm": "107.303", "train_loss_scale": "8", "train_train_wall": "2268", "train_gb_free": "32.2", "train_wall": "78494"}
[2024-07-06 06:38:22,185][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 06:38:22,827][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 06:38:22,831][fairseq.trainer][INFO] - begin training epoch 35
[2024-07-06 06:38:22,831][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 06:41:55,949][train_inner][INFO] - {"epoch": 35, "update": 34.094, "loss": "73.147", "ntokens": "14869.4", "nsentences": "82.68", "nll_loss": "0.407", "wps": "7729.7", "ups": "0.52", "wpb": "14869.4", "bsz": "82.7", "num_updates": "44200", "lr": "3e-05", "gnorm": "103.999", "loss_scale": "8", "train_wall": "351", "gb_free": "31.7", "wall": "78708"}
[2024-07-06 06:47:48,711][train_inner][INFO] - {"epoch": 35, "update": 34.248, "loss": "74.633", "ntokens": "14781.4", "nsentences": "79.96", "nll_loss": "0.404", "wps": "8380.9", "ups": "0.57", "wpb": "14781.4", "bsz": "80", "num_updates": "44400", "lr": "3e-05", "gnorm": "106.499", "loss_scale": "8", "train_wall": "352", "gb_free": "32.7", "wall": "79060"}
[2024-07-06 06:53:35,625][train_inner][INFO] - {"epoch": 35, "update": 34.402, "loss": "74.296", "ntokens": "14827.9", "nsentences": "79.36", "nll_loss": "0.398", "wps": "8550", "ups": "0.58", "wpb": "14827.9", "bsz": "79.4", "num_updates": "44600", "lr": "3e-05", "gnorm": "109.315", "loss_scale": "8", "train_wall": "346", "gb_free": "32.5", "wall": "79407"}
[2024-07-06 06:59:21,185][train_inner][INFO] - {"epoch": 35, "update": 34.557, "loss": "74.546", "ntokens": "14895.5", "nsentences": "82.12", "nll_loss": "0.411", "wps": "8621.3", "ups": "0.58", "wpb": "14895.5", "bsz": "82.1", "num_updates": "44800", "lr": "3e-05", "gnorm": "109.128", "loss_scale": "8", "train_wall": "345", "gb_free": "33.4", "wall": "79753"}
[2024-07-06 07:05:12,255][train_inner][INFO] - {"epoch": 35, "update": 34.711, "loss": "76.684", "ntokens": "14702.8", "nsentences": "77.76", "nll_loss": "0.406", "wps": "8378.3", "ups": "0.57", "wpb": "14702.8", "bsz": "77.8", "num_updates": "45000", "lr": "3e-05", "gnorm": "110.221", "loss_scale": "8", "train_wall": "350", "gb_free": "32", "wall": "80104"}
[2024-07-06 07:10:58,734][train_inner][INFO] - {"epoch": 35, "update": 34.865, "loss": "73.233", "ntokens": "14831.9", "nsentences": "80.32", "nll_loss": "0.397", "wps": "8561.8", "ups": "0.58", "wpb": "14831.9", "bsz": "80.3", "num_updates": "45200", "lr": "3e-05", "gnorm": "107.502", "loss_scale": "8", "train_wall": "346", "gb_free": "32.4", "wall": "80450"}
[2024-07-06 07:14:45,951][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-06 07:16:08,687][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 07:16:08,699][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 07:16:40,999][dev-other][INFO] - {"epoch": 35, "dev-other_loss": "22.745", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.242", "dev-other_uer": "3.646", "dev-other_wer": "9.621", "dev-other_raw_wer": "9.621", "dev-other_wps": "8669.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "45374", "dev-other_best_wer": "9.621"}
[2024-07-06 07:16:41,000][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 35 @ 45374 updates
[2024-07-06 07:16:41,002][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt
[2024-07-06 07:16:42,512][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt
[2024-07-06 07:16:43,176][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt (epoch 35 @ 45374 updates, score 9.621) (writing took 2.1756032705307007 seconds)
[2024-07-06 07:16:43,176][fairseq_cli.train][INFO] - end of epoch 35 (average epoch stats below)
[2024-07-06 07:16:43,181][train][INFO] - {"epoch": 35, "train_loss": "74.168", "train_ntokens": "14821.3", "train_nsentences": "80.1975", "train_nll_loss": "0.401", "train_wps": "8347.9", "train_ups": "0.56", "train_wpb": "14821.3", "train_bsz": "80.2", "train_num_updates": "45374", "train_lr": "3e-05", "train_gnorm": "107.475", "train_loss_scale": "8", "train_train_wall": "2262", "train_gb_free": "32.4", "train_wall": "80795"}
[2024-07-06 07:16:43,182][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 07:16:43,395][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 07:16:43,398][fairseq.trainer][INFO] - begin training epoch 36
[2024-07-06 07:16:43,398][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 07:17:26,260][train_inner][INFO] - {"epoch": 36, "update": 35.02, "loss": "72.803", "ntokens": "14836.8", "nsentences": "79.72", "nll_loss": "0.391", "wps": "7658.7", "ups": "0.52", "wpb": "14836.8", "bsz": "79.7", "num_updates": "45400", "lr": "3e-05", "gnorm": "105.724", "loss_scale": "8", "train_wall": "352", "gb_free": "33.5", "wall": "80838"}
[2024-07-06 07:23:18,884][train_inner][INFO] - {"epoch": 36, "update": 35.174, "loss": "72.476", "ntokens": "14863.2", "nsentences": "80.48", "nll_loss": "0.392", "wps": "8431.5", "ups": "0.57", "wpb": "14863.2", "bsz": "80.5", "num_updates": "45600", "lr": "3e-05", "gnorm": "107.566", "loss_scale": "8", "train_wall": "352", "gb_free": "31.9", "wall": "81191"}
[2024-07-06 07:29:00,553][train_inner][INFO] - {"epoch": 36, "update": 35.328, "loss": "74.712", "ntokens": "14841.9", "nsentences": "80.68", "nll_loss": "0.406", "wps": "8690.2", "ups": "0.59", "wpb": "14841.9", "bsz": "80.7", "num_updates": "45800", "lr": "3e-05", "gnorm": "108.409", "loss_scale": "8", "train_wall": "341", "gb_free": "32.4", "wall": "81532"}
[2024-07-06 07:34:56,219][train_inner][INFO] - {"epoch": 36, "update": 35.483, "loss": "75.774", "ntokens": "14708.3", "nsentences": "77", "nll_loss": "0.397", "wps": "8272.6", "ups": "0.56", "wpb": "14708.3", "bsz": "77", "num_updates": "46000", "lr": "3e-05", "gnorm": "109.691", "loss_scale": "8", "train_wall": "355", "gb_free": "32.1", "wall": "81888"}
[2024-07-06 07:40:50,591][train_inner][INFO] - {"epoch": 36, "update": 35.637, "loss": "73.431", "ntokens": "14868.8", "nsentences": "80.96", "nll_loss": "0.4", "wps": "8393.6", "ups": "0.56", "wpb": "14868.8", "bsz": "81", "num_updates": "46200", "lr": "3e-05", "gnorm": "108.277", "loss_scale": "8", "train_wall": "354", "gb_free": "31.8", "wall": "82242"}
[2024-07-06 07:46:45,153][train_inner][INFO] - {"epoch": 36, "update": 35.791, "loss": "72.636", "ntokens": "14883", "nsentences": "82.15", "nll_loss": "0.401", "wps": "8396.9", "ups": "0.56", "wpb": "14883", "bsz": "82.2", "num_updates": "46400", "lr": "3e-05", "gnorm": "105.277", "loss_scale": "8", "train_wall": "354", "gb_free": "32", "wall": "82597"}
[2024-07-06 07:52:39,220][train_inner][INFO] - {"epoch": 36, "update": 35.945, "loss": "72.359", "ntokens": "14744.7", "nsentences": "79.72", "nll_loss": "0.391", "wps": "8330.5", "ups": "0.56", "wpb": "14744.7", "bsz": "79.7", "num_updates": "46600", "lr": "3e-05", "gnorm": "106.114", "loss_scale": "8", "train_wall": "353", "gb_free": "31.3", "wall": "82951"}
[2024-07-06 07:54:43,215][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 07:54:43,284][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 07:55:15,432][dev-other][INFO] - {"epoch": 36, "dev-other_loss": "23.123", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.246", "dev-other_uer": "3.706", "dev-other_wer": "9.78", "dev-other_raw_wer": "9.78", "dev-other_wps": "8665.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "46671", "dev-other_best_wer": "9.621"}
[2024-07-06 07:55:15,432][fairseq_cli.train][INFO] - end of epoch 36 (average epoch stats below)
[2024-07-06 07:55:15,435][train][INFO] - {"epoch": 36, "train_loss": "73.471", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.398", "train_wps": "8314.5", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "46671", "train_lr": "3e-05", "train_gnorm": "107.526", "train_loss_scale": "8", "train_train_wall": "2275", "train_gb_free": "31.6", "train_wall": "83107"}
[2024-07-06 07:55:15,436][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 07:55:16,059][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 07:55:16,063][fairseq.trainer][INFO] - begin training epoch 37
[2024-07-06 07:55:16,063][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 07:59:04,934][train_inner][INFO] - {"epoch": 37, "update": 36.099, "loss": "71.885", "ntokens": "14945.8", "nsentences": "81.64", "nll_loss": "0.393", "wps": "7751.6", "ups": "0.52", "wpb": "14945.8", "bsz": "81.6", "num_updates": "46800", "lr": "3e-05", "gnorm": "105.414", "loss_scale": "8", "train_wall": "352", "gb_free": "32.3", "wall": "83337"}
[2024-07-06 08:04:58,942][train_inner][INFO] - {"epoch": 37, "update": 36.254, "loss": "76.651", "ntokens": "14739", "nsentences": "79.35", "nll_loss": "0.413", "wps": "8328.8", "ups": "0.57", "wpb": "14739", "bsz": "79.4", "num_updates": "47000", "lr": "3e-05", "gnorm": "109.328", "loss_scale": "8", "train_wall": "353", "gb_free": "31.8", "wall": "83691"}
[2024-07-06 08:10:50,518][train_inner][INFO] - {"epoch": 37, "update": 36.408, "loss": "71.837", "ntokens": "14718.1", "nsentences": "80.76", "nll_loss": "0.394", "wps": "8374.5", "ups": "0.57", "wpb": "14718.1", "bsz": "80.8", "num_updates": "47200", "lr": "3e-05", "gnorm": "106.819", "loss_scale": "8", "train_wall": "351", "gb_free": "30.6", "wall": "84042"}
[2024-07-06 08:16:31,803][train_inner][INFO] - {"epoch": 37, "update": 36.562, "loss": "75.861", "ntokens": "14838.7", "nsentences": "79.68", "nll_loss": "0.407", "wps": "8697.8", "ups": "0.59", "wpb": "14838.7", "bsz": "79.7", "num_updates": "47400", "lr": "3e-05", "gnorm": "107.855", "loss_scale": "16", "train_wall": "341", "gb_free": "29.3", "wall": "84383"}
[2024-07-06 08:22:24,829][train_inner][INFO] - {"epoch": 37, "update": 36.716, "loss": "72.809", "ntokens": "14859.6", "nsentences": "80.56", "nll_loss": "0.395", "wps": "8418.7", "ups": "0.57", "wpb": "14859.6", "bsz": "80.6", "num_updates": "47600", "lr": "3e-05", "gnorm": "108.379", "loss_scale": "16", "train_wall": "352", "gb_free": "32.5", "wall": "84737"}
[2024-07-06 08:28:11,885][train_inner][INFO] - {"epoch": 37, "update": 36.87, "loss": "76.096", "ntokens": "14789.5", "nsentences": "79.56", "nll_loss": "0.409", "wps": "8524.5", "ups": "0.58", "wpb": "14789.5", "bsz": "79.6", "num_updates": "47800", "lr": "3e-05", "gnorm": "108.75", "loss_scale": "16", "train_wall": "346", "gb_free": "31.8", "wall": "85084"}
[2024-07-06 08:33:04,619][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 08:33:04,682][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 08:33:36,964][dev-other][INFO] - {"epoch": 37, "dev-other_loss": "23.866", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.254", "dev-other_uer": "3.778", "dev-other_wer": "9.788", "dev-other_raw_wer": "9.788", "dev-other_wps": "8659.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "47968", "dev-other_best_wer": "9.621"}
[2024-07-06 08:33:36,967][fairseq_cli.train][INFO] - end of epoch 37 (average epoch stats below)
[2024-07-06 08:33:36,971][train][INFO] - {"epoch": 37, "train_loss": "74.275", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.402", "train_wps": "8353.3", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "47968", "train_lr": "3e-05", "train_gnorm": "108.09", "train_loss_scale": "16", "train_train_wall": "2264", "train_gb_free": "31.6", "train_wall": "85409"}
[2024-07-06 08:33:36,973][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 08:33:37,555][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 08:33:37,559][fairseq.trainer][INFO] - begin training epoch 38
[2024-07-06 08:33:37,559][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 08:34:29,630][train_inner][INFO] - {"epoch": 38, "update": 37.025, "loss": "74.175", "ntokens": "14860.9", "nsentences": "79.96", "nll_loss": "0.399", "wps": "7869.7", "ups": "0.53", "wpb": "14860.9", "bsz": "80", "num_updates": "48000", "lr": "3e-05", "gnorm": "109.653", "loss_scale": "16", "train_wall": "344", "gb_free": "32.4", "wall": "85461"}
[2024-07-06 08:40:18,755][train_inner][INFO] - {"epoch": 38, "update": 37.179, "loss": "73.706", "ntokens": "14785.7", "nsentences": "80.16", "nll_loss": "0.4", "wps": "8471.5", "ups": "0.57", "wpb": "14785.7", "bsz": "80.2", "num_updates": "48200", "lr": "3e-05", "gnorm": "108.74", "loss_scale": "16", "train_wall": "349", "gb_free": "32.3", "wall": "85810"}
[2024-07-06 08:46:15,677][train_inner][INFO] - {"epoch": 38, "update": 37.333, "loss": "73.807", "ntokens": "14909.4", "nsentences": "80", "nll_loss": "0.396", "wps": "8356", "ups": "0.56", "wpb": "14909.4", "bsz": "80", "num_updates": "48400", "lr": "3e-05", "gnorm": "107.516", "loss_scale": "16", "train_wall": "356", "gb_free": "32", "wall": "86167"}
[2024-07-06 08:49:45,939][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-06 08:52:12,106][train_inner][INFO] - {"epoch": 38, "update": 37.488, "loss": "71.996", "ntokens": "14838.7", "nsentences": "80.12", "nll_loss": "0.389", "wps": "8328", "ups": "0.56", "wpb": "14838.7", "bsz": "80.1", "num_updates": "48600", "lr": "3e-05", "gnorm": "106.05", "loss_scale": "8", "train_wall": "356", "gb_free": "33.2", "wall": "86524"}
[2024-07-06 08:57:55,171][train_inner][INFO] - {"epoch": 38, "update": 37.642, "loss": "74.925", "ntokens": "14831.9", "nsentences": "79.52", "nll_loss": "0.402", "wps": "8648.4", "ups": "0.58", "wpb": "14831.9", "bsz": "79.5", "num_updates": "48800", "lr": "3e-05", "gnorm": "110.194", "loss_scale": "8", "train_wall": "342", "gb_free": "32.1", "wall": "86867"}
[2024-07-06 09:03:50,968][train_inner][INFO] - {"epoch": 38, "update": 37.796, "loss": "74.378", "ntokens": "14792.1", "nsentences": "81.32", "nll_loss": "0.409", "wps": "8316.6", "ups": "0.56", "wpb": "14792.1", "bsz": "81.3", "num_updates": "49000", "lr": "3e-05", "gnorm": "107.661", "loss_scale": "8", "train_wall": "355", "gb_free": "32.8", "wall": "87223"}
[2024-07-06 09:09:41,614][train_inner][INFO] - {"epoch": 38, "update": 37.951, "loss": "72.307", "ntokens": "14798.9", "nsentences": "80.36", "nll_loss": "0.393", "wps": "8442.7", "ups": "0.57", "wpb": "14798.9", "bsz": "80.4", "num_updates": "49200", "lr": "3e-05", "gnorm": "106.072", "loss_scale": "8", "train_wall": "350", "gb_free": "32", "wall": "87573"}
[2024-07-06 09:11:32,903][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 09:11:32,969][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 09:12:05,245][dev-other][INFO] - {"epoch": 38, "dev-other_loss": "23.187", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.246", "dev-other_uer": "3.663", "dev-other_wer": "9.496", "dev-other_raw_wer": "9.496", "dev-other_wps": "8663.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "49264", "dev-other_best_wer": "9.496"}
[2024-07-06 09:12:05,245][fairseq_cli.train][INFO] - end of epoch 38 (average epoch stats below)
[2024-07-06 09:12:05,250][train][INFO] - {"epoch": 38, "train_loss": "73.513", "train_ntokens": "14821.7", "train_nsentences": "80.2037", "train_nll_loss": "0.398", "train_wps": "8321.8", "train_ups": "0.56", "train_wpb": "14821.7", "train_bsz": "80.2", "train_num_updates": "49264", "train_lr": "3e-05", "train_gnorm": "107.738", "train_loss_scale": "8", "train_train_wall": "2271", "train_gb_free": "32.6", "train_wall": "87717"}
[2024-07-06 09:12:05,252][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 09:12:05,840][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 09:12:05,844][fairseq.trainer][INFO] - begin training epoch 39
[2024-07-06 09:12:05,845][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 09:16:04,772][train_inner][INFO] - {"epoch": 39, "update": 38.105, "loss": "74.3", "ntokens": "14839.4", "nsentences": "80.03", "nll_loss": "0.401", "wps": "7746", "ups": "0.52", "wpb": "14839.4", "bsz": "80", "num_updates": "49400", "lr": "3e-05", "gnorm": "108.076", "loss_scale": "8", "train_wall": "350", "gb_free": "31.3", "wall": "87956"}
[2024-07-06 09:21:59,895][train_inner][INFO] - {"epoch": 39, "update": 38.259, "loss": "72.069", "ntokens": "14752.3", "nsentences": "80.72", "nll_loss": "0.394", "wps": "8310.4", "ups": "0.56", "wpb": "14752.3", "bsz": "80.7", "num_updates": "49600", "lr": "3e-05", "gnorm": "105.705", "loss_scale": "8", "train_wall": "354", "gb_free": "31.4", "wall": "88312"}
[2024-07-06 09:27:45,624][train_inner][INFO] - {"epoch": 39, "update": 38.413, "loss": "71.607", "ntokens": "14794", "nsentences": "80.24", "nll_loss": "0.388", "wps": "8560.2", "ups": "0.58", "wpb": "14794", "bsz": "80.2", "num_updates": "49800", "lr": "3e-05", "gnorm": "106.487", "loss_scale": "8", "train_wall": "345", "gb_free": "33.2", "wall": "88657"}
[2024-07-06 09:33:25,095][train_inner][INFO] - {"epoch": 39, "update": 38.567, "loss": "75.767", "ntokens": "14866.8", "nsentences": "80.6", "nll_loss": "0.411", "wps": "8760.9", "ups": "0.59", "wpb": "14866.8", "bsz": "80.6", "num_updates": "50000", "lr": "3e-05", "gnorm": "111.958", "loss_scale": "8", "train_wall": "339", "gb_free": "32.6", "wall": "88997"}
[2024-07-06 09:39:18,950][train_inner][INFO] - {"epoch": 39, "update": 38.722, "loss": "70.729", "ntokens": "14918.2", "nsentences": "81.2", "nll_loss": "0.385", "wps": "8433.6", "ups": "0.57", "wpb": "14918.2", "bsz": "81.2", "num_updates": "50200", "lr": "2.96427e-05", "gnorm": "104.412", "loss_scale": "8", "train_wall": "353", "gb_free": "33", "wall": "89351"}
[2024-07-06 09:45:02,139][train_inner][INFO] - {"epoch": 39, "update": 38.876, "loss": "75.229", "ntokens": "14785", "nsentences": "78.68", "nll_loss": "0.4", "wps": "8617", "ups": "0.58", "wpb": "14785.1", "bsz": "78.7", "num_updates": "50400", "lr": "2.92896e-05", "gnorm": "111.985", "loss_scale": "8", "train_wall": "343", "gb_free": "29.7", "wall": "89694"}
[2024-07-06 09:49:35,493][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 09:49:35,567][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 09:50:07,653][dev-other][INFO] - {"epoch": 39, "dev-other_loss": "24.068", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.256", "dev-other_uer": "3.791", "dev-other_wer": "9.771", "dev-other_raw_wer": "9.771", "dev-other_wps": "8705.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "50561", "dev-other_best_wer": "9.621"}
[2024-07-06 09:50:07,653][fairseq_cli.train][INFO] - end of epoch 39 (average epoch stats below)
[2024-07-06 09:50:07,664][train][INFO] - {"epoch": 39, "train_loss": "73.883", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.4", "train_wps": "8423.3", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "50561", "train_lr": "2.90084e-05", "train_gnorm": "108.855", "train_loss_scale": "8", "train_train_wall": "2246", "train_gb_free": "32.7", "train_wall": "89999"}
[2024-07-06 09:50:07,666][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 09:50:08,260][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 09:50:08,263][fairseq.trainer][INFO] - begin training epoch 40
[2024-07-06 09:50:08,264][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 09:51:17,387][train_inner][INFO] - {"epoch": 40, "update": 39.03, "loss": "76.214", "ntokens": "14823.2", "nsentences": "80.84", "nll_loss": "0.416", "wps": "7900.7", "ups": "0.53", "wpb": "14823.2", "bsz": "80.8", "num_updates": "50600", "lr": "2.89407e-05", "gnorm": "111.444", "loss_scale": "16", "train_wall": "342", "gb_free": "31.7", "wall": "90069"}
[2024-07-06 09:57:15,785][train_inner][INFO] - {"epoch": 40, "update": 39.184, "loss": "70.498", "ntokens": "14920.5", "nsentences": "82.04", "nll_loss": "0.388", "wps": "8328.4", "ups": "0.56", "wpb": "14920.5", "bsz": "82", "num_updates": "50800", "lr": "2.8596e-05", "gnorm": "104.503", "loss_scale": "16", "train_wall": "358", "gb_free": "29.5", "wall": "90427"}
[2024-07-06 10:03:09,823][train_inner][INFO] - {"epoch": 40, "update": 39.338, "loss": "73.506", "ntokens": "14805.9", "nsentences": "79.36", "nll_loss": "0.394", "wps": "8365.7", "ups": "0.57", "wpb": "14805.9", "bsz": "79.4", "num_updates": "51000", "lr": "2.82553e-05", "gnorm": "107.079", "loss_scale": "16", "train_wall": "353", "gb_free": "31.4", "wall": "90781"}
[2024-07-06 10:09:05,274][train_inner][INFO] - {"epoch": 40, "update": 39.493, "loss": "74.111", "ntokens": "14868.6", "nsentences": "79.36", "nll_loss": "0.396", "wps": "8366.3", "ups": "0.56", "wpb": "14868.6", "bsz": "79.4", "num_updates": "51200", "lr": "2.79188e-05", "gnorm": "108.539", "loss_scale": "16", "train_wall": "355", "gb_free": "31.9", "wall": "91137"}
[2024-07-06 10:10:10,669][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-06 10:14:59,503][train_inner][INFO] - {"epoch": 40, "update": 39.648, "loss": "72.104", "ntokens": "14790.3", "nsentences": "79.72", "nll_loss": "0.389", "wps": "8352.6", "ups": "0.56", "wpb": "14790.3", "bsz": "79.7", "num_updates": "51400", "lr": "2.75862e-05", "gnorm": "106.855", "loss_scale": "8", "train_wall": "354", "gb_free": "33.7", "wall": "91491"}
[2024-07-06 10:20:59,887][train_inner][INFO] - {"epoch": 40, "update": 39.802, "loss": "72.423", "ntokens": "14784.6", "nsentences": "79.4", "nll_loss": "0.389", "wps": "8205.7", "ups": "0.56", "wpb": "14784.6", "bsz": "79.4", "num_updates": "51600", "lr": "2.72576e-05", "gnorm": "106.936", "loss_scale": "8", "train_wall": "360", "gb_free": "31.3", "wall": "91852"}
[2024-07-06 10:26:35,467][train_inner][INFO] - {"epoch": 40, "update": 39.956, "loss": "75.186", "ntokens": "14771.8", "nsentences": "80.08", "nll_loss": "0.408", "wps": "8805.6", "ups": "0.6", "wpb": "14771.8", "bsz": "80.1", "num_updates": "51800", "lr": "2.6933e-05", "gnorm": "111.364", "loss_scale": "8", "train_wall": "335", "gb_free": "31.9", "wall": "92187"}
[2024-07-06 10:28:14,758][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 10:28:14,825][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 10:28:47,188][dev-other][INFO] - {"epoch": 40, "dev-other_loss": "24", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.255", "dev-other_uer": "3.819", "dev-other_wer": "9.865", "dev-other_raw_wer": "9.865", "dev-other_wps": "8644.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "51857", "dev-other_best_wer": "9.621"}
[2024-07-06 10:28:47,190][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 40 @ 51857 updates
[2024-07-06 10:28:47,191][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_last.pt
[2024-07-06 10:28:48,538][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_last.pt
[2024-07-06 10:28:48,550][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_last.pt (epoch 40 @ 51857 updates, score 9.865) (writing took 1.3601414114236832 seconds)
[2024-07-06 10:28:48,550][fairseq_cli.train][INFO] - end of epoch 40 (average epoch stats below)
[2024-07-06 10:28:48,555][train][INFO] - {"epoch": 40, "train_loss": "72.681", "train_ntokens": "14821.2", "train_nsentences": "80.1852", "train_nll_loss": "0.393", "train_wps": "8276.3", "train_ups": "0.56", "train_wpb": "14821.2", "train_bsz": "80.2", "train_num_updates": "51857", "train_lr": "2.68411e-05", "train_gnorm": "107.445", "train_loss_scale": "8", "train_train_wall": "2282", "train_gb_free": "32.8", "train_wall": "92320"}
[2024-07-06 10:28:48,557][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 10:28:48,810][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 10:28:48,814][fairseq.trainer][INFO] - begin training epoch 41
[2024-07-06 10:28:48,815][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 10:32:56,597][train_inner][INFO] - {"epoch": 41, "update": 40.11, "loss": "70.537", "ntokens": "14867.8", "nsentences": "81.68", "nll_loss": "0.388", "wps": "7803.6", "ups": "0.52", "wpb": "14867.8", "bsz": "81.7", "num_updates": "52000", "lr": "2.66122e-05", "gnorm": "107.06", "loss_scale": "8", "train_wall": "346", "gb_free": "32", "wall": "92568"}
[2024-07-06 10:38:46,042][train_inner][INFO] - {"epoch": 41, "update": 40.264, "loss": "68.09", "ntokens": "14801.5", "nsentences": "81.52", "nll_loss": "0.375", "wps": "8473.4", "ups": "0.57", "wpb": "14801.5", "bsz": "81.5", "num_updates": "52200", "lr": "2.62952e-05", "gnorm": "105.302", "loss_scale": "8", "train_wall": "349", "gb_free": "32.6", "wall": "92918"}
[2024-07-06 10:44:34,748][train_inner][INFO] - {"epoch": 41, "update": 40.419, "loss": "72.869", "ntokens": "14844.5", "nsentences": "79.8", "nll_loss": "0.392", "wps": "8515.8", "ups": "0.57", "wpb": "14844.5", "bsz": "79.8", "num_updates": "52400", "lr": "2.5982e-05", "gnorm": "109.462", "loss_scale": "8", "train_wall": "348", "gb_free": "31.8", "wall": "93266"}
[2024-07-06 10:50:24,501][train_inner][INFO] - {"epoch": 41, "update": 40.573, "loss": "70.445", "ntokens": "14879.9", "nsentences": "81.36", "nll_loss": "0.385", "wps": "8509.3", "ups": "0.57", "wpb": "14879.9", "bsz": "81.4", "num_updates": "52600", "lr": "2.56725e-05", "gnorm": "105.692", "loss_scale": "8", "train_wall": "349", "gb_free": "31.8", "wall": "93616"}
[2024-07-06 10:56:09,256][train_inner][INFO] - {"epoch": 41, "update": 40.727, "loss": "73.987", "ntokens": "14885", "nsentences": "80.6", "nll_loss": "0.401", "wps": "8635.4", "ups": "0.58", "wpb": "14885", "bsz": "80.6", "num_updates": "52800", "lr": "2.53667e-05", "gnorm": "110.487", "loss_scale": "8", "train_wall": "344", "gb_free": "32.8", "wall": "93961"}
[2024-07-06 11:01:57,578][train_inner][INFO] - {"epoch": 41, "update": 40.881, "loss": "73.567", "ntokens": "14760.1", "nsentences": "78.4", "nll_loss": "0.391", "wps": "8475.2", "ups": "0.57", "wpb": "14760.1", "bsz": "78.4", "num_updates": "53000", "lr": "2.50645e-05", "gnorm": "108.519", "loss_scale": "8", "train_wall": "348", "gb_free": "32", "wall": "94309"}
[2024-07-06 11:06:36,741][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 11:06:36,808][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 11:07:08,990][dev-other][INFO] - {"epoch": 41, "dev-other_loss": "23.813", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.253", "dev-other_uer": "3.834", "dev-other_wer": "9.843", "dev-other_raw_wer": "9.843", "dev-other_wps": "8668.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "53154", "dev-other_best_wer": "9.621"}
[2024-07-06 11:07:08,991][fairseq_cli.train][INFO] - end of epoch 41 (average epoch stats below)
[2024-07-06 11:07:08,996][train][INFO] - {"epoch": 41, "train_loss": "71.74", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.388", "train_wps": "8357.2", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "53154", "train_lr": "2.48343e-05", "train_gnorm": "107.546", "train_loss_scale": "8", "train_train_wall": "2264", "train_gb_free": "33.1", "train_wall": "94621"}
[2024-07-06 11:07:08,998][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 11:07:09,590][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 11:07:09,593][fairseq.trainer][INFO] - begin training epoch 42
[2024-07-06 11:07:09,594][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 11:08:27,449][train_inner][INFO] - {"epoch": 42, "update": 41.035, "loss": "72.528", "ntokens": "14726.1", "nsentences": "78.79", "nll_loss": "0.388", "wps": "7555.9", "ups": "0.51", "wpb": "14726.1", "bsz": "78.8", "num_updates": "53200", "lr": "2.4766e-05", "gnorm": "106.244", "loss_scale": "8", "train_wall": "356", "gb_free": "31.3", "wall": "94699"}
[2024-07-06 11:14:15,891][train_inner][INFO] - {"epoch": 42, "update": 41.19, "loss": "72.118", "ntokens": "14803.6", "nsentences": "80.32", "nll_loss": "0.391", "wps": "8498.7", "ups": "0.57", "wpb": "14803.6", "bsz": "80.3", "num_updates": "53400", "lr": "2.4471e-05", "gnorm": "107.958", "loss_scale": "16", "train_wall": "348", "gb_free": "32.7", "wall": "95048"}
[2024-07-06 11:20:03,276][train_inner][INFO] - {"epoch": 42, "update": 41.344, "loss": "72.332", "ntokens": "14864.2", "nsentences": "79.64", "nll_loss": "0.388", "wps": "8559.5", "ups": "0.58", "wpb": "14864.2", "bsz": "79.6", "num_updates": "53600", "lr": "2.41795e-05", "gnorm": "107.963", "loss_scale": "16", "train_wall": "347", "gb_free": "31.9", "wall": "95395"}
[2024-07-06 11:25:48,365][train_inner][INFO] - {"epoch": 42, "update": 41.498, "loss": "70.662", "ntokens": "14703.5", "nsentences": "80.68", "nll_loss": "0.388", "wps": "8521.8", "ups": "0.58", "wpb": "14703.5", "bsz": "80.7", "num_updates": "53800", "lr": "2.38915e-05", "gnorm": "108.46", "loss_scale": "16", "train_wall": "345", "gb_free": "30.7", "wall": "95740"}
[2024-07-06 11:27:02,058][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-06 11:31:52,243][train_inner][INFO] - {"epoch": 42, "update": 41.653, "loss": "70.306", "ntokens": "14926.2", "nsentences": "79.44", "nll_loss": "0.374", "wps": "8205.6", "ups": "0.55", "wpb": "14926.2", "bsz": "79.4", "num_updates": "54000", "lr": "2.36069e-05", "gnorm": "104.283", "loss_scale": "8", "train_wall": "363", "gb_free": "32.9", "wall": "96104"}
[2024-07-06 11:37:46,803][train_inner][INFO] - {"epoch": 42, "update": 41.807, "loss": "70.253", "ntokens": "14799.6", "nsentences": "79.28", "nll_loss": "0.376", "wps": "8349.8", "ups": "0.56", "wpb": "14799.6", "bsz": "79.3", "num_updates": "54200", "lr": "2.33257e-05", "gnorm": "105.328", "loss_scale": "8", "train_wall": "354", "gb_free": "32.5", "wall": "96458"}
[2024-07-06 11:43:45,254][train_inner][INFO] - {"epoch": 42, "update": 41.961, "loss": "69.662", "ntokens": "14830.9", "nsentences": "80.92", "nll_loss": "0.38", "wps": "8276.9", "ups": "0.56", "wpb": "14830.9", "bsz": "80.9", "num_updates": "54400", "lr": "2.30479e-05", "gnorm": "105.014", "loss_scale": "8", "train_wall": "358", "gb_free": "32", "wall": "96817"}
[2024-07-06 11:45:14,537][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 11:45:14,545][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 11:45:46,751][dev-other][INFO] - {"epoch": 42, "dev-other_loss": "23.815", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.253", "dev-other_uer": "3.714", "dev-other_wer": "9.608", "dev-other_raw_wer": "9.608", "dev-other_wps": "8690.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "54450", "dev-other_best_wer": "9.608"}
[2024-07-06 11:45:46,752][fairseq_cli.train][INFO] - end of epoch 42 (average epoch stats below)
[2024-07-06 11:45:46,757][train][INFO] - {"epoch": 42, "train_loss": "71.139", "train_ntokens": "14823", "train_nsentences": "80.2037", "train_nll_loss": "0.385", "train_wps": "8288.4", "train_ups": "0.56", "train_wpb": "14823", "train_bsz": "80.2", "train_num_updates": "54450", "train_lr": "2.29789e-05", "train_gnorm": "106.548", "train_loss_scale": "8", "train_train_wall": "2281", "train_gb_free": "31.7", "train_wall": "96938"}
[2024-07-06 11:45:46,759][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 11:45:47,337][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 11:45:47,341][fairseq.trainer][INFO] - begin training epoch 43
[2024-07-06 11:45:47,341][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 11:50:18,088][train_inner][INFO] - {"epoch": 43, "update": 42.116, "loss": "71.933", "ntokens": "14789.9", "nsentences": "79.36", "nll_loss": "0.386", "wps": "7531.5", "ups": "0.51", "wpb": "14789.9", "bsz": "79.4", "num_updates": "54600", "lr": "2.27733e-05", "gnorm": "106.148", "loss_scale": "8", "train_wall": "359", "gb_free": "32.4", "wall": "97210"}
[2024-07-06 11:56:07,307][train_inner][INFO] - {"epoch": 43, "update": 42.27, "loss": "70.094", "ntokens": "14907.3", "nsentences": "82.32", "nll_loss": "0.387", "wps": "8539.4", "ups": "0.57", "wpb": "14907.3", "bsz": "82.3", "num_updates": "54800", "lr": "2.25021e-05", "gnorm": "103.9", "loss_scale": "8", "train_wall": "349", "gb_free": "33.1", "wall": "97559"}
[2024-07-06 12:01:51,063][train_inner][INFO] - {"epoch": 43, "update": 42.424, "loss": "72.81", "ntokens": "14928.1", "nsentences": "80.8", "nll_loss": "0.394", "wps": "8685.6", "ups": "0.58", "wpb": "14928.1", "bsz": "80.8", "num_updates": "55000", "lr": "2.2234e-05", "gnorm": "108.487", "loss_scale": "8", "train_wall": "343", "gb_free": "32.7", "wall": "97903"}
[2024-07-06 12:07:48,686][train_inner][INFO] - {"epoch": 43, "update": 42.578, "loss": "71.485", "ntokens": "14765.7", "nsentences": "78.83", "nll_loss": "0.382", "wps": "8259.4", "ups": "0.56", "wpb": "14765.7", "bsz": "78.8", "num_updates": "55200", "lr": "2.19692e-05", "gnorm": "106.382", "loss_scale": "8", "train_wall": "357", "gb_free": "29.6", "wall": "98260"}
[2024-07-06 12:13:36,336][train_inner][INFO] - {"epoch": 43, "update": 42.732, "loss": "72.431", "ntokens": "14791.2", "nsentences": "81.56", "nll_loss": "0.399", "wps": "8511.1", "ups": "0.58", "wpb": "14791.2", "bsz": "81.6", "num_updates": "55400", "lr": "2.17075e-05", "gnorm": "106.104", "loss_scale": "8", "train_wall": "347", "gb_free": "33.5", "wall": "98608"}
[2024-07-06 12:19:32,120][train_inner][INFO] - {"epoch": 43, "update": 42.887, "loss": "68.804", "ntokens": "14778.8", "nsentences": "79.44", "nll_loss": "0.37", "wps": "8308.3", "ups": "0.56", "wpb": "14778.8", "bsz": "79.4", "num_updates": "55600", "lr": "2.14489e-05", "gnorm": "105.493", "loss_scale": "8", "train_wall": "355", "gb_free": "33.2", "wall": "98964"}
[2024-07-06 12:23:48,286][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 12:23:48,353][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 12:24:20,469][dev-other][INFO] - {"epoch": 43, "dev-other_loss": "23.432", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.249", "dev-other_uer": "3.722", "dev-other_wer": "9.582", "dev-other_raw_wer": "9.582", "dev-other_wps": "8713.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "55747", "dev-other_best_wer": "9.582"}
[2024-07-06 12:24:20,469][fairseq_cli.train][INFO] - end of epoch 43 (average epoch stats below)
[2024-07-06 12:24:20,473][train][INFO] - {"epoch": 43, "train_loss": "71.41", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.386", "train_wps": "8309.3", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "55747", "train_lr": "2.12609e-05", "train_gnorm": "106.331", "train_loss_scale": "8", "train_train_wall": "2277", "train_gb_free": "31.2", "train_wall": "99252"}
[2024-07-06 12:24:20,475][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 12:24:21,145][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 12:24:21,148][fairseq.trainer][INFO] - begin training epoch 44
[2024-07-06 12:24:21,148][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 12:25:57,764][train_inner][INFO] - {"epoch": 44, "update": 43.041, "loss": "72.523", "ntokens": "14709.1", "nsentences": "79.07", "nll_loss": "0.39", "wps": "7628.5", "ups": "0.52", "wpb": "14709.1", "bsz": "79.1", "num_updates": "55800", "lr": "2.11935e-05", "gnorm": "107.235", "loss_scale": "8", "train_wall": "352", "gb_free": "31", "wall": "99349"}
[2024-07-06 12:31:49,290][train_inner][INFO] - {"epoch": 44, "update": 43.195, "loss": "69.16", "ntokens": "14789.1", "nsentences": "79.12", "nll_loss": "0.37", "wps": "8414.5", "ups": "0.57", "wpb": "14789.1", "bsz": "79.1", "num_updates": "56000", "lr": "2.0941e-05", "gnorm": "106.872", "loss_scale": "16", "train_wall": "351", "gb_free": "30.2", "wall": "99701"}
[2024-07-06 12:37:36,567][train_inner][INFO] - {"epoch": 44, "update": 43.349, "loss": "72.162", "ntokens": "14926", "nsentences": "80.76", "nll_loss": "0.39", "wps": "8597.6", "ups": "0.58", "wpb": "14926", "bsz": "80.8", "num_updates": "56200", "lr": "2.06916e-05", "gnorm": "106.098", "loss_scale": "16", "train_wall": "347", "gb_free": "32.5", "wall": "100048"}
[2024-07-06 12:43:33,643][train_inner][INFO] - {"epoch": 44, "update": 43.503, "loss": "69.319", "ntokens": "14770.9", "nsentences": "79.84", "nll_loss": "0.375", "wps": "8273.5", "ups": "0.56", "wpb": "14770.9", "bsz": "79.8", "num_updates": "56400", "lr": "2.04451e-05", "gnorm": "104.125", "loss_scale": "16", "train_wall": "357", "gb_free": "31.7", "wall": "100405"}
[2024-07-06 12:49:33,244][train_inner][INFO] - {"epoch": 44, "update": 43.658, "loss": "65.529", "ntokens": "14916.6", "nsentences": "83.24", "nll_loss": "0.366", "wps": "8298.7", "ups": "0.56", "wpb": "14916.6", "bsz": "83.2", "num_updates": "56600", "lr": "2.02016e-05", "gnorm": "102.104", "loss_scale": "16", "train_wall": "359", "gb_free": "32.9", "wall": "100765"}
[2024-07-06 12:55:19,217][train_inner][INFO] - {"epoch": 44, "update": 43.812, "loss": "72.432", "ntokens": "14829.3", "nsentences": "79.68", "nll_loss": "0.389", "wps": "8574.5", "ups": "0.58", "wpb": "14829.3", "bsz": "79.7", "num_updates": "56800", "lr": "1.99609e-05", "gnorm": "106.719", "loss_scale": "16", "train_wall": "345", "gb_free": "32.6", "wall": "101111"}
[2024-07-06 13:01:15,877][train_inner][INFO] - {"epoch": 44, "update": 43.966, "loss": "69.773", "ntokens": "14766.9", "nsentences": "79.08", "nll_loss": "0.374", "wps": "8282.5", "ups": "0.56", "wpb": "14766.9", "bsz": "79.1", "num_updates": "57000", "lr": "1.97232e-05", "gnorm": "106.447", "loss_scale": "16", "train_wall": "356", "gb_free": "31.9", "wall": "101467"}
[2024-07-06 13:02:36,439][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 13:02:36,517][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 13:03:08,743][dev-other][INFO] - {"epoch": 44, "dev-other_loss": "23.354", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.248", "dev-other_uer": "3.679", "dev-other_wer": "9.478", "dev-other_raw_wer": "9.478", "dev-other_wps": "8645", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "57044", "dev-other_best_wer": "9.478"}
[2024-07-06 13:03:08,743][fairseq_cli.train][INFO] - end of epoch 44 (average epoch stats below)
[2024-07-06 13:03:08,746][train][INFO] - {"epoch": 44, "train_loss": "69.647", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.377", "train_wps": "8257.3", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "57044", "train_lr": "1.96713e-05", "train_gnorm": "105.385", "train_loss_scale": "16", "train_train_wall": "2291", "train_gb_free": "32.9", "train_wall": "101580"}
[2024-07-06 13:03:08,772][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 13:03:09,374][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 13:03:09,378][fairseq.trainer][INFO] - begin training epoch 45
[2024-07-06 13:03:09,378][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 13:07:45,610][train_inner][INFO] - {"epoch": 45, "update": 44.12, "loss": "68.96", "ntokens": "14858.6", "nsentences": "81.08", "nll_loss": "0.376", "wps": "7626.6", "ups": "0.51", "wpb": "14858.6", "bsz": "81.1", "num_updates": "57200", "lr": "1.94883e-05", "gnorm": "105.312", "loss_scale": "16", "train_wall": "356", "gb_free": "31.9", "wall": "101857"}
[2024-07-06 13:12:07,069][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-06 13:13:32,538][train_inner][INFO] - {"epoch": 45, "update": 44.275, "loss": "71.77", "ntokens": "14795.4", "nsentences": "80", "nll_loss": "0.388", "wps": "8531.3", "ups": "0.58", "wpb": "14795.4", "bsz": "80", "num_updates": "57400", "lr": "1.92561e-05", "gnorm": "109.018", "loss_scale": "8", "train_wall": "346", "gb_free": "31.8", "wall": "102204"}
[2024-07-06 13:19:19,091][train_inner][INFO] - {"epoch": 45, "update": 44.429, "loss": "71.084", "ntokens": "14778.8", "nsentences": "79.12", "nll_loss": "0.381", "wps": "8531.2", "ups": "0.58", "wpb": "14778.8", "bsz": "79.1", "num_updates": "57600", "lr": "1.90268e-05", "gnorm": "107.741", "loss_scale": "8", "train_wall": "346", "gb_free": "32.1", "wall": "102551"}
[2024-07-06 13:25:07,897][train_inner][INFO] - {"epoch": 45, "update": 44.584, "loss": "70.403", "ntokens": "14851.9", "nsentences": "80.44", "nll_loss": "0.381", "wps": "8517.6", "ups": "0.57", "wpb": "14851.9", "bsz": "80.4", "num_updates": "57800", "lr": "1.88001e-05", "gnorm": "107.142", "loss_scale": "8", "train_wall": "348", "gb_free": "32.4", "wall": "102900"}
[2024-07-06 13:30:57,325][train_inner][INFO] - {"epoch": 45, "update": 44.738, "loss": "71.408", "ntokens": "14754.7", "nsentences": "79", "nll_loss": "0.382", "wps": "8447.1", "ups": "0.57", "wpb": "14754.7", "bsz": "79", "num_updates": "58000", "lr": "1.85762e-05", "gnorm": "107.234", "loss_scale": "8", "train_wall": "349", "gb_free": "31", "wall": "103249"}
[2024-07-06 13:36:50,033][train_inner][INFO] - {"epoch": 45, "update": 44.892, "loss": "67.348", "ntokens": "14944.8", "nsentences": "82.44", "nll_loss": "0.372", "wps": "8474.6", "ups": "0.57", "wpb": "14944.8", "bsz": "82.4", "num_updates": "58200", "lr": "1.83549e-05", "gnorm": "105.275", "loss_scale": "8", "train_wall": "352", "gb_free": "33.5", "wall": "103602"}
[2024-07-06 13:40:56,117][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 13:40:56,123][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 13:41:28,347][dev-other][INFO] - {"epoch": 45, "dev-other_loss": "23.89", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.254", "dev-other_uer": "3.756", "dev-other_wer": "9.659", "dev-other_raw_wer": "9.659", "dev-other_wps": "8638.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "58340", "dev-other_best_wer": "9.621"}
[2024-07-06 13:41:28,350][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 45 @ 58340 updates
[2024-07-06 13:41:28,351][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_last.pt
[2024-07-06 13:41:30,353][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_last.pt
[2024-07-06 13:41:30,375][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_last.pt (epoch 45 @ 58340 updates, score 9.659) (writing took 2.024862088263035 seconds)
[2024-07-06 13:41:30,375][fairseq_cli.train][INFO] - end of epoch 45 (average epoch stats below)
[2024-07-06 13:41:30,379][train][INFO] - {"epoch": 45, "train_loss": "70.193", "train_ntokens": "14822", "train_nsentences": "80.2037", "train_nll_loss": "0.38", "train_wps": "8346", "train_ups": "0.56", "train_wpb": "14822", "train_bsz": "80.2", "train_num_updates": "58340", "train_lr": "1.82016e-05", "train_gnorm": "107.006", "train_loss_scale": "8", "train_train_wall": "2263", "train_gb_free": "32.8", "train_wall": "103882"}
[2024-07-06 13:41:30,381][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 13:41:30,637][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 13:41:30,640][fairseq.trainer][INFO] - begin training epoch 46
[2024-07-06 13:41:30,640][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 13:43:19,684][train_inner][INFO] - {"epoch": 46, "update": 45.046, "loss": "69.088", "ntokens": "14734.8", "nsentences": "78", "nll_loss": "0.366", "wps": "7564.6", "ups": "0.51", "wpb": "14734.8", "bsz": "78", "num_updates": "58400", "lr": "1.81363e-05", "gnorm": "107.263", "loss_scale": "8", "train_wall": "354", "gb_free": "32.6", "wall": "103991"}
[2024-07-06 13:49:16,932][train_inner][INFO] - {"epoch": 46, "update": 45.2, "loss": "68.586", "ntokens": "14852.6", "nsentences": "80.87", "nll_loss": "0.373", "wps": "8317.4", "ups": "0.56", "wpb": "14852.6", "bsz": "80.9", "num_updates": "58600", "lr": "1.79203e-05", "gnorm": "104.266", "loss_scale": "8", "train_wall": "357", "gb_free": "30.4", "wall": "104349"}
[2024-07-06 13:55:16,473][train_inner][INFO] - {"epoch": 46, "update": 45.355, "loss": "67.816", "ntokens": "14801.9", "nsentences": "79.56", "nll_loss": "0.365", "wps": "8235.6", "ups": "0.56", "wpb": "14801.9", "bsz": "79.6", "num_updates": "58800", "lr": "1.77068e-05", "gnorm": "104.859", "loss_scale": "8", "train_wall": "359", "gb_free": "32.9", "wall": "104708"}
[2024-07-06 14:01:04,362][train_inner][INFO] - {"epoch": 46, "update": 45.509, "loss": "67.048", "ntokens": "14872.9", "nsentences": "83.08", "nll_loss": "0.375", "wps": "8552.2", "ups": "0.58", "wpb": "14872.9", "bsz": "83.1", "num_updates": "59000", "lr": "1.74959e-05", "gnorm": "103.641", "loss_scale": "8", "train_wall": "347", "gb_free": "33.4", "wall": "105056"}
[2024-07-06 14:07:01,651][train_inner][INFO] - {"epoch": 46, "update": 45.663, "loss": "69.669", "ntokens": "14817.4", "nsentences": "79.96", "nll_loss": "0.376", "wps": "8296", "ups": "0.56", "wpb": "14817.4", "bsz": "80", "num_updates": "59200", "lr": "1.72875e-05", "gnorm": "106.101", "loss_scale": "8", "train_wall": "357", "gb_free": "29.8", "wall": "105413"}
[2024-07-06 14:12:50,067][train_inner][INFO] - {"epoch": 46, "update": 45.817, "loss": "71.598", "ntokens": "14879.7", "nsentences": "79.76", "nll_loss": "0.384", "wps": "8541.6", "ups": "0.57", "wpb": "14879.7", "bsz": "79.8", "num_updates": "59400", "lr": "1.70816e-05", "gnorm": "107.087", "loss_scale": "16", "train_wall": "348", "gb_free": "32.8", "wall": "105762"}
[2024-07-06 14:18:33,935][train_inner][INFO] - {"epoch": 46, "update": 45.971, "loss": "70.714", "ntokens": "14750", "nsentences": "79.6", "nll_loss": "0.382", "wps": "8580.7", "ups": "0.58", "wpb": "14750", "bsz": "79.6", "num_updates": "59600", "lr": "1.68781e-05", "gnorm": "108.565", "loss_scale": "16", "train_wall": "343", "gb_free": "32.6", "wall": "106106"}
[2024-07-06 14:19:39,480][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 14:19:39,492][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 14:20:11,481][dev-other][INFO] - {"epoch": 46, "dev-other_loss": "23.392", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.249", "dev-other_uer": "3.724", "dev-other_wer": "9.647", "dev-other_raw_wer": "9.647", "dev-other_wps": "8740.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "59637", "dev-other_best_wer": "9.621"}
[2024-07-06 14:20:11,482][fairseq_cli.train][INFO] - end of epoch 46 (average epoch stats below)
[2024-07-06 14:20:11,498][train][INFO] - {"epoch": 46, "train_loss": "69.203", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.374", "train_wps": "8282.8", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "59637", "train_lr": "1.68407e-05", "train_gnorm": "105.83", "train_loss_scale": "16", "train_train_wall": "2285", "train_gb_free": "32.3", "train_wall": "106203"}
[2024-07-06 14:20:11,499][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 14:20:12,134][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 14:20:12,137][fairseq.trainer][INFO] - begin training epoch 47
[2024-07-06 14:20:12,138][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 14:24:58,061][train_inner][INFO] - {"epoch": 47, "update": 46.126, "loss": "70.199", "ntokens": "14868.4", "nsentences": "80.88", "nll_loss": "0.382", "wps": "7743.1", "ups": "0.52", "wpb": "14868.4", "bsz": "80.9", "num_updates": "59800", "lr": "1.66771e-05", "gnorm": "105.233", "loss_scale": "16", "train_wall": "351", "gb_free": "32.8", "wall": "106490"}
[2024-07-06 14:30:51,851][train_inner][INFO] - {"epoch": 47, "update": 46.28, "loss": "69.41", "ntokens": "14863.7", "nsentences": "79.84", "nll_loss": "0.373", "wps": "8404.3", "ups": "0.57", "wpb": "14863.7", "bsz": "79.8", "num_updates": "60000", "lr": "1.64784e-05", "gnorm": "106.359", "loss_scale": "16", "train_wall": "353", "gb_free": "32", "wall": "106843"}
[2024-07-06 14:36:44,830][train_inner][INFO] - {"epoch": 47, "update": 46.434, "loss": "68.102", "ntokens": "14782.1", "nsentences": "80.64", "nll_loss": "0.372", "wps": "8375.8", "ups": "0.57", "wpb": "14782.1", "bsz": "80.6", "num_updates": "60200", "lr": "1.62821e-05", "gnorm": "104.824", "loss_scale": "16", "train_wall": "352", "gb_free": "32.9", "wall": "107197"}
[2024-07-06 14:42:34,872][train_inner][INFO] - {"epoch": 47, "update": 46.588, "loss": "71.429", "ntokens": "14916.9", "nsentences": "81", "nll_loss": "0.388", "wps": "8524.7", "ups": "0.57", "wpb": "14916.9", "bsz": "81", "num_updates": "60400", "lr": "1.60882e-05", "gnorm": "106.514", "loss_scale": "16", "train_wall": "349", "gb_free": "32.7", "wall": "107546"}
[2024-07-06 14:48:33,134][train_inner][INFO] - {"epoch": 47, "update": 46.742, "loss": "70.73", "ntokens": "14699.8", "nsentences": "77.52", "nll_loss": "0.373", "wps": "8206.5", "ups": "0.56", "wpb": "14699.8", "bsz": "77.5", "num_updates": "60600", "lr": "1.58966e-05", "gnorm": "106.757", "loss_scale": "16", "train_wall": "358", "gb_free": "32.1", "wall": "107905"}
[2024-07-06 14:54:26,032][train_inner][INFO] - {"epoch": 47, "update": 46.897, "loss": "70.424", "ntokens": "14795.6", "nsentences": "81.2", "nll_loss": "0.386", "wps": "8385.6", "ups": "0.57", "wpb": "14795.6", "bsz": "81.2", "num_updates": "60800", "lr": "1.57072e-05", "gnorm": "104.904", "loss_scale": "16", "train_wall": "352", "gb_free": "32.9", "wall": "108258"}
[2024-07-06 14:56:24,890][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-06 14:58:19,340][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 14:58:19,406][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 14:58:51,672][dev-other][INFO] - {"epoch": 47, "dev-other_loss": "24.198", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.257", "dev-other_uer": "3.744", "dev-other_wer": "9.617", "dev-other_raw_wer": "9.617", "dev-other_wps": "8667.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "60933", "dev-other_best_wer": "9.617"}
[2024-07-06 14:58:51,673][fairseq_cli.train][INFO] - end of epoch 47 (average epoch stats below)
[2024-07-06 14:58:51,680][train][INFO] - {"epoch": 47, "train_loss": "70.306", "train_ntokens": "14821.9", "train_nsentences": "80.2037", "train_nll_loss": "0.38", "train_wps": "8279.2", "train_ups": "0.56", "train_wpb": "14821.9", "train_bsz": "80.2", "train_num_updates": "60933", "train_lr": "1.55825e-05", "train_gnorm": "105.985", "train_loss_scale": "8", "train_train_wall": "2283", "train_gb_free": "30.9", "train_wall": "108523"}
[2024-07-06 14:58:51,682][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 14:58:52,292][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 14:58:52,296][fairseq.trainer][INFO] - begin training epoch 48
[2024-07-06 14:58:52,297][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 15:00:49,332][train_inner][INFO] - {"epoch": 48, "update": 47.052, "loss": "72.188", "ntokens": "14841.2", "nsentences": "80", "nll_loss": "0.389", "wps": "7745.3", "ups": "0.52", "wpb": "14841.2", "bsz": "80", "num_updates": "61000", "lr": "1.55201e-05", "gnorm": "108.348", "loss_scale": "8", "train_wall": "350", "gb_free": "32.4", "wall": "108641"}
[2024-07-06 15:06:43,298][train_inner][INFO] - {"epoch": 48, "update": 47.206, "loss": "69.034", "ntokens": "14829.7", "nsentences": "80.52", "nll_loss": "0.375", "wps": "8380.8", "ups": "0.57", "wpb": "14829.7", "bsz": "80.5", "num_updates": "61200", "lr": "1.53352e-05", "gnorm": "105.496", "loss_scale": "8", "train_wall": "353", "gb_free": "32.5", "wall": "108995"}
[2024-07-06 15:12:40,032][train_inner][INFO] - {"epoch": 48, "update": 47.36, "loss": "69.7", "ntokens": "14804.3", "nsentences": "79.16", "nll_loss": "0.373", "wps": "8301.7", "ups": "0.56", "wpb": "14804.3", "bsz": "79.2", "num_updates": "61400", "lr": "1.51526e-05", "gnorm": "105.673", "loss_scale": "8", "train_wall": "356", "gb_free": "30.6", "wall": "109352"}
[2024-07-06 15:18:37,653][train_inner][INFO] - {"epoch": 48, "update": 47.514, "loss": "69.891", "ntokens": "14692.1", "nsentences": "79.11", "nll_loss": "0.376", "wps": "8216.8", "ups": "0.56", "wpb": "14692.1", "bsz": "79.1", "num_updates": "61600", "lr": "1.49721e-05", "gnorm": "106.489", "loss_scale": "8", "train_wall": "357", "gb_free": "31.9", "wall": "109709"}
[2024-07-06 15:24:26,218][train_inner][INFO] - {"epoch": 48, "update": 47.668, "loss": "68.711", "ntokens": "14921.3", "nsentences": "81.88", "nll_loss": "0.377", "wps": "8561.8", "ups": "0.57", "wpb": "14921.3", "bsz": "81.9", "num_updates": "61800", "lr": "1.47937e-05", "gnorm": "105.005", "loss_scale": "8", "train_wall": "348", "gb_free": "33.8", "wall": "110058"}
[2024-07-06 15:30:13,096][train_inner][INFO] - {"epoch": 48, "update": 47.823, "loss": "71.696", "ntokens": "14789.6", "nsentences": "79.32", "nll_loss": "0.385", "wps": "8529", "ups": "0.58", "wpb": "14789.6", "bsz": "79.3", "num_updates": "62000", "lr": "1.46175e-05", "gnorm": "109.31", "loss_scale": "8", "train_wall": "346", "gb_free": "31.7", "wall": "110405"}
[2024-07-06 15:36:00,466][train_inner][INFO] - {"epoch": 48, "update": 47.977, "loss": "69.752", "ntokens": "14915.8", "nsentences": "81.72", "nll_loss": "0.382", "wps": "8589.7", "ups": "0.58", "wpb": "14915.8", "bsz": "81.7", "num_updates": "62200", "lr": "1.44434e-05", "gnorm": "104.97", "loss_scale": "8", "train_wall": "347", "gb_free": "32", "wall": "110752"}
[2024-07-06 15:36:52,044][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 15:36:52,045][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 15:37:24,099][dev-other][INFO] - {"epoch": 48, "dev-other_loss": "23.238", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.247", "dev-other_uer": "3.701", "dev-other_wer": "9.464", "dev-other_raw_wer": "9.464", "dev-other_wps": "8718.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "62230", "dev-other_best_wer": "9.464"}
[2024-07-06 15:37:24,100][fairseq_cli.train][INFO] - end of epoch 48 (average epoch stats below)
[2024-07-06 15:37:24,104][train][INFO] - {"epoch": 48, "train_loss": "70.014", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.379", "train_wps": "8313.9", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "62230", "train_lr": "1.44175e-05", "train_gnorm": "106.351", "train_loss_scale": "8", "train_train_wall": "2276", "train_gb_free": "31.9", "train_wall": "110836"}
[2024-07-06 15:37:24,105][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 15:37:24,694][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 15:37:24,720][fairseq.trainer][INFO] - begin training epoch 49
[2024-07-06 15:37:24,721][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 15:42:25,546][train_inner][INFO] - {"epoch": 49, "update": 48.131, "loss": "71.131", "ntokens": "14803.8", "nsentences": "79.16", "nll_loss": "0.38", "wps": "7690.2", "ups": "0.52", "wpb": "14803.8", "bsz": "79.2", "num_updates": "62400", "lr": "1.42714e-05", "gnorm": "107.646", "loss_scale": "8", "train_wall": "352", "gb_free": "32.5", "wall": "111137"}
[2024-07-06 15:48:18,815][train_inner][INFO] - {"epoch": 49, "update": 48.285, "loss": "68.15", "ntokens": "14865.7", "nsentences": "80.99", "nll_loss": "0.371", "wps": "8417.8", "ups": "0.57", "wpb": "14865.7", "bsz": "81", "num_updates": "62600", "lr": "1.41014e-05", "gnorm": "106.174", "loss_scale": "8", "train_wall": "353", "gb_free": "33.5", "wall": "111490"}
[2024-07-06 15:54:04,617][train_inner][INFO] - {"epoch": 49, "update": 48.439, "loss": "67.306", "ntokens": "14751.3", "nsentences": "80.96", "nll_loss": "0.369", "wps": "8531.9", "ups": "0.58", "wpb": "14751.3", "bsz": "81", "num_updates": "62800", "lr": "1.39334e-05", "gnorm": "106.135", "loss_scale": "8", "train_wall": "345", "gb_free": "32.6", "wall": "111836"}
[2024-07-06 15:59:52,630][train_inner][INFO] - {"epoch": 49, "update": 48.594, "loss": "66.823", "ntokens": "14933", "nsentences": "82.28", "nll_loss": "0.368", "wps": "8583.5", "ups": "0.57", "wpb": "14933", "bsz": "82.3", "num_updates": "63000", "lr": "1.37674e-05", "gnorm": "104.018", "loss_scale": "16", "train_wall": "347", "gb_free": "32.4", "wall": "112184"}
[2024-07-06 16:05:40,209][train_inner][INFO] - {"epoch": 49, "update": 48.748, "loss": "68.311", "ntokens": "14821.9", "nsentences": "80.36", "nll_loss": "0.37", "wps": "8530.6", "ups": "0.58", "wpb": "14821.9", "bsz": "80.4", "num_updates": "63200", "lr": "1.36035e-05", "gnorm": "106.228", "loss_scale": "16", "train_wall": "347", "gb_free": "33", "wall": "112532"}
[2024-07-06 16:11:22,150][train_inner][INFO] - {"epoch": 49, "update": 48.902, "loss": "73.484", "ntokens": "14789.8", "nsentences": "77.88", "nll_loss": "0.387", "wps": "8650.8", "ups": "0.58", "wpb": "14789.8", "bsz": "77.9", "num_updates": "63400", "lr": "1.34414e-05", "gnorm": "109.724", "loss_scale": "16", "train_wall": "341", "gb_free": "31.5", "wall": "112874"}
[2024-07-06 16:14:53,858][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 16:14:53,918][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 16:15:25,684][dev-other][INFO] - {"epoch": 49, "dev-other_loss": "23.219", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.247", "dev-other_uer": "3.724", "dev-other_wer": "9.521", "dev-other_raw_wer": "9.521", "dev-other_wps": "8795.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "63527", "dev-other_best_wer": "9.521"}
[2024-07-06 16:15:25,685][fairseq_cli.train][INFO] - end of epoch 49 (average epoch stats below)
[2024-07-06 16:15:25,687][train][INFO] - {"epoch": 49, "train_loss": "69.33", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.375", "train_wps": "8426.3", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "63527", "train_lr": "1.33395e-05", "train_gnorm": "107.172", "train_loss_scale": "16", "train_train_wall": "2245", "train_gb_free": "32.9", "train_wall": "113117"}
[2024-07-06 16:15:25,688][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 16:15:26,314][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 16:15:26,324][fairseq.trainer][INFO] - begin training epoch 50
[2024-07-06 16:15:26,325][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 16:17:36,102][train_inner][INFO] - {"epoch": 50, "update": 49.056, "loss": "70.495", "ntokens": "14762.1", "nsentences": "78.88", "nll_loss": "0.377", "wps": "7895.4", "ups": "0.53", "wpb": "14762.1", "bsz": "78.9", "num_updates": "63600", "lr": "1.32813e-05", "gnorm": "109.715", "loss_scale": "16", "train_wall": "341", "gb_free": "32.1", "wall": "113248"}
[2024-07-06 16:23:19,488][train_inner][INFO] - {"epoch": 50, "update": 49.21, "loss": "73.559", "ntokens": "14837.1", "nsentences": "79.4", "nll_loss": "0.394", "wps": "8644", "ups": "0.58", "wpb": "14837.1", "bsz": "79.4", "num_updates": "63800", "lr": "1.31231e-05", "gnorm": "110.035", "loss_scale": "16", "train_wall": "343", "gb_free": "32.1", "wall": "113591"}
[2024-07-06 16:29:17,114][train_inner][INFO] - {"epoch": 50, "update": 49.365, "loss": "68.818", "ntokens": "14727.7", "nsentences": "79.6", "nll_loss": "0.372", "wps": "8238.1", "ups": "0.56", "wpb": "14727.7", "bsz": "79.6", "num_updates": "64000", "lr": "1.29668e-05", "gnorm": "107.311", "loss_scale": "16", "train_wall": "357", "gb_free": "32.7", "wall": "113949"}
[2024-07-06 16:30:21,220][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-06 16:35:01,130][train_inner][INFO] - {"epoch": 50, "update": 49.52, "loss": "69.778", "ntokens": "15010.5", "nsentences": "83.52", "nll_loss": "0.388", "wps": "8728.1", "ups": "0.58", "wpb": "15010.5", "bsz": "83.5", "num_updates": "64200", "lr": "1.28123e-05", "gnorm": "107.317", "loss_scale": "8", "train_wall": "343", "gb_free": "32.8", "wall": "114293"}
[2024-07-06 16:40:55,813][train_inner][INFO] - {"epoch": 50, "update": 49.674, "loss": "67.367", "ntokens": "14880", "nsentences": "82.24", "nll_loss": "0.372", "wps": "8392.3", "ups": "0.56", "wpb": "14880", "bsz": "82.2", "num_updates": "64400", "lr": "1.26597e-05", "gnorm": "104.807", "loss_scale": "8", "train_wall": "354", "gb_free": "31.2", "wall": "114647"}
[2024-07-06 16:46:50,528][train_inner][INFO] - {"epoch": 50, "update": 49.828, "loss": "69.737", "ntokens": "14708.1", "nsentences": "77.64", "nll_loss": "0.368", "wps": "8294.4", "ups": "0.56", "wpb": "14708.1", "bsz": "77.6", "num_updates": "64600", "lr": "1.25089e-05", "gnorm": "109.49", "loss_scale": "8", "train_wall": "354", "gb_free": "32", "wall": "115002"}
[2024-07-06 16:52:41,422][train_inner][INFO] - {"epoch": 50, "update": 49.982, "loss": "70.507", "ntokens": "14772.7", "nsentences": "79.16", "nll_loss": "0.378", "wps": "8420.4", "ups": "0.57", "wpb": "14772.7", "bsz": "79.2", "num_updates": "64800", "lr": "1.23599e-05", "gnorm": "106.781", "loss_scale": "8", "train_wall": "350", "gb_free": "31.8", "wall": "115353"}
[2024-07-06 16:53:21,331][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 16:53:21,333][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 16:53:53,605][dev-other][INFO] - {"epoch": 50, "dev-other_loss": "24.086", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.256", "dev-other_uer": "3.771", "dev-other_wer": "9.645", "dev-other_raw_wer": "9.645", "dev-other_wps": "8665.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "64823", "dev-other_best_wer": "9.621"}
[2024-07-06 16:53:53,618][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 50 @ 64823 updates
[2024-07-06 16:53:53,619][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_last.pt
[2024-07-06 16:53:55,095][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_last.pt
[2024-07-06 16:53:55,122][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_last.pt (epoch 50 @ 64823 updates, score 9.645) (writing took 1.5031547285616398 seconds)
[2024-07-06 16:53:55,122][fairseq_cli.train][INFO] - end of epoch 50 (average epoch stats below)
[2024-07-06 16:53:55,145][train][INFO] - {"epoch": 50, "train_loss": "69.715", "train_ntokens": "14823.1", "train_nsentences": "80.2099", "train_nll_loss": "0.377", "train_wps": "8318.4", "train_ups": "0.56", "train_wpb": "14823.1", "train_bsz": "80.2", "train_num_updates": "64823", "train_lr": "1.23429e-05", "train_gnorm": "107.505", "train_loss_scale": "8", "train_train_wall": "2271", "train_gb_free": "32", "train_wall": "115427"}
[2024-07-06 16:53:55,146][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 16:53:55,801][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 16:53:55,805][fairseq.trainer][INFO] - begin training epoch 51
[2024-07-06 16:53:55,805][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 16:59:05,694][train_inner][INFO] - {"epoch": 51, "update": 50.136, "loss": "70.42", "ntokens": "14802.6", "nsentences": "80.43", "nll_loss": "0.383", "wps": "7704.5", "ups": "0.52", "wpb": "14802.6", "bsz": "80.4", "num_updates": "65000", "lr": "1.22127e-05", "gnorm": "107.333", "loss_scale": "8", "train_wall": "349", "gb_free": "31.8", "wall": "115737"}
[2024-07-06 17:04:51,387][train_inner][INFO] - {"epoch": 51, "update": 50.291, "loss": "71.219", "ntokens": "14760.5", "nsentences": "79.24", "nll_loss": "0.382", "wps": "8539.9", "ups": "0.58", "wpb": "14760.5", "bsz": "79.2", "num_updates": "65200", "lr": "1.20672e-05", "gnorm": "110.1", "loss_scale": "8", "train_wall": "345", "gb_free": "31.8", "wall": "116083"}
[2024-07-06 17:10:50,378][train_inner][INFO] - {"epoch": 51, "update": 50.445, "loss": "68.52", "ntokens": "14755.2", "nsentences": "79.8", "nll_loss": "0.371", "wps": "8222", "ups": "0.56", "wpb": "14755.2", "bsz": "79.8", "num_updates": "65400", "lr": "1.19235e-05", "gnorm": "108.921", "loss_scale": "8", "train_wall": "358", "gb_free": "32.1", "wall": "116442"}
[2024-07-06 17:16:34,098][train_inner][INFO] - {"epoch": 51, "update": 50.599, "loss": "69.948", "ntokens": "14846.7", "nsentences": "80.08", "nll_loss": "0.377", "wps": "8639.1", "ups": "0.58", "wpb": "14846.7", "bsz": "80.1", "num_updates": "65600", "lr": "1.17815e-05", "gnorm": "108.028", "loss_scale": "8", "train_wall": "343", "gb_free": "32.4", "wall": "116786"}
[2024-07-06 17:22:28,361][train_inner][INFO] - {"epoch": 51, "update": 50.753, "loss": "67.435", "ntokens": "14976.4", "nsentences": "82.48", "nll_loss": "0.371", "wps": "8456.6", "ups": "0.56", "wpb": "14976.4", "bsz": "82.5", "num_updates": "65800", "lr": "1.16411e-05", "gnorm": "105.736", "loss_scale": "8", "train_wall": "354", "gb_free": "32.2", "wall": "117140"}
[2024-07-06 17:28:15,517][train_inner][INFO] - {"epoch": 51, "update": 50.907, "loss": "70.532", "ntokens": "14813", "nsentences": "78.84", "nll_loss": "0.375", "wps": "8536.4", "ups": "0.58", "wpb": "14813", "bsz": "78.8", "num_updates": "66000", "lr": "1.15025e-05", "gnorm": "108.633", "loss_scale": "8", "train_wall": "346", "gb_free": "32.6", "wall": "117487"}
[2024-07-06 17:31:50,933][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 17:31:50,999][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 17:32:23,062][dev-other][INFO] - {"epoch": 51, "dev-other_loss": "24.019", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.255", "dev-other_uer": "3.755", "dev-other_wer": "9.682", "dev-other_raw_wer": "9.682", "dev-other_wps": "8703.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "66120", "dev-other_best_wer": "9.621"}
[2024-07-06 17:32:23,063][fairseq_cli.train][INFO] - end of epoch 51 (average epoch stats below)
[2024-07-06 17:32:23,067][train][INFO] - {"epoch": 51, "train_loss": "69.249", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.375", "train_wps": "8330.1", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "66120", "train_lr": "1.14201e-05", "train_gnorm": "107.679", "train_loss_scale": "16", "train_train_wall": "2271", "train_gb_free": "32", "train_wall": "117735"}
[2024-07-06 17:32:23,069][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 17:32:23,666][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 17:32:23,670][fairseq.trainer][INFO] - begin training epoch 52
[2024-07-06 17:32:23,670][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 17:34:40,269][train_inner][INFO] - {"epoch": 52, "update": 51.062, "loss": "65.978", "ntokens": "14792.6", "nsentences": "80.24", "nll_loss": "0.358", "wps": "7689.9", "ups": "0.52", "wpb": "14792.6", "bsz": "80.2", "num_updates": "66200", "lr": "1.13655e-05", "gnorm": "105.874", "loss_scale": "16", "train_wall": "351", "gb_free": "31.7", "wall": "117872"}
[2024-07-06 17:40:29,782][train_inner][INFO] - {"epoch": 52, "update": 51.216, "loss": "70.698", "ntokens": "14819.1", "nsentences": "77.95", "nll_loss": "0.372", "wps": "8480.2", "ups": "0.57", "wpb": "14819.1", "bsz": "78", "num_updates": "66400", "lr": "1.12301e-05", "gnorm": "109.375", "loss_scale": "16", "train_wall": "349", "gb_free": "33.2", "wall": "118221"}
[2024-07-06 17:46:24,845][train_inner][INFO] - {"epoch": 52, "update": 51.37, "loss": "67.643", "ntokens": "14888.1", "nsentences": "81.48", "nll_loss": "0.37", "wps": "8388.4", "ups": "0.56", "wpb": "14888.1", "bsz": "81.5", "num_updates": "66600", "lr": "1.10963e-05", "gnorm": "104.919", "loss_scale": "16", "train_wall": "354", "gb_free": "31.7", "wall": "118576"}
[2024-07-06 17:52:15,505][train_inner][INFO] - {"epoch": 52, "update": 51.524, "loss": "68.486", "ntokens": "14779.7", "nsentences": "80.28", "nll_loss": "0.372", "wps": "8431.5", "ups": "0.57", "wpb": "14779.7", "bsz": "80.3", "num_updates": "66800", "lr": "1.09642e-05", "gnorm": "106.115", "loss_scale": "16", "train_wall": "350", "gb_free": "32.1", "wall": "118927"}
[2024-07-06 17:58:06,932][train_inner][INFO] - {"epoch": 52, "update": 51.678, "loss": "67.588", "ntokens": "14803.8", "nsentences": "81.16", "nll_loss": "0.371", "wps": "8426.9", "ups": "0.57", "wpb": "14803.8", "bsz": "81.2", "num_updates": "67000", "lr": "1.08336e-05", "gnorm": "104.495", "loss_scale": "16", "train_wall": "351", "gb_free": "32.5", "wall": "119279"}
[2024-07-06 18:03:56,010][train_inner][INFO] - {"epoch": 52, "update": 51.833, "loss": "68.719", "ntokens": "14855.8", "nsentences": "81", "nll_loss": "0.375", "wps": "8513.4", "ups": "0.57", "wpb": "14855.8", "bsz": "81", "num_updates": "67200", "lr": "1.07045e-05", "gnorm": "106.346", "loss_scale": "16", "train_wall": "348", "gb_free": "31.5", "wall": "119628"}
[2024-07-06 18:08:12,600][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-06 18:09:49,173][train_inner][INFO] - {"epoch": 52, "update": 51.988, "loss": "69.51", "ntokens": "14765.7", "nsentences": "79.4", "nll_loss": "0.374", "wps": "8362.3", "ups": "0.57", "wpb": "14765.7", "bsz": "79.4", "num_updates": "67400", "lr": "1.0577e-05", "gnorm": "107.831", "loss_scale": "8", "train_wall": "353", "gb_free": "32.2", "wall": "119981"}
[2024-07-06 18:10:18,923][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 18:10:18,924][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 18:10:51,088][dev-other][INFO] - {"epoch": 52, "dev-other_loss": "23.19", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.247", "dev-other_uer": "3.701", "dev-other_wer": "9.527", "dev-other_raw_wer": "9.527", "dev-other_wps": "8698.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "67416", "dev-other_best_wer": "9.527"}
[2024-07-06 18:10:51,088][fairseq_cli.train][INFO] - end of epoch 52 (average epoch stats below)
[2024-07-06 18:10:51,099][train][INFO] - {"epoch": 52, "train_loss": "68.627", "train_ntokens": "14822.4", "train_nsentences": "80.196", "train_nll_loss": "0.371", "train_wps": "8323", "train_ups": "0.56", "train_wpb": "14822.4", "train_bsz": "80.2", "train_num_updates": "67416", "train_lr": "1.05669e-05", "train_gnorm": "106.6", "train_loss_scale": "8", "train_train_wall": "2271", "train_gb_free": "31.2", "train_wall": "120043"}
[2024-07-06 18:10:51,100][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 18:10:51,714][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 18:10:51,717][fairseq.trainer][INFO] - begin training epoch 53
[2024-07-06 18:10:51,717][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 18:16:13,785][train_inner][INFO] - {"epoch": 53, "update": 52.142, "loss": "68.497", "ntokens": "14946.7", "nsentences": "80.56", "nll_loss": "0.369", "wps": "7772.7", "ups": "0.52", "wpb": "14946.7", "bsz": "80.6", "num_updates": "67600", "lr": "1.0451e-05", "gnorm": "104.739", "loss_scale": "8", "train_wall": "351", "gb_free": "33.3", "wall": "120365"}
[2024-07-06 18:22:12,156][train_inner][INFO] - {"epoch": 53, "update": 52.296, "loss": "64.523", "ntokens": "14812", "nsentences": "81.28", "nll_loss": "0.354", "wps": "8267.8", "ups": "0.56", "wpb": "14812", "bsz": "81.3", "num_updates": "67800", "lr": "1.03265e-05", "gnorm": "102.923", "loss_scale": "8", "train_wall": "358", "gb_free": "32", "wall": "120724"}
[2024-07-06 18:27:50,683][train_inner][INFO] - {"epoch": 53, "update": 52.45, "loss": "70.753", "ntokens": "14893.6", "nsentences": "80.56", "nll_loss": "0.383", "wps": "8799.7", "ups": "0.59", "wpb": "14893.6", "bsz": "80.6", "num_updates": "68000", "lr": "1.02035e-05", "gnorm": "108.681", "loss_scale": "8", "train_wall": "338", "gb_free": "32.5", "wall": "121062"}
[2024-07-06 18:33:35,643][train_inner][INFO] - {"epoch": 53, "update": 52.604, "loss": "70.981", "ntokens": "14828.4", "nsentences": "78.96", "nll_loss": "0.378", "wps": "8597.5", "ups": "0.58", "wpb": "14828.4", "bsz": "79", "num_updates": "68200", "lr": "1.0082e-05", "gnorm": "108.289", "loss_scale": "8", "train_wall": "344", "gb_free": "31.6", "wall": "121407"}
[2024-07-06 18:39:27,477][train_inner][INFO] - {"epoch": 53, "update": 52.759, "loss": "67.806", "ntokens": "14764.3", "nsentences": "79.28", "nll_loss": "0.364", "wps": "8393", "ups": "0.57", "wpb": "14764.3", "bsz": "79.3", "num_updates": "68400", "lr": "9.9619e-06", "gnorm": "107.916", "loss_scale": "8", "train_wall": "351", "gb_free": "32.3", "wall": "121759"}
[2024-07-06 18:45:19,195][train_inner][INFO] - {"epoch": 53, "update": 52.913, "loss": "67.264", "ntokens": "14782.3", "nsentences": "80.71", "nll_loss": "0.367", "wps": "8407.5", "ups": "0.57", "wpb": "14782.3", "bsz": "80.7", "num_updates": "68600", "lr": "9.84324e-06", "gnorm": "105.785", "loss_scale": "8", "train_wall": "351", "gb_free": "32.9", "wall": "122111"}
[2024-07-06 18:48:35,716][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 18:48:35,784][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 18:49:07,881][dev-other][INFO] - {"epoch": 53, "dev-other_loss": "23.374", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.248", "dev-other_uer": "3.691", "dev-other_wer": "9.513", "dev-other_raw_wer": "9.513", "dev-other_wps": "8670.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "68713", "dev-other_best_wer": "9.513"}
[2024-07-06 18:49:07,882][fairseq_cli.train][INFO] - end of epoch 53 (average epoch stats below)
[2024-07-06 18:49:07,885][train][INFO] - {"epoch": 53, "train_loss": "68.323", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.37", "train_wps": "8370.5", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "68713", "train_lr": "9.77682e-06", "train_gnorm": "106.497", "train_loss_scale": "8", "train_train_wall": "2260", "train_gb_free": "32.3", "train_wall": "122340"}
[2024-07-06 18:49:07,886][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 18:49:08,529][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 18:49:08,533][fairseq.trainer][INFO] - begin training epoch 54
[2024-07-06 18:49:08,533][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 18:51:41,709][train_inner][INFO] - {"epoch": 54, "update": 53.067, "loss": "69.427", "ntokens": "14727.4", "nsentences": "79.92", "nll_loss": "0.377", "wps": "7700.6", "ups": "0.52", "wpb": "14727.4", "bsz": "79.9", "num_updates": "68800", "lr": "9.72599e-06", "gnorm": "107.794", "loss_scale": "8", "train_wall": "349", "gb_free": "31.9", "wall": "122493"}
[2024-07-06 18:57:27,217][train_inner][INFO] - {"epoch": 54, "update": 53.221, "loss": "71.186", "ntokens": "14810.6", "nsentences": "77.99", "nll_loss": "0.375", "wps": "8574.8", "ups": "0.58", "wpb": "14810.6", "bsz": "78", "num_updates": "69000", "lr": "9.61014e-06", "gnorm": "109.323", "loss_scale": "8", "train_wall": "345", "gb_free": "32.4", "wall": "122839"}
[2024-07-06 19:03:15,796][train_inner][INFO] - {"epoch": 54, "update": 53.375, "loss": "68.101", "ntokens": "14801.2", "nsentences": "81.16", "nll_loss": "0.373", "wps": "8494.1", "ups": "0.57", "wpb": "14801.2", "bsz": "81.2", "num_updates": "69200", "lr": "9.49567e-06", "gnorm": "110.392", "loss_scale": "8", "train_wall": "348", "gb_free": "31.4", "wall": "123187"}
[2024-07-06 19:09:08,916][train_inner][INFO] - {"epoch": 54, "update": 53.53, "loss": "68.371", "ntokens": "14901.7", "nsentences": "80.36", "nll_loss": "0.369", "wps": "8446", "ups": "0.57", "wpb": "14901.7", "bsz": "80.4", "num_updates": "69400", "lr": "9.38257e-06", "gnorm": "105.556", "loss_scale": "16", "train_wall": "352", "gb_free": "31.3", "wall": "123540"}
[2024-07-06 19:15:04,462][train_inner][INFO] - {"epoch": 54, "update": 53.684, "loss": "66.853", "ntokens": "14811.6", "nsentences": "80.24", "nll_loss": "0.362", "wps": "8333.8", "ups": "0.56", "wpb": "14811.6", "bsz": "80.2", "num_updates": "69600", "lr": "9.27081e-06", "gnorm": "105.346", "loss_scale": "16", "train_wall": "355", "gb_free": "32.4", "wall": "123896"}
[2024-07-06 19:20:57,257][train_inner][INFO] - {"epoch": 54, "update": 53.838, "loss": "67.097", "ntokens": "14788.7", "nsentences": "80.36", "nll_loss": "0.365", "wps": "8385.4", "ups": "0.57", "wpb": "14788.7", "bsz": "80.4", "num_updates": "69800", "lr": "9.16038e-06", "gnorm": "105.705", "loss_scale": "16", "train_wall": "352", "gb_free": "32.2", "wall": "124249"}
[2024-07-06 19:26:53,690][train_inner][INFO] - {"epoch": 54, "update": 53.992, "loss": "65.935", "ntokens": "14874.8", "nsentences": "81.28", "nll_loss": "0.36", "wps": "8348.3", "ups": "0.56", "wpb": "14874.8", "bsz": "81.3", "num_updates": "70000", "lr": "9.05126e-06", "gnorm": "104.322", "loss_scale": "16", "train_wall": "356", "gb_free": "32.7", "wall": "124605"}
[2024-07-06 19:27:11,842][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 19:27:11,844][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 19:27:44,166][dev-other][INFO] - {"epoch": 54, "dev-other_loss": "23.698", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.252", "dev-other_uer": "3.691", "dev-other_wer": "9.484", "dev-other_raw_wer": "9.484", "dev-other_wps": "8653.3", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "70010", "dev-other_best_wer": "9.484"}
[2024-07-06 19:27:44,166][fairseq_cli.train][INFO] - end of epoch 54 (average epoch stats below)
[2024-07-06 19:27:44,172][train][INFO] - {"epoch": 54, "train_loss": "68.058", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.368", "train_wps": "8300.1", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "70010", "train_lr": "9.04584e-06", "train_gnorm": "106.913", "train_loss_scale": "16", "train_train_wall": "2279", "train_gb_free": "32.5", "train_wall": "124656"}
[2024-07-06 19:27:44,173][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 19:27:44,775][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 19:27:44,778][fairseq.trainer][INFO] - begin training epoch 55
[2024-07-06 19:27:44,778][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 19:33:18,755][train_inner][INFO] - {"epoch": 55, "update": 54.146, "loss": "63.796", "ntokens": "14835.9", "nsentences": "82.24", "nll_loss": "0.354", "wps": "7707.4", "ups": "0.52", "wpb": "14835.9", "bsz": "82.2", "num_updates": "70200", "lr": "8.94345e-06", "gnorm": "104.807", "loss_scale": "16", "train_wall": "351", "gb_free": "31.9", "wall": "124990"}
[2024-07-06 19:37:08,741][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-06 19:39:16,215][train_inner][INFO] - {"epoch": 55, "update": 54.301, "loss": "68.518", "ntokens": "14857.5", "nsentences": "79.16", "nll_loss": "0.365", "wps": "8314.9", "ups": "0.56", "wpb": "14857.5", "bsz": "79.2", "num_updates": "70400", "lr": "8.83692e-06", "gnorm": "106.41", "loss_scale": "8", "train_wall": "357", "gb_free": "32.8", "wall": "125348"}
[2024-07-06 19:45:06,923][train_inner][INFO] - {"epoch": 55, "update": 54.456, "loss": "66.255", "ntokens": "14872.1", "nsentences": "81.68", "nll_loss": "0.364", "wps": "8483.2", "ups": "0.57", "wpb": "14872.1", "bsz": "81.7", "num_updates": "70600", "lr": "8.73166e-06", "gnorm": "105.965", "loss_scale": "8", "train_wall": "350", "gb_free": "32.6", "wall": "125699"}
[2024-07-06 19:51:00,008][train_inner][INFO] - {"epoch": 55, "update": 54.61, "loss": "70.009", "ntokens": "14785.1", "nsentences": "77.28", "nll_loss": "0.366", "wps": "8375.1", "ups": "0.57", "wpb": "14785.1", "bsz": "77.3", "num_updates": "70800", "lr": "8.62766e-06", "gnorm": "107.78", "loss_scale": "8", "train_wall": "353", "gb_free": "32.6", "wall": "126052"}
[2024-07-06 19:56:48,540][train_inner][INFO] - {"epoch": 55, "update": 54.764, "loss": "65.343", "ntokens": "14867.8", "nsentences": "82.04", "nll_loss": "0.361", "wps": "8532.3", "ups": "0.57", "wpb": "14867.8", "bsz": "82", "num_updates": "71000", "lr": "8.52489e-06", "gnorm": "104.277", "loss_scale": "8", "train_wall": "348", "gb_free": "31.5", "wall": "126400"}
[2024-07-06 20:02:40,782][train_inner][INFO] - {"epoch": 55, "update": 54.918, "loss": "69.149", "ntokens": "14708.5", "nsentences": "78.64", "nll_loss": "0.37", "wps": "8353.2", "ups": "0.57", "wpb": "14708.5", "bsz": "78.6", "num_updates": "71200", "lr": "8.42334e-06", "gnorm": "108.659", "loss_scale": "8", "train_wall": "352", "gb_free": "32", "wall": "126752"}
[2024-07-06 20:05:49,018][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 20:05:49,024][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 20:06:21,227][dev-other][INFO] - {"epoch": 55, "dev-other_loss": "24.089", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.256", "dev-other_uer": "3.701", "dev-other_wer": "9.537", "dev-other_raw_wer": "9.537", "dev-other_wps": "8701", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "71306", "dev-other_best_wer": "9.537"}
[2024-07-06 20:06:21,229][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 55 @ 71306 updates
[2024-07-06 20:06:21,230][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt
[2024-07-06 20:06:22,643][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt
[2024-07-06 20:06:23,230][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt (epoch 55 @ 71306 updates, score 9.537) (writing took 2.0009255968034267 seconds)
[2024-07-06 20:06:23,230][fairseq_cli.train][INFO] - end of epoch 55 (average epoch stats below)
[2024-07-06 20:06:23,242][train][INFO] - {"epoch": 55, "train_loss": "67.166", "train_ntokens": "14822.6", "train_nsentences": "80.1852", "train_nll_loss": "0.363", "train_wps": "8283.6", "train_ups": "0.56", "train_wpb": "14822.6", "train_bsz": "80.2", "train_num_updates": "71306", "train_lr": "8.37002e-06", "train_gnorm": "106.148", "train_loss_scale": "8", "train_train_wall": "2280", "train_gb_free": "32.9", "train_wall": "126975"}
[2024-07-06 20:06:23,243][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 20:06:23,483][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 20:06:23,486][fairseq.trainer][INFO] - begin training epoch 56
[2024-07-06 20:06:23,487][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 20:09:14,277][train_inner][INFO] - {"epoch": 56, "update": 55.072, "loss": "64.286", "ntokens": "14843.8", "nsentences": "82.16", "nll_loss": "0.356", "wps": "7544.9", "ups": "0.51", "wpb": "14843.8", "bsz": "82.2", "num_updates": "71400", "lr": "8.32301e-06", "gnorm": "102.621", "loss_scale": "8", "train_wall": "358", "gb_free": "33.1", "wall": "127146"}
[2024-07-06 20:15:09,552][train_inner][INFO] - {"epoch": 56, "update": 55.227, "loss": "65.78", "ntokens": "14868.2", "nsentences": "79.52", "nll_loss": "0.352", "wps": "8371.8", "ups": "0.56", "wpb": "14868.2", "bsz": "79.5", "num_updates": "71600", "lr": "8.22387e-06", "gnorm": "105.293", "loss_scale": "8", "train_wall": "355", "gb_free": "32", "wall": "127501"}
[2024-07-06 20:21:00,155][train_inner][INFO] - {"epoch": 56, "update": 55.381, "loss": "66.775", "ntokens": "14880", "nsentences": "82.24", "nll_loss": "0.369", "wps": "8488.5", "ups": "0.57", "wpb": "14880", "bsz": "82.2", "num_updates": "71800", "lr": "8.12591e-06", "gnorm": "104.31", "loss_scale": "8", "train_wall": "350", "gb_free": "31.9", "wall": "127852"}
[2024-07-06 20:26:56,691][train_inner][INFO] - {"epoch": 56, "update": 55.535, "loss": "67.992", "ntokens": "14781.6", "nsentences": "78.24", "nll_loss": "0.36", "wps": "8292.1", "ups": "0.56", "wpb": "14781.6", "bsz": "78.2", "num_updates": "72000", "lr": "8.02912e-06", "gnorm": "106.076", "loss_scale": "8", "train_wall": "356", "gb_free": "32.3", "wall": "128208"}
[2024-07-06 20:32:51,234][train_inner][INFO] - {"epoch": 56, "update": 55.689, "loss": "69.859", "ntokens": "14796.9", "nsentences": "79.36", "nll_loss": "0.375", "wps": "8348.8", "ups": "0.56", "wpb": "14796.9", "bsz": "79.4", "num_updates": "72200", "lr": "7.93348e-06", "gnorm": "106.619", "loss_scale": "8", "train_wall": "354", "gb_free": "33.4", "wall": "128563"}
[2024-07-06 20:38:43,284][train_inner][INFO] - {"epoch": 56, "update": 55.843, "loss": "66.411", "ntokens": "14852.7", "nsentences": "80.76", "nll_loss": "0.361", "wps": "8438.1", "ups": "0.57", "wpb": "14852.7", "bsz": "80.8", "num_updates": "72400", "lr": "7.83898e-06", "gnorm": "106.23", "loss_scale": "16", "train_wall": "352", "gb_free": "32.5", "wall": "128915"}
[2024-07-06 20:42:08,572][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-06 20:44:42,968][train_inner][INFO] - {"epoch": 56, "update": 55.998, "loss": "66.697", "ntokens": "14756.7", "nsentences": "79.48", "nll_loss": "0.359", "wps": "8206.1", "ups": "0.56", "wpb": "14756.7", "bsz": "79.5", "num_updates": "72600", "lr": "7.74561e-06", "gnorm": "106.698", "loss_scale": "8", "train_wall": "359", "gb_free": "30.9", "wall": "129275"}
[2024-07-06 20:44:46,794][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 20:44:46,807][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 20:45:19,057][dev-other][INFO] - {"epoch": 56, "dev-other_loss": "23.967", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.255", "dev-other_uer": "3.745", "dev-other_wer": "9.596", "dev-other_raw_wer": "9.596", "dev-other_wps": "8668.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "72602", "dev-other_best_wer": "9.537"}
[2024-07-06 20:45:19,058][fairseq_cli.train][INFO] - end of epoch 56 (average epoch stats below)
[2024-07-06 20:45:19,062][train][INFO] - {"epoch": 56, "train_loss": "66.821", "train_ntokens": "14822.8", "train_nsentences": "80.2037", "train_nll_loss": "0.362", "train_wps": "8224.3", "train_ups": "0.55", "train_wpb": "14822.8", "train_bsz": "80.2", "train_num_updates": "72602", "train_lr": "7.74468e-06", "train_gnorm": "105.532", "train_loss_scale": "8", "train_train_wall": "2299", "train_gb_free": "32.4", "train_wall": "129311"}
[2024-07-06 20:45:19,063][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 20:45:19,697][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 20:45:19,702][fairseq.trainer][INFO] - begin training epoch 57
[2024-07-06 20:45:19,702][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 20:51:11,135][train_inner][INFO] - {"epoch": 57, "update": 56.153, "loss": "71.724", "ntokens": "14830", "nsentences": "79.08", "nll_loss": "0.382", "wps": "7642.6", "ups": "0.52", "wpb": "14830", "bsz": "79.1", "num_updates": "72800", "lr": "7.65335e-06", "gnorm": "106.267", "loss_scale": "8", "train_wall": "355", "gb_free": "32.7", "wall": "129663"}
[2024-07-06 20:57:04,978][train_inner][INFO] - {"epoch": 57, "update": 56.307, "loss": "66.089", "ntokens": "14868.9", "nsentences": "82.07", "nll_loss": "0.365", "wps": "8405", "ups": "0.57", "wpb": "14868.9", "bsz": "82.1", "num_updates": "73000", "lr": "7.56219e-06", "gnorm": "104.423", "loss_scale": "8", "train_wall": "353", "gb_free": "30.6", "wall": "130017"}
[2024-07-06 21:02:57,925][train_inner][INFO] - {"epoch": 57, "update": 56.461, "loss": "68.052", "ntokens": "14751.3", "nsentences": "80.88", "nll_loss": "0.373", "wps": "8360.9", "ups": "0.57", "wpb": "14751.3", "bsz": "80.9", "num_updates": "73200", "lr": "7.47211e-06", "gnorm": "105.451", "loss_scale": "8", "train_wall": "352", "gb_free": "32.2", "wall": "130370"}
[2024-07-06 21:08:50,448][train_inner][INFO] - {"epoch": 57, "update": 56.615, "loss": "67.79", "ntokens": "14826.7", "nsentences": "79.96", "nll_loss": "0.366", "wps": "8413.4", "ups": "0.57", "wpb": "14826.7", "bsz": "80", "num_updates": "73400", "lr": "7.38311e-06", "gnorm": "105.252", "loss_scale": "8", "train_wall": "352", "gb_free": "32.8", "wall": "130722"}
[2024-07-06 21:14:31,622][train_inner][INFO] - {"epoch": 57, "update": 56.769, "loss": "68.405", "ntokens": "14835.8", "nsentences": "80.84", "nll_loss": "0.373", "wps": "8697.3", "ups": "0.59", "wpb": "14835.8", "bsz": "80.8", "num_updates": "73600", "lr": "7.29516e-06", "gnorm": "106.369", "loss_scale": "8", "train_wall": "341", "gb_free": "31.8", "wall": "131063"}
[2024-07-06 21:20:21,996][train_inner][INFO] - {"epoch": 57, "update": 56.924, "loss": "69.017", "ntokens": "14790", "nsentences": "77.96", "nll_loss": "0.364", "wps": "8444.1", "ups": "0.57", "wpb": "14790", "bsz": "78", "num_updates": "73800", "lr": "7.20827e-06", "gnorm": "108.298", "loss_scale": "8", "train_wall": "350", "gb_free": "32.3", "wall": "131414"}
[2024-07-06 21:23:04,337][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 21:23:04,400][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 21:23:36,607][dev-other][INFO] - {"epoch": 57, "dev-other_loss": "23.664", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.252", "dev-other_uer": "3.711", "dev-other_wer": "9.553", "dev-other_raw_wer": "9.553", "dev-other_wps": "8665.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "73899", "dev-other_best_wer": "9.537"}
[2024-07-06 21:23:36,607][fairseq_cli.train][INFO] - end of epoch 57 (average epoch stats below)
[2024-07-06 21:23:36,613][train][INFO] - {"epoch": 57, "train_loss": "68.626", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.371", "train_wps": "8367.7", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "73899", "train_lr": "7.16564e-06", "train_gnorm": "106.425", "train_loss_scale": "8", "train_train_wall": "2261", "train_gb_free": "32.4", "train_wall": "131608"}
[2024-07-06 21:23:36,615][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 21:23:37,195][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 21:23:37,200][fairseq.trainer][INFO] - begin training epoch 58
[2024-07-06 21:23:37,201][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 21:26:41,055][train_inner][INFO] - {"epoch": 58, "update": 57.078, "loss": "67.957", "ntokens": "14857", "nsentences": "79.76", "nll_loss": "0.365", "wps": "7839.2", "ups": "0.53", "wpb": "14857", "bsz": "79.8", "num_updates": "74000", "lr": "7.12241e-06", "gnorm": "108.485", "loss_scale": "8", "train_wall": "346", "gb_free": "31.6", "wall": "131793"}
[2024-07-06 21:32:25,509][train_inner][INFO] - {"epoch": 58, "update": 57.232, "loss": "69.664", "ntokens": "14791.4", "nsentences": "80.96", "nll_loss": "0.381", "wps": "8590.1", "ups": "0.58", "wpb": "14791.4", "bsz": "81", "num_updates": "74200", "lr": "7.03757e-06", "gnorm": "106.042", "loss_scale": "8", "train_wall": "344", "gb_free": "32.8", "wall": "132137"}
[2024-07-06 21:38:10,825][train_inner][INFO] - {"epoch": 58, "update": 57.386, "loss": "66.684", "ntokens": "14893.1", "nsentences": "81.4", "nll_loss": "0.364", "wps": "8627.8", "ups": "0.58", "wpb": "14893.1", "bsz": "81.4", "num_updates": "74400", "lr": "6.95374e-06", "gnorm": "107.624", "loss_scale": "8", "train_wall": "345", "gb_free": "31.2", "wall": "132482"}
[2024-07-06 21:43:54,781][train_inner][INFO] - {"epoch": 58, "update": 57.54, "loss": "70.616", "ntokens": "14899.7", "nsentences": "80.8", "nll_loss": "0.383", "wps": "8665.8", "ups": "0.58", "wpb": "14899.7", "bsz": "80.8", "num_updates": "74600", "lr": "6.87091e-06", "gnorm": "111.326", "loss_scale": "16", "train_wall": "343", "gb_free": "31.7", "wall": "132826"}
[2024-07-06 21:49:51,949][train_inner][INFO] - {"epoch": 58, "update": 57.695, "loss": "68.135", "ntokens": "14778.6", "nsentences": "78.88", "nll_loss": "0.364", "wps": "8275.7", "ups": "0.56", "wpb": "14778.6", "bsz": "78.9", "num_updates": "74800", "lr": "6.78907e-06", "gnorm": "106.162", "loss_scale": "16", "train_wall": "357", "gb_free": "33.1", "wall": "133184"}
[2024-07-06 21:55:35,634][train_inner][INFO] - {"epoch": 58, "update": 57.849, "loss": "70.683", "ntokens": "14760.1", "nsentences": "78.84", "nll_loss": "0.378", "wps": "8589.5", "ups": "0.58", "wpb": "14760.1", "bsz": "78.8", "num_updates": "75000", "lr": "6.7082e-06", "gnorm": "110.232", "loss_scale": "16", "train_wall": "343", "gb_free": "33.3", "wall": "133527"}
[2024-07-06 22:00:07,484][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-06 22:01:22,628][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 22:01:22,691][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 22:01:54,660][dev-other][INFO] - {"epoch": 58, "dev-other_loss": "23.274", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.247", "dev-other_uer": "3.678", "dev-other_wer": "9.47", "dev-other_raw_wer": "9.47", "dev-other_wps": "8747.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "75195", "dev-other_best_wer": "9.47"}
[2024-07-06 22:01:54,661][fairseq_cli.train][INFO] - end of epoch 58 (average epoch stats below)
[2024-07-06 22:01:54,666][train][INFO] - {"epoch": 58, "train_loss": "68.128", "train_ntokens": "14822.7", "train_nsentences": "80.2099", "train_nll_loss": "0.369", "train_wps": "8359.3", "train_ups": "0.56", "train_wpb": "14822.7", "train_bsz": "80.2", "train_num_updates": "75195", "train_lr": "6.63029e-06", "train_gnorm": "107.35", "train_loss_scale": "8", "train_train_wall": "2262", "train_gb_free": "32.3", "train_wall": "133906"}
[2024-07-06 22:01:54,667][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 22:01:55,250][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 22:01:55,254][fairseq.trainer][INFO] - begin training epoch 59
[2024-07-06 22:01:55,254][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 22:02:04,881][train_inner][INFO] - {"epoch": 59, "update": 58.004, "loss": "64.019", "ntokens": "14827.8", "nsentences": "81.56", "nll_loss": "0.352", "wps": "7618.9", "ups": "0.51", "wpb": "14827.8", "bsz": "81.6", "num_updates": "75200", "lr": "6.6283e-06", "gnorm": "103.005", "loss_scale": "8", "train_wall": "356", "gb_free": "32.4", "wall": "133917"}
[2024-07-06 22:07:59,093][train_inner][INFO] - {"epoch": 59, "update": 58.158, "loss": "66.831", "ntokens": "14745", "nsentences": "79", "nll_loss": "0.358", "wps": "8327.3", "ups": "0.56", "wpb": "14745", "bsz": "79", "num_updates": "75400", "lr": "6.54935e-06", "gnorm": "105.981", "loss_scale": "8", "train_wall": "354", "gb_free": "30.7", "wall": "134271"}
[2024-07-06 22:13:44,101][train_inner][INFO] - {"epoch": 59, "update": 58.312, "loss": "69.236", "ntokens": "14771.9", "nsentences": "77.92", "nll_loss": "0.365", "wps": "8565.9", "ups": "0.58", "wpb": "14771.9", "bsz": "77.9", "num_updates": "75600", "lr": "6.47134e-06", "gnorm": "109.216", "loss_scale": "8", "train_wall": "344", "gb_free": "31.2", "wall": "134616"}
[2024-07-06 22:19:32,585][train_inner][INFO] - {"epoch": 59, "update": 58.466, "loss": "67.546", "ntokens": "14851.4", "nsentences": "81.28", "nll_loss": "0.37", "wps": "8524.1", "ups": "0.57", "wpb": "14851.4", "bsz": "81.3", "num_updates": "75800", "lr": "6.39425e-06", "gnorm": "106.923", "loss_scale": "8", "train_wall": "348", "gb_free": "32.9", "wall": "134964"}
[2024-07-06 22:25:23,488][train_inner][INFO] - {"epoch": 59, "update": 58.621, "loss": "66.415", "ntokens": "14874.5", "nsentences": "80.83", "nll_loss": "0.361", "wps": "8479.5", "ups": "0.57", "wpb": "14874.5", "bsz": "80.8", "num_updates": "76000", "lr": "6.31809e-06", "gnorm": "106.813", "loss_scale": "8", "train_wall": "350", "gb_free": "32.9", "wall": "135315"}
[2024-07-06 22:31:11,923][train_inner][INFO] - {"epoch": 59, "update": 58.775, "loss": "69.373", "ntokens": "14784.7", "nsentences": "80.44", "nll_loss": "0.377", "wps": "8488.4", "ups": "0.57", "wpb": "14784.7", "bsz": "80.4", "num_updates": "76200", "lr": "6.24283e-06", "gnorm": "107.2", "loss_scale": "8", "train_wall": "348", "gb_free": "33", "wall": "135664"}
[2024-07-06 22:37:02,153][train_inner][INFO] - {"epoch": 59, "update": 58.929, "loss": "66.094", "ntokens": "14883.6", "nsentences": "81.52", "nll_loss": "0.362", "wps": "8501.5", "ups": "0.57", "wpb": "14883.6", "bsz": "81.5", "num_updates": "76400", "lr": "6.16847e-06", "gnorm": "104.706", "loss_scale": "8", "train_wall": "350", "gb_free": "31.9", "wall": "136014"}
[2024-07-06 22:39:43,609][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 22:39:43,670][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 22:40:15,784][dev-other][INFO] - {"epoch": 59, "dev-other_loss": "23.546", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.25", "dev-other_uer": "3.727", "dev-other_wer": "9.549", "dev-other_raw_wer": "9.549", "dev-other_wps": "8701.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "76492", "dev-other_best_wer": "9.537"}
[2024-07-06 22:40:15,785][fairseq_cli.train][INFO] - end of epoch 59 (average epoch stats below)
[2024-07-06 22:40:15,790][train][INFO] - {"epoch": 59, "train_loss": "67.629", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.366", "train_wps": "8354.8", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "76492", "train_lr": "6.13456e-06", "train_gnorm": "106.689", "train_loss_scale": "8", "train_train_wall": "2264", "train_gb_free": "32.6", "train_wall": "136207"}
[2024-07-06 22:40:15,792][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 22:40:16,383][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 22:40:16,387][fairseq.trainer][INFO] - begin training epoch 60
[2024-07-06 22:40:16,387][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 22:43:31,730][train_inner][INFO] - {"epoch": 60, "update": 59.083, "loss": "66.563", "ntokens": "14858.2", "nsentences": "80.04", "nll_loss": "0.359", "wps": "7629.2", "ups": "0.51", "wpb": "14858.2", "bsz": "80", "num_updates": "76600", "lr": "6.09499e-06", "gnorm": "105.096", "loss_scale": "8", "train_wall": "356", "gb_free": "30.6", "wall": "136403"}
[2024-07-06 22:49:19,071][train_inner][INFO] - {"epoch": 60, "update": 59.237, "loss": "65.116", "ntokens": "14842.2", "nsentences": "81.88", "nll_loss": "0.359", "wps": "8548.2", "ups": "0.58", "wpb": "14842.2", "bsz": "81.9", "num_updates": "76800", "lr": "6.02239e-06", "gnorm": "105.412", "loss_scale": "8", "train_wall": "347", "gb_free": "33.1", "wall": "136751"}
[2024-07-06 22:55:15,317][train_inner][INFO] - {"epoch": 60, "update": 59.392, "loss": "65.519", "ntokens": "14848.7", "nsentences": "81.24", "nll_loss": "0.358", "wps": "8338.2", "ups": "0.56", "wpb": "14848.7", "bsz": "81.2", "num_updates": "77000", "lr": "5.95066e-06", "gnorm": "104.737", "loss_scale": "8", "train_wall": "356", "gb_free": "31.7", "wall": "137107"}
[2024-07-06 23:01:12,037][train_inner][INFO] - {"epoch": 60, "update": 59.546, "loss": "66.773", "ntokens": "14832.7", "nsentences": "79.2", "nll_loss": "0.357", "wps": "8318.2", "ups": "0.56", "wpb": "14832.7", "bsz": "79.2", "num_updates": "77200", "lr": "5.87978e-06", "gnorm": "105.968", "loss_scale": "16", "train_wall": "356", "gb_free": "32", "wall": "137464"}
[2024-07-06 23:05:18,251][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-06 23:07:12,753][train_inner][INFO] - {"epoch": 60, "update": 59.701, "loss": "66.714", "ntokens": "14804.3", "nsentences": "79.64", "nll_loss": "0.359", "wps": "8209.9", "ups": "0.55", "wpb": "14804.3", "bsz": "79.6", "num_updates": "77400", "lr": "5.80974e-06", "gnorm": "105.983", "loss_scale": "8", "train_wall": "360", "gb_free": "32.3", "wall": "137824"}
[2024-07-06 23:13:03,740][train_inner][INFO] - {"epoch": 60, "update": 59.855, "loss": "67.177", "ntokens": "14838.3", "nsentences": "79.96", "nll_loss": "0.362", "wps": "8456.9", "ups": "0.57", "wpb": "14838.3", "bsz": "80", "num_updates": "77600", "lr": "5.74054e-06", "gnorm": "106.512", "loss_scale": "8", "train_wall": "350", "gb_free": "32.1", "wall": "138175"}
[2024-07-06 23:18:36,139][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 23:18:36,200][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 23:19:08,428][dev-other][INFO] - {"epoch": 60, "dev-other_loss": "23.579", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.251", "dev-other_uer": "3.659", "dev-other_wer": "9.396", "dev-other_raw_wer": "9.396", "dev-other_wps": "8667.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "77788", "dev-other_best_wer": "9.396"}
[2024-07-06 23:19:08,436][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 60 @ 77788 updates
[2024-07-06 23:19:08,437][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt
[2024-07-06 23:19:10,056][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt
[2024-07-06 23:19:10,669][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_best.pt (epoch 60 @ 77788 updates, score 9.396) (writing took 2.2330778278410435 seconds)
[2024-07-06 23:19:10,669][fairseq_cli.train][INFO] - end of epoch 60 (average epoch stats below)
[2024-07-06 23:19:10,674][train][INFO] - {"epoch": 60, "train_loss": "66.198", "train_ntokens": "14821.9", "train_nsentences": "80.2037", "train_nll_loss": "0.358", "train_wps": "8227.1", "train_ups": "0.56", "train_wpb": "14821.9", "train_bsz": "80.2", "train_num_updates": "77788", "train_lr": "5.67624e-06", "train_gnorm": "105.708", "train_loss_scale": "8", "train_train_wall": "2296", "train_gb_free": "32.2", "train_wall": "138542"}
[2024-07-06 23:19:10,675][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 23:19:10,911][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 23:19:10,915][fairseq.trainer][INFO] - begin training epoch 61
[2024-07-06 23:19:10,915][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-06 23:19:30,269][train_inner][INFO] - {"epoch": 61, "update": 60.009, "loss": "66.043", "ntokens": "14732.9", "nsentences": "80.04", "nll_loss": "0.359", "wps": "7624.5", "ups": "0.52", "wpb": "14732.9", "bsz": "80", "num_updates": "77800", "lr": "5.67216e-06", "gnorm": "105.638", "loss_scale": "8", "train_wall": "351", "gb_free": "33.4", "wall": "138562"}
[2024-07-06 23:25:22,017][train_inner][INFO] - {"epoch": 61, "update": 60.163, "loss": "68.489", "ntokens": "14794.1", "nsentences": "78.4", "nll_loss": "0.363", "wps": "8412.1", "ups": "0.57", "wpb": "14794.1", "bsz": "78.4", "num_updates": "78000", "lr": "5.6046e-06", "gnorm": "106.318", "loss_scale": "8", "train_wall": "351", "gb_free": "32.4", "wall": "138914"}
[2024-07-06 23:31:06,810][train_inner][INFO] - {"epoch": 61, "update": 60.318, "loss": "67.57", "ntokens": "14786.2", "nsentences": "79.56", "nll_loss": "0.364", "wps": "8578.6", "ups": "0.58", "wpb": "14786.2", "bsz": "79.6", "num_updates": "78200", "lr": "5.53784e-06", "gnorm": "107.826", "loss_scale": "8", "train_wall": "344", "gb_free": "31.6", "wall": "139258"}
[2024-07-06 23:36:56,313][train_inner][INFO] - {"epoch": 61, "update": 60.472, "loss": "67.892", "ntokens": "14860.6", "nsentences": "80.36", "nll_loss": "0.367", "wps": "8506.1", "ups": "0.57", "wpb": "14860.6", "bsz": "80.4", "num_updates": "78400", "lr": "5.47188e-06", "gnorm": "106.896", "loss_scale": "8", "train_wall": "349", "gb_free": "32.3", "wall": "139608"}
[2024-07-06 23:42:43,258][train_inner][INFO] - {"epoch": 61, "update": 60.626, "loss": "64.916", "ntokens": "14864", "nsentences": "81.64", "nll_loss": "0.357", "wps": "8568.8", "ups": "0.58", "wpb": "14864", "bsz": "81.6", "num_updates": "78600", "lr": "5.4067e-06", "gnorm": "104.006", "loss_scale": "8", "train_wall": "346", "gb_free": "32.1", "wall": "139955"}
[2024-07-06 23:48:37,235][train_inner][INFO] - {"epoch": 61, "update": 60.78, "loss": "67.306", "ntokens": "14825.6", "nsentences": "80.2", "nll_loss": "0.364", "wps": "8378.3", "ups": "0.57", "wpb": "14825.6", "bsz": "80.2", "num_updates": "78800", "lr": "5.3423e-06", "gnorm": "104.895", "loss_scale": "8", "train_wall": "353", "gb_free": "31.8", "wall": "140309"}
[2024-07-06 23:54:30,539][train_inner][INFO] - {"epoch": 61, "update": 60.934, "loss": "67.804", "ntokens": "14786.8", "nsentences": "79.07", "nll_loss": "0.363", "wps": "8370.8", "ups": "0.57", "wpb": "14786.8", "bsz": "79.1", "num_updates": "79000", "lr": "5.27866e-06", "gnorm": "106.97", "loss_scale": "8", "train_wall": "353", "gb_free": "32.3", "wall": "140662"}
[2024-07-06 23:56:56,644][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-06 23:56:56,649][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 23:57:29,041][dev-other][INFO] - {"epoch": 61, "dev-other_loss": "23.577", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.251", "dev-other_uer": "3.671", "dev-other_wer": "9.435", "dev-other_raw_wer": "9.435", "dev-other_wps": "8635.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "79085", "dev-other_best_wer": "9.396"}
[2024-07-06 23:57:29,041][fairseq_cli.train][INFO] - end of epoch 61 (average epoch stats below)
[2024-07-06 23:57:29,048][train][INFO] - {"epoch": 61, "train_loss": "67.561", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.366", "train_wps": "8364.8", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "79085", "train_lr": "5.25185e-06", "train_gnorm": "106.195", "train_loss_scale": "8", "train_train_wall": "2262", "train_gb_free": "32", "train_wall": "140841"}
[2024-07-06 23:57:29,050][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-06 23:57:29,647][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-06 23:57:29,651][fairseq.trainer][INFO] - begin training epoch 62
[2024-07-06 23:57:29,651][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 00:00:51,198][train_inner][INFO] - {"epoch": 62, "update": 61.089, "loss": "70.917", "ntokens": "14822.8", "nsentences": "80.4", "nll_loss": "0.385", "wps": "7789.6", "ups": "0.53", "wpb": "14822.8", "bsz": "80.4", "num_updates": "79200", "lr": "5.21579e-06", "gnorm": "108.84", "loss_scale": "8", "train_wall": "347", "gb_free": "31.3", "wall": "141043"}
[2024-07-07 00:06:42,524][train_inner][INFO] - {"epoch": 62, "update": 61.243, "loss": "66.484", "ntokens": "14855.3", "nsentences": "80.92", "nll_loss": "0.362", "wps": "8457.2", "ups": "0.57", "wpb": "14855.3", "bsz": "80.9", "num_updates": "79400", "lr": "5.15366e-06", "gnorm": "107.364", "loss_scale": "16", "train_wall": "351", "gb_free": "32.2", "wall": "141394"}
[2024-07-07 00:12:28,846][train_inner][INFO] - {"epoch": 62, "update": 61.397, "loss": "70.361", "ntokens": "14841", "nsentences": "80.04", "nll_loss": "0.379", "wps": "8570.9", "ups": "0.58", "wpb": "14841", "bsz": "80", "num_updates": "79600", "lr": "5.09227e-06", "gnorm": "107.392", "loss_scale": "16", "train_wall": "346", "gb_free": "32", "wall": "141741"}
[2024-07-07 00:18:21,381][train_inner][INFO] - {"epoch": 62, "update": 61.551, "loss": "67.974", "ntokens": "14783.4", "nsentences": "79.32", "nll_loss": "0.365", "wps": "8387.2", "ups": "0.57", "wpb": "14783.4", "bsz": "79.3", "num_updates": "79800", "lr": "5.03161e-06", "gnorm": "107.791", "loss_scale": "16", "train_wall": "352", "gb_free": "32.4", "wall": "142093"}
[2024-07-07 00:24:11,702][train_inner][INFO] - {"epoch": 62, "update": 61.705, "loss": "65.317", "ntokens": "14831.2", "nsentences": "81.4", "nll_loss": "0.358", "wps": "8467.7", "ups": "0.57", "wpb": "14831.2", "bsz": "81.4", "num_updates": "80000", "lr": "4.97168e-06", "gnorm": "105.642", "loss_scale": "16", "train_wall": "350", "gb_free": "31.3", "wall": "142443"}
[2024-07-07 00:29:57,121][train_inner][INFO] - {"epoch": 62, "update": 61.86, "loss": "67.346", "ntokens": "14759.7", "nsentences": "80.24", "nll_loss": "0.366", "wps": "8546.2", "ups": "0.58", "wpb": "14759.7", "bsz": "80.2", "num_updates": "80200", "lr": "4.91246e-06", "gnorm": "107.366", "loss_scale": "16", "train_wall": "345", "gb_free": "31.1", "wall": "142789"}
[2024-07-07 00:31:17,287][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-07 00:35:13,767][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 00:35:13,828][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 00:35:46,089][dev-other][INFO] - {"epoch": 62, "dev-other_loss": "24.434", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.26", "dev-other_uer": "3.707", "dev-other_wer": "9.449", "dev-other_raw_wer": "9.449", "dev-other_wps": "8686", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "80381", "dev-other_best_wer": "9.396"}
[2024-07-07 00:35:46,090][fairseq_cli.train][INFO] - end of epoch 62 (average epoch stats below)
[2024-07-07 00:35:46,101][train][INFO] - {"epoch": 62, "train_loss": "67.483", "train_ntokens": "14822.4", "train_nsentences": "80.2099", "train_nll_loss": "0.365", "train_wps": "8362.8", "train_ups": "0.56", "train_wpb": "14822.4", "train_bsz": "80.2", "train_num_updates": "80381", "train_lr": "4.85948e-06", "train_gnorm": "107.071", "train_loss_scale": "8", "train_train_wall": "2260", "train_gb_free": "30.9", "train_wall": "143138"}
[2024-07-07 00:35:46,103][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 00:35:46,703][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-07 00:35:46,707][fairseq.trainer][INFO] - begin training epoch 63
[2024-07-07 00:35:46,707][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 00:36:19,085][train_inner][INFO] - {"epoch": 63, "update": 62.015, "loss": "66.171", "ntokens": "14897.4", "nsentences": "80.56", "nll_loss": "0.358", "wps": "7800.6", "ups": "0.52", "wpb": "14897.4", "bsz": "80.6", "num_updates": "80400", "lr": "4.85395e-06", "gnorm": "105.915", "loss_scale": "8", "train_wall": "348", "gb_free": "30.5", "wall": "143171"}
[2024-07-07 00:42:09,525][train_inner][INFO] - {"epoch": 63, "update": 62.169, "loss": "68.992", "ntokens": "14867", "nsentences": "78.48", "nll_loss": "0.364", "wps": "8484.9", "ups": "0.57", "wpb": "14867", "bsz": "78.5", "num_updates": "80600", "lr": "4.79613e-06", "gnorm": "110.767", "loss_scale": "8", "train_wall": "350", "gb_free": "32.5", "wall": "143521"}
[2024-07-07 00:47:58,984][train_inner][INFO] - {"epoch": 63, "update": 62.323, "loss": "65.521", "ntokens": "14934", "nsentences": "81.6", "nll_loss": "0.358", "wps": "8547.2", "ups": "0.57", "wpb": "14934", "bsz": "81.6", "num_updates": "80800", "lr": "4.739e-06", "gnorm": "105.039", "loss_scale": "8", "train_wall": "349", "gb_free": "32.3", "wall": "143871"}
[2024-07-07 00:53:45,624][train_inner][INFO] - {"epoch": 63, "update": 62.477, "loss": "69.101", "ntokens": "14706.8", "nsentences": "79.28", "nll_loss": "0.373", "wps": "8487.1", "ups": "0.58", "wpb": "14706.8", "bsz": "79.3", "num_updates": "81000", "lr": "4.68255e-06", "gnorm": "107.829", "loss_scale": "8", "train_wall": "346", "gb_free": "32.2", "wall": "144217"}
[2024-07-07 00:59:40,500][train_inner][INFO] - {"epoch": 63, "update": 62.631, "loss": "66.834", "ntokens": "14817.3", "nsentences": "80.4", "nll_loss": "0.363", "wps": "8351.4", "ups": "0.56", "wpb": "14817.3", "bsz": "80.4", "num_updates": "81200", "lr": "4.62678e-06", "gnorm": "103.896", "loss_scale": "8", "train_wall": "354", "gb_free": "33.4", "wall": "144572"}
[2024-07-07 01:05:29,356][train_inner][INFO] - {"epoch": 63, "update": 62.786, "loss": "67.342", "ntokens": "14861.6", "nsentences": "81.28", "nll_loss": "0.368", "wps": "8522.6", "ups": "0.57", "wpb": "14861.6", "bsz": "81.3", "num_updates": "81400", "lr": "4.57167e-06", "gnorm": "105.836", "loss_scale": "8", "train_wall": "348", "gb_free": "31.9", "wall": "144921"}
[2024-07-07 01:11:22,349][train_inner][INFO] - {"epoch": 63, "update": 62.94, "loss": "65.412", "ntokens": "14736.5", "nsentences": "79.72", "nll_loss": "0.354", "wps": "8351.5", "ups": "0.57", "wpb": "14736.5", "bsz": "79.7", "num_updates": "81600", "lr": "4.51721e-06", "gnorm": "106.697", "loss_scale": "8", "train_wall": "352", "gb_free": "32.8", "wall": "145274"}
[2024-07-07 01:13:40,151][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 01:13:40,244][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 01:14:12,337][dev-other][INFO] - {"epoch": 63, "dev-other_loss": "23.16", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.246", "dev-other_uer": "3.698", "dev-other_wer": "9.476", "dev-other_raw_wer": "9.476", "dev-other_wps": "8706.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "81678", "dev-other_best_wer": "9.396"}
[2024-07-07 01:14:12,338][fairseq_cli.train][INFO] - end of epoch 63 (average epoch stats below)
[2024-07-07 01:14:12,343][train][INFO] - {"epoch": 63, "train_loss": "67.152", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.363", "train_wps": "8336.2", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "81678", "train_lr": "4.49615e-06", "train_gnorm": "106.6", "train_loss_scale": "8", "train_train_wall": "2269", "train_gb_free": "32.5", "train_wall": "145444"}
[2024-07-07 01:14:12,344][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 01:14:12,930][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-07 01:14:12,934][fairseq.trainer][INFO] - begin training epoch 64
[2024-07-07 01:14:12,934][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 01:17:43,998][train_inner][INFO] - {"epoch": 64, "update": 63.094, "loss": "67.882", "ntokens": "14860.3", "nsentences": "79.91", "nll_loss": "0.365", "wps": "7787.8", "ups": "0.52", "wpb": "14860.3", "bsz": "79.9", "num_updates": "81800", "lr": "4.4634e-06", "gnorm": "106.625", "loss_scale": "8", "train_wall": "348", "gb_free": "33.1", "wall": "145656"}
[2024-07-07 01:23:31,199][train_inner][INFO] - {"epoch": 64, "update": 63.248, "loss": "69.607", "ntokens": "14793.3", "nsentences": "79.28", "nll_loss": "0.373", "wps": "8521.7", "ups": "0.58", "wpb": "14793.3", "bsz": "79.3", "num_updates": "82000", "lr": "4.41024e-06", "gnorm": "109.436", "loss_scale": "8", "train_wall": "347", "gb_free": "32.9", "wall": "146003"}
[2024-07-07 01:29:22,720][train_inner][INFO] - {"epoch": 64, "update": 63.402, "loss": "65.907", "ntokens": "14907.1", "nsentences": "81.32", "nll_loss": "0.36", "wps": "8481.7", "ups": "0.57", "wpb": "14907.1", "bsz": "81.3", "num_updates": "82200", "lr": "4.35771e-06", "gnorm": "105.195", "loss_scale": "8", "train_wall": "351", "gb_free": "32.9", "wall": "146354"}
[2024-07-07 01:35:03,422][train_inner][INFO] - {"epoch": 64, "update": 63.557, "loss": "70.531", "ntokens": "14779.1", "nsentences": "78.27", "nll_loss": "0.374", "wps": "8677.8", "ups": "0.59", "wpb": "14779.1", "bsz": "78.3", "num_updates": "82400", "lr": "4.3058e-06", "gnorm": "108.093", "loss_scale": "16", "train_wall": "340", "gb_free": "33.4", "wall": "146695"}
[2024-07-07 01:40:56,620][train_inner][INFO] - {"epoch": 64, "update": 63.711, "loss": "63.706", "ntokens": "14856.3", "nsentences": "81.52", "nll_loss": "0.35", "wps": "8414.4", "ups": "0.57", "wpb": "14856.3", "bsz": "81.5", "num_updates": "82600", "lr": "4.25451e-06", "gnorm": "103.502", "loss_scale": "16", "train_wall": "353", "gb_free": "30.6", "wall": "147048"}
[2024-07-07 01:46:43,109][train_inner][INFO] - {"epoch": 64, "update": 63.865, "loss": "66.995", "ntokens": "14839.3", "nsentences": "81.68", "nll_loss": "0.369", "wps": "8565.8", "ups": "0.58", "wpb": "14839.3", "bsz": "81.7", "num_updates": "82800", "lr": "4.20383e-06", "gnorm": "106.252", "loss_scale": "16", "train_wall": "346", "gb_free": "32.5", "wall": "147395"}
[2024-07-07 01:51:57,087][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 01:51:57,169][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 01:52:29,146][dev-other][INFO] - {"epoch": 64, "dev-other_loss": "23.209", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.247", "dev-other_uer": "3.701", "dev-other_wer": "9.504", "dev-other_raw_wer": "9.504", "dev-other_wps": "8717.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "82975", "dev-other_best_wer": "9.396"}
[2024-07-07 01:52:29,147][fairseq_cli.train][INFO] - end of epoch 64 (average epoch stats below)
[2024-07-07 01:52:29,152][train][INFO] - {"epoch": 64, "train_loss": "67.113", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.363", "train_wps": "8370.4", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "82975", "train_lr": "4.15999e-06", "train_gnorm": "106.387", "train_loss_scale": "16", "train_train_wall": "2260", "train_gb_free": "31.5", "train_wall": "147741"}
[2024-07-07 01:52:29,154][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 01:52:29,725][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-07 01:52:29,729][fairseq.trainer][INFO] - begin training epoch 65
[2024-07-07 01:52:29,730][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 01:53:13,742][train_inner][INFO] - {"epoch": 65, "update": 64.019, "loss": "65.028", "ntokens": "14729.6", "nsentences": "79.64", "nll_loss": "0.352", "wps": "7542.7", "ups": "0.51", "wpb": "14729.6", "bsz": "79.6", "num_updates": "83000", "lr": "4.15376e-06", "gnorm": "104.376", "loss_scale": "16", "train_wall": "357", "gb_free": "31.1", "wall": "147785"}
[2024-07-07 01:58:57,554][train_inner][INFO] - {"epoch": 65, "update": 64.173, "loss": "68.499", "ntokens": "14853.2", "nsentences": "80.52", "nll_loss": "0.371", "wps": "8641.6", "ups": "0.58", "wpb": "14853.2", "bsz": "80.5", "num_updates": "83200", "lr": "4.10428e-06", "gnorm": "107.316", "loss_scale": "16", "train_wall": "343", "gb_free": "33.4", "wall": "148129"}
[2024-07-07 02:04:53,125][train_inner][INFO] - {"epoch": 65, "update": 64.328, "loss": "66.275", "ntokens": "14910", "nsentences": "80.28", "nll_loss": "0.357", "wps": "8388.3", "ups": "0.56", "wpb": "14910", "bsz": "80.3", "num_updates": "83400", "lr": "4.0554e-06", "gnorm": "105.155", "loss_scale": "16", "train_wall": "355", "gb_free": "30.6", "wall": "148485"}
[2024-07-07 02:10:33,317][train_inner][INFO] - {"epoch": 65, "update": 64.482, "loss": "70.344", "ntokens": "14817.5", "nsentences": "80.72", "nll_loss": "0.383", "wps": "8711.6", "ups": "0.59", "wpb": "14817.5", "bsz": "80.7", "num_updates": "83600", "lr": "4.00709e-06", "gnorm": "109.78", "loss_scale": "16", "train_wall": "340", "gb_free": "32.7", "wall": "148825"}
[2024-07-07 02:16:14,371][train_inner][INFO] - {"epoch": 65, "update": 64.636, "loss": "69.206", "ntokens": "14927.3", "nsentences": "81.4", "nll_loss": "0.377", "wps": "8753.9", "ups": "0.59", "wpb": "14927.3", "bsz": "81.4", "num_updates": "83800", "lr": "3.95936e-06", "gnorm": "106.141", "loss_scale": "16", "train_wall": "341", "gb_free": "32.6", "wall": "149166"}
[2024-07-07 02:21:56,804][train_inner][INFO] - {"epoch": 65, "update": 64.79, "loss": "70.097", "ntokens": "14793.9", "nsentences": "80.16", "nll_loss": "0.38", "wps": "8640.7", "ups": "0.58", "wpb": "14793.9", "bsz": "80.2", "num_updates": "84000", "lr": "3.9122e-06", "gnorm": "107.967", "loss_scale": "16", "train_wall": "342", "gb_free": "31.9", "wall": "149508"}
[2024-07-07 02:22:48,740][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-07 02:27:38,322][train_inner][INFO] - {"epoch": 65, "update": 64.945, "loss": "69.081", "ntokens": "14726.9", "nsentences": "79.16", "nll_loss": "0.371", "wps": "8626.3", "ups": "0.59", "wpb": "14726.9", "bsz": "79.2", "num_updates": "84200", "lr": "3.8656e-06", "gnorm": "108.914", "loss_scale": "8", "train_wall": "341", "gb_free": "33", "wall": "149850"}
[2024-07-07 02:29:37,656][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 02:29:37,662][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 02:30:09,673][dev-other][INFO] - {"epoch": 65, "dev-other_loss": "23.542", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.25", "dev-other_uer": "3.662", "dev-other_wer": "9.419", "dev-other_raw_wer": "9.419", "dev-other_wps": "8720.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "84271", "dev-other_best_wer": "9.396"}
[2024-07-07 02:30:09,675][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 65 @ 84271 updates
[2024-07-07 02:30:09,676][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_last.pt
[2024-07-07 02:30:10,863][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_last.pt
[2024-07-07 02:30:10,875][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_last.pt (epoch 65 @ 84271 updates, score 9.419) (writing took 1.1998773328959942 seconds)
[2024-07-07 02:30:10,875][fairseq_cli.train][INFO] - end of epoch 65 (average epoch stats below)
[2024-07-07 02:30:10,884][train][INFO] - {"epoch": 65, "train_loss": "68.901", "train_ntokens": "14822.5", "train_nsentences": "80.2037", "train_nll_loss": "0.373", "train_wps": "8493.5", "train_ups": "0.57", "train_wpb": "14822.5", "train_bsz": "80.2", "train_num_updates": "84271", "train_lr": "3.84919e-06", "train_gnorm": "107.816", "train_loss_scale": "8", "train_train_wall": "2224", "train_gb_free": "31.5", "train_wall": "150003"}
[2024-07-07 02:30:10,885][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 02:30:11,111][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-07 02:30:11,115][fairseq.trainer][INFO] - begin training epoch 66
[2024-07-07 02:30:11,115][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 02:33:51,435][train_inner][INFO] - {"epoch": 66, "update": 65.099, "loss": "70.746", "ntokens": "14788.4", "nsentences": "80.64", "nll_loss": "0.386", "wps": "7927.3", "ups": "0.54", "wpb": "14788.4", "bsz": "80.6", "num_updates": "84400", "lr": "3.81955e-06", "gnorm": "110.559", "loss_scale": "8", "train_wall": "339", "gb_free": "33", "wall": "150223"}
[2024-07-07 02:39:46,769][train_inner][INFO] - {"epoch": 66, "update": 65.254, "loss": "65.584", "ntokens": "14929.2", "nsentences": "80.72", "nll_loss": "0.355", "wps": "8404.5", "ups": "0.56", "wpb": "14929.2", "bsz": "80.7", "num_updates": "84600", "lr": "3.77406e-06", "gnorm": "104.316", "loss_scale": "8", "train_wall": "355", "gb_free": "32.4", "wall": "150578"}
[2024-07-07 02:45:37,759][train_inner][INFO] - {"epoch": 66, "update": 65.408, "loss": "68.303", "ntokens": "14831.5", "nsentences": "78.6", "nll_loss": "0.362", "wps": "8451.8", "ups": "0.57", "wpb": "14831.5", "bsz": "78.6", "num_updates": "84800", "lr": "3.7291e-06", "gnorm": "106.191", "loss_scale": "8", "train_wall": "350", "gb_free": "32.9", "wall": "150929"}
[2024-07-07 02:51:31,368][train_inner][INFO] - {"epoch": 66, "update": 65.562, "loss": "65.658", "ntokens": "14761.7", "nsentences": "79.96", "nll_loss": "0.356", "wps": "8349.4", "ups": "0.57", "wpb": "14761.7", "bsz": "80", "num_updates": "85000", "lr": "3.68468e-06", "gnorm": "104.159", "loss_scale": "8", "train_wall": "353", "gb_free": "30.1", "wall": "151283"}
[2024-07-07 02:57:16,569][train_inner][INFO] - {"epoch": 66, "update": 65.716, "loss": "70.37", "ntokens": "14786.8", "nsentences": "79.03", "nll_loss": "0.376", "wps": "8567.3", "ups": "0.58", "wpb": "14786.8", "bsz": "79", "num_updates": "85200", "lr": "3.64079e-06", "gnorm": "108.269", "loss_scale": "8", "train_wall": "345", "gb_free": "30.6", "wall": "151628"}
[2024-07-07 03:02:59,748][train_inner][INFO] - {"epoch": 66, "update": 65.87, "loss": "67.321", "ntokens": "14827.5", "nsentences": "81.12", "nll_loss": "0.368", "wps": "8641.5", "ups": "0.58", "wpb": "14827.5", "bsz": "81.1", "num_updates": "85400", "lr": "3.59743e-06", "gnorm": "106.842", "loss_scale": "8", "train_wall": "343", "gb_free": "32.8", "wall": "151971"}
[2024-07-07 03:05:00,354][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-07-07 03:07:51,118][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 03:07:51,188][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 03:08:23,072][dev-other][INFO] - {"epoch": 66, "dev-other_loss": "23.119", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.246", "dev-other_uer": "3.676", "dev-other_wer": "9.504", "dev-other_raw_wer": "9.504", "dev-other_wps": "8741", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "85567", "dev-other_best_wer": "9.396"}
[2024-07-07 03:08:23,073][fairseq_cli.train][INFO] - end of epoch 66 (average epoch stats below)
[2024-07-07 03:08:23,076][train][INFO] - {"epoch": 66, "train_loss": "67.892", "train_ntokens": "14822.5", "train_nsentences": "80.196", "train_nll_loss": "0.367", "train_wps": "8380.6", "train_ups": "0.57", "train_wpb": "14822.5", "train_bsz": "80.2", "train_num_updates": "85567", "train_lr": "3.56161e-06", "train_gnorm": "106.156", "train_loss_scale": "4", "train_train_wall": "2256", "train_gb_free": "31.8", "train_wall": "152295"}
[2024-07-07 03:08:23,078][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 03:08:23,736][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-07 03:08:23,740][fairseq.trainer][INFO] - begin training epoch 67
[2024-07-07 03:08:23,740][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 03:09:22,471][train_inner][INFO] - {"epoch": 67, "update": 66.025, "loss": "68.116", "ntokens": "14741", "nsentences": "79.84", "nll_loss": "0.369", "wps": "7703.4", "ups": "0.52", "wpb": "14741", "bsz": "79.8", "num_updates": "85600", "lr": "3.55458e-06", "gnorm": "106.25", "loss_scale": "4", "train_wall": "349", "gb_free": "33.3", "wall": "152354"}
[2024-07-07 03:15:10,109][train_inner][INFO] - {"epoch": 67, "update": 66.18, "loss": "67.696", "ntokens": "14882.4", "nsentences": "80.15", "nll_loss": "0.365", "wps": "8562.2", "ups": "0.58", "wpb": "14882.4", "bsz": "80.2", "num_updates": "85800", "lr": "3.51224e-06", "gnorm": "107.076", "loss_scale": "4", "train_wall": "347", "gb_free": "31.9", "wall": "152702"}
[2024-07-07 03:20:58,443][train_inner][INFO] - {"epoch": 67, "update": 66.334, "loss": "65.478", "ntokens": "14889.2", "nsentences": "82.72", "nll_loss": "0.364", "wps": "8550.5", "ups": "0.57", "wpb": "14889.2", "bsz": "82.7", "num_updates": "86000", "lr": "3.4704e-06", "gnorm": "104.239", "loss_scale": "4", "train_wall": "348", "gb_free": "32", "wall": "153050"}
[2024-07-07 03:26:47,866][train_inner][INFO] - {"epoch": 67, "update": 66.488, "loss": "68.919", "ntokens": "14799.6", "nsentences": "80.16", "nll_loss": "0.373", "wps": "8472.7", "ups": "0.57", "wpb": "14799.6", "bsz": "80.2", "num_updates": "86200", "lr": "3.42906e-06", "gnorm": "109.094", "loss_scale": "4", "train_wall": "349", "gb_free": "32.4", "wall": "153399"}
[2024-07-07 03:32:44,608][train_inner][INFO] - {"epoch": 67, "update": 66.642, "loss": "68.136", "ntokens": "14777.2", "nsentences": "78.6", "nll_loss": "0.362", "wps": "8286.3", "ups": "0.56", "wpb": "14777.2", "bsz": "78.6", "num_updates": "86400", "lr": "3.38822e-06", "gnorm": "107.353", "loss_scale": "4", "train_wall": "356", "gb_free": "31.8", "wall": "153756"}
[2024-07-07 03:38:30,671][train_inner][INFO] - {"epoch": 67, "update": 66.796, "loss": "69.811", "ntokens": "14715.1", "nsentences": "79.28", "nll_loss": "0.376", "wps": "8504.7", "ups": "0.58", "wpb": "14715.1", "bsz": "79.3", "num_updates": "86600", "lr": "3.34786e-06", "gnorm": "107.341", "loss_scale": "4", "train_wall": "346", "gb_free": "32.7", "wall": "154102"}
[2024-07-07 03:44:18,530][train_inner][INFO] - {"epoch": 67, "update": 66.951, "loss": "66.346", "ntokens": "14881.7", "nsentences": "80.96", "nll_loss": "0.361", "wps": "8558.2", "ups": "0.58", "wpb": "14881.7", "bsz": "81", "num_updates": "86800", "lr": "3.30798e-06", "gnorm": "106.786", "loss_scale": "4", "train_wall": "347", "gb_free": "32.6", "wall": "154450"}
[2024-07-07 03:46:10,415][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 03:46:10,420][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 03:46:42,516][dev-other][INFO] - {"epoch": 67, "dev-other_loss": "23.309", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.248", "dev-other_uer": "3.664", "dev-other_wer": "9.437", "dev-other_raw_wer": "9.437", "dev-other_wps": "8692.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "86864", "dev-other_best_wer": "9.396"}
[2024-07-07 03:46:42,516][fairseq_cli.train][INFO] - end of epoch 67 (average epoch stats below)
[2024-07-07 03:46:42,519][train][INFO] - {"epoch": 67, "train_loss": "67.638", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.366", "train_wps": "8360.9", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "86864", "train_lr": "3.29532e-06", "train_gnorm": "106.979", "train_loss_scale": "4", "train_train_wall": "2263", "train_gb_free": "32.1", "train_wall": "154594"}
[2024-07-07 03:46:42,520][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 03:46:43,131][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-07 03:46:43,153][fairseq.trainer][INFO] - begin training epoch 68
[2024-07-07 03:46:43,153][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 03:50:44,141][train_inner][INFO] - {"epoch": 68, "update": 67.105, "loss": "66", "ntokens": "14870", "nsentences": "79.95", "nll_loss": "0.355", "wps": "7712.7", "ups": "0.52", "wpb": "14870", "bsz": "80", "num_updates": "87000", "lr": "3.26858e-06", "gnorm": "105.569", "loss_scale": "4", "train_wall": "352", "gb_free": "31.8", "wall": "154836"}
[2024-07-07 03:56:38,317][train_inner][INFO] - {"epoch": 68, "update": 67.259, "loss": "67.646", "ntokens": "14864.5", "nsentences": "80.6", "nll_loss": "0.367", "wps": "8394", "ups": "0.56", "wpb": "14864.5", "bsz": "80.6", "num_updates": "87200", "lr": "3.22965e-06", "gnorm": "105.962", "loss_scale": "4", "train_wall": "354", "gb_free": "32.3", "wall": "155190"}
[2024-07-07 04:02:28,094][train_inner][INFO] - {"epoch": 68, "update": 67.413, "loss": "68.43", "ntokens": "14748.7", "nsentences": "80.4", "nll_loss": "0.373", "wps": "8433.7", "ups": "0.57", "wpb": "14748.7", "bsz": "80.4", "num_updates": "87400", "lr": "3.19118e-06", "gnorm": "105.759", "loss_scale": "4", "train_wall": "349", "gb_free": "33", "wall": "155540"}
[2024-07-07 04:08:16,841][train_inner][INFO] - {"epoch": 68, "update": 67.567, "loss": "66.416", "ntokens": "14843.2", "nsentences": "80.36", "nll_loss": "0.36", "wps": "8514.3", "ups": "0.57", "wpb": "14843.2", "bsz": "80.4", "num_updates": "87600", "lr": "3.15317e-06", "gnorm": "105.956", "loss_scale": "8", "train_wall": "348", "gb_free": "32.6", "wall": "155888"}
[2024-07-07 04:14:09,613][train_inner][INFO] - {"epoch": 68, "update": 67.722, "loss": "67.801", "ntokens": "14849.1", "nsentences": "80.44", "nll_loss": "0.367", "wps": "8420.4", "ups": "0.57", "wpb": "14849.1", "bsz": "80.4", "num_updates": "87800", "lr": "3.11561e-06", "gnorm": "106.847", "loss_scale": "8", "train_wall": "352", "gb_free": "31.8", "wall": "156241"}
[2024-07-07 04:19:58,936][train_inner][INFO] - {"epoch": 68, "update": 67.876, "loss": "68.425", "ntokens": "14772.9", "nsentences": "79.08", "nll_loss": "0.366", "wps": "8459.8", "ups": "0.57", "wpb": "14772.9", "bsz": "79.1", "num_updates": "88000", "lr": "3.0785e-06", "gnorm": "106.93", "loss_scale": "8", "train_wall": "349", "gb_free": "31.4", "wall": "156591"}
[2024-07-07 04:24:47,637][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 04:24:47,680][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 04:25:19,702][dev-other][INFO] - {"epoch": 68, "dev-other_loss": "23.67", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.252", "dev-other_uer": "3.694", "dev-other_wer": "9.431", "dev-other_raw_wer": "9.431", "dev-other_wps": "8700.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "88161", "dev-other_best_wer": "9.396"}
[2024-07-07 04:25:19,703][fairseq_cli.train][INFO] - end of epoch 68 (average epoch stats below)
[2024-07-07 04:25:19,706][train][INFO] - {"epoch": 68, "train_loss": "67.363", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.364", "train_wps": "8296.8", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "88161", "train_lr": "3.04894e-06", "train_gnorm": "105.94", "train_loss_scale": "8", "train_train_wall": "2281", "train_gb_free": "32.6", "train_wall": "156911"}
[2024-07-07 04:25:19,707][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 04:25:20,352][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-07 04:25:20,356][fairseq.trainer][INFO] - begin training epoch 69
[2024-07-07 04:25:20,356][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 04:26:31,898][train_inner][INFO] - {"epoch": 69, "update": 68.03, "loss": "65.019", "ntokens": "14874.6", "nsentences": "81.24", "nll_loss": "0.355", "wps": "7572", "ups": "0.51", "wpb": "14874.6", "bsz": "81.2", "num_updates": "88200", "lr": "3.04183e-06", "gnorm": "103.223", "loss_scale": "8", "train_wall": "359", "gb_free": "31.9", "wall": "156984"}
[2024-07-07 04:32:19,635][train_inner][INFO] - {"epoch": 69, "update": 68.184, "loss": "66.523", "ntokens": "14732.4", "nsentences": "79.32", "nll_loss": "0.358", "wps": "8475.1", "ups": "0.58", "wpb": "14732.4", "bsz": "79.3", "num_updates": "88400", "lr": "3.00559e-06", "gnorm": "107.586", "loss_scale": "8", "train_wall": "347", "gb_free": "32.6", "wall": "157331"}
[2024-07-07 04:38:15,721][train_inner][INFO] - {"epoch": 69, "update": 68.338, "loss": "67.667", "ntokens": "14782.7", "nsentences": "80.35", "nll_loss": "0.368", "wps": "8304.6", "ups": "0.56", "wpb": "14782.7", "bsz": "80.4", "num_updates": "88600", "lr": "2.96979e-06", "gnorm": "106.026", "loss_scale": "8", "train_wall": "355", "gb_free": "31.7", "wall": "157687"}
[2024-07-07 04:44:07,332][train_inner][INFO] - {"epoch": 69, "update": 68.493, "loss": "66.135", "ntokens": "14654.8", "nsentences": "78.48", "nll_loss": "0.354", "wps": "8336.4", "ups": "0.57", "wpb": "14654.8", "bsz": "78.5", "num_updates": "88800", "lr": "2.93442e-06", "gnorm": "107.128", "loss_scale": "8", "train_wall": "351", "gb_free": "32.4", "wall": "158039"}
[2024-07-07 04:49:50,210][train_inner][INFO] - {"epoch": 69, "update": 68.647, "loss": "65.377", "ntokens": "14838.2", "nsentences": "80.76", "nll_loss": "0.356", "wps": "8656.9", "ups": "0.58", "wpb": "14838.2", "bsz": "80.8", "num_updates": "89000", "lr": "2.89946e-06", "gnorm": "106.403", "loss_scale": "8", "train_wall": "342", "gb_free": "32.2", "wall": "158382"}
[2024-07-07 04:55:40,209][train_inner][INFO] - {"epoch": 69, "update": 68.801, "loss": "67.99", "ntokens": "14963.2", "nsentences": "80.56", "nll_loss": "0.366", "wps": "8551.1", "ups": "0.57", "wpb": "14963.2", "bsz": "80.6", "num_updates": "89200", "lr": "2.86493e-06", "gnorm": "106.042", "loss_scale": "8", "train_wall": "349", "gb_free": "33.5", "wall": "158732"}
[2024-07-07 05:01:30,697][train_inner][INFO] - {"epoch": 69, "update": 68.955, "loss": "66.702", "ntokens": "14859.5", "nsentences": "79.8", "nll_loss": "0.358", "wps": "8480.9", "ups": "0.57", "wpb": "14859.5", "bsz": "79.8", "num_updates": "89400", "lr": "2.8308e-06", "gnorm": "105.758", "loss_scale": "8", "train_wall": "350", "gb_free": "31.8", "wall": "159082"}
[2024-07-07 05:03:09,592][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 05:03:09,661][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 05:03:41,748][dev-other][INFO] - {"epoch": 69, "dev-other_loss": "23.448", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.249", "dev-other_uer": "3.679", "dev-other_wer": "9.488", "dev-other_raw_wer": "9.488", "dev-other_wps": "8694", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "89458", "dev-other_best_wer": "9.396"}
[2024-07-07 05:03:41,749][fairseq_cli.train][INFO] - end of epoch 69 (average epoch stats below)
[2024-07-07 05:03:41,764][train][INFO] - {"epoch": 69, "train_loss": "66.496", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.36", "train_wps": "8351.4", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "89458", "train_lr": "2.82098e-06", "train_gnorm": "106.077", "train_loss_scale": "8", "train_train_wall": "2265", "train_gb_free": "31.9", "train_wall": "159213"}
[2024-07-07 05:03:41,766][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 05:03:42,389][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-07 05:03:42,393][fairseq.trainer][INFO] - begin training epoch 70
[2024-07-07 05:03:42,393][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 05:08:00,038][train_inner][INFO] - {"epoch": 70, "update": 69.109, "loss": "65.583", "ntokens": "14839.2", "nsentences": "80.24", "nll_loss": "0.355", "wps": "7624.4", "ups": "0.51", "wpb": "14839.2", "bsz": "80.2", "num_updates": "89600", "lr": "2.79708e-06", "gnorm": "104.679", "loss_scale": "16", "train_wall": "356", "gb_free": "30.6", "wall": "159472"}
[2024-07-07 05:13:43,010][train_inner][INFO] - {"epoch": 70, "update": 69.264, "loss": "66.016", "ntokens": "14864.5", "nsentences": "81.68", "nll_loss": "0.363", "wps": "8668.3", "ups": "0.58", "wpb": "14864.5", "bsz": "81.7", "num_updates": "89800", "lr": "2.76377e-06", "gnorm": "104.251", "loss_scale": "16", "train_wall": "342", "gb_free": "31.8", "wall": "159815"}
[2024-07-07 05:16:53,694][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-07 05:19:32,856][train_inner][INFO] - {"epoch": 70, "update": 69.419, "loss": "67.068", "ntokens": "14794.7", "nsentences": "79.88", "nll_loss": "0.362", "wps": "8459.8", "ups": "0.57", "wpb": "14794.7", "bsz": "79.9", "num_updates": "90000", "lr": "2.73085e-06", "gnorm": "107.532", "loss_scale": "8", "train_wall": "349", "gb_free": "32.1", "wall": "160164"}
[2024-07-07 05:25:27,218][train_inner][INFO] - {"epoch": 70, "update": 69.573, "loss": "66.519", "ntokens": "14792.1", "nsentences": "79.91", "nll_loss": "0.359", "wps": "8350.4", "ups": "0.56", "wpb": "14792.1", "bsz": "79.9", "num_updates": "90200", "lr": "2.69832e-06", "gnorm": "106.528", "loss_scale": "8", "train_wall": "354", "gb_free": "32.2", "wall": "160519"}
[2024-07-07 05:31:25,166][train_inner][INFO] - {"epoch": 70, "update": 69.727, "loss": "64.958", "ntokens": "14890.7", "nsentences": "80.2", "nll_loss": "0.35", "wps": "8320.6", "ups": "0.56", "wpb": "14890.7", "bsz": "80.2", "num_updates": "90400", "lr": "2.66618e-06", "gnorm": "103.74", "loss_scale": "8", "train_wall": "357", "gb_free": "31.7", "wall": "160877"}
[2024-07-07 05:37:12,951][train_inner][INFO] - {"epoch": 70, "update": 69.881, "loss": "67.656", "ntokens": "14787.3", "nsentences": "79.56", "nll_loss": "0.364", "wps": "8505.6", "ups": "0.58", "wpb": "14787.3", "bsz": "79.6", "num_updates": "90600", "lr": "2.63442e-06", "gnorm": "106.533", "loss_scale": "8", "train_wall": "347", "gb_free": "32.5", "wall": "161225"}
[2024-07-07 05:41:44,262][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 05:41:44,337][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 05:42:16,300][dev-other][INFO] - {"epoch": 70, "dev-other_loss": "23.454", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.249", "dev-other_uer": "3.67", "dev-other_wer": "9.431", "dev-other_raw_wer": "9.431", "dev-other_wps": "8721.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "90754", "dev-other_best_wer": "9.396"}
[2024-07-07 05:42:16,301][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 70 @ 90754 updates
[2024-07-07 05:42:16,302][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_last.pt
[2024-07-07 05:42:18,306][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_last.pt
[2024-07-07 05:42:18,317][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_last.pt (epoch 70 @ 90754 updates, score 9.431) (writing took 2.015989802777767 seconds)
[2024-07-07 05:42:18,318][fairseq_cli.train][INFO] - end of epoch 70 (average epoch stats below)
[2024-07-07 05:42:18,322][train][INFO] - {"epoch": 70, "train_loss": "66.348", "train_ntokens": "14821.9", "train_nsentences": "80.1651", "train_nll_loss": "0.359", "train_wps": "8292.1", "train_ups": "0.56", "train_wpb": "14821.9", "train_bsz": "80.2", "train_num_updates": "90754", "train_lr": "2.61022e-06", "train_gnorm": "105.714", "train_loss_scale": "8", "train_train_wall": "2278", "train_gb_free": "33", "train_wall": "161530"}
[2024-07-07 05:42:18,323][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 05:42:18,548][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-07 05:42:18,551][fairseq.trainer][INFO] - begin training epoch 71
[2024-07-07 05:42:18,551][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 05:43:34,718][train_inner][INFO] - {"epoch": 71, "update": 70.035, "loss": "66.184", "ntokens": "14832.3", "nsentences": "80.92", "nll_loss": "0.361", "wps": "7771.8", "ups": "0.52", "wpb": "14832.3", "bsz": "80.9", "num_updates": "90800", "lr": "2.60304e-06", "gnorm": "106.224", "loss_scale": "8", "train_wall": "347", "gb_free": "32.4", "wall": "161606"}
[2024-07-07 05:49:19,846][train_inner][INFO] - {"epoch": 71, "update": 70.19, "loss": "68.051", "ntokens": "14787.7", "nsentences": "79.44", "nll_loss": "0.366", "wps": "8569.9", "ups": "0.58", "wpb": "14787.7", "bsz": "79.4", "num_updates": "91000", "lr": "2.57203e-06", "gnorm": "108.229", "loss_scale": "8", "train_wall": "345", "gb_free": "32.5", "wall": "161952"}
[2024-07-07 05:55:11,557][train_inner][INFO] - {"epoch": 71, "update": 70.344, "loss": "65.033", "ntokens": "14939.2", "nsentences": "81.32", "nll_loss": "0.354", "wps": "8497.1", "ups": "0.57", "wpb": "14939.2", "bsz": "81.3", "num_updates": "91200", "lr": "2.5414e-06", "gnorm": "104.919", "loss_scale": "8", "train_wall": "351", "gb_free": "32.7", "wall": "162303"}
[2024-07-07 06:00:57,800][train_inner][INFO] - {"epoch": 71, "update": 70.498, "loss": "66.082", "ntokens": "14968.1", "nsentences": "82.51", "nll_loss": "0.364", "wps": "8648.2", "ups": "0.58", "wpb": "14968.1", "bsz": "82.5", "num_updates": "91400", "lr": "2.51113e-06", "gnorm": "106.743", "loss_scale": "8", "train_wall": "346", "gb_free": "31.7", "wall": "162649"}
[2024-07-07 06:06:42,626][train_inner][INFO] - {"epoch": 71, "update": 70.652, "loss": "69.197", "ntokens": "14733.5", "nsentences": "78.72", "nll_loss": "0.37", "wps": "8545.9", "ups": "0.58", "wpb": "14733.5", "bsz": "78.7", "num_updates": "91600", "lr": "2.48121e-06", "gnorm": "109.372", "loss_scale": "8", "train_wall": "344", "gb_free": "33.2", "wall": "162994"}
[2024-07-07 06:12:25,000][train_inner][INFO] - {"epoch": 71, "update": 70.806, "loss": "67.987", "ntokens": "14790.6", "nsentences": "81.04", "nll_loss": "0.373", "wps": "8642.2", "ups": "0.58", "wpb": "14790.6", "bsz": "81", "num_updates": "91800", "lr": "2.45166e-06", "gnorm": "106.826", "loss_scale": "8", "train_wall": "342", "gb_free": "32.1", "wall": "163337"}
[2024-07-07 06:18:14,805][train_inner][INFO] - {"epoch": 71, "update": 70.961, "loss": "68.45", "ntokens": "14701.1", "nsentences": "78.44", "nll_loss": "0.365", "wps": "8407", "ups": "0.57", "wpb": "14701.1", "bsz": "78.4", "num_updates": "92000", "lr": "2.42246e-06", "gnorm": "109.082", "loss_scale": "16", "train_wall": "349", "gb_free": "32.4", "wall": "163686"}
[2024-07-07 06:19:43,771][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 06:19:43,837][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 06:20:16,022][dev-other][INFO] - {"epoch": 71, "dev-other_loss": "23.304", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.248", "dev-other_uer": "3.667", "dev-other_wer": "9.49", "dev-other_raw_wer": "9.49", "dev-other_wps": "8667.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "92051", "dev-other_best_wer": "9.396"}
[2024-07-07 06:20:16,023][fairseq_cli.train][INFO] - end of epoch 71 (average epoch stats below)
[2024-07-07 06:20:16,034][train][INFO] - {"epoch": 71, "train_loss": "67.371", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.364", "train_wps": "8440.7", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "92051", "train_lr": "2.41507e-06", "train_gnorm": "107.559", "train_loss_scale": "16", "train_train_wall": "2241", "train_gb_free": "32.6", "train_wall": "163808"}
[2024-07-07 06:20:16,036][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 06:20:16,629][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-07 06:20:16,633][fairseq.trainer][INFO] - begin training epoch 72
[2024-07-07 06:20:16,633][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 06:24:38,878][train_inner][INFO] - {"epoch": 72, "update": 71.115, "loss": "67.321", "ntokens": "14816.7", "nsentences": "79.88", "nll_loss": "0.363", "wps": "7717.4", "ups": "0.52", "wpb": "14816.7", "bsz": "79.9", "num_updates": "92200", "lr": "2.3936e-06", "gnorm": "107.268", "loss_scale": "16", "train_wall": "350", "gb_free": "32.4", "wall": "164070"}
[2024-07-07 06:30:23,885][train_inner][INFO] - {"epoch": 72, "update": 71.269, "loss": "68.365", "ntokens": "14821", "nsentences": "80.16", "nll_loss": "0.37", "wps": "8593.5", "ups": "0.58", "wpb": "14821", "bsz": "80.2", "num_updates": "92400", "lr": "2.36509e-06", "gnorm": "108.343", "loss_scale": "16", "train_wall": "344", "gb_free": "32.8", "wall": "164415"}
[2024-07-07 06:30:37,266][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-07 06:36:22,736][train_inner][INFO] - {"epoch": 72, "update": 71.424, "loss": "65.454", "ntokens": "14841.5", "nsentences": "79.6", "nll_loss": "0.351", "wps": "8273.2", "ups": "0.56", "wpb": "14841.5", "bsz": "79.6", "num_updates": "92600", "lr": "2.33692e-06", "gnorm": "105.526", "loss_scale": "8", "train_wall": "358", "gb_free": "33", "wall": "164774"}
[2024-07-07 06:42:05,037][train_inner][INFO] - {"epoch": 72, "update": 71.578, "loss": "70.32", "ntokens": "14847.4", "nsentences": "80.39", "nll_loss": "0.381", "wps": "8677.9", "ups": "0.58", "wpb": "14847.4", "bsz": "80.4", "num_updates": "92800", "lr": "2.30908e-06", "gnorm": "109.395", "loss_scale": "8", "train_wall": "342", "gb_free": "32.4", "wall": "165117"}
[2024-07-07 06:47:48,852][train_inner][INFO] - {"epoch": 72, "update": 71.732, "loss": "71.553", "ntokens": "14800.2", "nsentences": "78.4", "nll_loss": "0.379", "wps": "8611.9", "ups": "0.58", "wpb": "14800.2", "bsz": "78.4", "num_updates": "93000", "lr": "2.28158e-06", "gnorm": "109.441", "loss_scale": "8", "train_wall": "343", "gb_free": "32.3", "wall": "165460"}
[2024-07-07 06:53:39,183][train_inner][INFO] - {"epoch": 72, "update": 71.887, "loss": "65.82", "ntokens": "14841.1", "nsentences": "81.2", "nll_loss": "0.36", "wps": "8473", "ups": "0.57", "wpb": "14841.1", "bsz": "81.2", "num_updates": "93200", "lr": "2.2544e-06", "gnorm": "105.577", "loss_scale": "8", "train_wall": "350", "gb_free": "32.1", "wall": "165811"}
[2024-07-07 06:57:56,177][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 06:57:56,245][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 06:58:28,259][dev-other][INFO] - {"epoch": 72, "dev-other_loss": "23.62", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.251", "dev-other_uer": "3.715", "dev-other_wer": "9.519", "dev-other_raw_wer": "9.519", "dev-other_wps": "8712.3", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "93347", "dev-other_best_wer": "9.396"}
[2024-07-07 06:58:28,259][fairseq_cli.train][INFO] - end of epoch 72 (average epoch stats below)
[2024-07-07 06:58:28,263][train][INFO] - {"epoch": 72, "train_loss": "67.753", "train_ntokens": "14822.8", "train_nsentences": "80.2022", "train_nll_loss": "0.367", "train_wps": "8380.7", "train_ups": "0.57", "train_wpb": "14822.8", "train_bsz": "80.2", "train_num_updates": "93347", "train_lr": "2.23463e-06", "train_gnorm": "107.274", "train_loss_scale": "8", "train_train_wall": "2255", "train_gb_free": "31.6", "train_wall": "166100"}
[2024-07-07 06:58:28,265][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 06:58:28,854][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-07 06:58:28,859][fairseq.trainer][INFO] - begin training epoch 73
[2024-07-07 06:58:28,859][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 07:00:00,902][train_inner][INFO] - {"epoch": 73, "update": 72.041, "loss": "65.153", "ntokens": "14790.4", "nsentences": "80.92", "nll_loss": "0.356", "wps": "7750.6", "ups": "0.52", "wpb": "14790.4", "bsz": "80.9", "num_updates": "93400", "lr": "2.22755e-06", "gnorm": "105.484", "loss_scale": "8", "train_wall": "348", "gb_free": "32.7", "wall": "166193"}
[2024-07-07 07:05:56,762][train_inner][INFO] - {"epoch": 73, "update": 72.195, "loss": "66.174", "ntokens": "14735.9", "nsentences": "79.23", "nll_loss": "0.356", "wps": "8283.6", "ups": "0.56", "wpb": "14735.9", "bsz": "79.2", "num_updates": "93600", "lr": "2.20102e-06", "gnorm": "106.907", "loss_scale": "8", "train_wall": "355", "gb_free": "33.3", "wall": "166548"}
[2024-07-07 07:11:44,966][train_inner][INFO] - {"epoch": 73, "update": 72.349, "loss": "64.01", "ntokens": "14938.5", "nsentences": "81.96", "nll_loss": "0.351", "wps": "8582.6", "ups": "0.57", "wpb": "14938.5", "bsz": "82", "num_updates": "93800", "lr": "2.1748e-06", "gnorm": "103.453", "loss_scale": "8", "train_wall": "348", "gb_free": "32.3", "wall": "166897"}
[2024-07-07 07:17:28,767][train_inner][INFO] - {"epoch": 73, "update": 72.503, "loss": "66.891", "ntokens": "14773.7", "nsentences": "80.12", "nll_loss": "0.363", "wps": "8595", "ups": "0.58", "wpb": "14773.7", "bsz": "80.1", "num_updates": "94000", "lr": "2.14889e-06", "gnorm": "106.787", "loss_scale": "8", "train_wall": "343", "gb_free": "31.6", "wall": "167240"}
[2024-07-07 07:23:19,797][train_inner][INFO] - {"epoch": 73, "update": 72.658, "loss": "66.885", "ntokens": "14862.6", "nsentences": "79.16", "nll_loss": "0.356", "wps": "8468.2", "ups": "0.57", "wpb": "14862.6", "bsz": "79.2", "num_updates": "94200", "lr": "2.1233e-06", "gnorm": "107.436", "loss_scale": "8", "train_wall": "350", "gb_free": "32", "wall": "167591"}
[2024-07-07 07:29:04,961][train_inner][INFO] - {"epoch": 73, "update": 72.812, "loss": "67.576", "ntokens": "14751.5", "nsentences": "80.36", "nll_loss": "0.368", "wps": "8549.3", "ups": "0.58", "wpb": "14751.5", "bsz": "80.4", "num_updates": "94400", "lr": "2.09801e-06", "gnorm": "107.335", "loss_scale": "8", "train_wall": "345", "gb_free": "31.2", "wall": "167937"}
[2024-07-07 07:34:53,948][train_inner][INFO] - {"epoch": 73, "update": 72.966, "loss": "65.658", "ntokens": "14881", "nsentences": "80.92", "nll_loss": "0.357", "wps": "8528.4", "ups": "0.57", "wpb": "14881.1", "bsz": "80.9", "num_updates": "94600", "lr": "2.07302e-06", "gnorm": "105.58", "loss_scale": "16", "train_wall": "348", "gb_free": "34", "wall": "168286"}
[2024-07-07 07:36:10,747][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 07:36:10,815][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 07:36:42,872][dev-other][INFO] - {"epoch": 73, "dev-other_loss": "23.929", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.254", "dev-other_uer": "3.684", "dev-other_wer": "9.427", "dev-other_raw_wer": "9.427", "dev-other_wps": "8703.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "94644", "dev-other_best_wer": "9.396"}
[2024-07-07 07:36:42,873][fairseq_cli.train][INFO] - end of epoch 73 (average epoch stats below)
[2024-07-07 07:36:42,877][train][INFO] - {"epoch": 73, "train_loss": "66.231", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.358", "train_wps": "8378.5", "train_ups": "0.57", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "94644", "train_lr": "2.06756e-06", "train_gnorm": "106.315", "train_loss_scale": "16", "train_train_wall": "2258", "train_gb_free": "31.8", "train_wall": "168395"}
[2024-07-07 07:36:42,879][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 07:36:43,472][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-07 07:36:43,476][fairseq.trainer][INFO] - begin training epoch 74
[2024-07-07 07:36:43,476][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 07:41:19,803][train_inner][INFO] - {"epoch": 74, "update": 73.12, "loss": "66.874", "ntokens": "14796.9", "nsentences": "78.68", "nll_loss": "0.356", "wps": "7671.1", "ups": "0.52", "wpb": "14796.9", "bsz": "78.7", "num_updates": "94800", "lr": "2.04832e-06", "gnorm": "106.419", "loss_scale": "16", "train_wall": "352", "gb_free": "33.2", "wall": "168671"}
[2024-07-07 07:41:51,091][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-07 07:47:08,890][train_inner][INFO] - {"epoch": 74, "update": 73.275, "loss": "64.321", "ntokens": "14958.9", "nsentences": "83", "nll_loss": "0.357", "wps": "8572.5", "ups": "0.57", "wpb": "14958.9", "bsz": "83", "num_updates": "95000", "lr": "2.02392e-06", "gnorm": "104.483", "loss_scale": "8", "train_wall": "348", "gb_free": "32.1", "wall": "169021"}
[2024-07-07 07:53:01,423][train_inner][INFO] - {"epoch": 74, "update": 73.429, "loss": "66.597", "ntokens": "14852.8", "nsentences": "79.48", "nll_loss": "0.356", "wps": "8428", "ups": "0.57", "wpb": "14852.8", "bsz": "79.5", "num_updates": "95200", "lr": "1.99982e-06", "gnorm": "106.402", "loss_scale": "8", "train_wall": "352", "gb_free": "32.2", "wall": "169373"}
[2024-07-07 07:58:41,268][train_inner][INFO] - {"epoch": 74, "update": 73.584, "loss": "67.229", "ntokens": "14728", "nsentences": "79.16", "nll_loss": "0.361", "wps": "8667.8", "ups": "0.59", "wpb": "14728", "bsz": "79.2", "num_updates": "95400", "lr": "1.976e-06", "gnorm": "108.587", "loss_scale": "8", "train_wall": "339", "gb_free": "31.9", "wall": "169713"}
[2024-07-07 08:04:39,761][train_inner][INFO] - {"epoch": 74, "update": 73.738, "loss": "64.6", "ntokens": "14897.8", "nsentences": "81.24", "nll_loss": "0.352", "wps": "8312.8", "ups": "0.56", "wpb": "14897.8", "bsz": "81.2", "num_updates": "95600", "lr": "1.95246e-06", "gnorm": "102.952", "loss_scale": "8", "train_wall": "358", "gb_free": "33.2", "wall": "170071"}
[2024-07-07 08:10:30,289][train_inner][INFO] - {"epoch": 74, "update": 73.892, "loss": "67.427", "ntokens": "14754.3", "nsentences": "78.48", "nll_loss": "0.359", "wps": "8420.1", "ups": "0.57", "wpb": "14754.3", "bsz": "78.5", "num_updates": "95800", "lr": "1.9292e-06", "gnorm": "107.855", "loss_scale": "8", "train_wall": "350", "gb_free": "31.8", "wall": "170422"}
[2024-07-07 08:14:27,348][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 08:14:27,414][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 08:14:59,408][dev-other][INFO] - {"epoch": 74, "dev-other_loss": "23.635", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.251", "dev-other_uer": "3.695", "dev-other_wer": "9.531", "dev-other_raw_wer": "9.531", "dev-other_wps": "8707.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "95940", "dev-other_best_wer": "9.396"}
[2024-07-07 08:14:59,409][fairseq_cli.train][INFO] - end of epoch 74 (average epoch stats below)
[2024-07-07 08:14:59,413][train][INFO] - {"epoch": 74, "train_loss": "66.156", "train_ntokens": "14823", "train_nsentences": "80.2099", "train_nll_loss": "0.358", "train_wps": "8365", "train_ups": "0.56", "train_wpb": "14823", "train_bsz": "80.2", "train_num_updates": "95940", "train_lr": "1.91309e-06", "train_gnorm": "106.153", "train_loss_scale": "8", "train_train_wall": "2260", "train_gb_free": "31.9", "train_wall": "170691"}
[2024-07-07 08:14:59,415][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 08:15:00,019][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-07 08:15:00,023][fairseq.trainer][INFO] - begin training epoch 75
[2024-07-07 08:15:00,023][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 08:16:47,340][train_inner][INFO] - {"epoch": 75, "update": 74.046, "loss": "67.369", "ntokens": "14731", "nsentences": "79.92", "nll_loss": "0.365", "wps": "7815.7", "ups": "0.53", "wpb": "14731", "bsz": "79.9", "num_updates": "96000", "lr": "1.90622e-06", "gnorm": "107.077", "loss_scale": "8", "train_wall": "344", "gb_free": "33.2", "wall": "170799"}
[2024-07-07 08:22:39,965][train_inner][INFO] - {"epoch": 75, "update": 74.2, "loss": "64.286", "ntokens": "14852.7", "nsentences": "82.88", "nll_loss": "0.359", "wps": "8425.9", "ups": "0.57", "wpb": "14852.7", "bsz": "82.9", "num_updates": "96200", "lr": "1.88352e-06", "gnorm": "102.45", "loss_scale": "8", "train_wall": "352", "gb_free": "33.1", "wall": "171152"}
[2024-07-07 08:28:30,561][train_inner][INFO] - {"epoch": 75, "update": 74.355, "loss": "67.785", "ntokens": "14704.5", "nsentences": "77.76", "nll_loss": "0.358", "wps": "8390.2", "ups": "0.57", "wpb": "14704.5", "bsz": "77.8", "num_updates": "96400", "lr": "1.86108e-06", "gnorm": "108.947", "loss_scale": "8", "train_wall": "350", "gb_free": "31.9", "wall": "171502"}
[2024-07-07 08:34:25,126][train_inner][INFO] - {"epoch": 75, "update": 74.509, "loss": "66.165", "ntokens": "14809.9", "nsentences": "81.39", "nll_loss": "0.364", "wps": "8356", "ups": "0.56", "wpb": "14809.9", "bsz": "81.4", "num_updates": "96600", "lr": "1.83891e-06", "gnorm": "104.963", "loss_scale": "8", "train_wall": "354", "gb_free": "31.3", "wall": "171857"}
[2024-07-07 08:40:21,351][train_inner][INFO] - {"epoch": 75, "update": 74.663, "loss": "65.354", "ntokens": "14920.6", "nsentences": "81.08", "nll_loss": "0.355", "wps": "8377.3", "ups": "0.56", "wpb": "14920.6", "bsz": "81.1", "num_updates": "96800", "lr": "1.81701e-06", "gnorm": "103.578", "loss_scale": "8", "train_wall": "356", "gb_free": "31.9", "wall": "172213"}
[2024-07-07 08:46:18,107][train_inner][INFO] - {"epoch": 75, "update": 74.817, "loss": "65.391", "ntokens": "14873.7", "nsentences": "80.6", "nll_loss": "0.354", "wps": "8339.9", "ups": "0.56", "wpb": "14873.7", "bsz": "80.6", "num_updates": "97000", "lr": "1.79537e-06", "gnorm": "104.512", "loss_scale": "16", "train_wall": "356", "gb_free": "31.3", "wall": "172570"}
[2024-07-07 08:52:04,805][train_inner][INFO] - {"epoch": 75, "update": 74.971, "loss": "69.982", "ntokens": "14793.6", "nsentences": "78.44", "nll_loss": "0.371", "wps": "8534.3", "ups": "0.58", "wpb": "14793.6", "bsz": "78.4", "num_updates": "97200", "lr": "1.77398e-06", "gnorm": "107.869", "loss_scale": "16", "train_wall": "346", "gb_free": "32.5", "wall": "172916"}
[2024-07-07 08:53:11,572][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 08:53:11,580][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 08:53:43,700][dev-other][INFO] - {"epoch": 75, "dev-other_loss": "23.601", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.251", "dev-other_uer": "3.708", "dev-other_wer": "9.504", "dev-other_raw_wer": "9.504", "dev-other_wps": "8710.3", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "97237", "dev-other_best_wer": "9.396"}
[2024-07-07 08:53:43,702][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 75 @ 97237 updates
[2024-07-07 08:53:43,703][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_last.pt
[2024-07-07 08:53:45,571][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_last.pt
[2024-07-07 08:53:45,603][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_last.pt (epoch 75 @ 97237 updates, score 9.504) (writing took 1.9010716155171394 seconds)
[2024-07-07 08:53:45,604][fairseq_cli.train][INFO] - end of epoch 75 (average epoch stats below)
[2024-07-07 08:53:45,608][train][INFO] - {"epoch": 75, "train_loss": "66.521", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "0.36", "train_wps": "8264.7", "train_ups": "0.56", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "97237", "train_lr": "1.77005e-06", "train_gnorm": "105.374", "train_loss_scale": "16", "train_train_wall": "2288", "train_gb_free": "31.2", "train_wall": "173017"}
[2024-07-07 08:53:45,610][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 08:53:45,887][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-07 08:53:45,890][fairseq.trainer][INFO] - begin training epoch 76
[2024-07-07 08:53:45,890][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 08:58:27,067][train_inner][INFO] - {"epoch": 76, "update": 75.126, "loss": "64.802", "ntokens": "14777", "nsentences": "81.08", "nll_loss": "0.356", "wps": "7732.7", "ups": "0.52", "wpb": "14777", "bsz": "81.1", "num_updates": "97400", "lr": "1.75285e-06", "gnorm": "105.012", "loss_scale": "16", "train_wall": "347", "gb_free": "32.5", "wall": "173299"}
[2024-07-07 09:04:17,254][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-07 09:04:22,344][train_inner][INFO] - {"epoch": 76, "update": 75.281, "loss": "69.377", "ntokens": "14709.1", "nsentences": "77.92", "nll_loss": "0.368", "wps": "8282.1", "ups": "0.56", "wpb": "14709.1", "bsz": "77.9", "num_updates": "97600", "lr": "1.73197e-06", "gnorm": "110.397", "loss_scale": "8", "train_wall": "355", "gb_free": "32", "wall": "173654"}
[2024-07-07 09:10:14,706][train_inner][INFO] - {"epoch": 76, "update": 75.435, "loss": "67.835", "ntokens": "14879", "nsentences": "80.04", "nll_loss": "0.365", "wps": "8446.9", "ups": "0.57", "wpb": "14879", "bsz": "80", "num_updates": "97800", "lr": "1.71134e-06", "gnorm": "107.14", "loss_scale": "8", "train_wall": "352", "gb_free": "32.4", "wall": "174006"}
[2024-07-07 09:15:59,355][train_inner][INFO] - {"epoch": 76, "update": 75.589, "loss": "66.109", "ntokens": "14827.2", "nsentences": "81.16", "nll_loss": "0.362", "wps": "8604.5", "ups": "0.58", "wpb": "14827.2", "bsz": "81.2", "num_updates": "98000", "lr": "1.69096e-06", "gnorm": "106.275", "loss_scale": "8", "train_wall": "344", "gb_free": "32", "wall": "174351"}
[2024-07-07 09:21:45,875][train_inner][INFO] - {"epoch": 76, "update": 75.743, "loss": "65.997", "ntokens": "14861.1", "nsentences": "80.4", "nll_loss": "0.357", "wps": "8579.2", "ups": "0.58", "wpb": "14861.1", "bsz": "80.4", "num_updates": "98200", "lr": "1.67081e-06", "gnorm": "106.738", "loss_scale": "8", "train_wall": "346", "gb_free": "33.6", "wall": "174697"}
[2024-07-07 09:27:34,032][train_inner][INFO] - {"epoch": 76, "update": 75.897, "loss": "68.492", "ntokens": "14912.6", "nsentences": "80.32", "nll_loss": "0.369", "wps": "8568.8", "ups": "0.57", "wpb": "14912.6", "bsz": "80.3", "num_updates": "98400", "lr": "1.65091e-06", "gnorm": "106.456", "loss_scale": "8", "train_wall": "348", "gb_free": "32.5", "wall": "175046"}
[2024-07-07 09:31:18,709][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 09:31:18,718][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 09:31:50,853][dev-other][INFO] - {"epoch": 76, "dev-other_loss": "23.311", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.248", "dev-other_uer": "3.673", "dev-other_wer": "9.358", "dev-other_raw_wer": "9.358", "dev-other_wps": "8699.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "98533", "dev-other_best_wer": "9.358"}
[2024-07-07 09:31:50,854][fairseq_cli.train][INFO] - end of epoch 76 (average epoch stats below)
[2024-07-07 09:31:50,860][train][INFO] - {"epoch": 76, "train_loss": "67.325", "train_ntokens": "14822.1", "train_nsentences": "80.1852", "train_nll_loss": "0.364", "train_wps": "8405.9", "train_ups": "0.57", "train_wpb": "14822.1", "train_bsz": "80.2", "train_num_updates": "98533", "train_lr": "1.63781e-06", "train_gnorm": "107.318", "train_loss_scale": "8", "train_train_wall": "2249", "train_gb_free": "31.6", "train_wall": "175303"}
[2024-07-07 09:31:50,862][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 09:31:51,445][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-07 09:31:51,448][fairseq.trainer][INFO] - begin training epoch 77
[2024-07-07 09:31:51,448][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 09:33:48,324][train_inner][INFO] - {"epoch": 77, "update": 76.052, "loss": "66.746", "ntokens": "14836.4", "nsentences": "80.36", "nll_loss": "0.362", "wps": "7929.6", "ups": "0.53", "wpb": "14836.4", "bsz": "80.4", "num_updates": "98600", "lr": "1.63125e-06", "gnorm": "108.379", "loss_scale": "8", "train_wall": "341", "gb_free": "32.7", "wall": "175420"}
[2024-07-07 09:39:34,579][train_inner][INFO] - {"epoch": 77, "update": 76.206, "loss": "68.908", "ntokens": "14723", "nsentences": "78.56", "nll_loss": "0.368", "wps": "8506.2", "ups": "0.58", "wpb": "14723.1", "bsz": "78.6", "num_updates": "98800", "lr": "1.61182e-06", "gnorm": "108.711", "loss_scale": "8", "train_wall": "346", "gb_free": "32.2", "wall": "175766"}
[2024-07-07 09:45:16,401][train_inner][INFO] - {"epoch": 77, "update": 76.36, "loss": "69.119", "ntokens": "14863.3", "nsentences": "81.92", "nll_loss": "0.381", "wps": "8696.8", "ups": "0.59", "wpb": "14863.3", "bsz": "81.9", "num_updates": "99000", "lr": "1.59262e-06", "gnorm": "106.202", "loss_scale": "8", "train_wall": "341", "gb_free": "33.2", "wall": "176108"}
[2024-07-07 09:51:01,159][train_inner][INFO] - {"epoch": 77, "update": 76.514, "loss": "66.981", "ntokens": "14839.1", "nsentences": "80.04", "nll_loss": "0.361", "wps": "8608.6", "ups": "0.58", "wpb": "14839.1", "bsz": "80", "num_updates": "99200", "lr": "1.57365e-06", "gnorm": "107.383", "loss_scale": "8", "train_wall": "344", "gb_free": "32.6", "wall": "176453"}
[2024-07-07 09:56:44,169][train_inner][INFO] - {"epoch": 77, "update": 76.668, "loss": "66.786", "ntokens": "14829.2", "nsentences": "80.44", "nll_loss": "0.362", "wps": "8648.4", "ups": "0.58", "wpb": "14829.2", "bsz": "80.4", "num_updates": "99400", "lr": "1.5549e-06", "gnorm": "107.916", "loss_scale": "8", "train_wall": "342", "gb_free": "30.4", "wall": "176796"}
[2024-07-07 10:02:27,548][train_inner][INFO] - {"epoch": 77, "update": 76.823, "loss": "67.036", "ntokens": "14844.3", "nsentences": "80.92", "nll_loss": "0.365", "wps": "8646.4", "ups": "0.58", "wpb": "14844.3", "bsz": "80.9", "num_updates": "99600", "lr": "1.53638e-06", "gnorm": "104.963", "loss_scale": "8", "train_wall": "343", "gb_free": "32.7", "wall": "177139"}
[2024-07-07 10:07:01,216][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-07 10:08:18,761][train_inner][INFO] - {"epoch": 77, "update": 76.978, "loss": "68.174", "ntokens": "14780.9", "nsentences": "78.96", "nll_loss": "0.364", "wps": "8418.8", "ups": "0.57", "wpb": "14780.9", "bsz": "79", "num_updates": "99800", "lr": "1.51808e-06", "gnorm": "108.348", "loss_scale": "8", "train_wall": "351", "gb_free": "29.2", "wall": "177490"}
[2024-07-07 10:09:06,911][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 10:09:06,912][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 10:09:39,078][dev-other][INFO] - {"epoch": 77, "dev-other_loss": "23.457", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.249", "dev-other_uer": "3.658", "dev-other_wer": "9.435", "dev-other_raw_wer": "9.435", "dev-other_wps": "8700.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "99829", "dev-other_best_wer": "9.396"}
[2024-07-07 10:09:39,079][fairseq_cli.train][INFO] - end of epoch 77 (average epoch stats below)
[2024-07-07 10:09:39,085][train][INFO] - {"epoch": 77, "train_loss": "67.61", "train_ntokens": "14822.4", "train_nsentences": "80.1914", "train_nll_loss": "0.366", "train_wps": "8469.1", "train_ups": "0.57", "train_wpb": "14822.4", "train_bsz": "80.2", "train_num_updates": "99829", "train_lr": "1.51545e-06", "train_gnorm": "107.242", "train_loss_scale": "8", "train_train_wall": "2231", "train_gb_free": "32.5", "train_wall": "177571"}
[2024-07-07 10:09:39,087][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 10:09:39,671][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-07 10:09:39,675][fairseq.trainer][INFO] - begin training epoch 78
[2024-07-07 10:09:39,675][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 10:14:41,443][train_inner][INFO] - {"epoch": 78, "update": 77.132, "loss": "63.689", "ntokens": "14931.6", "nsentences": "82.2", "nll_loss": "0.351", "wps": "7805.5", "ups": "0.52", "wpb": "14931.6", "bsz": "82.2", "num_updates": "100000", "lr": "1.5e-06", "gnorm": "104.878", "loss_scale": "8", "train_wall": "349", "gb_free": "31.9", "wall": "177873"}
[2024-07-07 10:14:41,448][fairseq_cli.train][INFO] - Stopping training due to num_updates: 100000 >= max_update: 100000
[2024-07-07 10:14:41,449][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 10:14:41,449][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 10:15:13,518][dev-other][INFO] - {"epoch": 78, "dev-other_loss": "23.391", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.249", "dev-other_uer": "3.676", "dev-other_wer": "9.421", "dev-other_raw_wer": "9.421", "dev-other_wps": "8712.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "100000", "dev-other_best_wer": "9.396"}
[2024-07-07 10:15:13,519][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 78 @ 100000 updates
[2024-07-07 10:15:13,520][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_last.pt
[2024-07-07 10:15:14,521][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_last.pt
[2024-07-07 10:15:14,531][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_360h_asr_finetune_10ksteps/checkpoint_last.pt (epoch 78 @ 100000 updates, score 9.421) (writing took 1.0120758190751076 seconds)
[2024-07-07 10:15:14,543][fairseq_cli.train][INFO] - end of epoch 78 (average epoch stats below)
[2024-07-07 10:15:14,548][train][INFO] - {"epoch": 78, "train_loss": "62.789", "train_ntokens": "14917.6", "train_nsentences": "82.0585", "train_nll_loss": "0.345", "train_wps": "7604.3", "train_ups": "0.51", "train_wpb": "14917.6", "train_bsz": "82.1", "train_num_updates": "100000", "train_lr": "1.5e-06", "train_gnorm": "104.718", "train_loss_scale": "8", "train_train_wall": "301", "train_gb_free": "31.9", "train_wall": "177906"}
[2024-07-07 10:15:14,548][fairseq_cli.train][INFO] - done training in 177880.4 seconds
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
fine tune base t-hubert model  using train-other-500 supervision data
[2024-07-07 10:15:26,539][fairseq.distributed.utils][INFO] - Rank 0, device_id: 0
2024-07-07 10:15:30 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:28610
2024-07-07 10:15:30 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:28610
2024-07-07 10:15:30 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2024-07-07 10:15:30 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:28610
2024-07-07 10:15:30 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:28610
2024-07-07 10:15:30 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2024-07-07 10:15:30 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2024-07-07 10:15:30 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2024-07-07 10:15:30 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-07-07 10:15:30 | INFO | fairseq.distributed.utils | initialized host pgpu13 as rank 0
2024-07-07 10:15:30 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-07-07 10:15:30 | INFO | fairseq.distributed.utils | initialized host pgpu13 as rank 1
2024-07-07 10:15:30 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-07-07 10:15:30 | INFO | fairseq.distributed.utils | initialized host pgpu13 as rank 3
2024-07-07 10:15:30 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-07-07 10:15:30 | INFO | fairseq.distributed.utils | initialized host pgpu13 as rank 2
[2024-07-07 10:15:32,945][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/mntcephfs/lab_data/maduo/exp//finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/t-hubert', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:28610', 'distributed_port': 28610, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3200000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train-other-500', 'valid_subset': 'dev-other', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3200000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 120000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [2], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/mntcephfs/lab_data/maduo/exp//finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'wer', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'hubert_ctc', 'w2v_path': '/mntcephfs/lab_data/maduo/exp//pretrain/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update/checkpoint_298_400000.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.1, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_embed_dim': 768, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 0, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'normalize': False, 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'w2v_args': None, 'autoregressive': False}, 'task': {'_name': 'hubert_pretraining', 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'fine_tuning': True, 'labels': ['ltr'], 'label_dir': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'label_rate': -1.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': None, 'min_sample_size': None, 'single_target': True, 'random_crop': True, 'pad_audio': False}, 'criterion': {'_name': 'ctc', 'zero_infinity': True, 'sentence_avg': True, 'post_process': 'letter', 'wer_kenlm_model': None, 'wer_lexicon': None, 'wer_lm_weight': 2.0, 'wer_word_score': -1.0, 'wer_sil_weight': 0.0, 'wer_args': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05], 'amsgrad': False}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 12000, 'hold_steps': 48000, 'decay_steps': 60000, 'phase_ratio': None, 'init_lr_scale': 0.01, 'final_lr_scale': 0.05, 'max_update': 120000.0, 'lr': [3e-05]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': '/mntcephfs/lab_data/maduo/exp//pretrain/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update/finetune.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-07-07 10:15:32,948][fairseq.tasks.hubert_pretraining][INFO] - current directory is /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/t-hubert
[2024-07-07 10:15:32,948][fairseq.tasks.hubert_pretraining][INFO] - HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'fine_tuning': True, 'labels': ['ltr'], 'label_dir': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'label_rate': -1.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': None, 'min_sample_size': None, 'single_target': True, 'random_crop': True, 'pad_audio': False}
[2024-07-07 10:15:32,952][fairseq.models.hubert.hubert_asr][INFO] - cfg: {'_name': 'hubert_ctc', 'w2v_path': '/mntcephfs/lab_data/maduo/exp//pretrain/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update/checkpoint_298_400000.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.1, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_embed_dim': 768, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 0, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'normalize': False, 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'w2v_args': None, 'autoregressive': False}, task: <fairseq.tasks.hubert_pretraining.HubertPretrainingTask object at 0x1554074f3c70>
[2024-07-07 10:15:32,952][fairseq.models.hubert.hubert_asr][INFO] - mdddd:::/mntcephfs/lab_data/maduo/exp//pretrain/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update/checkpoint_298_400000.pt
[2024-07-07 10:15:36,645][fairseq.tasks.hubert_pretraining][INFO] - current directory is /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/t-hubert
[2024-07-07 10:15:36,645][fairseq.tasks.hubert_pretraining][INFO] - HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'fine_tuning': False, 'labels': ['phncode', 'km'], 'label_dir': '/mntcephfs/lab_data/maduo/datasets/format/librispeech//offical_hubert_codes_and_librispeech_frame_monophncode_using_wav2vec-u2_model', 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
[2024-07-07 10:15:36,654][fairseq.models.hubert.hubert2][INFO] - HubertModel2 Config: {'_name': 'ils_hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'attention_type': 'rel_attention', 'weighted_sum': False, 'predict_layers': '[7,12]', 'separate_label_embeds': True, 'separate_layer_targets': False, 'km4_bpekm7_km12': False, 'bpekm7_km12': False, 'phnkm6_km12': False, 'phnkm7_km12': True, 'km4_phnkm6_km12': False, 'km4_phnkm7_km12': False}
[2024-07-07 10:15:36,862][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-07 10:15:36,916][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-07 10:15:37,093][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-07 10:15:37,144][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-07 10:15:37,192][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-07 10:15:37,241][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-07 10:15:37,291][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-07 10:15:37,341][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-07 10:15:37,389][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-07 10:15:37,439][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-07 10:15:37,487][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-07 10:15:37,537][fairseq.models.unispeech_sat.unispeech_sat][INFO] - using rel_attention now!
[2024-07-07 10:15:38,028][fairseq.models.hubert.ils_hubert][INFO] - HubertModel Config: {'_name': 'ils_hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'attention_type': 'rel_attention', 'weighted_sum': False, 'predict_layers': '[7,12]', 'separate_label_embeds': True, 'separate_layer_targets': False, 'km4_bpekm7_km12': False, 'bpekm7_km12': False, 'phnkm6_km12': False, 'phnkm7_km12': True, 'km4_phnkm6_km12': False, 'km4_phnkm7_km12': False}
[2024-07-07 10:15:41,677][fairseq_cli.train][INFO] - HubertCtc(
  (w2v_encoder): HubertEncoder(
    (w2v_model): ILSHubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention2(
              (dropout_module): FairseqDropout()
              (relative_attention_bias): Embedding(320, 12)
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1-11): 11 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention2(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (proj): Linear(in_features=768, out_features=32, bias=True)
  )
)
[2024-07-07 10:15:41,679][fairseq_cli.train][INFO] - task: HubertPretrainingTask
[2024-07-07 10:15:41,686][fairseq_cli.train][INFO] - model: HubertCtc
[2024-07-07 10:15:41,686][fairseq_cli.train][INFO] - criterion: CtcCriterion
[2024-07-07 10:15:41,687][fairseq_cli.train][INFO] - num. shared model params: 94,400,160 (num. trained: 94,400,160)
[2024-07-07 10:15:41,688][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-07-07 10:15:41,692][fairseq.data.audio.hubert_dataset][INFO] - max_keep=None, min_keep=None, loaded 2864, skipped 0 short and 0 long, longest-loaded=562480, shortest-loaded=17040
[2024-07-07 10:15:41,693][fairseq.data.audio.hubert_dataset][INFO] - /mntcephfs/lab_data/maduo/datasets/format/librispeech//dev-other.ltr is sequence label. skipped
[2024-07-07 10:15:41,694][fairseq.data.audio.hubert_dataset][INFO] - pad_audio=False, random_crop=True, normalize=False, max_sample_size=9223372036854775807
[2024-07-07 10:15:45,306][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:2 to store for rank: 0
[2024-07-07 10:15:45,337][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
[2024-07-07 10:15:45,338][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
[2024-07-07 10:15:45,338][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
[2024-07-07 10:15:45,338][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
[2024-07-07 10:15:45,338][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
[2024-07-07 10:15:45,338][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
[2024-07-07 10:15:45,338][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
[2024-07-07 10:15:45,338][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.label_embs_concat <- w2v_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
[2024-07-07 10:15:46,208][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2024-07-07 10:15:46,209][fairseq.utils][INFO] - rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
[2024-07-07 10:15:46,209][fairseq.utils][INFO] - rank   1: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
[2024-07-07 10:15:46,209][fairseq.utils][INFO] - rank   2: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
[2024-07-07 10:15:46,209][fairseq.utils][INFO] - rank   3: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
[2024-07-07 10:15:46,209][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2024-07-07 10:15:46,209][fairseq_cli.train][INFO] - training on 4 devices (GPUs/TPUs)
[2024-07-07 10:15:46,209][fairseq_cli.train][INFO] - max tokens per device = 3200000 and max sentences per device = None
[2024-07-07 10:15:46,210][fairseq.trainer][INFO] - Preparing to load checkpoint /mntcephfs/lab_data/maduo/exp//finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_last.pt
[2024-07-07 10:15:46,210][fairseq.trainer][INFO] - No existing checkpoint found /mntcephfs/lab_data/maduo/exp//finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_last.pt
[2024-07-07 10:15:46,210][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-07-07 10:15:46,310][fairseq.data.audio.hubert_dataset][INFO] - max_keep=None, min_keep=None, loaded 148688, skipped 0 short and 0 long, longest-loaded=446720, shortest-loaded=13280
[2024-07-07 10:15:46,463][fairseq.data.audio.hubert_dataset][INFO] - /mntcephfs/lab_data/maduo/datasets/format/librispeech//train-other-500.ltr is sequence label. skipped
[2024-07-07 10:15:46,463][fairseq.data.audio.hubert_dataset][INFO] - pad_audio=False, random_crop=True, normalize=False, max_sample_size=9223372036854775807
[2024-07-07 10:15:46,515][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 10:15:46,516][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2024-07-07 10:15:46,516][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = False
[2024-07-07 10:15:46,516][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2024-07-07 10:15:47,552][fairseq_cli.train][INFO] - begin dry-run validation on "dev-other" subset
[2024-07-07 10:15:47,553][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 10:15:47,553][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2024-07-07 10:15:47,553][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = False
[2024-07-07 10:15:47,553][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2024-07-07 10:16:11,727][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-07 10:16:11,730][fairseq.trainer][INFO] - begin training epoch 1
[2024-07-07 10:16:11,730][fairseq_cli.train][INFO] - Start iterating over samples
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
[2024-07-07 10:16:44,395][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2024-07-07 10:16:46,300][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2024-07-07 10:16:47,500][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-07 10:16:54,658][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-07 10:20:46,163][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-07-07 10:22:49,443][train_inner][INFO] - {"epoch": 1, "update": 0.117, "loss": "2133.14", "ntokens": "14514.2", "nsentences": "82.44", "nll_loss": "12.116", "wps": "8025.4", "ups": "0.55", "wpb": "14514.2", "bsz": "82.4", "num_updates": "200", "lr": "7.95e-07", "gnorm": "1348.75", "loss_scale": "4", "train_wall": "373", "gb_free": "32.8", "wall": "423"}
[2024-07-07 10:24:51,265][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-07-07 10:28:41,271][train_inner][INFO] - {"epoch": 1, "update": 0.232, "loss": "1311.18", "ntokens": "14567", "nsentences": "85.2", "nll_loss": "7.669", "wps": "8282.5", "ups": "0.57", "wpb": "14567", "bsz": "85.2", "num_updates": "400", "lr": "1.29e-06", "gnorm": "2074.6", "loss_scale": "2", "train_wall": "351", "gb_free": "32.5", "wall": "775"}
[2024-07-07 10:34:36,319][train_inner][INFO] - {"epoch": 1, "update": 0.346, "loss": "832.035", "ntokens": "14587.4", "nsentences": "83.96", "nll_loss": "4.789", "wps": "8219.5", "ups": "0.56", "wpb": "14587.4", "bsz": "84", "num_updates": "600", "lr": "1.785e-06", "gnorm": "756.823", "loss_scale": "2", "train_wall": "354", "gb_free": "31.3", "wall": "1130"}
[2024-07-07 10:40:26,771][train_inner][INFO] - {"epoch": 1, "update": 0.46, "loss": "728.038", "ntokens": "14451.4", "nsentences": "85.16", "nll_loss": "4.29", "wps": "8247.7", "ups": "0.57", "wpb": "14451.4", "bsz": "85.2", "num_updates": "800", "lr": "2.28e-06", "gnorm": "323.464", "loss_scale": "2", "train_wall": "350", "gb_free": "31.9", "wall": "1481"}
[2024-07-07 10:46:14,193][train_inner][INFO] - {"epoch": 1, "update": 0.574, "loss": "724.066", "ntokens": "14630.2", "nsentences": "84.995", "nll_loss": "4.207", "wps": "8424", "ups": "0.58", "wpb": "14630.2", "bsz": "85", "num_updates": "1000", "lr": "2.775e-06", "gnorm": "219.451", "loss_scale": "2", "train_wall": "347", "gb_free": "31.3", "wall": "1828"}
[2024-07-07 10:52:11,197][train_inner][INFO] - {"epoch": 1, "update": 0.688, "loss": "710.869", "ntokens": "14641.4", "nsentences": "86.04", "nll_loss": "4.177", "wps": "8204.4", "ups": "0.56", "wpb": "14641.4", "bsz": "86", "num_updates": "1200", "lr": "3.27e-06", "gnorm": "172.953", "loss_scale": "2", "train_wall": "356", "gb_free": "30.1", "wall": "2185"}
[2024-07-07 10:57:53,282][train_inner][INFO] - {"epoch": 1, "update": 0.803, "loss": "702.641", "ntokens": "14638.5", "nsentences": "86.24", "nll_loss": "4.139", "wps": "8558.8", "ups": "0.58", "wpb": "14638.5", "bsz": "86.2", "num_updates": "1400", "lr": "3.765e-06", "gnorm": "150.991", "loss_scale": "2", "train_wall": "342", "gb_free": "31.2", "wall": "2527"}
[2024-07-07 11:03:45,398][train_inner][INFO] - {"epoch": 1, "update": 0.917, "loss": "709.537", "ntokens": "14559.6", "nsentences": "85.08", "nll_loss": "4.146", "wps": "8270.1", "ups": "0.57", "wpb": "14559.6", "bsz": "85.1", "num_updates": "1600", "lr": "4.26e-06", "gnorm": "171.092", "loss_scale": "2", "train_wall": "352", "gb_free": "31.4", "wall": "2879"}
[2024-07-07 11:07:59,043][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 11:07:59,050][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 11:08:31,328][dev-other][INFO] - {"epoch": 1, "dev-other_loss": "394.016", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "4.188", "dev-other_uer": "100", "dev-other_wer": "100", "dev-other_raw_wer": "100", "dev-other_wps": "8647.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "1746"}
[2024-07-07 11:08:31,329][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2024-07-07 11:08:31,332][train][INFO] - {"epoch": 1, "train_loss": "954.286", "train_ntokens": "14576.8", "train_nsentences": "84.87", "train_nll_loss": "5.556", "train_wps": "8200.6", "train_ups": "0.56", "train_wpb": "14576.8", "train_bsz": "84.9", "train_num_updates": "1746", "train_lr": "4.62135e-06", "train_gnorm": "610.62", "train_loss_scale": "2", "train_train_wall": "3078", "train_gb_free": "32.6", "train_wall": "3165"}
[2024-07-07 11:08:31,333][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 11:08:32,065][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-07 11:08:32,069][fairseq.trainer][INFO] - begin training epoch 2
[2024-07-07 11:08:32,069][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 11:10:09,689][train_inner][INFO] - {"epoch": 2, "update": 1.031, "loss": "714.409", "ntokens": "14603.5", "nsentences": "84.36", "nll_loss": "4.127", "wps": "7601.8", "ups": "0.52", "wpb": "14603.5", "bsz": "84.4", "num_updates": "1800", "lr": "4.755e-06", "gnorm": "169.048", "loss_scale": "2", "train_wall": "351", "gb_free": "31.9", "wall": "3263"}
[2024-07-07 11:15:59,030][train_inner][INFO] - {"epoch": 2, "update": 1.145, "loss": "701.466", "ntokens": "14613.4", "nsentences": "85.96", "nll_loss": "4.126", "wps": "8368.1", "ups": "0.57", "wpb": "14613.4", "bsz": "86", "num_updates": "2000", "lr": "5.25e-06", "gnorm": "136.74", "loss_scale": "2", "train_wall": "349", "gb_free": "33", "wall": "3613"}
[2024-07-07 11:21:50,646][train_inner][INFO] - {"epoch": 2, "update": 1.259, "loss": "715.2", "ntokens": "14514.7", "nsentences": "83.36", "nll_loss": "4.107", "wps": "8257.8", "ups": "0.57", "wpb": "14514.7", "bsz": "83.4", "num_updates": "2200", "lr": "5.745e-06", "gnorm": "167.656", "loss_scale": "2", "train_wall": "351", "gb_free": "31.8", "wall": "3964"}
[2024-07-07 11:27:45,965][train_inner][INFO] - {"epoch": 2, "update": 1.373, "loss": "694.885", "ntokens": "14604.7", "nsentences": "85.76", "nll_loss": "4.08", "wps": "8222.7", "ups": "0.56", "wpb": "14604.7", "bsz": "85.8", "num_updates": "2400", "lr": "6.24e-06", "gnorm": "158.928", "loss_scale": "4", "train_wall": "355", "gb_free": "32.3", "wall": "4320"}
[2024-07-07 11:33:31,363][train_inner][INFO] - {"epoch": 2, "update": 1.487, "loss": "657.909", "ntokens": "14632.7", "nsentences": "85.68", "nll_loss": "3.852", "wps": "8474.9", "ups": "0.58", "wpb": "14632.7", "bsz": "85.7", "num_updates": "2600", "lr": "6.735e-06", "gnorm": "211.845", "loss_scale": "4", "train_wall": "345", "gb_free": "30.5", "wall": "4665"}
[2024-07-07 11:39:24,040][train_inner][INFO] - {"epoch": 2, "update": 1.602, "loss": "599.812", "ntokens": "14464", "nsentences": "82.12", "nll_loss": "3.405", "wps": "8204.3", "ups": "0.57", "wpb": "14464", "bsz": "82.1", "num_updates": "2800", "lr": "7.23e-06", "gnorm": "207.133", "loss_scale": "4", "train_wall": "352", "gb_free": "30.8", "wall": "5018"}
[2024-07-07 11:45:07,458][train_inner][INFO] - {"epoch": 2, "update": 1.716, "loss": "488.892", "ntokens": "14597.6", "nsentences": "86.12", "nll_loss": "2.884", "wps": "8502.2", "ups": "0.58", "wpb": "14597.6", "bsz": "86.1", "num_updates": "3000", "lr": "7.725e-06", "gnorm": "193.363", "loss_scale": "4", "train_wall": "343", "gb_free": "31.6", "wall": "5361"}
[2024-07-07 11:50:48,795][train_inner][INFO] - {"epoch": 2, "update": 1.83, "loss": "416.765", "ntokens": "14655.6", "nsentences": "85.36", "nll_loss": "2.427", "wps": "8590.4", "ups": "0.59", "wpb": "14655.6", "bsz": "85.4", "num_updates": "3200", "lr": "8.22e-06", "gnorm": "188.686", "loss_scale": "4", "train_wall": "341", "gb_free": "30.8", "wall": "5703"}
[2024-07-07 11:56:36,482][train_inner][INFO] - {"epoch": 2, "update": 1.944, "loss": "359.663", "ntokens": "14617.5", "nsentences": "86.155", "nll_loss": "2.12", "wps": "8408.7", "ups": "0.58", "wpb": "14617.5", "bsz": "86.2", "num_updates": "3400", "lr": "8.715e-06", "gnorm": "185.787", "loss_scale": "4", "train_wall": "347", "gb_free": "32.6", "wall": "6050"}
[2024-07-07 11:59:24,964][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 11:59:24,966][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 11:59:56,953][dev-other][INFO] - {"epoch": 2, "dev-other_loss": "95.025", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "1.01", "dev-other_uer": "19.962", "dev-other_wer": "57.573", "dev-other_raw_wer": "57.573", "dev-other_wps": "8756.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "3498"}
[2024-07-07 11:59:56,954][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2024-07-07 11:59:56,958][train][INFO] - {"epoch": 2, "train_loss": "569.363", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "3.315", "train_wps": "8277", "train_ups": "0.57", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "3498", "train_lr": "8.95755e-06", "train_gnorm": "181.14", "train_loss_scale": "4", "train_train_wall": "3047", "train_gb_free": "32.6", "train_wall": "6251"}
[2024-07-07 11:59:56,959][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 11:59:57,636][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-07 11:59:57,639][fairseq.trainer][INFO] - begin training epoch 3
[2024-07-07 11:59:57,639][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 12:02:57,771][train_inner][INFO] - {"epoch": 3, "update": 2.058, "loss": "316.636", "ntokens": "14446.3", "nsentences": "83.12", "nll_loss": "1.822", "wps": "7577.8", "ups": "0.52", "wpb": "14446.3", "bsz": "83.1", "num_updates": "3600", "lr": "9.21e-06", "gnorm": "164.484", "loss_scale": "4", "train_wall": "348", "gb_free": "32.3", "wall": "6432"}
[2024-07-07 12:08:49,219][train_inner][INFO] - {"epoch": 3, "update": 2.172, "loss": "289.175", "ntokens": "14487.2", "nsentences": "83.555", "nll_loss": "1.668", "wps": "8244.5", "ups": "0.57", "wpb": "14487.2", "bsz": "83.6", "num_updates": "3800", "lr": "9.705e-06", "gnorm": "159.282", "loss_scale": "4", "train_wall": "351", "gb_free": "31.5", "wall": "6783"}
[2024-07-07 12:14:34,911][train_inner][INFO] - {"epoch": 3, "update": 2.287, "loss": "261.803", "ntokens": "14601.4", "nsentences": "84.76", "nll_loss": "1.52", "wps": "8449", "ups": "0.58", "wpb": "14601.4", "bsz": "84.8", "num_updates": "4000", "lr": "1.02e-05", "gnorm": "155.595", "loss_scale": "4", "train_wall": "345", "gb_free": "33.4", "wall": "7129"}
[2024-07-07 12:20:26,118][train_inner][INFO] - {"epoch": 3, "update": 2.401, "loss": "250.167", "ntokens": "14583", "nsentences": "82.72", "nll_loss": "1.419", "wps": "8304.8", "ups": "0.57", "wpb": "14583", "bsz": "82.7", "num_updates": "4200", "lr": "1.0695e-05", "gnorm": "155.334", "loss_scale": "4", "train_wall": "351", "gb_free": "32.6", "wall": "7480"}
[2024-07-07 12:26:09,833][train_inner][INFO] - {"epoch": 3, "update": 2.515, "loss": "211.678", "ntokens": "14769.3", "nsentences": "90.96", "nll_loss": "1.304", "wps": "8594.2", "ups": "0.58", "wpb": "14769.3", "bsz": "91", "num_updates": "4400", "lr": "1.119e-05", "gnorm": "149.656", "loss_scale": "8", "train_wall": "343", "gb_free": "33", "wall": "7824"}
[2024-07-07 12:31:55,911][train_inner][INFO] - {"epoch": 3, "update": 2.629, "loss": "214.642", "ntokens": "14663.8", "nsentences": "87.28", "nll_loss": "1.278", "wps": "8476.2", "ups": "0.58", "wpb": "14663.8", "bsz": "87.3", "num_updates": "4600", "lr": "1.1685e-05", "gnorm": "156.217", "loss_scale": "8", "train_wall": "345", "gb_free": "30", "wall": "8170"}
[2024-07-07 12:37:43,203][train_inner][INFO] - {"epoch": 3, "update": 2.743, "loss": "202.347", "ntokens": "14571.4", "nsentences": "84.24", "nll_loss": "1.17", "wps": "8391.7", "ups": "0.58", "wpb": "14571.4", "bsz": "84.2", "num_updates": "4800", "lr": "1.218e-05", "gnorm": "141.374", "loss_scale": "8", "train_wall": "347", "gb_free": "32.1", "wall": "8517"}
[2024-07-07 12:43:27,839][train_inner][INFO] - {"epoch": 3, "update": 2.857, "loss": "208.876", "ntokens": "14453.2", "nsentences": "83", "nll_loss": "1.2", "wps": "8389.3", "ups": "0.58", "wpb": "14453.2", "bsz": "83", "num_updates": "5000", "lr": "1.2675e-05", "gnorm": "151.058", "loss_scale": "8", "train_wall": "344", "gb_free": "32.8", "wall": "8862"}
[2024-07-07 12:49:20,007][train_inner][INFO] - {"epoch": 3, "update": 2.971, "loss": "185.275", "ntokens": "14591.2", "nsentences": "83.64", "nll_loss": "1.062", "wps": "8288.2", "ups": "0.57", "wpb": "14591.2", "bsz": "83.6", "num_updates": "5200", "lr": "1.317e-05", "gnorm": "141.227", "loss_scale": "8", "train_wall": "352", "gb_free": "32.7", "wall": "9214"}
[2024-07-07 12:50:47,617][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 12:50:47,627][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 12:51:19,800][dev-other][INFO] - {"epoch": 3, "dev-other_loss": "43.677", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.464", "dev-other_uer": "8.493", "dev-other_wer": "27.674", "dev-other_raw_wer": "27.674", "dev-other_wps": "8686.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "5250"}
[2024-07-07 12:51:19,801][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)
[2024-07-07 12:51:19,808][train][INFO] - {"epoch": 3, "train_loss": "230.873", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "1.344", "train_wps": "8284.5", "train_ups": "0.57", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "5250", "train_lr": "1.32937e-05", "train_gnorm": "151.694", "train_loss_scale": "8", "train_train_wall": "3045", "train_gb_free": "32.7", "train_wall": "9334"}
[2024-07-07 12:51:19,809][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 12:51:20,505][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-07 12:51:20,510][fairseq.trainer][INFO] - begin training epoch 4
[2024-07-07 12:51:20,511][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 12:55:40,120][train_inner][INFO] - {"epoch": 4, "update": 3.086, "loss": "179.015", "ntokens": "14517.7", "nsentences": "84.915", "nll_loss": "1.047", "wps": "7640.7", "ups": "0.53", "wpb": "14517.7", "bsz": "84.9", "num_updates": "5400", "lr": "1.3665e-05", "gnorm": "143.407", "loss_scale": "8", "train_wall": "346", "gb_free": "32.2", "wall": "9594"}
[2024-07-07 13:01:31,742][train_inner][INFO] - {"epoch": 4, "update": 3.2, "loss": "178.282", "ntokens": "14516.9", "nsentences": "82.44", "nll_loss": "1.012", "wps": "8259.4", "ups": "0.57", "wpb": "14516.9", "bsz": "82.4", "num_updates": "5600", "lr": "1.416e-05", "gnorm": "139.753", "loss_scale": "8", "train_wall": "351", "gb_free": "32.6", "wall": "9945"}
[2024-07-07 13:07:25,516][train_inner][INFO] - {"epoch": 4, "update": 3.314, "loss": "159.777", "ntokens": "14536.7", "nsentences": "84.68", "nll_loss": "0.931", "wps": "8220", "ups": "0.57", "wpb": "14536.7", "bsz": "84.7", "num_updates": "5800", "lr": "1.4655e-05", "gnorm": "132.63", "loss_scale": "8", "train_wall": "353", "gb_free": "32.1", "wall": "10299"}
[2024-07-07 13:13:09,844][train_inner][INFO] - {"epoch": 4, "update": 3.428, "loss": "163.904", "ntokens": "14611.4", "nsentences": "86.88", "nll_loss": "0.975", "wps": "8488.6", "ups": "0.58", "wpb": "14611.4", "bsz": "86.9", "num_updates": "6000", "lr": "1.515e-05", "gnorm": "137.166", "loss_scale": "8", "train_wall": "344", "gb_free": "33.1", "wall": "10644"}
[2024-07-07 13:19:06,972][train_inner][INFO] - {"epoch": 4, "update": 3.542, "loss": "147.734", "ntokens": "14663", "nsentences": "86.84", "nll_loss": "0.875", "wps": "8213.2", "ups": "0.56", "wpb": "14663", "bsz": "86.8", "num_updates": "6200", "lr": "1.5645e-05", "gnorm": "129.141", "loss_scale": "8", "train_wall": "357", "gb_free": "31.8", "wall": "11001"}
[2024-07-07 13:25:03,267][train_inner][INFO] - {"epoch": 4, "update": 3.656, "loss": "153.784", "ntokens": "14572.5", "nsentences": "84.64", "nll_loss": "0.893", "wps": "8180.4", "ups": "0.56", "wpb": "14572.5", "bsz": "84.6", "num_updates": "6400", "lr": "1.614e-05", "gnorm": "133.14", "loss_scale": "8", "train_wall": "356", "gb_free": "31.8", "wall": "11357"}
[2024-07-07 13:30:54,937][train_inner][INFO] - {"epoch": 4, "update": 3.771, "loss": "150.764", "ntokens": "14548", "nsentences": "82.8", "nll_loss": "0.858", "wps": "8275.6", "ups": "0.57", "wpb": "14548", "bsz": "82.8", "num_updates": "6600", "lr": "1.6635e-05", "gnorm": "136.018", "loss_scale": "16", "train_wall": "351", "gb_free": "31.7", "wall": "11709"}
[2024-07-07 13:36:45,620][train_inner][INFO] - {"epoch": 4, "update": 3.885, "loss": "148.066", "ntokens": "14547.5", "nsentences": "82.04", "nll_loss": "0.835", "wps": "8298.4", "ups": "0.57", "wpb": "14547.5", "bsz": "82", "num_updates": "6800", "lr": "1.713e-05", "gnorm": "135.032", "loss_scale": "16", "train_wall": "350", "gb_free": "32.3", "wall": "12059"}
[2024-07-07 13:42:27,641][train_inner][INFO] - {"epoch": 4, "update": 3.999, "loss": "143.083", "ntokens": "14674.3", "nsentences": "88.12", "nll_loss": "0.859", "wps": "8583.1", "ups": "0.58", "wpb": "14674.3", "bsz": "88.1", "num_updates": "7000", "lr": "1.7625e-05", "gnorm": "133.847", "loss_scale": "16", "train_wall": "341", "gb_free": "31.6", "wall": "12401"}
[2024-07-07 13:42:29,717][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 13:42:29,718][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 13:43:01,837][dev-other][INFO] - {"epoch": 4, "dev-other_loss": "31.533", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.335", "dev-other_uer": "5.734", "dev-other_wer": "17.301", "dev-other_raw_wer": "17.301", "dev-other_wps": "8701.3", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "7002"}
[2024-07-07 13:43:01,838][fairseq_cli.train][INFO] - end of epoch 4 (average epoch stats below)
[2024-07-07 13:43:01,844][train][INFO] - {"epoch": 4, "train_loss": "157.742", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.918", "train_wps": "8233.3", "train_ups": "0.56", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "7002", "train_lr": "1.76299e-05", "train_gnorm": "135.586", "train_loss_scale": "16", "train_train_wall": "3064", "train_gb_free": "31.7", "train_wall": "12436"}
[2024-07-07 13:43:01,846][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 13:43:02,546][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-07 13:43:02,550][fairseq.trainer][INFO] - begin training epoch 5
[2024-07-07 13:43:02,550][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 13:48:53,685][train_inner][INFO] - {"epoch": 5, "update": 4.113, "loss": "136.552", "ntokens": "14472.9", "nsentences": "83.88", "nll_loss": "0.791", "wps": "7498.3", "ups": "0.52", "wpb": "14472.9", "bsz": "83.9", "num_updates": "7200", "lr": "1.812e-05", "gnorm": "133.711", "loss_scale": "16", "train_wall": "352", "gb_free": "33.1", "wall": "12787"}
[2024-07-07 13:54:35,532][train_inner][INFO] - {"epoch": 5, "update": 4.227, "loss": "141.677", "ntokens": "14493.1", "nsentences": "84.28", "nll_loss": "0.824", "wps": "8481.1", "ups": "0.59", "wpb": "14493.1", "bsz": "84.3", "num_updates": "7400", "lr": "1.8615e-05", "gnorm": "135.954", "loss_scale": "16", "train_wall": "341", "gb_free": "32.1", "wall": "13129"}
[2024-07-07 14:00:33,236][train_inner][INFO] - {"epoch": 5, "update": 4.341, "loss": "132.943", "ntokens": "14718.6", "nsentences": "85.6", "nll_loss": "0.773", "wps": "8230.3", "ups": "0.56", "wpb": "14718.6", "bsz": "85.6", "num_updates": "7600", "lr": "1.911e-05", "gnorm": "127.836", "loss_scale": "16", "train_wall": "357", "gb_free": "32.2", "wall": "13487"}
[2024-07-07 14:04:29,363][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-07 14:06:24,640][train_inner][INFO] - {"epoch": 5, "update": 4.456, "loss": "135.843", "ntokens": "14622", "nsentences": "84.96", "nll_loss": "0.789", "wps": "8324.1", "ups": "0.57", "wpb": "14622", "bsz": "85", "num_updates": "7800", "lr": "1.9605e-05", "gnorm": "132.574", "loss_scale": "8", "train_wall": "351", "gb_free": "33.1", "wall": "13838"}
[2024-07-07 14:12:16,706][train_inner][INFO] - {"epoch": 5, "update": 4.57, "loss": "133.198", "ntokens": "14472", "nsentences": "83.12", "nll_loss": "0.765", "wps": "8221.5", "ups": "0.57", "wpb": "14472", "bsz": "83.1", "num_updates": "8000", "lr": "2.01e-05", "gnorm": "134.226", "loss_scale": "8", "train_wall": "352", "gb_free": "33.1", "wall": "14190"}
[2024-07-07 14:18:04,147][train_inner][INFO] - {"epoch": 5, "update": 4.684, "loss": "131.08", "ntokens": "14642.7", "nsentences": "86.48", "nll_loss": "0.774", "wps": "8429.1", "ups": "0.58", "wpb": "14642.7", "bsz": "86.5", "num_updates": "8200", "lr": "2.0595e-05", "gnorm": "128.662", "loss_scale": "8", "train_wall": "347", "gb_free": "32.2", "wall": "14538"}
[2024-07-07 14:23:55,529][train_inner][INFO] - {"epoch": 5, "update": 4.799, "loss": "131.897", "ntokens": "14642.1", "nsentences": "87.44", "nll_loss": "0.788", "wps": "8334.3", "ups": "0.57", "wpb": "14642.1", "bsz": "87.4", "num_updates": "8400", "lr": "2.109e-05", "gnorm": "138.521", "loss_scale": "8", "train_wall": "351", "gb_free": "31.8", "wall": "14889"}
[2024-07-07 14:29:41,657][train_inner][INFO] - {"epoch": 5, "update": 4.913, "loss": "125.081", "ntokens": "14555.1", "nsentences": "85.395", "nll_loss": "0.734", "wps": "8410.6", "ups": "0.58", "wpb": "14555.1", "bsz": "85.4", "num_updates": "8600", "lr": "2.1585e-05", "gnorm": "129.899", "loss_scale": "8", "train_wall": "346", "gb_free": "32.2", "wall": "15235"}
[2024-07-07 14:34:08,889][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 14:34:08,955][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 14:34:40,990][dev-other][INFO] - {"epoch": 5, "dev-other_loss": "28.309", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.301", "dev-other_uer": "4.79", "dev-other_wer": "13.87", "dev-other_raw_wer": "13.87", "dev-other_wps": "8710.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "8753"}
[2024-07-07 14:34:40,992][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 8753 updates
[2024-07-07 14:34:40,994][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-07 14:34:42,425][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-07 14:34:43,063][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 5 @ 8753 updates, score 13.87) (writing took 2.0701977498829365 seconds)
[2024-07-07 14:34:43,063][fairseq_cli.train][INFO] - end of epoch 5 (average epoch stats below)
[2024-07-07 14:34:43,067][train][INFO] - {"epoch": 5, "train_loss": "133.724", "train_ntokens": "14577.8", "train_nsentences": "84.8744", "train_nll_loss": "0.779", "train_wps": "8230.9", "train_ups": "0.56", "train_wpb": "14577.8", "train_bsz": "84.9", "train_num_updates": "8753", "train_lr": "2.19637e-05", "train_gnorm": "133.06", "train_loss_scale": "8", "train_train_wall": "3061", "train_gb_free": "33.9", "train_wall": "15537"}
[2024-07-07 14:34:43,069][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 14:34:43,366][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-07 14:34:43,370][fairseq.trainer][INFO] - begin training epoch 6
[2024-07-07 14:34:43,370][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 14:36:03,562][train_inner][INFO] - {"epoch": 6, "update": 5.027, "loss": "134.835", "ntokens": "14482.4", "nsentences": "81.36", "nll_loss": "0.757", "wps": "7584.5", "ups": "0.52", "wpb": "14482.4", "bsz": "81.4", "num_updates": "8800", "lr": "2.208e-05", "gnorm": "137.504", "loss_scale": "8", "train_wall": "347", "gb_free": "32", "wall": "15617"}
[2024-07-07 14:41:49,007][train_inner][INFO] - {"epoch": 6, "update": 5.141, "loss": "132.684", "ntokens": "14666.5", "nsentences": "84.44", "nll_loss": "0.764", "wps": "8493.6", "ups": "0.58", "wpb": "14666.5", "bsz": "84.4", "num_updates": "9000", "lr": "2.2575e-05", "gnorm": "140.931", "loss_scale": "8", "train_wall": "345", "gb_free": "33.3", "wall": "15963"}
[2024-07-07 14:47:36,958][train_inner][INFO] - {"epoch": 6, "update": 5.255, "loss": "120.427", "ntokens": "14533.5", "nsentences": "85.52", "nll_loss": "0.709", "wps": "8356", "ups": "0.57", "wpb": "14533.6", "bsz": "85.5", "num_updates": "9200", "lr": "2.307e-05", "gnorm": "129.7", "loss_scale": "8", "train_wall": "347", "gb_free": "33.2", "wall": "16311"}
[2024-07-07 14:53:32,730][train_inner][INFO] - {"epoch": 6, "update": 5.369, "loss": "118.844", "ntokens": "14681.9", "nsentences": "86.72", "nll_loss": "0.702", "wps": "8253.9", "ups": "0.56", "wpb": "14681.9", "bsz": "86.7", "num_updates": "9400", "lr": "2.3565e-05", "gnorm": "127.835", "loss_scale": "8", "train_wall": "355", "gb_free": "32.2", "wall": "16667"}
[2024-07-07 14:59:26,185][train_inner][INFO] - {"epoch": 6, "update": 5.483, "loss": "123.439", "ntokens": "14578.9", "nsentences": "83.96", "nll_loss": "0.711", "wps": "8249.6", "ups": "0.57", "wpb": "14578.9", "bsz": "84", "num_updates": "9600", "lr": "2.406e-05", "gnorm": "133.64", "loss_scale": "8", "train_wall": "353", "gb_free": "31.8", "wall": "17020"}
[2024-07-07 15:05:15,046][train_inner][INFO] - {"epoch": 6, "update": 5.598, "loss": "118.723", "ntokens": "14586.1", "nsentences": "85.16", "nll_loss": "0.693", "wps": "8364.1", "ups": "0.57", "wpb": "14586.1", "bsz": "85.2", "num_updates": "9800", "lr": "2.4555e-05", "gnorm": "128.25", "loss_scale": "16", "train_wall": "348", "gb_free": "32.8", "wall": "17369"}
[2024-07-07 15:11:04,373][train_inner][INFO] - {"epoch": 6, "update": 5.712, "loss": "121.162", "ntokens": "14618.9", "nsentences": "83.835", "nll_loss": "0.695", "wps": "8371.6", "ups": "0.57", "wpb": "14618.9", "bsz": "83.8", "num_updates": "10000", "lr": "2.505e-05", "gnorm": "130.455", "loss_scale": "16", "train_wall": "349", "gb_free": "31.6", "wall": "17718"}
[2024-07-07 15:16:48,702][train_inner][INFO] - {"epoch": 6, "update": 5.826, "loss": "120.463", "ntokens": "14584.8", "nsentences": "85.24", "nll_loss": "0.704", "wps": "8471.9", "ups": "0.58", "wpb": "14584.8", "bsz": "85.2", "num_updates": "10200", "lr": "2.5545e-05", "gnorm": "133.973", "loss_scale": "16", "train_wall": "344", "gb_free": "32.7", "wall": "18062"}
[2024-07-07 15:19:23,223][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-07 15:22:44,570][train_inner][INFO] - {"epoch": 6, "update": 5.941, "loss": "112.52", "ntokens": "14520.8", "nsentences": "86.64", "nll_loss": "0.671", "wps": "8161.1", "ups": "0.56", "wpb": "14520.8", "bsz": "86.6", "num_updates": "10400", "lr": "2.604e-05", "gnorm": "126.922", "loss_scale": "8", "train_wall": "355", "gb_free": "32.8", "wall": "18418"}
[2024-07-07 15:25:41,167][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 15:25:41,235][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 15:26:13,198][dev-other][INFO] - {"epoch": 6, "dev-other_loss": "25.562", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.272", "dev-other_uer": "4.361", "dev-other_wer": "12.354", "dev-other_raw_wer": "12.354", "dev-other_wps": "8732.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "10504", "dev-other_best_wer": "12.354"}
[2024-07-07 15:26:13,205][fairseq_cli.train][INFO] - end of epoch 6 (average epoch stats below)
[2024-07-07 15:26:13,210][train][INFO] - {"epoch": 6, "train_loss": "121.494", "train_ntokens": "14576.8", "train_nsentences": "84.8652", "train_nll_loss": "0.707", "train_wps": "8259.8", "train_ups": "0.57", "train_wpb": "14576.8", "train_bsz": "84.9", "train_num_updates": "10504", "train_lr": "2.62974e-05", "train_gnorm": "132.133", "train_loss_scale": "8", "train_train_wall": "3052", "train_gb_free": "33.1", "train_wall": "18627"}
[2024-07-07 15:26:13,211][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 15:26:13,901][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-07 15:26:13,905][fairseq.trainer][INFO] - begin training epoch 7
[2024-07-07 15:26:13,905][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 15:28:58,118][train_inner][INFO] - {"epoch": 7, "update": 6.055, "loss": "120.556", "ntokens": "14481", "nsentences": "84.16", "nll_loss": "0.701", "wps": "7753.5", "ups": "0.54", "wpb": "14481", "bsz": "84.2", "num_updates": "10600", "lr": "2.6535e-05", "gnorm": "135.308", "loss_scale": "8", "train_wall": "340", "gb_free": "32.8", "wall": "18792"}
[2024-07-07 15:34:50,814][train_inner][INFO] - {"epoch": 7, "update": 6.169, "loss": "113.248", "ntokens": "14591.6", "nsentences": "84.96", "nll_loss": "0.659", "wps": "8276.5", "ups": "0.57", "wpb": "14591.6", "bsz": "85", "num_updates": "10800", "lr": "2.703e-05", "gnorm": "127.247", "loss_scale": "8", "train_wall": "352", "gb_free": "32.2", "wall": "19145"}
[2024-07-07 15:40:39,224][train_inner][INFO] - {"epoch": 7, "update": 6.283, "loss": "118.652", "ntokens": "14524.2", "nsentences": "84.235", "nll_loss": "0.688", "wps": "8340.2", "ups": "0.57", "wpb": "14524.2", "bsz": "84.2", "num_updates": "11000", "lr": "2.7525e-05", "gnorm": "133.538", "loss_scale": "8", "train_wall": "348", "gb_free": "32.5", "wall": "19493"}
[2024-07-07 15:46:33,491][train_inner][INFO] - {"epoch": 7, "update": 6.397, "loss": "116.16", "ntokens": "14614.6", "nsentences": "83.44", "nll_loss": "0.663", "wps": "8252.7", "ups": "0.56", "wpb": "14614.6", "bsz": "83.4", "num_updates": "11200", "lr": "2.802e-05", "gnorm": "128.023", "loss_scale": "8", "train_wall": "354", "gb_free": "32", "wall": "19847"}
[2024-07-07 15:52:19,011][train_inner][INFO] - {"epoch": 7, "update": 6.511, "loss": "111.161", "ntokens": "14649.7", "nsentences": "86.96", "nll_loss": "0.66", "wps": "8480.6", "ups": "0.58", "wpb": "14649.7", "bsz": "87", "num_updates": "11400", "lr": "2.8515e-05", "gnorm": "126.577", "loss_scale": "8", "train_wall": "345", "gb_free": "29.5", "wall": "20193"}
[2024-07-07 15:58:08,237][train_inner][INFO] - {"epoch": 7, "update": 6.626, "loss": "123.451", "ntokens": "14552.3", "nsentences": "82.96", "nll_loss": "0.704", "wps": "8335.9", "ups": "0.57", "wpb": "14552.3", "bsz": "83", "num_updates": "11600", "lr": "2.901e-05", "gnorm": "136.621", "loss_scale": "8", "train_wall": "349", "gb_free": "32.1", "wall": "20542"}
[2024-07-07 16:03:55,201][train_inner][INFO] - {"epoch": 7, "update": 6.74, "loss": "118.843", "ntokens": "14590.6", "nsentences": "84.4", "nll_loss": "0.687", "wps": "8412.7", "ups": "0.58", "wpb": "14590.6", "bsz": "84.4", "num_updates": "11800", "lr": "2.9505e-05", "gnorm": "132.719", "loss_scale": "8", "train_wall": "346", "gb_free": "32.3", "wall": "20889"}
[2024-07-07 16:09:48,101][train_inner][INFO] - {"epoch": 7, "update": 6.854, "loss": "106.361", "ntokens": "14728.1", "nsentences": "87.4", "nll_loss": "0.631", "wps": "8347.2", "ups": "0.57", "wpb": "14728.1", "bsz": "87.4", "num_updates": "12000", "lr": "3e-05", "gnorm": "123.432", "loss_scale": "8", "train_wall": "352", "gb_free": "31.3", "wall": "21242"}
[2024-07-07 16:12:36,909][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-07-07 16:15:33,792][train_inner][INFO] - {"epoch": 7, "update": 6.969, "loss": "114.358", "ntokens": "14445.7", "nsentences": "84.12", "nll_loss": "0.666", "wps": "8359.4", "ups": "0.58", "wpb": "14445.7", "bsz": "84.1", "num_updates": "12200", "lr": "3e-05", "gnorm": "130.314", "loss_scale": "4", "train_wall": "345", "gb_free": "32", "wall": "21588"}
[2024-07-07 16:17:09,902][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 16:17:09,977][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 16:17:41,995][dev-other][INFO] - {"epoch": 7, "dev-other_loss": "24.488", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.26", "dev-other_uer": "4.149", "dev-other_wer": "11.498", "dev-other_raw_wer": "11.498", "dev-other_wps": "8715.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "12255", "dev-other_best_wer": "11.498"}
[2024-07-07 16:17:41,996][fairseq_cli.train][INFO] - end of epoch 7 (average epoch stats below)
[2024-07-07 16:17:42,003][train][INFO] - {"epoch": 7, "train_loss": "115.172", "train_ntokens": "14577.1", "train_nsentences": "84.8698", "train_nll_loss": "0.671", "train_wps": "8263.6", "train_ups": "0.57", "train_wpb": "14577.1", "train_bsz": "84.9", "train_num_updates": "12255", "train_lr": "3e-05", "train_gnorm": "129.666", "train_loss_scale": "4", "train_train_wall": "3050", "train_gb_free": "33.9", "train_wall": "21716"}
[2024-07-07 16:17:42,005][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 16:17:42,700][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-07 16:17:42,704][fairseq.trainer][INFO] - begin training epoch 8
[2024-07-07 16:17:42,704][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 16:22:00,700][train_inner][INFO] - {"epoch": 8, "update": 7.083, "loss": "107.356", "ntokens": "14577.4", "nsentences": "86.035", "nll_loss": "0.634", "wps": "7536.8", "ups": "0.52", "wpb": "14577.4", "bsz": "86", "num_updates": "12400", "lr": "3e-05", "gnorm": "124.205", "loss_scale": "4", "train_wall": "353", "gb_free": "33.3", "wall": "21974"}
[2024-07-07 16:27:46,341][train_inner][INFO] - {"epoch": 8, "update": 7.197, "loss": "114.496", "ntokens": "14583.3", "nsentences": "83.64", "nll_loss": "0.657", "wps": "8440.1", "ups": "0.58", "wpb": "14583.3", "bsz": "83.6", "num_updates": "12600", "lr": "3e-05", "gnorm": "135.286", "loss_scale": "4", "train_wall": "345", "gb_free": "32", "wall": "22320"}
[2024-07-07 16:33:44,712][train_inner][INFO] - {"epoch": 8, "update": 7.311, "loss": "101.687", "ntokens": "14537.9", "nsentences": "86.36", "nll_loss": "0.604", "wps": "8114.9", "ups": "0.56", "wpb": "14537.9", "bsz": "86.4", "num_updates": "12800", "lr": "3e-05", "gnorm": "120.727", "loss_scale": "4", "train_wall": "358", "gb_free": "31.8", "wall": "22678"}
[2024-07-07 16:39:41,475][train_inner][INFO] - {"epoch": 8, "update": 7.425, "loss": "107.256", "ntokens": "14684.1", "nsentences": "85.36", "nll_loss": "0.623", "wps": "8234.1", "ups": "0.56", "wpb": "14684.1", "bsz": "85.4", "num_updates": "13000", "lr": "3e-05", "gnorm": "124.661", "loss_scale": "4", "train_wall": "356", "gb_free": "32.2", "wall": "23035"}
[2024-07-07 16:45:33,212][train_inner][INFO] - {"epoch": 8, "update": 7.539, "loss": "110.189", "ntokens": "14483.5", "nsentences": "82.8", "nll_loss": "0.63", "wps": "8237.5", "ups": "0.57", "wpb": "14483.5", "bsz": "82.8", "num_updates": "13200", "lr": "3e-05", "gnorm": "129.415", "loss_scale": "4", "train_wall": "351", "gb_free": "31.7", "wall": "23387"}
[2024-07-07 16:51:23,221][train_inner][INFO] - {"epoch": 8, "update": 7.654, "loss": "102.797", "ntokens": "14667.5", "nsentences": "86.96", "nll_loss": "0.609", "wps": "8383.1", "ups": "0.57", "wpb": "14667.5", "bsz": "87", "num_updates": "13400", "lr": "3e-05", "gnorm": "124.04", "loss_scale": "4", "train_wall": "349", "gb_free": "32.2", "wall": "23737"}
[2024-07-07 16:57:19,053][train_inner][INFO] - {"epoch": 8, "update": 7.768, "loss": "109.901", "ntokens": "14504.9", "nsentences": "82.84", "nll_loss": "0.628", "wps": "8155", "ups": "0.56", "wpb": "14504.9", "bsz": "82.8", "num_updates": "13600", "lr": "3e-05", "gnorm": "126.78", "loss_scale": "4", "train_wall": "355", "gb_free": "33", "wall": "24093"}
[2024-07-07 17:03:09,465][train_inner][INFO] - {"epoch": 8, "update": 7.882, "loss": "107.055", "ntokens": "14535", "nsentences": "83.68", "nll_loss": "0.616", "wps": "8297.7", "ups": "0.57", "wpb": "14535", "bsz": "83.7", "num_updates": "13800", "lr": "3e-05", "gnorm": "125.774", "loss_scale": "4", "train_wall": "350", "gb_free": "32.4", "wall": "24443"}
[2024-07-07 17:09:07,814][train_inner][INFO] - {"epoch": 8, "update": 7.996, "loss": "102.084", "ntokens": "14598.9", "nsentences": "86.2", "nll_loss": "0.603", "wps": "8149.9", "ups": "0.56", "wpb": "14598.9", "bsz": "86.2", "num_updates": "14000", "lr": "3e-05", "gnorm": "126.604", "loss_scale": "4", "train_wall": "358", "gb_free": "29.9", "wall": "24802"}
[2024-07-07 17:09:19,342][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 17:09:19,343][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 17:09:51,512][dev-other][INFO] - {"epoch": 8, "dev-other_loss": "23.096", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.246", "dev-other_uer": "4.006", "dev-other_wer": "11.017", "dev-other_raw_wer": "11.017", "dev-other_wps": "8697.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "14007", "dev-other_best_wer": "11.017"}
[2024-07-07 17:09:51,513][fairseq_cli.train][INFO] - end of epoch 8 (average epoch stats below)
[2024-07-07 17:09:51,518][train][INFO] - {"epoch": 8, "train_loss": "106.668", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.621", "train_wps": "8161", "train_ups": "0.56", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "14007", "train_lr": "3e-05", "train_gnorm": "126.357", "train_loss_scale": "4", "train_train_wall": "3091", "train_gb_free": "32.2", "train_wall": "24845"}
[2024-07-07 17:09:51,519][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 17:09:52,211][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-07 17:09:52,215][fairseq.trainer][INFO] - begin training epoch 9
[2024-07-07 17:09:52,215][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 17:15:31,311][train_inner][INFO] - {"epoch": 9, "update": 8.11, "loss": "104.319", "ntokens": "14557.6", "nsentences": "85.32", "nll_loss": "0.611", "wps": "7593.8", "ups": "0.52", "wpb": "14557.6", "bsz": "85.3", "num_updates": "14200", "lr": "3e-05", "gnorm": "122.945", "loss_scale": "8", "train_wall": "350", "gb_free": "30.5", "wall": "25185"}
[2024-07-07 17:21:18,170][train_inner][INFO] - {"epoch": 9, "update": 8.224, "loss": "100.342", "ntokens": "14653.1", "nsentences": "86.04", "nll_loss": "0.589", "wps": "8451", "ups": "0.58", "wpb": "14653.1", "bsz": "86", "num_updates": "14400", "lr": "3e-05", "gnorm": "123.117", "loss_scale": "8", "train_wall": "346", "gb_free": "32.6", "wall": "25532"}
[2024-07-07 17:27:17,550][train_inner][INFO] - {"epoch": 9, "update": 8.338, "loss": "101.461", "ntokens": "14634.7", "nsentences": "86.08", "nll_loss": "0.597", "wps": "8146.2", "ups": "0.56", "wpb": "14634.7", "bsz": "86.1", "num_updates": "14600", "lr": "3e-05", "gnorm": "124.218", "loss_scale": "8", "train_wall": "359", "gb_free": "31.2", "wall": "25891"}
[2024-07-07 17:33:08,674][train_inner][INFO] - {"epoch": 9, "update": 8.453, "loss": "106.679", "ntokens": "14458.7", "nsentences": "83.2", "nll_loss": "0.614", "wps": "8237.1", "ups": "0.57", "wpb": "14458.7", "bsz": "83.2", "num_updates": "14800", "lr": "3e-05", "gnorm": "126.312", "loss_scale": "8", "train_wall": "351", "gb_free": "31.5", "wall": "26242"}
[2024-07-07 17:39:05,585][train_inner][INFO] - {"epoch": 9, "update": 8.567, "loss": "103.161", "ntokens": "14635.4", "nsentences": "84.195", "nll_loss": "0.593", "wps": "8201.5", "ups": "0.56", "wpb": "14635.4", "bsz": "84.2", "num_updates": "15000", "lr": "3e-05", "gnorm": "125.029", "loss_scale": "8", "train_wall": "356", "gb_free": "32.8", "wall": "26599"}
[2024-07-07 17:44:59,872][train_inner][INFO] - {"epoch": 9, "update": 8.681, "loss": "107.011", "ntokens": "14504.5", "nsentences": "81.8", "nll_loss": "0.603", "wps": "8189.7", "ups": "0.56", "wpb": "14504.5", "bsz": "81.8", "num_updates": "15200", "lr": "3e-05", "gnorm": "126.66", "loss_scale": "8", "train_wall": "354", "gb_free": "32.6", "wall": "26954"}
[2024-07-07 17:50:46,936][train_inner][INFO] - {"epoch": 9, "update": 8.795, "loss": "102.843", "ntokens": "14603.8", "nsentences": "87.36", "nll_loss": "0.615", "wps": "8416.2", "ups": "0.58", "wpb": "14603.8", "bsz": "87.4", "num_updates": "15400", "lr": "3e-05", "gnorm": "120.454", "loss_scale": "8", "train_wall": "347", "gb_free": "32.7", "wall": "27301"}
[2024-07-07 17:56:42,043][train_inner][INFO] - {"epoch": 9, "update": 8.909, "loss": "104.059", "ntokens": "14548.8", "nsentences": "82.96", "nll_loss": "0.593", "wps": "8194.3", "ups": "0.56", "wpb": "14548.8", "bsz": "83", "num_updates": "15600", "lr": "3e-05", "gnorm": "127.435", "loss_scale": "8", "train_wall": "355", "gb_free": "32.7", "wall": "27656"}
[2024-07-07 18:01:18,521][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 18:01:18,588][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 18:01:50,639][dev-other][INFO] - {"epoch": 9, "dev-other_loss": "22.981", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.244", "dev-other_uer": "3.919", "dev-other_wer": "10.689", "dev-other_raw_wer": "10.689", "dev-other_wps": "8684.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "15759", "dev-other_best_wer": "10.689"}
[2024-07-07 18:01:50,640][fairseq_cli.train][INFO] - end of epoch 9 (average epoch stats below)
[2024-07-07 18:01:50,642][train][INFO] - {"epoch": 9, "train_loss": "103.263", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.601", "train_wps": "8188.1", "train_ups": "0.56", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "15759", "train_lr": "3e-05", "train_gnorm": "124.136", "train_loss_scale": "8", "train_train_wall": "3081", "train_gb_free": "32.3", "train_wall": "27964"}
[2024-07-07 18:01:50,644][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 18:01:51,369][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-07 18:01:51,372][fairseq.trainer][INFO] - begin training epoch 10
[2024-07-07 18:01:51,373][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 18:03:01,445][train_inner][INFO] - {"epoch": 10, "update": 9.023, "loss": "100.542", "ntokens": "14511.8", "nsentences": "85.76", "nll_loss": "0.594", "wps": "7651.3", "ups": "0.53", "wpb": "14511.8", "bsz": "85.8", "num_updates": "15800", "lr": "3e-05", "gnorm": "122.897", "loss_scale": "8", "train_wall": "346", "gb_free": "31.2", "wall": "28035"}
[2024-07-07 18:08:52,282][train_inner][INFO] - {"epoch": 10, "update": 9.138, "loss": "98.62", "ntokens": "14601.6", "nsentences": "85", "nll_loss": "0.574", "wps": "8324.6", "ups": "0.57", "wpb": "14601.6", "bsz": "85", "num_updates": "16000", "lr": "3e-05", "gnorm": "124.001", "loss_scale": "8", "train_wall": "350", "gb_free": "32.3", "wall": "28386"}
[2024-07-07 18:11:48,674][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-07-07 18:14:43,770][train_inner][INFO] - {"epoch": 10, "update": 9.252, "loss": "98.812", "ntokens": "14628.9", "nsentences": "85.68", "nll_loss": "0.579", "wps": "8324.2", "ups": "0.57", "wpb": "14628.9", "bsz": "85.7", "num_updates": "16200", "lr": "3e-05", "gnorm": "123.251", "loss_scale": "4", "train_wall": "351", "gb_free": "32.5", "wall": "28738"}
[2024-07-07 18:20:34,532][train_inner][INFO] - {"epoch": 10, "update": 9.366, "loss": "102.059", "ntokens": "14605.1", "nsentences": "86.12", "nll_loss": "0.602", "wps": "8327.9", "ups": "0.57", "wpb": "14605.1", "bsz": "86.1", "num_updates": "16400", "lr": "3e-05", "gnorm": "124.693", "loss_scale": "4", "train_wall": "350", "gb_free": "32.6", "wall": "29088"}
[2024-07-07 18:26:21,138][train_inner][INFO] - {"epoch": 10, "update": 9.481, "loss": "103.11", "ntokens": "14606.6", "nsentences": "84.76", "nll_loss": "0.598", "wps": "8430.2", "ups": "0.58", "wpb": "14606.6", "bsz": "84.8", "num_updates": "16600", "lr": "3e-05", "gnorm": "124.134", "loss_scale": "4", "train_wall": "346", "gb_free": "33.3", "wall": "29435"}
[2024-07-07 18:32:02,537][train_inner][INFO] - {"epoch": 10, "update": 9.595, "loss": "107.02", "ntokens": "14504.6", "nsentences": "83.6", "nll_loss": "0.617", "wps": "8498.8", "ups": "0.59", "wpb": "14504.6", "bsz": "83.6", "num_updates": "16800", "lr": "3e-05", "gnorm": "129.251", "loss_scale": "4", "train_wall": "341", "gb_free": "31.5", "wall": "29776"}
[2024-07-07 18:37:59,702][train_inner][INFO] - {"epoch": 10, "update": 9.709, "loss": "95.935", "ntokens": "14666", "nsentences": "86.68", "nll_loss": "0.567", "wps": "8212.8", "ups": "0.56", "wpb": "14666", "bsz": "86.7", "num_updates": "17000", "lr": "3e-05", "gnorm": "119.666", "loss_scale": "4", "train_wall": "357", "gb_free": "32.6", "wall": "30133"}
[2024-07-07 18:43:49,808][train_inner][INFO] - {"epoch": 10, "update": 9.823, "loss": "100.806", "ntokens": "14573.4", "nsentences": "84.32", "nll_loss": "0.583", "wps": "8325.7", "ups": "0.57", "wpb": "14573.4", "bsz": "84.3", "num_updates": "17200", "lr": "3e-05", "gnorm": "124.661", "loss_scale": "4", "train_wall": "350", "gb_free": "29.8", "wall": "30484"}
[2024-07-07 18:49:40,837][train_inner][INFO] - {"epoch": 10, "update": 9.937, "loss": "101.883", "ntokens": "14552.7", "nsentences": "84.875", "nll_loss": "0.594", "wps": "8293.1", "ups": "0.57", "wpb": "14552.7", "bsz": "84.9", "num_updates": "17400", "lr": "3e-05", "gnorm": "123.171", "loss_scale": "4", "train_wall": "350", "gb_free": "31.5", "wall": "30835"}
[2024-07-07 18:53:01,142][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 18:53:01,144][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 18:53:33,239][dev-other][INFO] - {"epoch": 10, "dev-other_loss": "22.218", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.236", "dev-other_uer": "3.792", "dev-other_wer": "10.428", "dev-other_raw_wer": "10.428", "dev-other_wps": "8719.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "17510", "dev-other_best_wer": "10.428"}
[2024-07-07 18:53:33,241][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 10 @ 17510 updates
[2024-07-07 18:53:33,242][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-07 18:53:34,860][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-07 18:53:35,427][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 10 @ 17510 updates, score 10.428) (writing took 2.186311546713114 seconds)
[2024-07-07 18:53:35,428][fairseq_cli.train][INFO] - end of epoch 10 (average epoch stats below)
[2024-07-07 18:53:35,433][train][INFO] - {"epoch": 10, "train_loss": "101.012", "train_ntokens": "14577.5", "train_nsentences": "84.8698", "train_nll_loss": "0.588", "train_wps": "8221.2", "train_ups": "0.56", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "17510", "train_lr": "3e-05", "train_gnorm": "124.028", "train_loss_scale": "4", "train_train_wall": "3064", "train_gb_free": "33.5", "train_wall": "31069"}
[2024-07-07 18:53:35,435][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 18:53:35,682][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-07 18:53:35,690][fairseq.trainer][INFO] - begin training epoch 11
[2024-07-07 18:53:35,690][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 18:56:13,508][train_inner][INFO] - {"epoch": 11, "update": 10.051, "loss": "96.409", "ntokens": "14599.7", "nsentences": "86.32", "nll_loss": "0.57", "wps": "7436.2", "ups": "0.51", "wpb": "14599.7", "bsz": "86.3", "num_updates": "17600", "lr": "3e-05", "gnorm": "118.388", "loss_scale": "4", "train_wall": "358", "gb_free": "31.9", "wall": "31227"}
[2024-07-07 19:02:05,000][train_inner][INFO] - {"epoch": 11, "update": 10.166, "loss": "98.528", "ntokens": "14532.2", "nsentences": "84.8", "nll_loss": "0.575", "wps": "8270.3", "ups": "0.57", "wpb": "14532.2", "bsz": "84.8", "num_updates": "17800", "lr": "3e-05", "gnorm": "122.165", "loss_scale": "4", "train_wall": "351", "gb_free": "31.6", "wall": "31579"}
[2024-07-07 19:07:59,907][train_inner][INFO] - {"epoch": 11, "update": 10.28, "loss": "97.935", "ntokens": "14579.2", "nsentences": "85", "nll_loss": "0.571", "wps": "8217.7", "ups": "0.56", "wpb": "14579.2", "bsz": "85", "num_updates": "18000", "lr": "3e-05", "gnorm": "121.393", "loss_scale": "4", "train_wall": "354", "gb_free": "31.9", "wall": "31934"}
[2024-07-07 19:13:48,332][train_inner][INFO] - {"epoch": 11, "update": 10.394, "loss": "99.085", "ntokens": "14584.4", "nsentences": "84.6", "nll_loss": "0.575", "wps": "8373.3", "ups": "0.57", "wpb": "14584.4", "bsz": "84.6", "num_updates": "18200", "lr": "3e-05", "gnorm": "124.826", "loss_scale": "8", "train_wall": "348", "gb_free": "32.7", "wall": "32282"}
[2024-07-07 19:19:45,138][train_inner][INFO] - {"epoch": 11, "update": 10.508, "loss": "95.311", "ntokens": "14509.8", "nsentences": "84.12", "nll_loss": "0.553", "wps": "8135", "ups": "0.56", "wpb": "14509.8", "bsz": "84.1", "num_updates": "18400", "lr": "3e-05", "gnorm": "121.133", "loss_scale": "8", "train_wall": "356", "gb_free": "30.2", "wall": "32639"}
[2024-07-07 19:25:39,494][train_inner][INFO] - {"epoch": 11, "update": 10.622, "loss": "97.143", "ntokens": "14596.3", "nsentences": "84.48", "nll_loss": "0.562", "wps": "8240.5", "ups": "0.56", "wpb": "14596.3", "bsz": "84.5", "num_updates": "18600", "lr": "3e-05", "gnorm": "122.634", "loss_scale": "8", "train_wall": "354", "gb_free": "32.2", "wall": "32993"}
[2024-07-07 19:31:33,917][train_inner][INFO] - {"epoch": 11, "update": 10.736, "loss": "99.547", "ntokens": "14496.1", "nsentences": "83.68", "nll_loss": "0.575", "wps": "8180.4", "ups": "0.56", "wpb": "14496.1", "bsz": "83.7", "num_updates": "18800", "lr": "3e-05", "gnorm": "122.768", "loss_scale": "8", "train_wall": "354", "gb_free": "31.5", "wall": "33348"}
[2024-07-07 19:37:23,615][train_inner][INFO] - {"epoch": 11, "update": 10.85, "loss": "102.583", "ntokens": "14588.4", "nsentences": "84.12", "nll_loss": "0.592", "wps": "8343.7", "ups": "0.57", "wpb": "14588.4", "bsz": "84.1", "num_updates": "19000", "lr": "3e-05", "gnorm": "127.57", "loss_scale": "8", "train_wall": "349", "gb_free": "32.2", "wall": "33697"}
[2024-07-07 19:43:08,269][train_inner][INFO] - {"epoch": 11, "update": 10.965, "loss": "96.523", "ntokens": "14700.4", "nsentences": "87.595", "nll_loss": "0.575", "wps": "8541.5", "ups": "0.58", "wpb": "14700.4", "bsz": "87.6", "num_updates": "19200", "lr": "3e-05", "gnorm": "119.445", "loss_scale": "8", "train_wall": "344", "gb_free": "32.8", "wall": "34042"}
[2024-07-07 19:44:55,521][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 19:44:55,584][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 19:45:27,566][dev-other][INFO] - {"epoch": 11, "dev-other_loss": "22.593", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.24", "dev-other_uer": "3.773", "dev-other_wer": "10.246", "dev-other_raw_wer": "10.246", "dev-other_wps": "8706.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "19262", "dev-other_best_wer": "10.246"}
[2024-07-07 19:45:27,567][fairseq_cli.train][INFO] - end of epoch 11 (average epoch stats below)
[2024-07-07 19:45:27,589][train][INFO] - {"epoch": 11, "train_loss": "98.433", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.573", "train_wps": "8206.5", "train_ups": "0.56", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "19262", "train_lr": "3e-05", "train_gnorm": "122.699", "train_loss_scale": "8", "train_train_wall": "3074", "train_gb_free": "31.4", "train_wall": "34181"}
[2024-07-07 19:45:27,591][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 19:45:28,301][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-07 19:45:28,304][fairseq.trainer][INFO] - begin training epoch 12
[2024-07-07 19:45:28,304][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 19:49:26,349][train_inner][INFO] - {"epoch": 12, "update": 11.079, "loss": "100.296", "ntokens": "14505.7", "nsentences": "82.24", "nll_loss": "0.569", "wps": "7675.5", "ups": "0.53", "wpb": "14505.7", "bsz": "82.2", "num_updates": "19400", "lr": "3e-05", "gnorm": "126.837", "loss_scale": "8", "train_wall": "345", "gb_free": "31", "wall": "34420"}
[2024-07-07 19:55:16,845][train_inner][INFO] - {"epoch": 12, "update": 11.193, "loss": "99.301", "ntokens": "14621.3", "nsentences": "85.4", "nll_loss": "0.58", "wps": "8345.1", "ups": "0.57", "wpb": "14621.3", "bsz": "85.4", "num_updates": "19600", "lr": "3e-05", "gnorm": "121.689", "loss_scale": "8", "train_wall": "350", "gb_free": "32.6", "wall": "34771"}
[2024-07-07 20:01:07,050][train_inner][INFO] - {"epoch": 12, "update": 11.307, "loss": "96.84", "ntokens": "14526.5", "nsentences": "84.44", "nll_loss": "0.563", "wps": "8298.2", "ups": "0.57", "wpb": "14526.5", "bsz": "84.4", "num_updates": "19800", "lr": "3e-05", "gnorm": "124.421", "loss_scale": "8", "train_wall": "350", "gb_free": "32.4", "wall": "35121"}
[2024-07-07 20:06:55,391][train_inner][INFO] - {"epoch": 12, "update": 11.421, "loss": "94.807", "ntokens": "14545.1", "nsentences": "85.08", "nll_loss": "0.555", "wps": "8351.3", "ups": "0.57", "wpb": "14545.1", "bsz": "85.1", "num_updates": "20000", "lr": "3e-05", "gnorm": "120.702", "loss_scale": "8", "train_wall": "348", "gb_free": "32.3", "wall": "35469"}
[2024-07-07 20:12:45,877][train_inner][INFO] - {"epoch": 12, "update": 11.535, "loss": "95.378", "ntokens": "14707.9", "nsentences": "86.16", "nll_loss": "0.559", "wps": "8393.2", "ups": "0.57", "wpb": "14707.9", "bsz": "86.2", "num_updates": "20200", "lr": "3e-05", "gnorm": "121.55", "loss_scale": "16", "train_wall": "350", "gb_free": "32.8", "wall": "35820"}
[2024-07-07 20:18:37,468][train_inner][INFO] - {"epoch": 12, "update": 11.65, "loss": "97.631", "ntokens": "14482.2", "nsentences": "83.8", "nll_loss": "0.565", "wps": "8239.8", "ups": "0.57", "wpb": "14482.2", "bsz": "83.8", "num_updates": "20400", "lr": "3e-05", "gnorm": "122.832", "loss_scale": "16", "train_wall": "351", "gb_free": "32.4", "wall": "36171"}
[2024-07-07 20:24:26,341][train_inner][INFO] - {"epoch": 12, "update": 11.764, "loss": "98.569", "ntokens": "14598.6", "nsentences": "84.92", "nll_loss": "0.573", "wps": "8369.5", "ups": "0.57", "wpb": "14598.6", "bsz": "84.9", "num_updates": "20600", "lr": "3e-05", "gnorm": "122.291", "loss_scale": "16", "train_wall": "348", "gb_free": "32.9", "wall": "36520"}
[2024-07-07 20:30:17,664][train_inner][INFO] - {"epoch": 12, "update": 11.878, "loss": "93.977", "ntokens": "14675.1", "nsentences": "86.68", "nll_loss": "0.555", "wps": "8354.5", "ups": "0.57", "wpb": "14675.1", "bsz": "86.7", "num_updates": "20800", "lr": "3e-05", "gnorm": "121.057", "loss_scale": "16", "train_wall": "351", "gb_free": "32", "wall": "36871"}
[2024-07-07 20:36:08,902][train_inner][INFO] - {"epoch": 12, "update": 11.992, "loss": "96.046", "ntokens": "14529.2", "nsentences": "83.635", "nll_loss": "0.553", "wps": "8273.4", "ups": "0.57", "wpb": "14529.2", "bsz": "83.6", "num_updates": "21000", "lr": "3e-05", "gnorm": "124.117", "loss_scale": "16", "train_wall": "351", "gb_free": "32.2", "wall": "37223"}
[2024-07-07 20:36:30,863][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 20:36:30,864][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 20:37:02,994][dev-other][INFO] - {"epoch": 12, "dev-other_loss": "22.405", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.238", "dev-other_uer": "3.699", "dev-other_wer": "10.057", "dev-other_raw_wer": "10.057", "dev-other_wps": "8704.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "21014", "dev-other_best_wer": "10.057"}
[2024-07-07 20:37:02,995][fairseq_cli.train][INFO] - end of epoch 12 (average epoch stats below)
[2024-07-07 20:37:03,002][train][INFO] - {"epoch": 12, "train_loss": "96.623", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.563", "train_wps": "8250.9", "train_ups": "0.57", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "21014", "train_lr": "3e-05", "train_gnorm": "122.74", "train_loss_scale": "16", "train_train_wall": "3057", "train_gb_free": "32.3", "train_wall": "37277"}
[2024-07-07 20:37:03,004][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 20:37:03,688][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-07 20:37:03,692][fairseq.trainer][INFO] - begin training epoch 13
[2024-07-07 20:37:03,692][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 20:42:24,944][train_inner][INFO] - {"epoch": 13, "update": 12.106, "loss": "96.237", "ntokens": "14601.7", "nsentences": "86.48", "nll_loss": "0.57", "wps": "7767.5", "ups": "0.53", "wpb": "14601.7", "bsz": "86.5", "num_updates": "21200", "lr": "3e-05", "gnorm": "122.341", "loss_scale": "16", "train_wall": "343", "gb_free": "32.2", "wall": "37599"}
[2024-07-07 20:48:16,310][train_inner][INFO] - {"epoch": 13, "update": 12.22, "loss": "98.454", "ntokens": "14508.9", "nsentences": "82.28", "nll_loss": "0.558", "wps": "8269.7", "ups": "0.57", "wpb": "14508.9", "bsz": "82.3", "num_updates": "21400", "lr": "3e-05", "gnorm": "125.186", "loss_scale": "16", "train_wall": "350", "gb_free": "33.4", "wall": "37950"}
[2024-07-07 20:54:02,981][train_inner][INFO] - {"epoch": 13, "update": 12.334, "loss": "94.282", "ntokens": "14513.6", "nsentences": "84.515", "nll_loss": "0.549", "wps": "8374", "ups": "0.58", "wpb": "14513.6", "bsz": "84.5", "num_updates": "21600", "lr": "3e-05", "gnorm": "121.218", "loss_scale": "16", "train_wall": "346", "gb_free": "33.2", "wall": "38297"}
[2024-07-07 20:59:51,091][train_inner][INFO] - {"epoch": 13, "update": 12.449, "loss": "95.752", "ntokens": "14567.8", "nsentences": "85.2", "nll_loss": "0.56", "wps": "8370", "ups": "0.57", "wpb": "14567.8", "bsz": "85.2", "num_updates": "21800", "lr": "3e-05", "gnorm": "123.216", "loss_scale": "16", "train_wall": "348", "gb_free": "31.4", "wall": "38645"}
[2024-07-07 21:05:41,492][train_inner][INFO] - {"epoch": 13, "update": 12.563, "loss": "94.733", "ntokens": "14604.8", "nsentences": "85.68", "nll_loss": "0.556", "wps": "8337.7", "ups": "0.57", "wpb": "14604.8", "bsz": "85.7", "num_updates": "22000", "lr": "3e-05", "gnorm": "119.231", "loss_scale": "16", "train_wall": "350", "gb_free": "32.7", "wall": "38995"}
[2024-07-07 21:11:37,389][train_inner][INFO] - {"epoch": 13, "update": 12.677, "loss": "95.501", "ntokens": "14503.3", "nsentences": "83.32", "nll_loss": "0.549", "wps": "8152.2", "ups": "0.56", "wpb": "14503.3", "bsz": "83.3", "num_updates": "22200", "lr": "3e-05", "gnorm": "120.305", "loss_scale": "16", "train_wall": "355", "gb_free": "31", "wall": "39351"}
[2024-07-07 21:17:23,827][train_inner][INFO] - {"epoch": 13, "update": 12.791, "loss": "96.86", "ntokens": "14562.5", "nsentences": "83.52", "nll_loss": "0.556", "wps": "8407.3", "ups": "0.58", "wpb": "14562.5", "bsz": "83.5", "num_updates": "22400", "lr": "3e-05", "gnorm": "123.06", "loss_scale": "32", "train_wall": "346", "gb_free": "31.7", "wall": "39698"}
[2024-07-07 21:23:15,049][train_inner][INFO] - {"epoch": 13, "update": 12.905, "loss": "92.358", "ntokens": "14595.4", "nsentences": "84.96", "nll_loss": "0.538", "wps": "8313.3", "ups": "0.57", "wpb": "14595.4", "bsz": "85", "num_updates": "22600", "lr": "3e-05", "gnorm": "120.725", "loss_scale": "32", "train_wall": "351", "gb_free": "31.7", "wall": "40049"}
[2024-07-07 21:28:06,751][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 21:28:06,758][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 21:28:38,700][dev-other][INFO] - {"epoch": 13, "dev-other_loss": "22.383", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.238", "dev-other_uer": "3.663", "dev-other_wer": "9.89", "dev-other_raw_wer": "9.89", "dev-other_wps": "8724.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "22766", "dev-other_best_wer": "9.89"}
[2024-07-07 21:28:38,700][fairseq_cli.train][INFO] - end of epoch 13 (average epoch stats below)
[2024-07-07 21:28:38,703][train][INFO] - {"epoch": 13, "train_loss": "95.155", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.554", "train_wps": "8250.1", "train_ups": "0.57", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "22766", "train_lr": "3e-05", "train_gnorm": "121.309", "train_loss_scale": "32", "train_train_wall": "3057", "train_gb_free": "33.5", "train_wall": "40372"}
[2024-07-07 21:28:38,704][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 21:28:39,448][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-07 21:28:39,452][fairseq.trainer][INFO] - begin training epoch 14
[2024-07-07 21:28:39,452][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 21:29:37,815][train_inner][INFO] - {"epoch": 14, "update": 13.019, "loss": "92.377", "ntokens": "14621.5", "nsentences": "87.24", "nll_loss": "0.551", "wps": "7640.3", "ups": "0.52", "wpb": "14621.5", "bsz": "87.2", "num_updates": "22800", "lr": "3e-05", "gnorm": "118.201", "loss_scale": "32", "train_wall": "349", "gb_free": "33", "wall": "40432"}
[2024-07-07 21:35:23,794][train_inner][INFO] - {"epoch": 14, "update": 13.134, "loss": "98.689", "ntokens": "14476.5", "nsentences": "82.24", "nll_loss": "0.561", "wps": "8370.1", "ups": "0.58", "wpb": "14476.5", "bsz": "82.2", "num_updates": "23000", "lr": "3e-05", "gnorm": "126.298", "loss_scale": "32", "train_wall": "345", "gb_free": "31.4", "wall": "40778"}
[2024-07-07 21:41:12,666][train_inner][INFO] - {"epoch": 14, "update": 13.248, "loss": "95.014", "ntokens": "14509.5", "nsentences": "83.08", "nll_loss": "0.544", "wps": "8320.2", "ups": "0.57", "wpb": "14509.5", "bsz": "83.1", "num_updates": "23200", "lr": "3e-05", "gnorm": "122.507", "loss_scale": "32", "train_wall": "348", "gb_free": "32.3", "wall": "41126"}
[2024-07-07 21:42:24,828][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-07 21:47:05,181][train_inner][INFO] - {"epoch": 14, "update": 13.362, "loss": "92.634", "ntokens": "14568.3", "nsentences": "85.32", "nll_loss": "0.543", "wps": "8267", "ups": "0.57", "wpb": "14568.3", "bsz": "85.3", "num_updates": "23400", "lr": "3e-05", "gnorm": "121.434", "loss_scale": "16", "train_wall": "352", "gb_free": "33.6", "wall": "41479"}
[2024-07-07 21:52:59,363][train_inner][INFO] - {"epoch": 14, "update": 13.477, "loss": "93.499", "ntokens": "14622.8", "nsentences": "84.48", "nll_loss": "0.54", "wps": "8257.8", "ups": "0.56", "wpb": "14622.8", "bsz": "84.5", "num_updates": "23600", "lr": "3e-05", "gnorm": "119.932", "loss_scale": "16", "train_wall": "354", "gb_free": "32.1", "wall": "41833"}
[2024-07-07 21:58:49,977][train_inner][INFO] - {"epoch": 14, "update": 13.591, "loss": "94.187", "ntokens": "14560.9", "nsentences": "83.56", "nll_loss": "0.541", "wps": "8306.6", "ups": "0.57", "wpb": "14560.9", "bsz": "83.6", "num_updates": "23800", "lr": "3e-05", "gnorm": "120.394", "loss_scale": "16", "train_wall": "350", "gb_free": "31.7", "wall": "42184"}
[2024-07-07 22:04:40,633][train_inner][INFO] - {"epoch": 14, "update": 13.705, "loss": "88.888", "ntokens": "14691.5", "nsentences": "87.555", "nll_loss": "0.53", "wps": "8380", "ups": "0.57", "wpb": "14691.5", "bsz": "87.6", "num_updates": "24000", "lr": "3e-05", "gnorm": "116.956", "loss_scale": "16", "train_wall": "350", "gb_free": "31.8", "wall": "42534"}
[2024-07-07 22:10:24,573][train_inner][INFO] - {"epoch": 14, "update": 13.819, "loss": "92.948", "ntokens": "14590.7", "nsentences": "85.88", "nll_loss": "0.547", "wps": "8485.1", "ups": "0.58", "wpb": "14590.7", "bsz": "85.9", "num_updates": "24200", "lr": "3e-05", "gnorm": "119.447", "loss_scale": "16", "train_wall": "343", "gb_free": "32.7", "wall": "42878"}
[2024-07-07 22:16:00,294][train_inner][INFO] - {"epoch": 14, "update": 13.933, "loss": "96.094", "ntokens": "14662.9", "nsentences": "85.6", "nll_loss": "0.561", "wps": "8736.9", "ups": "0.6", "wpb": "14662.9", "bsz": "85.6", "num_updates": "24400", "lr": "3e-05", "gnorm": "123.985", "loss_scale": "16", "train_wall": "335", "gb_free": "31.8", "wall": "43214"}
[2024-07-07 22:19:22,844][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 22:19:22,876][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 22:19:54,964][dev-other][INFO] - {"epoch": 14, "dev-other_loss": "21.859", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.232", "dev-other_uer": "3.629", "dev-other_wer": "9.835", "dev-other_raw_wer": "9.835", "dev-other_wps": "8707", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "24517", "dev-other_best_wer": "9.835"}
[2024-07-07 22:19:54,965][fairseq_cli.train][INFO] - end of epoch 14 (average epoch stats below)
[2024-07-07 22:19:54,971][train][INFO] - {"epoch": 14, "train_loss": "93.738", "train_ntokens": "14575.8", "train_nsentences": "84.8515", "train_nll_loss": "0.546", "train_wps": "8296.5", "train_ups": "0.57", "train_wpb": "14575.8", "train_bsz": "84.9", "train_num_updates": "24517", "train_lr": "3e-05", "train_gnorm": "121.336", "train_loss_scale": "16", "train_train_wall": "3038", "train_gb_free": "33.3", "train_wall": "43449"}
[2024-07-07 22:19:54,973][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 22:19:55,670][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-07 22:19:55,675][fairseq.trainer][INFO] - begin training epoch 15
[2024-07-07 22:19:55,675][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 22:22:26,345][train_inner][INFO] - {"epoch": 15, "update": 14.047, "loss": "89.397", "ntokens": "14604.4", "nsentences": "85.88", "nll_loss": "0.526", "wps": "7567.6", "ups": "0.52", "wpb": "14604.4", "bsz": "85.9", "num_updates": "24600", "lr": "3e-05", "gnorm": "118.662", "loss_scale": "16", "train_wall": "353", "gb_free": "32.3", "wall": "43600"}
[2024-07-07 22:23:51,165][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-07 22:28:24,560][train_inner][INFO] - {"epoch": 15, "update": 14.162, "loss": "86.912", "ntokens": "14562.1", "nsentences": "86.92", "nll_loss": "0.519", "wps": "8132.4", "ups": "0.56", "wpb": "14562.1", "bsz": "86.9", "num_updates": "24800", "lr": "3e-05", "gnorm": "115.686", "loss_scale": "8", "train_wall": "358", "gb_free": "32", "wall": "43958"}
[2024-07-07 22:34:14,134][train_inner][INFO] - {"epoch": 15, "update": 14.276, "loss": "91.517", "ntokens": "14591.5", "nsentences": "84.88", "nll_loss": "0.532", "wps": "8348.9", "ups": "0.57", "wpb": "14591.5", "bsz": "84.9", "num_updates": "25000", "lr": "3e-05", "gnorm": "117.838", "loss_scale": "8", "train_wall": "349", "gb_free": "32", "wall": "44308"}
[2024-07-07 22:39:59,819][train_inner][INFO] - {"epoch": 15, "update": 14.39, "loss": "94.932", "ntokens": "14582.6", "nsentences": "83.08", "nll_loss": "0.541", "wps": "8437.1", "ups": "0.58", "wpb": "14582.6", "bsz": "83.1", "num_updates": "25200", "lr": "3e-05", "gnorm": "122.343", "loss_scale": "8", "train_wall": "345", "gb_free": "32.1", "wall": "44654"}
[2024-07-07 22:45:55,976][train_inner][INFO] - {"epoch": 15, "update": 14.505, "loss": "91.419", "ntokens": "14526.1", "nsentences": "83.16", "nll_loss": "0.523", "wps": "8158.6", "ups": "0.56", "wpb": "14526.1", "bsz": "83.2", "num_updates": "25400", "lr": "3e-05", "gnorm": "119.702", "loss_scale": "8", "train_wall": "356", "gb_free": "32", "wall": "45010"}
[2024-07-07 22:51:40,970][train_inner][INFO] - {"epoch": 15, "update": 14.619, "loss": "91.309", "ntokens": "14734.7", "nsentences": "87.835", "nll_loss": "0.544", "wps": "8543.1", "ups": "0.58", "wpb": "14734.7", "bsz": "87.8", "num_updates": "25600", "lr": "3e-05", "gnorm": "119.176", "loss_scale": "8", "train_wall": "344", "gb_free": "32.1", "wall": "45355"}
[2024-07-07 22:57:21,754][train_inner][INFO] - {"epoch": 15, "update": 14.733, "loss": "94.066", "ntokens": "14542.2", "nsentences": "85.8", "nll_loss": "0.555", "wps": "8535.9", "ups": "0.59", "wpb": "14542.2", "bsz": "85.8", "num_updates": "25800", "lr": "3e-05", "gnorm": "121.459", "loss_scale": "8", "train_wall": "340", "gb_free": "33.4", "wall": "45695"}
[2024-07-07 23:03:17,251][train_inner][INFO] - {"epoch": 15, "update": 14.847, "loss": "92.204", "ntokens": "14492.9", "nsentences": "82.32", "nll_loss": "0.524", "wps": "8154.1", "ups": "0.56", "wpb": "14492.9", "bsz": "82.3", "num_updates": "26000", "lr": "3e-05", "gnorm": "121.641", "loss_scale": "8", "train_wall": "355", "gb_free": "31.6", "wall": "46051"}
[2024-07-07 23:09:02,528][train_inner][INFO] - {"epoch": 15, "update": 14.961, "loss": "93.543", "ntokens": "14546.1", "nsentences": "84.48", "nll_loss": "0.543", "wps": "8425.9", "ups": "0.58", "wpb": "14546.1", "bsz": "84.5", "num_updates": "26200", "lr": "3e-05", "gnorm": "119.853", "loss_scale": "8", "train_wall": "345", "gb_free": "31", "wall": "46396"}
[2024-07-07 23:11:04,309][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-07 23:11:04,315][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 23:11:36,572][dev-other][INFO] - {"epoch": 15, "dev-other_loss": "21.35", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.227", "dev-other_uer": "3.568", "dev-other_wer": "9.592", "dev-other_raw_wer": "9.592", "dev-other_wps": "8676.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "26268", "dev-other_best_wer": "9.592"}
[2024-07-07 23:11:36,574][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 15 @ 26268 updates
[2024-07-07 23:11:36,575][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-07 23:11:38,112][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-07 23:11:38,563][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 15 @ 26268 updates, score 9.592) (writing took 1.988920621573925 seconds)
[2024-07-07 23:11:38,563][fairseq_cli.train][INFO] - end of epoch 15 (average epoch stats below)
[2024-07-07 23:11:38,567][train][INFO] - {"epoch": 15, "train_loss": "91.659", "train_ntokens": "14577.8", "train_nsentences": "84.8652", "train_nll_loss": "0.534", "train_wps": "8224.6", "train_ups": "0.56", "train_wpb": "14577.8", "train_bsz": "84.9", "train_num_updates": "26268", "train_lr": "3e-05", "train_gnorm": "119.397", "train_loss_scale": "8", "train_train_wall": "3063", "train_gb_free": "33.3", "train_wall": "46552"}
[2024-07-07 23:11:38,569][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-07 23:11:38,818][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-07 23:11:38,822][fairseq.trainer][INFO] - begin training epoch 16
[2024-07-07 23:11:38,822][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-07 23:15:35,098][train_inner][INFO] - {"epoch": 16, "update": 15.075, "loss": "88.997", "ntokens": "14592.5", "nsentences": "84.8", "nll_loss": "0.517", "wps": "7434.5", "ups": "0.51", "wpb": "14592.5", "bsz": "84.8", "num_updates": "26400", "lr": "3e-05", "gnorm": "116.913", "loss_scale": "8", "train_wall": "357", "gb_free": "31.5", "wall": "46789"}
[2024-07-07 23:21:23,024][train_inner][INFO] - {"epoch": 16, "update": 15.189, "loss": "91.293", "ntokens": "14589.4", "nsentences": "85.16", "nll_loss": "0.533", "wps": "8386.7", "ups": "0.57", "wpb": "14589.4", "bsz": "85.2", "num_updates": "26600", "lr": "3e-05", "gnorm": "120.411", "loss_scale": "8", "train_wall": "347", "gb_free": "32.4", "wall": "47137"}
[2024-07-07 23:27:12,067][train_inner][INFO] - {"epoch": 16, "update": 15.304, "loss": "91.744", "ntokens": "14497.1", "nsentences": "84.075", "nll_loss": "0.532", "wps": "8308.8", "ups": "0.57", "wpb": "14497.1", "bsz": "84.1", "num_updates": "26800", "lr": "3e-05", "gnorm": "121.016", "loss_scale": "16", "train_wall": "348", "gb_free": "32.4", "wall": "47486"}
[2024-07-07 23:33:13,341][train_inner][INFO] - {"epoch": 16, "update": 15.418, "loss": "86.706", "ntokens": "14627.8", "nsentences": "85.96", "nll_loss": "0.51", "wps": "8098.3", "ups": "0.55", "wpb": "14627.8", "bsz": "86", "num_updates": "27000", "lr": "3e-05", "gnorm": "115.137", "loss_scale": "16", "train_wall": "361", "gb_free": "33.3", "wall": "47847"}
[2024-07-07 23:39:05,410][train_inner][INFO] - {"epoch": 16, "update": 15.532, "loss": "91.95", "ntokens": "14613.8", "nsentences": "84.32", "nll_loss": "0.531", "wps": "8301.9", "ups": "0.57", "wpb": "14613.8", "bsz": "84.3", "num_updates": "27200", "lr": "3e-05", "gnorm": "120.309", "loss_scale": "16", "train_wall": "352", "gb_free": "31.5", "wall": "48199"}
[2024-07-07 23:44:47,438][train_inner][INFO] - {"epoch": 16, "update": 15.646, "loss": "92.699", "ntokens": "14637.2", "nsentences": "86.76", "nll_loss": "0.549", "wps": "8559.3", "ups": "0.58", "wpb": "14637.2", "bsz": "86.8", "num_updates": "27400", "lr": "3e-05", "gnorm": "121.741", "loss_scale": "16", "train_wall": "341", "gb_free": "31.7", "wall": "48541"}
[2024-07-07 23:50:45,058][train_inner][INFO] - {"epoch": 16, "update": 15.76, "loss": "93.95", "ntokens": "14558.9", "nsentences": "83.28", "nll_loss": "0.537", "wps": "8142.8", "ups": "0.56", "wpb": "14558.9", "bsz": "83.3", "num_updates": "27600", "lr": "3e-05", "gnorm": "119.323", "loss_scale": "16", "train_wall": "357", "gb_free": "32.9", "wall": "48899"}
[2024-07-07 23:56:32,224][train_inner][INFO] - {"epoch": 16, "update": 15.874, "loss": "91.903", "ntokens": "14574.5", "nsentences": "85.08", "nll_loss": "0.536", "wps": "8396.5", "ups": "0.58", "wpb": "14574.5", "bsz": "85.1", "num_updates": "27800", "lr": "3e-05", "gnorm": "120.303", "loss_scale": "16", "train_wall": "347", "gb_free": "32.6", "wall": "49246"}
[2024-07-08 00:02:24,279][train_inner][INFO] - {"epoch": 16, "update": 15.989, "loss": "88.758", "ntokens": "14540.1", "nsentences": "84.92", "nll_loss": "0.518", "wps": "8262.2", "ups": "0.57", "wpb": "14540.1", "bsz": "84.9", "num_updates": "28000", "lr": "3e-05", "gnorm": "118.538", "loss_scale": "16", "train_wall": "351", "gb_free": "32.7", "wall": "49598"}
[2024-07-08 00:02:58,192][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 00:02:58,194][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 00:03:30,129][dev-other][INFO] - {"epoch": 16, "dev-other_loss": "22.157", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.236", "dev-other_uer": "3.607", "dev-other_wer": "9.655", "dev-other_raw_wer": "9.655", "dev-other_wps": "8742.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "28020", "dev-other_best_wer": "9.592"}
[2024-07-08 00:03:30,129][fairseq_cli.train][INFO] - end of epoch 16 (average epoch stats below)
[2024-07-08 00:03:30,132][train][INFO] - {"epoch": 16, "train_loss": "90.813", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.529", "train_wps": "8208", "train_ups": "0.56", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "28020", "train_lr": "3e-05", "train_gnorm": "119.499", "train_loss_scale": "16", "train_train_wall": "3074", "train_gb_free": "33.7", "train_wall": "49664"}
[2024-07-08 00:03:30,133][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 00:03:30,881][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 00:03:30,884][fairseq.trainer][INFO] - begin training epoch 17
[2024-07-08 00:03:30,885][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 00:06:30,256][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-08 00:08:44,798][train_inner][INFO] - {"epoch": 17, "update": 16.103, "loss": "89.485", "ntokens": "14614.4", "nsentences": "85.56", "nll_loss": "0.524", "wps": "7681.6", "ups": "0.53", "wpb": "14614.4", "bsz": "85.6", "num_updates": "28200", "lr": "3e-05", "gnorm": "121.314", "loss_scale": "8", "train_wall": "347", "gb_free": "32.8", "wall": "49979"}
[2024-07-08 00:14:30,789][train_inner][INFO] - {"epoch": 17, "update": 16.217, "loss": "88.171", "ntokens": "14653.9", "nsentences": "86.92", "nll_loss": "0.523", "wps": "8470.9", "ups": "0.58", "wpb": "14653.9", "bsz": "86.9", "num_updates": "28400", "lr": "3e-05", "gnorm": "117.611", "loss_scale": "8", "train_wall": "345", "gb_free": "33.2", "wall": "50325"}
[2024-07-08 00:20:24,728][train_inner][INFO] - {"epoch": 17, "update": 16.332, "loss": "92.922", "ntokens": "14594.6", "nsentences": "85.48", "nll_loss": "0.544", "wps": "8247.3", "ups": "0.57", "wpb": "14594.6", "bsz": "85.5", "num_updates": "28600", "lr": "3e-05", "gnorm": "117.606", "loss_scale": "8", "train_wall": "353", "gb_free": "31.3", "wall": "50679"}
[2024-07-08 00:26:15,092][train_inner][INFO] - {"epoch": 17, "update": 16.446, "loss": "91.375", "ntokens": "14530.1", "nsentences": "83.72", "nll_loss": "0.526", "wps": "8294.5", "ups": "0.57", "wpb": "14530.1", "bsz": "83.7", "num_updates": "28800", "lr": "3e-05", "gnorm": "121.939", "loss_scale": "8", "train_wall": "350", "gb_free": "31.6", "wall": "51029"}
[2024-07-08 00:32:07,169][train_inner][INFO] - {"epoch": 17, "update": 16.56, "loss": "93.098", "ntokens": "14419.1", "nsentences": "82.28", "nll_loss": "0.531", "wps": "8191", "ups": "0.57", "wpb": "14419.1", "bsz": "82.3", "num_updates": "29000", "lr": "3e-05", "gnorm": "122.824", "loss_scale": "8", "train_wall": "352", "gb_free": "31.5", "wall": "51381"}
[2024-07-08 00:38:00,657][train_inner][INFO] - {"epoch": 17, "update": 16.674, "loss": "89.831", "ntokens": "14562.3", "nsentences": "84.04", "nll_loss": "0.518", "wps": "8240.8", "ups": "0.57", "wpb": "14562.3", "bsz": "84", "num_updates": "29200", "lr": "3e-05", "gnorm": "119.152", "loss_scale": "8", "train_wall": "353", "gb_free": "31.8", "wall": "51734"}
[2024-07-08 00:43:47,523][train_inner][INFO] - {"epoch": 17, "update": 16.788, "loss": "89.268", "ntokens": "14577.8", "nsentences": "87.52", "nll_loss": "0.536", "wps": "8407", "ups": "0.58", "wpb": "14577.8", "bsz": "87.5", "num_updates": "29400", "lr": "3e-05", "gnorm": "119.511", "loss_scale": "8", "train_wall": "346", "gb_free": "32.9", "wall": "52081"}
[2024-07-08 00:49:36,257][train_inner][INFO] - {"epoch": 17, "update": 16.902, "loss": "92.49", "ntokens": "14680.5", "nsentences": "85", "nll_loss": "0.536", "wps": "8419.5", "ups": "0.57", "wpb": "14680.5", "bsz": "85", "num_updates": "29600", "lr": "3e-05", "gnorm": "118.566", "loss_scale": "8", "train_wall": "348", "gb_free": "31.8", "wall": "52430"}
[2024-07-08 00:54:32,778][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 00:54:32,855][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 00:55:04,927][dev-other][INFO] - {"epoch": 17, "dev-other_loss": "21.564", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.229", "dev-other_uer": "3.569", "dev-other_wer": "9.545", "dev-other_raw_wer": "9.545", "dev-other_wps": "8684.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "29771", "dev-other_best_wer": "9.545"}
[2024-07-08 00:55:04,927][fairseq_cli.train][INFO] - end of epoch 17 (average epoch stats below)
[2024-07-08 00:55:04,967][train][INFO] - {"epoch": 17, "train_loss": "91.11", "train_ntokens": "14576.4", "train_nsentences": "84.8241", "train_nll_loss": "0.53", "train_wps": "8247.2", "train_ups": "0.57", "train_wpb": "14576.4", "train_bsz": "84.8", "train_num_updates": "29771", "train_lr": "3e-05", "train_gnorm": "119.952", "train_loss_scale": "8", "train_train_wall": "3057", "train_gb_free": "32.9", "train_wall": "52759"}
[2024-07-08 00:55:04,969][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 00:55:05,674][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 00:55:05,678][fairseq.trainer][INFO] - begin training epoch 18
[2024-07-08 00:55:05,678][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 00:55:56,201][train_inner][INFO] - {"epoch": 18, "update": 17.017, "loss": "92.699", "ntokens": "14458.3", "nsentences": "82.475", "nll_loss": "0.529", "wps": "7612", "ups": "0.53", "wpb": "14458.3", "bsz": "82.5", "num_updates": "29800", "lr": "3e-05", "gnorm": "121.942", "loss_scale": "8", "train_wall": "346", "gb_free": "33.4", "wall": "52810"}
[2024-07-08 01:01:46,907][train_inner][INFO] - {"epoch": 18, "update": 17.131, "loss": "89.68", "ntokens": "14621.4", "nsentences": "85.755", "nll_loss": "0.526", "wps": "8339.9", "ups": "0.57", "wpb": "14621.4", "bsz": "85.8", "num_updates": "30000", "lr": "3e-05", "gnorm": "118.839", "loss_scale": "8", "train_wall": "350", "gb_free": "33.3", "wall": "53161"}
[2024-07-08 01:07:39,796][train_inner][INFO] - {"epoch": 18, "update": 17.245, "loss": "87.577", "ntokens": "14578.3", "nsentences": "85.12", "nll_loss": "0.511", "wps": "8262.7", "ups": "0.57", "wpb": "14578.3", "bsz": "85.1", "num_updates": "30200", "lr": "3e-05", "gnorm": "117.64", "loss_scale": "16", "train_wall": "352", "gb_free": "30.1", "wall": "53514"}
[2024-07-08 01:13:28,274][train_inner][INFO] - {"epoch": 18, "update": 17.359, "loss": "87.628", "ntokens": "14604.9", "nsentences": "84.92", "nll_loss": "0.51", "wps": "8382.8", "ups": "0.57", "wpb": "14604.9", "bsz": "84.9", "num_updates": "30400", "lr": "3e-05", "gnorm": "118.988", "loss_scale": "16", "train_wall": "348", "gb_free": "32.1", "wall": "53862"}
[2024-07-08 01:19:05,889][train_inner][INFO] - {"epoch": 18, "update": 17.473, "loss": "90.848", "ntokens": "14657.5", "nsentences": "86.4", "nll_loss": "0.536", "wps": "8684.8", "ups": "0.59", "wpb": "14657.5", "bsz": "86.4", "num_updates": "30600", "lr": "3e-05", "gnorm": "120.431", "loss_scale": "16", "train_wall": "337", "gb_free": "32.4", "wall": "54200"}
[2024-07-08 01:24:59,690][train_inner][INFO] - {"epoch": 18, "update": 17.587, "loss": "91.793", "ntokens": "14430.2", "nsentences": "80.92", "nll_loss": "0.515", "wps": "8158.8", "ups": "0.57", "wpb": "14430.2", "bsz": "80.9", "num_updates": "30800", "lr": "3e-05", "gnorm": "122.486", "loss_scale": "16", "train_wall": "353", "gb_free": "32.1", "wall": "54553"}
[2024-07-08 01:30:44,121][train_inner][INFO] - {"epoch": 18, "update": 17.701, "loss": "89.961", "ntokens": "14591.8", "nsentences": "85.84", "nll_loss": "0.529", "wps": "8473.4", "ups": "0.58", "wpb": "14591.8", "bsz": "85.8", "num_updates": "31000", "lr": "3e-05", "gnorm": "119.661", "loss_scale": "16", "train_wall": "344", "gb_free": "32", "wall": "54898"}
[2024-07-08 01:36:30,495][train_inner][INFO] - {"epoch": 18, "update": 17.816, "loss": "91.233", "ntokens": "14665.9", "nsentences": "84.84", "nll_loss": "0.528", "wps": "8468.4", "ups": "0.58", "wpb": "14665.9", "bsz": "84.8", "num_updates": "31200", "lr": "3e-05", "gnorm": "122.123", "loss_scale": "16", "train_wall": "346", "gb_free": "30.6", "wall": "55244"}
[2024-07-08 01:42:25,182][train_inner][INFO] - {"epoch": 18, "update": 17.93, "loss": "85.037", "ntokens": "14545", "nsentences": "85.48", "nll_loss": "0.5", "wps": "8202.2", "ups": "0.56", "wpb": "14545", "bsz": "85.5", "num_updates": "31400", "lr": "3e-05", "gnorm": "116.132", "loss_scale": "16", "train_wall": "354", "gb_free": "32.4", "wall": "55599"}
[2024-07-08 01:46:08,726][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 01:46:08,731][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 01:46:40,829][dev-other][INFO] - {"epoch": 18, "dev-other_loss": "21.507", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.229", "dev-other_uer": "3.593", "dev-other_wer": "9.549", "dev-other_raw_wer": "9.549", "dev-other_wps": "8685.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "31523", "dev-other_best_wer": "9.549"}
[2024-07-08 01:46:40,830][fairseq_cli.train][INFO] - end of epoch 18 (average epoch stats below)
[2024-07-08 01:46:40,855][train][INFO] - {"epoch": 18, "train_loss": "88.869", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.517", "train_wps": "8249.7", "train_ups": "0.57", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "31523", "train_lr": "3e-05", "train_gnorm": "119.268", "train_loss_scale": "16", "train_train_wall": "3058", "train_gb_free": "31.6", "train_wall": "55855"}
[2024-07-08 01:46:40,856][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 01:46:41,570][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 01:46:41,574][fairseq.trainer][INFO] - begin training epoch 19
[2024-07-08 01:46:41,574][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 01:48:56,200][train_inner][INFO] - {"epoch": 19, "update": 18.044, "loss": "86.51", "ntokens": "14607.3", "nsentences": "85.36", "nll_loss": "0.506", "wps": "7471.6", "ups": "0.51", "wpb": "14607.3", "bsz": "85.4", "num_updates": "31600", "lr": "3e-05", "gnorm": "115.144", "loss_scale": "16", "train_wall": "357", "gb_free": "32.6", "wall": "55990"}
[2024-07-08 01:54:41,884][train_inner][INFO] - {"epoch": 19, "update": 18.158, "loss": "91.419", "ntokens": "14568.1", "nsentences": "84.52", "nll_loss": "0.53", "wps": "8428.8", "ups": "0.58", "wpb": "14568.1", "bsz": "84.5", "num_updates": "31800", "lr": "3e-05", "gnorm": "119.104", "loss_scale": "16", "train_wall": "345", "gb_free": "33.4", "wall": "56336"}
[2024-07-08 02:00:32,204][train_inner][INFO] - {"epoch": 19, "update": 18.272, "loss": "91.89", "ntokens": "14461.3", "nsentences": "82.955", "nll_loss": "0.527", "wps": "8256.2", "ups": "0.57", "wpb": "14461.3", "bsz": "83", "num_updates": "32000", "lr": "3e-05", "gnorm": "122.15", "loss_scale": "16", "train_wall": "350", "gb_free": "29.2", "wall": "56686"}
[2024-07-08 02:06:14,664][train_inner][INFO] - {"epoch": 19, "update": 18.386, "loss": "87.417", "ntokens": "14694.8", "nsentences": "88.2", "nll_loss": "0.525", "wps": "8582.1", "ups": "0.58", "wpb": "14694.8", "bsz": "88.2", "num_updates": "32200", "lr": "3e-05", "gnorm": "118.54", "loss_scale": "16", "train_wall": "342", "gb_free": "32.3", "wall": "57028"}
[2024-07-08 02:12:03,962][train_inner][INFO] - {"epoch": 19, "update": 18.501, "loss": "85.045", "ntokens": "14623.9", "nsentences": "86.68", "nll_loss": "0.504", "wps": "8373.5", "ups": "0.57", "wpb": "14623.9", "bsz": "86.7", "num_updates": "32400", "lr": "3e-05", "gnorm": "117.003", "loss_scale": "32", "train_wall": "349", "gb_free": "31.8", "wall": "57378"}
[2024-07-08 02:17:52,214][train_inner][INFO] - {"epoch": 19, "update": 18.615, "loss": "87.316", "ntokens": "14538.2", "nsentences": "84.52", "nll_loss": "0.508", "wps": "8350.9", "ups": "0.57", "wpb": "14538.2", "bsz": "84.5", "num_updates": "32600", "lr": "3e-05", "gnorm": "118.431", "loss_scale": "32", "train_wall": "348", "gb_free": "32.2", "wall": "57726"}
[2024-07-08 02:23:16,976][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-08 02:23:41,531][train_inner][INFO] - {"epoch": 19, "update": 18.729, "loss": "88.803", "ntokens": "14623.2", "nsentences": "85", "nll_loss": "0.516", "wps": "8374.4", "ups": "0.57", "wpb": "14623.2", "bsz": "85", "num_updates": "32800", "lr": "3e-05", "gnorm": "119.867", "loss_scale": "16", "train_wall": "349", "gb_free": "31.7", "wall": "58075"}
[2024-07-08 02:29:35,850][train_inner][INFO] - {"epoch": 19, "update": 18.844, "loss": "90.851", "ntokens": "14528.5", "nsentences": "83.28", "nll_loss": "0.521", "wps": "8202.3", "ups": "0.56", "wpb": "14528.5", "bsz": "83.3", "num_updates": "33000", "lr": "3e-05", "gnorm": "119.471", "loss_scale": "16", "train_wall": "354", "gb_free": "31", "wall": "58430"}
[2024-07-08 02:35:25,983][train_inner][INFO] - {"epoch": 19, "update": 18.958, "loss": "88.526", "ntokens": "14583.6", "nsentences": "83.76", "nll_loss": "0.508", "wps": "8332", "ups": "0.57", "wpb": "14583.6", "bsz": "83.8", "num_updates": "33200", "lr": "3e-05", "gnorm": "119.496", "loss_scale": "16", "train_wall": "350", "gb_free": "32.7", "wall": "58780"}
[2024-07-08 02:37:33,169][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 02:37:33,243][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 02:38:05,309][dev-other][INFO] - {"epoch": 19, "dev-other_loss": "22.032", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.234", "dev-other_uer": "3.515", "dev-other_wer": "9.345", "dev-other_raw_wer": "9.345", "dev-other_wps": "8686.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "33274", "dev-other_best_wer": "9.345"}
[2024-07-08 02:38:05,310][fairseq_cli.train][INFO] - end of epoch 19 (average epoch stats below)
[2024-07-08 02:38:05,315][train][INFO] - {"epoch": 19, "train_loss": "89.212", "train_ntokens": "14577.5", "train_nsentences": "84.8698", "train_nll_loss": "0.519", "train_wps": "8275.4", "train_ups": "0.57", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "33274", "train_lr": "3e-05", "train_gnorm": "119.343", "train_loss_scale": "16", "train_train_wall": "3046", "train_gb_free": "32.2", "train_wall": "58939"}
[2024-07-08 02:38:05,317][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 02:38:06,022][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 02:38:06,024][fairseq.trainer][INFO] - begin training epoch 20
[2024-07-08 02:38:06,025][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 02:41:46,326][train_inner][INFO] - {"epoch": 20, "update": 19.072, "loss": "86.688", "ntokens": "14600.7", "nsentences": "87.12", "nll_loss": "0.517", "wps": "7679.5", "ups": "0.53", "wpb": "14600.7", "bsz": "87.1", "num_updates": "33400", "lr": "3e-05", "gnorm": "118.369", "loss_scale": "16", "train_wall": "347", "gb_free": "31.4", "wall": "59160"}
[2024-07-08 02:47:35,077][train_inner][INFO] - {"epoch": 20, "update": 19.186, "loss": "87.439", "ntokens": "14586.8", "nsentences": "84.8", "nll_loss": "0.508", "wps": "8366.9", "ups": "0.57", "wpb": "14586.8", "bsz": "84.8", "num_updates": "33600", "lr": "3e-05", "gnorm": "118.315", "loss_scale": "16", "train_wall": "348", "gb_free": "32.2", "wall": "59509"}
[2024-07-08 02:53:31,843][train_inner][INFO] - {"epoch": 20, "update": 19.3, "loss": "82.717", "ntokens": "14623.2", "nsentences": "87.6", "nll_loss": "0.496", "wps": "8199.4", "ups": "0.56", "wpb": "14623.2", "bsz": "87.6", "num_updates": "33800", "lr": "3e-05", "gnorm": "112.887", "loss_scale": "16", "train_wall": "356", "gb_free": "32.2", "wall": "59866"}
[2024-07-08 02:59:21,099][train_inner][INFO] - {"epoch": 20, "update": 19.414, "loss": "88.538", "ntokens": "14555.1", "nsentences": "84.24", "nll_loss": "0.512", "wps": "8337.4", "ups": "0.57", "wpb": "14555.1", "bsz": "84.2", "num_updates": "34000", "lr": "3e-05", "gnorm": "119.483", "loss_scale": "16", "train_wall": "349", "gb_free": "32.2", "wall": "60215"}
[2024-07-08 03:05:11,277][train_inner][INFO] - {"epoch": 20, "update": 19.529, "loss": "90.815", "ntokens": "14570.5", "nsentences": "83.72", "nll_loss": "0.522", "wps": "8323.8", "ups": "0.57", "wpb": "14570.5", "bsz": "83.7", "num_updates": "34200", "lr": "3e-05", "gnorm": "119.22", "loss_scale": "16", "train_wall": "350", "gb_free": "31.5", "wall": "60565"}
[2024-07-08 03:11:09,433][train_inner][INFO] - {"epoch": 20, "update": 19.643, "loss": "86.585", "ntokens": "14530.9", "nsentences": "83.755", "nll_loss": "0.499", "wps": "8116.1", "ups": "0.56", "wpb": "14530.9", "bsz": "83.8", "num_updates": "34400", "lr": "3e-05", "gnorm": "116.598", "loss_scale": "16", "train_wall": "358", "gb_free": "31.2", "wall": "60923"}
[2024-07-08 03:17:00,145][train_inner][INFO] - {"epoch": 20, "update": 19.757, "loss": "88.292", "ntokens": "14611.4", "nsentences": "84.08", "nll_loss": "0.508", "wps": "8332.7", "ups": "0.57", "wpb": "14611.4", "bsz": "84.1", "num_updates": "34600", "lr": "3e-05", "gnorm": "119.599", "loss_scale": "16", "train_wall": "350", "gb_free": "31.3", "wall": "61274"}
[2024-07-08 03:22:46,760][train_inner][INFO] - {"epoch": 20, "update": 19.871, "loss": "87.731", "ntokens": "14579.1", "nsentences": "84.76", "nll_loss": "0.51", "wps": "8413.8", "ups": "0.58", "wpb": "14579.1", "bsz": "84.8", "num_updates": "34800", "lr": "3e-05", "gnorm": "118.528", "loss_scale": "16", "train_wall": "346", "gb_free": "31.6", "wall": "61620"}
[2024-07-08 03:24:04,153][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-08 03:28:36,271][train_inner][INFO] - {"epoch": 20, "update": 19.986, "loss": "92.542", "ntokens": "14529.9", "nsentences": "83.2", "nll_loss": "0.53", "wps": "8316.5", "ups": "0.57", "wpb": "14529.9", "bsz": "83.2", "num_updates": "35000", "lr": "3e-05", "gnorm": "125.724", "loss_scale": "16", "train_wall": "349", "gb_free": "32.9", "wall": "61970"}
[2024-07-08 03:29:19,302][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 03:29:19,304][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 03:29:51,424][dev-other][INFO] - {"epoch": 20, "dev-other_loss": "21.394", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.227", "dev-other_uer": "3.524", "dev-other_wer": "9.439", "dev-other_raw_wer": "9.439", "dev-other_wps": "8710.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "35025", "dev-other_best_wer": "9.439"}
[2024-07-08 03:29:51,426][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 20 @ 35025 updates
[2024-07-08 03:29:51,427][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-08 03:29:52,994][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-08 03:29:53,611][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 20 @ 35025 updates, score 9.439) (writing took 2.1851330623030663 seconds)
[2024-07-08 03:29:53,611][fairseq_cli.train][INFO] - end of epoch 20 (average epoch stats below)
[2024-07-08 03:29:53,617][train][INFO] - {"epoch": 20, "train_loss": "87.509", "train_ntokens": "14576.9", "train_nsentences": "84.8515", "train_nll_loss": "0.509", "train_wps": "8211.6", "train_ups": "0.56", "train_wpb": "14576.9", "train_bsz": "84.9", "train_num_updates": "35025", "train_lr": "3e-05", "train_gnorm": "118.488", "train_loss_scale": "16", "train_train_wall": "3068", "train_gb_free": "32.2", "train_wall": "62047"}
[2024-07-08 03:29:53,619][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 03:29:53,886][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 03:29:53,891][fairseq.trainer][INFO] - begin training epoch 21
[2024-07-08 03:29:53,891][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 03:34:51,129][train_inner][INFO] - {"epoch": 21, "update": 20.1, "loss": "87.213", "ntokens": "14486.5", "nsentences": "84.84", "nll_loss": "0.511", "wps": "7730.6", "ups": "0.53", "wpb": "14486.5", "bsz": "84.8", "num_updates": "35200", "lr": "3e-05", "gnorm": "118.696", "loss_scale": "16", "train_wall": "340", "gb_free": "31.3", "wall": "62345"}
[2024-07-08 03:40:39,646][train_inner][INFO] - {"epoch": 21, "update": 20.214, "loss": "88.546", "ntokens": "14468.2", "nsentences": "82.04", "nll_loss": "0.502", "wps": "8304.8", "ups": "0.57", "wpb": "14468.2", "bsz": "82", "num_updates": "35400", "lr": "3e-05", "gnorm": "120.836", "loss_scale": "16", "train_wall": "348", "gb_free": "29.9", "wall": "62693"}
[2024-07-08 03:46:34,177][train_inner][INFO] - {"epoch": 21, "update": 20.328, "loss": "87.962", "ntokens": "14556.1", "nsentences": "84.2", "nll_loss": "0.509", "wps": "8213.3", "ups": "0.56", "wpb": "14556.1", "bsz": "84.2", "num_updates": "35600", "lr": "3e-05", "gnorm": "118.211", "loss_scale": "16", "train_wall": "354", "gb_free": "33.2", "wall": "63048"}
[2024-07-08 03:52:17,615][train_inner][INFO] - {"epoch": 21, "update": 20.442, "loss": "86.615", "ntokens": "14649.8", "nsentences": "87.44", "nll_loss": "0.517", "wps": "8533.3", "ups": "0.58", "wpb": "14649.8", "bsz": "87.4", "num_updates": "35800", "lr": "3e-05", "gnorm": "118.872", "loss_scale": "16", "train_wall": "343", "gb_free": "31.1", "wall": "63391"}
[2024-07-08 03:58:17,965][train_inner][INFO] - {"epoch": 21, "update": 20.557, "loss": "86.049", "ntokens": "14549.8", "nsentences": "83.755", "nll_loss": "0.495", "wps": "8075.6", "ups": "0.56", "wpb": "14549.8", "bsz": "83.8", "num_updates": "36000", "lr": "3e-05", "gnorm": "115.883", "loss_scale": "16", "train_wall": "360", "gb_free": "29.4", "wall": "63752"}
[2024-07-08 04:04:14,038][train_inner][INFO] - {"epoch": 21, "update": 20.671, "loss": "84.983", "ntokens": "14624.4", "nsentences": "84.96", "nll_loss": "0.494", "wps": "8216", "ups": "0.56", "wpb": "14624.4", "bsz": "85", "num_updates": "36200", "lr": "3e-05", "gnorm": "117.397", "loss_scale": "16", "train_wall": "355", "gb_free": "32.6", "wall": "64108"}
[2024-07-08 04:10:03,923][train_inner][INFO] - {"epoch": 21, "update": 20.785, "loss": "85.768", "ntokens": "14668", "nsentences": "86.44", "nll_loss": "0.505", "wps": "8386.2", "ups": "0.57", "wpb": "14668", "bsz": "86.4", "num_updates": "36400", "lr": "3e-05", "gnorm": "119.023", "loss_scale": "16", "train_wall": "349", "gb_free": "30.5", "wall": "64458"}
[2024-07-08 04:15:53,768][train_inner][INFO] - {"epoch": 21, "update": 20.899, "loss": "86.701", "ntokens": "14590", "nsentences": "85.04", "nll_loss": "0.505", "wps": "8342.6", "ups": "0.57", "wpb": "14590.1", "bsz": "85", "num_updates": "36600", "lr": "3e-05", "gnorm": "117.412", "loss_scale": "16", "train_wall": "349", "gb_free": "32.2", "wall": "64807"}
[2024-07-08 04:21:01,119][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 04:21:01,194][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 04:21:33,308][dev-other][INFO] - {"epoch": 21, "dev-other_loss": "21.091", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.224", "dev-other_uer": "3.514", "dev-other_wer": "9.388", "dev-other_raw_wer": "9.388", "dev-other_wps": "8687.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "36777", "dev-other_best_wer": "9.388"}
[2024-07-08 04:21:33,309][fairseq_cli.train][INFO] - end of epoch 21 (average epoch stats below)
[2024-07-08 04:21:33,315][train][INFO] - {"epoch": 21, "train_loss": "86.774", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.505", "train_wps": "8239.5", "train_ups": "0.57", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "36777", "train_lr": "3e-05", "train_gnorm": "118.306", "train_loss_scale": "16", "train_train_wall": "3062", "train_gb_free": "33.5", "train_wall": "65147"}
[2024-07-08 04:21:33,317][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 04:21:34,012][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 04:21:34,016][fairseq.trainer][INFO] - begin training epoch 22
[2024-07-08 04:21:34,017][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 04:22:16,689][train_inner][INFO] - {"epoch": 22, "update": 21.013, "loss": "86.371", "ntokens": "14537.2", "nsentences": "84.52", "nll_loss": "0.502", "wps": "7594.3", "ups": "0.52", "wpb": "14537.2", "bsz": "84.5", "num_updates": "36800", "lr": "3e-05", "gnorm": "118.941", "loss_scale": "16", "train_wall": "349", "gb_free": "31.8", "wall": "65190"}
[2024-07-08 04:25:25,927][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-08 04:28:12,385][train_inner][INFO] - {"epoch": 22, "update": 21.128, "loss": "86.012", "ntokens": "14533.3", "nsentences": "84.84", "nll_loss": "0.502", "wps": "8173.6", "ups": "0.56", "wpb": "14533.3", "bsz": "84.8", "num_updates": "37000", "lr": "3e-05", "gnorm": "116.605", "loss_scale": "16", "train_wall": "355", "gb_free": "32.3", "wall": "65546"}
[2024-07-08 04:34:03,095][train_inner][INFO] - {"epoch": 22, "update": 21.242, "loss": "84.059", "ntokens": "14614.2", "nsentences": "84.68", "nll_loss": "0.487", "wps": "8336", "ups": "0.57", "wpb": "14614.2", "bsz": "84.7", "num_updates": "37200", "lr": "3e-05", "gnorm": "118.256", "loss_scale": "16", "train_wall": "350", "gb_free": "32.1", "wall": "65897"}
[2024-07-08 04:39:55,885][train_inner][INFO] - {"epoch": 22, "update": 21.356, "loss": "83.772", "ntokens": "14613", "nsentences": "86.8", "nll_loss": "0.498", "wps": "8286", "ups": "0.57", "wpb": "14613", "bsz": "86.8", "num_updates": "37400", "lr": "3e-05", "gnorm": "115.697", "loss_scale": "16", "train_wall": "352", "gb_free": "31.5", "wall": "66250"}
[2024-07-08 04:45:50,909][train_inner][INFO] - {"epoch": 22, "update": 21.47, "loss": "88.381", "ntokens": "14636", "nsentences": "83.84", "nll_loss": "0.506", "wps": "8245.4", "ups": "0.56", "wpb": "14636", "bsz": "83.8", "num_updates": "37600", "lr": "3e-05", "gnorm": "118.152", "loss_scale": "16", "train_wall": "354", "gb_free": "31", "wall": "66605"}
[2024-07-08 04:51:40,325][train_inner][INFO] - {"epoch": 22, "update": 21.584, "loss": "86.51", "ntokens": "14679.1", "nsentences": "86.155", "nll_loss": "0.508", "wps": "8403.8", "ups": "0.57", "wpb": "14679.1", "bsz": "86.2", "num_updates": "37800", "lr": "3e-05", "gnorm": "116.79", "loss_scale": "16", "train_wall": "349", "gb_free": "30.5", "wall": "66954"}
[2024-07-08 04:57:14,560][train_inner][INFO] - {"epoch": 22, "update": 21.699, "loss": "88.905", "ntokens": "14623.7", "nsentences": "86", "nll_loss": "0.523", "wps": "8750.9", "ups": "0.6", "wpb": "14623.7", "bsz": "86", "num_updates": "38000", "lr": "3e-05", "gnorm": "119.955", "loss_scale": "16", "train_wall": "334", "gb_free": "31.7", "wall": "67288"}
[2024-07-08 05:03:06,230][train_inner][INFO] - {"epoch": 22, "update": 21.813, "loss": "84.567", "ntokens": "14507.6", "nsentences": "83.96", "nll_loss": "0.489", "wps": "8252.4", "ups": "0.57", "wpb": "14507.6", "bsz": "84", "num_updates": "38200", "lr": "3e-05", "gnorm": "117.578", "loss_scale": "16", "train_wall": "351", "gb_free": "32.1", "wall": "67640"}
[2024-07-08 05:08:57,345][train_inner][INFO] - {"epoch": 22, "update": 21.927, "loss": "85.03", "ntokens": "14555.1", "nsentences": "84", "nll_loss": "0.491", "wps": "8291", "ups": "0.57", "wpb": "14555.1", "bsz": "84", "num_updates": "38400", "lr": "3e-05", "gnorm": "118.428", "loss_scale": "16", "train_wall": "351", "gb_free": "31.9", "wall": "67991"}
[2024-07-08 05:12:40,765][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 05:12:40,839][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 05:13:12,877][dev-other][INFO] - {"epoch": 22, "dev-other_loss": "20.805", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.221", "dev-other_uer": "3.507", "dev-other_wer": "9.35", "dev-other_raw_wer": "9.35", "dev-other_wps": "8709.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "38528", "dev-other_best_wer": "9.35"}
[2024-07-08 05:13:12,878][fairseq_cli.train][INFO] - end of epoch 22 (average epoch stats below)
[2024-07-08 05:13:12,882][train][INFO] - {"epoch": 22, "train_loss": "85.909", "train_ntokens": "14578.2", "train_nsentences": "84.8195", "train_nll_loss": "0.5", "train_wps": "8235.5", "train_ups": "0.56", "train_wpb": "14578.2", "train_bsz": "84.8", "train_num_updates": "38528", "train_lr": "3e-05", "train_gnorm": "117.993", "train_loss_scale": "16", "train_train_wall": "3061", "train_gb_free": "32.9", "train_wall": "68247"}
[2024-07-08 05:13:12,884][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 05:13:13,579][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 05:13:13,582][fairseq.trainer][INFO] - begin training epoch 23
[2024-07-08 05:13:13,583][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 05:15:21,813][train_inner][INFO] - {"epoch": 23, "update": 22.041, "loss": "85.152", "ntokens": "14451.7", "nsentences": "83.88", "nll_loss": "0.494", "wps": "7519.2", "ups": "0.52", "wpb": "14451.7", "bsz": "83.9", "num_updates": "38600", "lr": "3e-05", "gnorm": "118.842", "loss_scale": "16", "train_wall": "351", "gb_free": "31.6", "wall": "68376"}
[2024-07-08 05:21:10,498][train_inner][INFO] - {"epoch": 23, "update": 22.155, "loss": "89.573", "ntokens": "14570.4", "nsentences": "83.555", "nll_loss": "0.514", "wps": "8359.3", "ups": "0.57", "wpb": "14570.4", "bsz": "83.6", "num_updates": "38800", "lr": "3e-05", "gnorm": "120.126", "loss_scale": "16", "train_wall": "348", "gb_free": "32", "wall": "68724"}
[2024-07-08 05:26:54,906][train_inner][INFO] - {"epoch": 23, "update": 22.269, "loss": "83.744", "ntokens": "14612.1", "nsentences": "87.64", "nll_loss": "0.502", "wps": "8487.2", "ups": "0.58", "wpb": "14612.1", "bsz": "87.6", "num_updates": "39000", "lr": "3e-05", "gnorm": "115.121", "loss_scale": "32", "train_wall": "344", "gb_free": "31.9", "wall": "69069"}
[2024-07-08 05:32:47,529][train_inner][INFO] - {"epoch": 23, "update": 22.384, "loss": "84.544", "ntokens": "14508.9", "nsentences": "85.08", "nll_loss": "0.496", "wps": "8230.9", "ups": "0.57", "wpb": "14508.9", "bsz": "85.1", "num_updates": "39200", "lr": "3e-05", "gnorm": "117.619", "loss_scale": "32", "train_wall": "352", "gb_free": "32.4", "wall": "69421"}
[2024-07-08 05:33:14,770][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-08 05:38:47,925][train_inner][INFO] - {"epoch": 23, "update": 22.498, "loss": "86.062", "ntokens": "14521.5", "nsentences": "82.36", "nll_loss": "0.488", "wps": "8060.6", "ups": "0.56", "wpb": "14521.5", "bsz": "82.4", "num_updates": "39400", "lr": "3e-05", "gnorm": "117.086", "loss_scale": "16", "train_wall": "360", "gb_free": "29.3", "wall": "69782"}
[2024-07-08 05:44:44,585][train_inner][INFO] - {"epoch": 23, "update": 22.612, "loss": "87.05", "ntokens": "14661.7", "nsentences": "85.24", "nll_loss": "0.506", "wps": "8223.4", "ups": "0.56", "wpb": "14661.7", "bsz": "85.2", "num_updates": "39600", "lr": "3e-05", "gnorm": "119.232", "loss_scale": "16", "train_wall": "356", "gb_free": "30.1", "wall": "70138"}
[2024-07-08 05:50:35,255][train_inner][INFO] - {"epoch": 23, "update": 22.727, "loss": "85.622", "ntokens": "14731.8", "nsentences": "84.92", "nll_loss": "0.494", "wps": "8403.8", "ups": "0.57", "wpb": "14731.8", "bsz": "84.9", "num_updates": "39800", "lr": "3e-05", "gnorm": "118.592", "loss_scale": "16", "train_wall": "350", "gb_free": "31.8", "wall": "70489"}
[2024-07-08 05:56:25,009][train_inner][INFO] - {"epoch": 23, "update": 22.841, "loss": "87.215", "ntokens": "14531", "nsentences": "84.04", "nll_loss": "0.504", "wps": "8311.2", "ups": "0.57", "wpb": "14531", "bsz": "84", "num_updates": "40000", "lr": "3e-05", "gnorm": "120.189", "loss_scale": "16", "train_wall": "349", "gb_free": "31.7", "wall": "70839"}
[2024-07-08 06:02:14,114][train_inner][INFO] - {"epoch": 23, "update": 22.955, "loss": "85.977", "ntokens": "14554.2", "nsentences": "85.44", "nll_loss": "0.505", "wps": "8340.1", "ups": "0.57", "wpb": "14554.2", "bsz": "85.4", "num_updates": "40200", "lr": "3e-05", "gnorm": "118.3", "loss_scale": "16", "train_wall": "348", "gb_free": "30", "wall": "71188"}
[2024-07-08 06:04:27,440][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 06:04:27,512][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 06:04:59,501][dev-other][INFO] - {"epoch": 23, "dev-other_loss": "21.466", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.228", "dev-other_uer": "3.531", "dev-other_wer": "9.362", "dev-other_raw_wer": "9.362", "dev-other_wps": "8728.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "40279", "dev-other_best_wer": "9.362"}
[2024-07-08 06:04:59,502][fairseq_cli.train][INFO] - end of epoch 23 (average epoch stats below)
[2024-07-08 06:04:59,506][train][INFO] - {"epoch": 23, "train_loss": "86.073", "train_ntokens": "14577.7", "train_nsentences": "84.8698", "train_nll_loss": "0.501", "train_wps": "8216.5", "train_ups": "0.56", "train_wpb": "14577.7", "train_bsz": "84.9", "train_num_updates": "40279", "train_lr": "3e-05", "train_gnorm": "118.156", "train_loss_scale": "16", "train_train_wall": "3068", "train_gb_free": "33", "train_wall": "71353"}
[2024-07-08 06:04:59,508][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 06:05:00,206][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 06:05:00,210][fairseq.trainer][INFO] - begin training epoch 24
[2024-07-08 06:05:00,210][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 06:08:38,025][train_inner][INFO] - {"epoch": 24, "update": 23.069, "loss": "83.531", "ntokens": "14489.4", "nsentences": "85.315", "nll_loss": "0.492", "wps": "7549.8", "ups": "0.52", "wpb": "14489.4", "bsz": "85.3", "num_updates": "40400", "lr": "3e-05", "gnorm": "116.101", "loss_scale": "16", "train_wall": "350", "gb_free": "31.3", "wall": "71572"}
[2024-07-08 06:14:23,590][train_inner][INFO] - {"epoch": 24, "update": 23.183, "loss": "88.56", "ntokens": "14606.2", "nsentences": "83.52", "nll_loss": "0.506", "wps": "8454", "ups": "0.58", "wpb": "14606.2", "bsz": "83.5", "num_updates": "40600", "lr": "3e-05", "gnorm": "120.338", "loss_scale": "16", "train_wall": "345", "gb_free": "33", "wall": "71917"}
[2024-07-08 06:20:14,029][train_inner][INFO] - {"epoch": 24, "update": 23.297, "loss": "83.17", "ntokens": "14559.3", "nsentences": "86", "nll_loss": "0.491", "wps": "8309.4", "ups": "0.57", "wpb": "14559.3", "bsz": "86", "num_updates": "40800", "lr": "3e-05", "gnorm": "116.109", "loss_scale": "16", "train_wall": "350", "gb_free": "31.4", "wall": "72268"}
[2024-07-08 06:26:03,877][train_inner][INFO] - {"epoch": 24, "update": 23.412, "loss": "84.319", "ntokens": "14569.6", "nsentences": "84.96", "nll_loss": "0.492", "wps": "8331", "ups": "0.57", "wpb": "14569.6", "bsz": "85", "num_updates": "41000", "lr": "3e-05", "gnorm": "117.242", "loss_scale": "16", "train_wall": "349", "gb_free": "32.7", "wall": "72618"}
[2024-07-08 06:31:56,438][train_inner][INFO] - {"epoch": 24, "update": 23.526, "loss": "83.473", "ntokens": "14496.5", "nsentences": "85.52", "nll_loss": "0.492", "wps": "8225.4", "ups": "0.57", "wpb": "14496.5", "bsz": "85.5", "num_updates": "41200", "lr": "3e-05", "gnorm": "118.904", "loss_scale": "16", "train_wall": "352", "gb_free": "31.9", "wall": "72970"}
[2024-07-08 06:34:29,592][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-08 06:37:46,308][train_inner][INFO] - {"epoch": 24, "update": 23.64, "loss": "84.871", "ntokens": "14662.5", "nsentences": "85.24", "nll_loss": "0.493", "wps": "8383.2", "ups": "0.57", "wpb": "14662.5", "bsz": "85.2", "num_updates": "41400", "lr": "3e-05", "gnorm": "117.425", "loss_scale": "16", "train_wall": "349", "gb_free": "31.8", "wall": "73320"}
[2024-07-08 06:43:32,091][train_inner][INFO] - {"epoch": 24, "update": 23.755, "loss": "85.901", "ntokens": "14564.3", "nsentences": "84.2", "nll_loss": "0.497", "wps": "8425.8", "ups": "0.58", "wpb": "14564.3", "bsz": "84.2", "num_updates": "41600", "lr": "3e-05", "gnorm": "119.305", "loss_scale": "16", "train_wall": "345", "gb_free": "32.5", "wall": "73666"}
[2024-07-08 06:49:27,830][train_inner][INFO] - {"epoch": 24, "update": 23.869, "loss": "83.123", "ntokens": "14627.8", "nsentences": "85.28", "nll_loss": "0.485", "wps": "8225.9", "ups": "0.56", "wpb": "14627.8", "bsz": "85.3", "num_updates": "41800", "lr": "3e-05", "gnorm": "116.7", "loss_scale": "16", "train_wall": "355", "gb_free": "31.5", "wall": "74022"}
[2024-07-08 06:55:18,575][train_inner][INFO] - {"epoch": 24, "update": 23.983, "loss": "84.997", "ntokens": "14619.3", "nsentences": "84.88", "nll_loss": "0.493", "wps": "8336.5", "ups": "0.57", "wpb": "14619.3", "bsz": "84.9", "num_updates": "42000", "lr": "3e-05", "gnorm": "117.471", "loss_scale": "16", "train_wall": "350", "gb_free": "33.2", "wall": "74372"}
[2024-07-08 06:56:11,115][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 06:56:11,117][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 06:56:43,388][dev-other][INFO] - {"epoch": 24, "dev-other_loss": "21.317", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.227", "dev-other_uer": "3.433", "dev-other_wer": "9.15", "dev-other_raw_wer": "9.15", "dev-other_wps": "8663.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "42030", "dev-other_best_wer": "9.15"}
[2024-07-08 06:56:43,395][fairseq_cli.train][INFO] - end of epoch 24 (average epoch stats below)
[2024-07-08 06:56:43,414][train][INFO] - {"epoch": 24, "train_loss": "84.588", "train_ntokens": "14577.4", "train_nsentences": "84.8469", "train_nll_loss": "0.492", "train_wps": "8223.6", "train_ups": "0.56", "train_wpb": "14577.4", "train_bsz": "84.8", "train_num_updates": "42030", "train_lr": "3e-05", "train_gnorm": "117.829", "train_loss_scale": "16", "train_train_wall": "3066", "train_gb_free": "32.9", "train_wall": "74457"}
[2024-07-08 06:56:43,416][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 06:56:44,095][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 06:56:44,099][fairseq.trainer][INFO] - begin training epoch 25
[2024-07-08 06:56:44,099][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 07:01:38,333][train_inner][INFO] - {"epoch": 25, "update": 24.097, "loss": "85.026", "ntokens": "14525.9", "nsentences": "84.4", "nll_loss": "0.494", "wps": "7651.5", "ups": "0.53", "wpb": "14525.9", "bsz": "84.4", "num_updates": "42200", "lr": "3e-05", "gnorm": "118.97", "loss_scale": "16", "train_wall": "346", "gb_free": "32", "wall": "74752"}
[2024-07-08 07:07:25,150][train_inner][INFO] - {"epoch": 25, "update": 24.211, "loss": "87.917", "ntokens": "14610.6", "nsentences": "86.72", "nll_loss": "0.522", "wps": "8427.5", "ups": "0.58", "wpb": "14610.6", "bsz": "86.7", "num_updates": "42400", "lr": "3e-05", "gnorm": "118.191", "loss_scale": "16", "train_wall": "346", "gb_free": "33.3", "wall": "75099"}
[2024-07-08 07:13:10,967][train_inner][INFO] - {"epoch": 25, "update": 24.325, "loss": "84.478", "ntokens": "14579.9", "nsentences": "84.84", "nll_loss": "0.492", "wps": "8434.5", "ups": "0.58", "wpb": "14579.9", "bsz": "84.8", "num_updates": "42600", "lr": "3e-05", "gnorm": "117.766", "loss_scale": "16", "train_wall": "345", "gb_free": "29.6", "wall": "75445"}
[2024-07-08 07:18:56,976][train_inner][INFO] - {"epoch": 25, "update": 24.439, "loss": "87.575", "ntokens": "14603.7", "nsentences": "82.915", "nll_loss": "0.497", "wps": "8442", "ups": "0.58", "wpb": "14603.7", "bsz": "82.9", "num_updates": "42800", "lr": "3e-05", "gnorm": "121.73", "loss_scale": "16", "train_wall": "345", "gb_free": "32.2", "wall": "75791"}
[2024-07-08 07:24:40,929][train_inner][INFO] - {"epoch": 25, "update": 24.554, "loss": "86.338", "ntokens": "14663.5", "nsentences": "85.12", "nll_loss": "0.501", "wps": "8526.8", "ups": "0.58", "wpb": "14663.5", "bsz": "85.1", "num_updates": "43000", "lr": "3e-05", "gnorm": "118.403", "loss_scale": "16", "train_wall": "343", "gb_free": "31.6", "wall": "76135"}
[2024-07-08 07:30:33,071][train_inner][INFO] - {"epoch": 25, "update": 24.668, "loss": "83.138", "ntokens": "14523.5", "nsentences": "85.32", "nll_loss": "0.488", "wps": "8250.4", "ups": "0.57", "wpb": "14523.5", "bsz": "85.3", "num_updates": "43200", "lr": "3e-05", "gnorm": "117.955", "loss_scale": "16", "train_wall": "352", "gb_free": "32.7", "wall": "76487"}
[2024-07-08 07:36:19,222][train_inner][INFO] - {"epoch": 25, "update": 24.782, "loss": "85.827", "ntokens": "14668.6", "nsentences": "86.16", "nll_loss": "0.504", "wps": "8477.1", "ups": "0.58", "wpb": "14668.6", "bsz": "86.2", "num_updates": "43400", "lr": "3e-05", "gnorm": "117.651", "loss_scale": "32", "train_wall": "346", "gb_free": "31.3", "wall": "76833"}
[2024-07-08 07:42:12,195][train_inner][INFO] - {"epoch": 25, "update": 24.896, "loss": "83.677", "ntokens": "14507.9", "nsentences": "84.4", "nll_loss": "0.487", "wps": "8220.8", "ups": "0.57", "wpb": "14507.9", "bsz": "84.4", "num_updates": "43600", "lr": "3e-05", "gnorm": "117.89", "loss_scale": "32", "train_wall": "352", "gb_free": "32.4", "wall": "77186"}
[2024-07-08 07:44:53,195][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-08 07:47:26,047][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 07:47:26,121][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 07:47:58,138][dev-other][INFO] - {"epoch": 25, "dev-other_loss": "21.351", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.227", "dev-other_uer": "3.417", "dev-other_wer": "9.072", "dev-other_raw_wer": "9.072", "dev-other_wps": "8710.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "43781", "dev-other_best_wer": "9.072"}
[2024-07-08 07:47:58,140][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 25 @ 43781 updates
[2024-07-08 07:47:58,141][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-08 07:47:59,628][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-08 07:48:00,379][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 25 @ 43781 updates, score 9.072) (writing took 2.238652378320694 seconds)
[2024-07-08 07:48:00,379][fairseq_cli.train][INFO] - end of epoch 25 (average epoch stats below)
[2024-07-08 07:48:00,383][train][INFO] - {"epoch": 25, "train_loss": "85.611", "train_ntokens": "14576", "train_nsentences": "84.8607", "train_nll_loss": "0.498", "train_wps": "8294.7", "train_ups": "0.57", "train_wpb": "14576", "train_bsz": "84.9", "train_num_updates": "43781", "train_lr": "3e-05", "train_gnorm": "118.723", "train_loss_scale": "16", "train_train_wall": "3037", "train_gb_free": "32", "train_wall": "77534"}
[2024-07-08 07:48:00,384][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 07:48:00,635][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 07:48:00,638][fairseq.trainer][INFO] - begin training epoch 26
[2024-07-08 07:48:00,638][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 07:48:33,985][train_inner][INFO] - {"epoch": 26, "update": 25.011, "loss": "85.736", "ntokens": "14444.1", "nsentences": "83.32", "nll_loss": "0.495", "wps": "7568.1", "ups": "0.52", "wpb": "14444.1", "bsz": "83.3", "num_updates": "43800", "lr": "3e-05", "gnorm": "120.448", "loss_scale": "16", "train_wall": "347", "gb_free": "33.2", "wall": "77568"}
[2024-07-08 07:54:20,412][train_inner][INFO] - {"epoch": 26, "update": 25.125, "loss": "85.383", "ntokens": "14563.9", "nsentences": "85.56", "nll_loss": "0.502", "wps": "8409.7", "ups": "0.58", "wpb": "14563.9", "bsz": "85.6", "num_updates": "44000", "lr": "3e-05", "gnorm": "117.199", "loss_scale": "16", "train_wall": "346", "gb_free": "30.1", "wall": "77914"}
[2024-07-08 08:00:11,394][train_inner][INFO] - {"epoch": 26, "update": 25.239, "loss": "84.239", "ntokens": "14666.9", "nsentences": "85.24", "nll_loss": "0.49", "wps": "8359.6", "ups": "0.57", "wpb": "14666.9", "bsz": "85.2", "num_updates": "44200", "lr": "3e-05", "gnorm": "117.306", "loss_scale": "16", "train_wall": "350", "gb_free": "32.4", "wall": "78265"}
[2024-07-08 08:05:58,695][train_inner][INFO] - {"epoch": 26, "update": 25.353, "loss": "85.051", "ntokens": "14590.9", "nsentences": "83.88", "nll_loss": "0.489", "wps": "8404.4", "ups": "0.58", "wpb": "14590.9", "bsz": "83.9", "num_updates": "44400", "lr": "3e-05", "gnorm": "119.162", "loss_scale": "16", "train_wall": "347", "gb_free": "32", "wall": "78612"}
[2024-07-08 08:11:49,148][train_inner][INFO] - {"epoch": 26, "update": 25.467, "loss": "83.108", "ntokens": "14632.2", "nsentences": "85.88", "nll_loss": "0.488", "wps": "8352.3", "ups": "0.57", "wpb": "14632.2", "bsz": "85.9", "num_updates": "44600", "lr": "3e-05", "gnorm": "116.737", "loss_scale": "16", "train_wall": "350", "gb_free": "32", "wall": "78963"}
[2024-07-08 08:17:40,679][train_inner][INFO] - {"epoch": 26, "update": 25.582, "loss": "84.374", "ntokens": "14505.1", "nsentences": "86.08", "nll_loss": "0.501", "wps": "8254.4", "ups": "0.57", "wpb": "14505.1", "bsz": "86.1", "num_updates": "44800", "lr": "3e-05", "gnorm": "116.944", "loss_scale": "16", "train_wall": "351", "gb_free": "31.9", "wall": "79314"}
[2024-07-08 08:23:29,708][train_inner][INFO] - {"epoch": 26, "update": 25.696, "loss": "86.107", "ntokens": "14587.9", "nsentences": "84.4", "nll_loss": "0.498", "wps": "8360.8", "ups": "0.57", "wpb": "14587.9", "bsz": "84.4", "num_updates": "45000", "lr": "3e-05", "gnorm": "117.527", "loss_scale": "16", "train_wall": "348", "gb_free": "32", "wall": "79663"}
[2024-07-08 08:29:22,085][train_inner][INFO] - {"epoch": 26, "update": 25.81, "loss": "87.175", "ntokens": "14529.9", "nsentences": "83.32", "nll_loss": "0.5", "wps": "8248.5", "ups": "0.57", "wpb": "14529.9", "bsz": "83.3", "num_updates": "45200", "lr": "3e-05", "gnorm": "119.062", "loss_scale": "16", "train_wall": "352", "gb_free": "30.6", "wall": "80016"}
[2024-07-08 08:35:15,985][train_inner][INFO] - {"epoch": 26, "update": 25.924, "loss": "84.715", "ntokens": "14538.9", "nsentences": "84.035", "nll_loss": "0.49", "wps": "8216.9", "ups": "0.57", "wpb": "14538.9", "bsz": "84", "num_updates": "45400", "lr": "3e-05", "gnorm": "117.591", "loss_scale": "16", "train_wall": "353", "gb_free": "32.1", "wall": "80370"}
[2024-07-08 08:39:08,019][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 08:39:08,089][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 08:39:40,140][dev-other][INFO] - {"epoch": 26, "dev-other_loss": "21.376", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.227", "dev-other_uer": "3.484", "dev-other_wer": "9.225", "dev-other_raw_wer": "9.225", "dev-other_wps": "8708.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "45533", "dev-other_best_wer": "9.072"}
[2024-07-08 08:39:40,141][fairseq_cli.train][INFO] - end of epoch 26 (average epoch stats below)
[2024-07-08 08:39:40,145][train][INFO] - {"epoch": 26, "train_loss": "84.761", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.493", "train_wps": "8239.3", "train_ups": "0.57", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "45533", "train_lr": "3e-05", "train_gnorm": "117.661", "train_loss_scale": "16", "train_train_wall": "3062", "train_gb_free": "33.1", "train_wall": "80634"}
[2024-07-08 08:39:40,146][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 08:39:40,858][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 08:39:40,863][fairseq.trainer][INFO] - begin training epoch 27
[2024-07-08 08:39:40,863][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 08:41:34,739][train_inner][INFO] - {"epoch": 27, "update": 26.038, "loss": "85.353", "ntokens": "14578.2", "nsentences": "84.4", "nll_loss": "0.494", "wps": "7699.5", "ups": "0.53", "wpb": "14578.2", "bsz": "84.4", "num_updates": "45600", "lr": "3e-05", "gnorm": "119.095", "loss_scale": "16", "train_wall": "345", "gb_free": "31.5", "wall": "80748"}
[2024-07-08 08:47:29,084][train_inner][INFO] - {"epoch": 27, "update": 26.152, "loss": "81.89", "ntokens": "14705.6", "nsentences": "87.52", "nll_loss": "0.487", "wps": "8301.6", "ups": "0.56", "wpb": "14705.6", "bsz": "87.5", "num_updates": "45800", "lr": "3e-05", "gnorm": "117.118", "loss_scale": "32", "train_wall": "354", "gb_free": "32.1", "wall": "81103"}
[2024-07-08 08:49:34,177][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-08 08:53:27,429][train_inner][INFO] - {"epoch": 27, "update": 26.267, "loss": "80.773", "ntokens": "14638.5", "nsentences": "85.44", "nll_loss": "0.471", "wps": "8172.1", "ups": "0.56", "wpb": "14638.5", "bsz": "85.4", "num_updates": "46000", "lr": "3e-05", "gnorm": "117.198", "loss_scale": "16", "train_wall": "358", "gb_free": "32.1", "wall": "81461"}
[2024-07-08 08:57:53,011][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-08 08:59:18,488][train_inner][INFO] - {"epoch": 27, "update": 26.382, "loss": "83.115", "ntokens": "14673", "nsentences": "86.52", "nll_loss": "0.49", "wps": "8360.9", "ups": "0.57", "wpb": "14673", "bsz": "86.5", "num_updates": "46200", "lr": "3e-05", "gnorm": "115.392", "loss_scale": "8", "train_wall": "350", "gb_free": "32.5", "wall": "81812"}
[2024-07-08 09:05:12,064][train_inner][INFO] - {"epoch": 27, "update": 26.496, "loss": "84.094", "ntokens": "14599.4", "nsentences": "84", "nll_loss": "0.484", "wps": "8258.5", "ups": "0.57", "wpb": "14599.4", "bsz": "84", "num_updates": "46400", "lr": "3e-05", "gnorm": "117.346", "loss_scale": "8", "train_wall": "353", "gb_free": "32.5", "wall": "82166"}
[2024-07-08 09:11:01,725][train_inner][INFO] - {"epoch": 27, "update": 26.61, "loss": "84.698", "ntokens": "14524.8", "nsentences": "83.115", "nll_loss": "0.485", "wps": "8308.1", "ups": "0.57", "wpb": "14524.8", "bsz": "83.1", "num_updates": "46600", "lr": "3e-05", "gnorm": "119.244", "loss_scale": "8", "train_wall": "349", "gb_free": "33.2", "wall": "82516"}
[2024-07-08 09:17:04,797][train_inner][INFO] - {"epoch": 27, "update": 26.724, "loss": "84.514", "ntokens": "14383.9", "nsentences": "82.24", "nll_loss": "0.483", "wps": "7925", "ups": "0.55", "wpb": "14383.9", "bsz": "82.2", "num_updates": "46800", "lr": "3e-05", "gnorm": "118.176", "loss_scale": "8", "train_wall": "362", "gb_free": "32.5", "wall": "82879"}
[2024-07-08 09:22:51,750][train_inner][INFO] - {"epoch": 27, "update": 26.838, "loss": "84.818", "ntokens": "14491.9", "nsentences": "85", "nll_loss": "0.497", "wps": "8355.2", "ups": "0.58", "wpb": "14491.9", "bsz": "85", "num_updates": "47000", "lr": "3e-05", "gnorm": "119.532", "loss_scale": "8", "train_wall": "346", "gb_free": "31.3", "wall": "83225"}
[2024-07-08 09:28:40,194][train_inner][INFO] - {"epoch": 27, "update": 26.953, "loss": "85.495", "ntokens": "14575.7", "nsentences": "85.28", "nll_loss": "0.5", "wps": "8368.1", "ups": "0.57", "wpb": "14575.7", "bsz": "85.3", "num_updates": "47200", "lr": "3e-05", "gnorm": "119.032", "loss_scale": "8", "train_wall": "348", "gb_free": "33.2", "wall": "83574"}
[2024-07-08 09:30:59,469][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 09:30:59,476][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 09:31:31,557][dev-other][INFO] - {"epoch": 27, "dev-other_loss": "21.516", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.229", "dev-other_uer": "3.444", "dev-other_wer": "9.076", "dev-other_raw_wer": "9.076", "dev-other_wps": "8717.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "47283", "dev-other_best_wer": "9.072"}
[2024-07-08 09:31:31,558][fairseq_cli.train][INFO] - end of epoch 27 (average epoch stats below)
[2024-07-08 09:31:31,570][train][INFO] - {"epoch": 27, "train_loss": "83.911", "train_ntokens": "14576.9", "train_nsentences": "84.868", "train_nll_loss": "0.489", "train_wps": "8198.7", "train_ups": "0.56", "train_wpb": "14576.9", "train_bsz": "84.9", "train_num_updates": "47283", "train_lr": "3e-05", "train_gnorm": "118.091", "train_loss_scale": "8", "train_train_wall": "3073", "train_gb_free": "31.6", "train_wall": "83745"}
[2024-07-08 09:31:31,572][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 09:31:32,256][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 09:31:32,261][fairseq.trainer][INFO] - begin training epoch 28
[2024-07-08 09:31:32,261][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 09:35:04,939][train_inner][INFO] - {"epoch": 28, "update": 27.067, "loss": "80.115", "ntokens": "14528.3", "nsentences": "85.72", "nll_loss": "0.473", "wps": "7552.5", "ups": "0.52", "wpb": "14528.3", "bsz": "85.7", "num_updates": "47400", "lr": "3e-05", "gnorm": "116", "loss_scale": "8", "train_wall": "351", "gb_free": "30.8", "wall": "83959"}
[2024-07-08 09:41:00,486][train_inner][INFO] - {"epoch": 28, "update": 27.181, "loss": "86.442", "ntokens": "14531.8", "nsentences": "81.76", "nll_loss": "0.486", "wps": "8176.2", "ups": "0.56", "wpb": "14531.8", "bsz": "81.8", "num_updates": "47600", "lr": "3e-05", "gnorm": "121.699", "loss_scale": "8", "train_wall": "347", "gb_free": "32.6", "wall": "84314"}
[2024-07-08 09:46:54,571][train_inner][INFO] - {"epoch": 28, "update": 27.295, "loss": "80.432", "ntokens": "14517.5", "nsentences": "84.36", "nll_loss": "0.467", "wps": "8201.7", "ups": "0.56", "wpb": "14517.5", "bsz": "84.4", "num_updates": "47800", "lr": "3e-05", "gnorm": "117.58", "loss_scale": "8", "train_wall": "353", "gb_free": "32.2", "wall": "84668"}
[2024-07-08 09:52:43,230][train_inner][INFO] - {"epoch": 28, "update": 27.409, "loss": "82.388", "ntokens": "14607.5", "nsentences": "86.24", "nll_loss": "0.486", "wps": "8379.5", "ups": "0.57", "wpb": "14607.5", "bsz": "86.2", "num_updates": "48000", "lr": "3e-05", "gnorm": "116.904", "loss_scale": "8", "train_wall": "348", "gb_free": "32.3", "wall": "85017"}
[2024-07-08 09:58:27,787][train_inner][INFO] - {"epoch": 28, "update": 27.523, "loss": "83.338", "ntokens": "14655", "nsentences": "86.12", "nll_loss": "0.49", "wps": "8508.2", "ups": "0.58", "wpb": "14655", "bsz": "86.1", "num_updates": "48200", "lr": "3e-05", "gnorm": "117.586", "loss_scale": "8", "train_wall": "344", "gb_free": "31.9", "wall": "85362"}
[2024-07-08 10:04:13,369][train_inner][INFO] - {"epoch": 28, "update": 27.638, "loss": "81.639", "ntokens": "14680.4", "nsentences": "89.52", "nll_loss": "0.498", "wps": "8496.3", "ups": "0.58", "wpb": "14680.4", "bsz": "89.5", "num_updates": "48400", "lr": "3e-05", "gnorm": "113.477", "loss_scale": "16", "train_wall": "345", "gb_free": "33.7", "wall": "85707"}
[2024-07-08 10:10:10,092][train_inner][INFO] - {"epoch": 28, "update": 27.752, "loss": "83.191", "ntokens": "14619.9", "nsentences": "83.48", "nll_loss": "0.475", "wps": "8198.5", "ups": "0.56", "wpb": "14619.9", "bsz": "83.5", "num_updates": "48600", "lr": "3e-05", "gnorm": "117.335", "loss_scale": "16", "train_wall": "356", "gb_free": "31.2", "wall": "86064"}
[2024-07-08 10:15:58,459][train_inner][INFO] - {"epoch": 28, "update": 27.866, "loss": "85.144", "ntokens": "14539.1", "nsentences": "83.36", "nll_loss": "0.488", "wps": "8347.5", "ups": "0.57", "wpb": "14539.1", "bsz": "83.4", "num_updates": "48800", "lr": "3e-05", "gnorm": "121.584", "loss_scale": "16", "train_wall": "348", "gb_free": "32.8", "wall": "86412"}
[2024-07-08 10:21:52,643][train_inner][INFO] - {"epoch": 28, "update": 27.98, "loss": "85.773", "ntokens": "14574.8", "nsentences": "83.315", "nll_loss": "0.49", "wps": "8230.3", "ups": "0.56", "wpb": "14574.8", "bsz": "83.3", "num_updates": "49000", "lr": "3e-05", "gnorm": "119.667", "loss_scale": "16", "train_wall": "354", "gb_free": "31.9", "wall": "86766"}
[2024-07-08 10:22:50,943][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 10:22:50,944][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 10:23:22,992][dev-other][INFO] - {"epoch": 28, "dev-other_loss": "21.365", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.227", "dev-other_uer": "3.489", "dev-other_wer": "9.158", "dev-other_raw_wer": "9.158", "dev-other_wps": "8706.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "49035", "dev-other_best_wer": "9.072"}
[2024-07-08 10:23:22,993][fairseq_cli.train][INFO] - end of epoch 28 (average epoch stats below)
[2024-07-08 10:23:22,995][train][INFO] - {"epoch": 28, "train_loss": "83.156", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.484", "train_wps": "8208.4", "train_ups": "0.56", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "49035", "train_lr": "3e-05", "train_gnorm": "117.955", "train_loss_scale": "16", "train_train_wall": "3065", "train_gb_free": "33", "train_wall": "86857"}
[2024-07-08 10:23:22,997][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 10:23:23,647][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 10:23:23,651][fairseq.trainer][INFO] - begin training epoch 29
[2024-07-08 10:23:23,664][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 10:28:11,204][train_inner][INFO] - {"epoch": 29, "update": 28.094, "loss": "83.618", "ntokens": "14493.9", "nsentences": "84.32", "nll_loss": "0.486", "wps": "7659", "ups": "0.53", "wpb": "14493.9", "bsz": "84.3", "num_updates": "49200", "lr": "3e-05", "gnorm": "119.246", "loss_scale": "16", "train_wall": "345", "gb_free": "29", "wall": "87145"}
[2024-07-08 10:33:53,458][train_inner][INFO] - {"epoch": 29, "update": 28.208, "loss": "82.387", "ntokens": "14602", "nsentences": "86", "nll_loss": "0.485", "wps": "8534.7", "ups": "0.58", "wpb": "14602", "bsz": "86", "num_updates": "49400", "lr": "3e-05", "gnorm": "117.769", "loss_scale": "16", "train_wall": "342", "gb_free": "32.3", "wall": "87487"}
[2024-07-08 10:39:40,170][train_inner][INFO] - {"epoch": 29, "update": 28.322, "loss": "83.206", "ntokens": "14585.6", "nsentences": "85.92", "nll_loss": "0.49", "wps": "8416", "ups": "0.58", "wpb": "14585.6", "bsz": "85.9", "num_updates": "49600", "lr": "3e-05", "gnorm": "118.162", "loss_scale": "16", "train_wall": "346", "gb_free": "32.1", "wall": "87834"}
[2024-07-08 10:45:30,812][train_inner][INFO] - {"epoch": 29, "update": 28.437, "loss": "82.65", "ntokens": "14714.7", "nsentences": "88.115", "nll_loss": "0.495", "wps": "8395.2", "ups": "0.57", "wpb": "14714.7", "bsz": "88.1", "num_updates": "49800", "lr": "3e-05", "gnorm": "113.983", "loss_scale": "16", "train_wall": "350", "gb_free": "32.2", "wall": "88185"}
[2024-07-08 10:51:17,667][train_inner][INFO] - {"epoch": 29, "update": 28.551, "loss": "85.38", "ntokens": "14538.3", "nsentences": "84.84", "nll_loss": "0.498", "wps": "8384.9", "ups": "0.58", "wpb": "14538.3", "bsz": "84.8", "num_updates": "50000", "lr": "3e-05", "gnorm": "119.17", "loss_scale": "16", "train_wall": "346", "gb_free": "29.1", "wall": "88531"}
[2024-07-08 10:57:10,688][train_inner][INFO] - {"epoch": 29, "update": 28.665, "loss": "83.676", "ntokens": "14636.5", "nsentences": "85.08", "nll_loss": "0.486", "wps": "8294.2", "ups": "0.57", "wpb": "14636.5", "bsz": "85.1", "num_updates": "50200", "lr": "3e-05", "gnorm": "117.795", "loss_scale": "16", "train_wall": "352", "gb_free": "30.9", "wall": "88884"}
[2024-07-08 11:03:02,396][train_inner][INFO] - {"epoch": 29, "update": 28.779, "loss": "84.134", "ntokens": "14616.2", "nsentences": "83.44", "nll_loss": "0.48", "wps": "8313.5", "ups": "0.57", "wpb": "14616.2", "bsz": "83.4", "num_updates": "50400", "lr": "3e-05", "gnorm": "120.538", "loss_scale": "32", "train_wall": "351", "gb_free": "33.4", "wall": "89236"}
[2024-07-08 11:08:50,191][train_inner][INFO] - {"epoch": 29, "update": 28.893, "loss": "84.231", "ntokens": "14523.5", "nsentences": "83.4", "nll_loss": "0.484", "wps": "8353.9", "ups": "0.58", "wpb": "14523.5", "bsz": "83.4", "num_updates": "50600", "lr": "3e-05", "gnorm": "119.824", "loss_scale": "32", "train_wall": "347", "gb_free": "31.3", "wall": "89584"}
[2024-07-08 11:13:18,299][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-08 11:14:12,929][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 11:14:12,930][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 11:14:44,955][dev-other][INFO] - {"epoch": 29, "dev-other_loss": "20.543", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.218", "dev-other_uer": "3.399", "dev-other_wer": "8.948", "dev-other_raw_wer": "8.948", "dev-other_wps": "8726.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "50786", "dev-other_best_wer": "8.948"}
[2024-07-08 11:14:44,956][fairseq_cli.train][INFO] - end of epoch 29 (average epoch stats below)
[2024-07-08 11:14:44,960][train][INFO] - {"epoch": 29, "train_loss": "83.758", "train_ntokens": "14576.8", "train_nsentences": "84.8241", "train_nll_loss": "0.487", "train_wps": "8281.8", "train_ups": "0.57", "train_wpb": "14576.8", "train_bsz": "84.8", "train_num_updates": "50786", "train_lr": "3e-05", "train_gnorm": "118.435", "train_loss_scale": "16", "train_train_wall": "3044", "train_gb_free": "31.7", "train_wall": "89939"}
[2024-07-08 11:14:44,962][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 11:14:45,662][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 11:14:45,666][fairseq.trainer][INFO] - begin training epoch 30
[2024-07-08 11:14:45,666][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 11:15:12,194][train_inner][INFO] - {"epoch": 30, "update": 29.008, "loss": "83.572", "ntokens": "14458.2", "nsentences": "83.32", "nll_loss": "0.482", "wps": "7569.9", "ups": "0.52", "wpb": "14458.2", "bsz": "83.3", "num_updates": "50800", "lr": "3e-05", "gnorm": "118.779", "loss_scale": "16", "train_wall": "349", "gb_free": "32.4", "wall": "89966"}
[2024-07-08 11:21:01,073][train_inner][INFO] - {"epoch": 30, "update": 29.122, "loss": "86.993", "ntokens": "14605.5", "nsentences": "82.64", "nll_loss": "0.492", "wps": "8373", "ups": "0.57", "wpb": "14605.6", "bsz": "82.6", "num_updates": "51000", "lr": "3e-05", "gnorm": "120.871", "loss_scale": "16", "train_wall": "348", "gb_free": "33.2", "wall": "90315"}
[2024-07-08 11:26:55,233][train_inner][INFO] - {"epoch": 30, "update": 29.236, "loss": "81.719", "ntokens": "14584.7", "nsentences": "84.6", "nll_loss": "0.474", "wps": "8237.9", "ups": "0.56", "wpb": "14584.7", "bsz": "84.6", "num_updates": "51200", "lr": "3e-05", "gnorm": "117.617", "loss_scale": "16", "train_wall": "354", "gb_free": "32.1", "wall": "90669"}
[2024-07-08 11:32:52,788][train_inner][INFO] - {"epoch": 30, "update": 29.35, "loss": "81.585", "ntokens": "14606.2", "nsentences": "85", "nll_loss": "0.475", "wps": "8171.9", "ups": "0.56", "wpb": "14606.2", "bsz": "85", "num_updates": "51400", "lr": "3e-05", "gnorm": "117.425", "loss_scale": "16", "train_wall": "357", "gb_free": "31.2", "wall": "91027"}
[2024-07-08 11:38:48,465][train_inner][INFO] - {"epoch": 30, "update": 29.465, "loss": "81.398", "ntokens": "14541.6", "nsentences": "84.92", "nll_loss": "0.475", "wps": "8178.7", "ups": "0.56", "wpb": "14541.6", "bsz": "84.9", "num_updates": "51600", "lr": "3e-05", "gnorm": "117.484", "loss_scale": "16", "train_wall": "355", "gb_free": "31", "wall": "91382"}
[2024-07-08 11:44:37,590][train_inner][INFO] - {"epoch": 30, "update": 29.579, "loss": "84.67", "ntokens": "14618.8", "nsentences": "82.72", "nll_loss": "0.479", "wps": "8376.3", "ups": "0.57", "wpb": "14618.8", "bsz": "82.7", "num_updates": "51800", "lr": "3e-05", "gnorm": "119.016", "loss_scale": "16", "train_wall": "349", "gb_free": "31.9", "wall": "91731"}
[2024-07-08 11:50:20,493][train_inner][INFO] - {"epoch": 30, "update": 29.693, "loss": "85.669", "ntokens": "14541.4", "nsentences": "84.035", "nll_loss": "0.495", "wps": "8481.8", "ups": "0.58", "wpb": "14541.4", "bsz": "84", "num_updates": "52000", "lr": "3e-05", "gnorm": "119.495", "loss_scale": "16", "train_wall": "342", "gb_free": "31.5", "wall": "92074"}
[2024-07-08 11:56:06,743][train_inner][INFO] - {"epoch": 30, "update": 29.807, "loss": "83.274", "ntokens": "14597.1", "nsentences": "85.52", "nll_loss": "0.488", "wps": "8431.8", "ups": "0.58", "wpb": "14597.1", "bsz": "85.5", "num_updates": "52200", "lr": "3e-05", "gnorm": "118.854", "loss_scale": "16", "train_wall": "346", "gb_free": "32.5", "wall": "92421"}
[2024-07-08 12:01:54,701][train_inner][INFO] - {"epoch": 30, "update": 29.921, "loss": "83.2", "ntokens": "14506.2", "nsentences": "84.68", "nll_loss": "0.486", "wps": "8339.6", "ups": "0.57", "wpb": "14506.2", "bsz": "84.7", "num_updates": "52400", "lr": "3e-05", "gnorm": "118.9", "loss_scale": "16", "train_wall": "347", "gb_free": "30.8", "wall": "92768"}
[2024-07-08 12:05:59,477][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 12:05:59,553][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 12:06:31,641][dev-other][INFO] - {"epoch": 30, "dev-other_loss": "20.316", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.216", "dev-other_uer": "3.351", "dev-other_wer": "8.889", "dev-other_raw_wer": "8.889", "dev-other_wps": "8704.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "52538", "dev-other_best_wer": "8.889"}
[2024-07-08 12:06:31,643][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 30 @ 52538 updates
[2024-07-08 12:06:31,644][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-08 12:06:33,130][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-08 12:06:33,916][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 30 @ 52538 updates, score 8.889) (writing took 2.2734537683427334 seconds)
[2024-07-08 12:06:33,917][fairseq_cli.train][INFO] - end of epoch 30 (average epoch stats below)
[2024-07-08 12:06:33,922][train][INFO] - {"epoch": 30, "train_loss": "82.896", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.483", "train_wps": "8214.9", "train_ups": "0.56", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "52538", "train_lr": "3e-05", "train_gnorm": "117.98", "train_loss_scale": "16", "train_train_wall": "3068", "train_gb_free": "33.1", "train_wall": "93048"}
[2024-07-08 12:06:33,923][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 12:06:34,173][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 12:06:34,177][fairseq.trainer][INFO] - begin training epoch 31
[2024-07-08 12:06:34,177][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 12:08:22,286][train_inner][INFO] - {"epoch": 31, "update": 30.035, "loss": "80.703", "ntokens": "14513.6", "nsentences": "87.96", "nll_loss": "0.489", "wps": "7490.7", "ups": "0.52", "wpb": "14513.6", "bsz": "88", "num_updates": "52600", "lr": "3e-05", "gnorm": "113.244", "loss_scale": "16", "train_wall": "352", "gb_free": "33.2", "wall": "93156"}
[2024-07-08 12:14:11,997][train_inner][INFO] - {"epoch": 31, "update": 30.15, "loss": "80.317", "ntokens": "14685.4", "nsentences": "86.32", "nll_loss": "0.472", "wps": "8399", "ups": "0.57", "wpb": "14685.4", "bsz": "86.3", "num_updates": "52800", "lr": "3e-05", "gnorm": "115.624", "loss_scale": "16", "train_wall": "349", "gb_free": "31.7", "wall": "93506"}
[2024-07-08 12:20:03,076][train_inner][INFO] - {"epoch": 31, "update": 30.264, "loss": "82.423", "ntokens": "14501.6", "nsentences": "84.12", "nll_loss": "0.478", "wps": "8262.9", "ups": "0.57", "wpb": "14501.6", "bsz": "84.1", "num_updates": "53000", "lr": "3e-05", "gnorm": "119.28", "loss_scale": "32", "train_wall": "350", "gb_free": "33.1", "wall": "93857"}
[2024-07-08 12:25:46,131][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-08 12:25:54,267][train_inner][INFO] - {"epoch": 31, "update": 30.378, "loss": "82.425", "ntokens": "14576.8", "nsentences": "85.56", "nll_loss": "0.484", "wps": "8303.1", "ups": "0.57", "wpb": "14576.8", "bsz": "85.6", "num_updates": "53200", "lr": "3e-05", "gnorm": "115.577", "loss_scale": "16", "train_wall": "351", "gb_free": "31.4", "wall": "94208"}
[2024-07-08 12:31:40,508][train_inner][INFO] - {"epoch": 31, "update": 30.493, "loss": "81.343", "ntokens": "14597.7", "nsentences": "86.32", "nll_loss": "0.481", "wps": "8432.6", "ups": "0.58", "wpb": "14597.7", "bsz": "86.3", "num_updates": "53400", "lr": "3e-05", "gnorm": "117.537", "loss_scale": "16", "train_wall": "346", "gb_free": "31.4", "wall": "94554"}
[2024-07-08 12:37:26,835][train_inner][INFO] - {"epoch": 31, "update": 30.607, "loss": "80.948", "ntokens": "14587.9", "nsentences": "84.2", "nll_loss": "0.467", "wps": "8425.9", "ups": "0.58", "wpb": "14587.9", "bsz": "84.2", "num_updates": "53600", "lr": "3e-05", "gnorm": "118.55", "loss_scale": "16", "train_wall": "346", "gb_free": "32.3", "wall": "94901"}
[2024-07-08 12:43:17,663][train_inner][INFO] - {"epoch": 31, "update": 30.721, "loss": "85.103", "ntokens": "14573.4", "nsentences": "83.995", "nll_loss": "0.49", "wps": "8319.5", "ups": "0.57", "wpb": "14573.4", "bsz": "84", "num_updates": "53800", "lr": "3e-05", "gnorm": "118.586", "loss_scale": "16", "train_wall": "350", "gb_free": "32.7", "wall": "95251"}
[2024-07-08 12:49:14,794][train_inner][INFO] - {"epoch": 31, "update": 30.835, "loss": "81.395", "ntokens": "14570.7", "nsentences": "84.96", "nll_loss": "0.475", "wps": "8160.4", "ups": "0.56", "wpb": "14570.7", "bsz": "85", "num_updates": "54000", "lr": "3e-05", "gnorm": "116.298", "loss_scale": "16", "train_wall": "357", "gb_free": "32", "wall": "95609"}
[2024-07-08 12:55:01,853][train_inner][INFO] - {"epoch": 31, "update": 30.949, "loss": "84.344", "ntokens": "14648", "nsentences": "84.88", "nll_loss": "0.489", "wps": "8442.9", "ups": "0.58", "wpb": "14648", "bsz": "84.9", "num_updates": "54200", "lr": "3e-05", "gnorm": "120.546", "loss_scale": "16", "train_wall": "346", "gb_free": "32.2", "wall": "95956"}
[2024-07-08 12:57:38,738][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 12:57:38,805][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 12:58:10,911][dev-other][INFO] - {"epoch": 31, "dev-other_loss": "21.11", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.224", "dev-other_uer": "3.329", "dev-other_wer": "8.822", "dev-other_raw_wer": "8.822", "dev-other_wps": "8693.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "54289", "dev-other_best_wer": "8.822"}
[2024-07-08 12:58:10,912][fairseq_cli.train][INFO] - end of epoch 31 (average epoch stats below)
[2024-07-08 12:58:10,919][train][INFO] - {"epoch": 31, "train_loss": "82.317", "train_ntokens": "14576.8", "train_nsentences": "84.8469", "train_nll_loss": "0.479", "train_wps": "8241.6", "train_ups": "0.57", "train_wpb": "14576.8", "train_bsz": "84.8", "train_num_updates": "54289", "train_lr": "3e-05", "train_gnorm": "117.703", "train_loss_scale": "16", "train_train_wall": "3059", "train_gb_free": "34.2", "train_wall": "96145"}
[2024-07-08 12:58:10,920][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 12:58:11,609][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 12:58:11,613][fairseq.trainer][INFO] - begin training epoch 32
[2024-07-08 12:58:11,613][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 13:01:22,325][train_inner][INFO] - {"epoch": 32, "update": 31.063, "loss": "81.825", "ntokens": "14540.5", "nsentences": "83.8", "nll_loss": "0.472", "wps": "7644.9", "ups": "0.53", "wpb": "14540.5", "bsz": "83.8", "num_updates": "54400", "lr": "3e-05", "gnorm": "118.841", "loss_scale": "16", "train_wall": "347", "gb_free": "33.4", "wall": "96336"}
[2024-07-08 13:07:10,792][train_inner][INFO] - {"epoch": 32, "update": 31.178, "loss": "79.595", "ntokens": "14702.1", "nsentences": "87.6", "nll_loss": "0.474", "wps": "8440.3", "ups": "0.57", "wpb": "14702.1", "bsz": "87.6", "num_updates": "54600", "lr": "3e-05", "gnorm": "117.054", "loss_scale": "16", "train_wall": "348", "gb_free": "31.1", "wall": "96685"}
[2024-07-08 13:12:58,070][train_inner][INFO] - {"epoch": 32, "update": 31.292, "loss": "80.228", "ntokens": "14528.6", "nsentences": "85.915", "nll_loss": "0.474", "wps": "8367.6", "ups": "0.58", "wpb": "14528.6", "bsz": "85.9", "num_updates": "54800", "lr": "3e-05", "gnorm": "118.322", "loss_scale": "16", "train_wall": "347", "gb_free": "32.9", "wall": "97032"}
[2024-07-08 13:18:43,745][train_inner][INFO] - {"epoch": 32, "update": 31.406, "loss": "85.051", "ntokens": "14517.8", "nsentences": "83.16", "nll_loss": "0.487", "wps": "8401.8", "ups": "0.58", "wpb": "14517.8", "bsz": "83.2", "num_updates": "55000", "lr": "3e-05", "gnorm": "120.59", "loss_scale": "16", "train_wall": "345", "gb_free": "32.4", "wall": "97377"}
[2024-07-08 13:24:32,307][train_inner][INFO] - {"epoch": 32, "update": 31.52, "loss": "81.289", "ntokens": "14598.9", "nsentences": "84.64", "nll_loss": "0.471", "wps": "8378.9", "ups": "0.57", "wpb": "14598.9", "bsz": "84.6", "num_updates": "55200", "lr": "3e-05", "gnorm": "119.702", "loss_scale": "16", "train_wall": "348", "gb_free": "31.8", "wall": "97726"}
[2024-07-08 13:30:23,643][train_inner][INFO] - {"epoch": 32, "update": 31.634, "loss": "78.981", "ntokens": "14579.7", "nsentences": "86.92", "nll_loss": "0.471", "wps": "8302.1", "ups": "0.57", "wpb": "14579.7", "bsz": "86.9", "num_updates": "55400", "lr": "3e-05", "gnorm": "115.155", "loss_scale": "32", "train_wall": "351", "gb_free": "31.1", "wall": "98077"}
[2024-07-08 13:36:09,158][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-08 13:36:13,097][train_inner][INFO] - {"epoch": 32, "update": 31.749, "loss": "83.963", "ntokens": "14578.6", "nsentences": "83.16", "nll_loss": "0.479", "wps": "8345.5", "ups": "0.57", "wpb": "14578.6", "bsz": "83.2", "num_updates": "55600", "lr": "3e-05", "gnorm": "120.054", "loss_scale": "16", "train_wall": "349", "gb_free": "33.1", "wall": "98427"}
[2024-07-08 13:42:00,907][train_inner][INFO] - {"epoch": 32, "update": 31.863, "loss": "84.126", "ntokens": "14636.7", "nsentences": "83.64", "nll_loss": "0.481", "wps": "8418.2", "ups": "0.58", "wpb": "14636.7", "bsz": "83.6", "num_updates": "55800", "lr": "3e-05", "gnorm": "120.177", "loss_scale": "16", "train_wall": "347", "gb_free": "31.7", "wall": "98775"}
[2024-07-08 13:47:52,969][train_inner][INFO] - {"epoch": 32, "update": 31.977, "loss": "80.723", "ntokens": "14504.2", "nsentences": "83.56", "nll_loss": "0.465", "wps": "8241.4", "ups": "0.57", "wpb": "14504.2", "bsz": "83.6", "num_updates": "56000", "lr": "3e-05", "gnorm": "118.027", "loss_scale": "16", "train_wall": "351", "gb_free": "31.7", "wall": "99127"}
[2024-07-08 13:48:58,882][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 13:48:58,905][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 13:49:30,885][dev-other][INFO] - {"epoch": 32, "dev-other_loss": "20.905", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.222", "dev-other_uer": "3.399", "dev-other_wer": "8.909", "dev-other_raw_wer": "8.909", "dev-other_wps": "8714.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "56040", "dev-other_best_wer": "8.889"}
[2024-07-08 13:49:30,886][fairseq_cli.train][INFO] - end of epoch 32 (average epoch stats below)
[2024-07-08 13:49:30,889][train][INFO] - {"epoch": 32, "train_loss": "81.615", "train_ntokens": "14578.5", "train_nsentences": "84.8789", "train_nll_loss": "0.475", "train_wps": "8288", "train_ups": "0.57", "train_wpb": "14578.5", "train_bsz": "84.9", "train_num_updates": "56040", "train_lr": "3e-05", "train_gnorm": "118.757", "train_loss_scale": "16", "train_train_wall": "3042", "train_gb_free": "32.7", "train_wall": "99225"}
[2024-07-08 13:49:30,890][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 13:49:31,604][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 13:49:31,608][fairseq.trainer][INFO] - begin training epoch 33
[2024-07-08 13:49:31,608][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 13:54:19,055][train_inner][INFO] - {"epoch": 33, "update": 32.091, "loss": "78.99", "ntokens": "14584", "nsentences": "87.08", "nll_loss": "0.472", "wps": "7556.6", "ups": "0.52", "wpb": "14584", "bsz": "87.1", "num_updates": "56200", "lr": "3e-05", "gnorm": "116.595", "loss_scale": "16", "train_wall": "353", "gb_free": "31.3", "wall": "99513"}
[2024-07-08 14:00:10,260][train_inner][INFO] - {"epoch": 33, "update": 32.205, "loss": "84.935", "ntokens": "14528.9", "nsentences": "83.08", "nll_loss": "0.486", "wps": "8274.1", "ups": "0.57", "wpb": "14528.9", "bsz": "83.1", "num_updates": "56400", "lr": "3e-05", "gnorm": "119.839", "loss_scale": "16", "train_wall": "351", "gb_free": "31.5", "wall": "99864"}
[2024-07-08 14:06:03,685][train_inner][INFO] - {"epoch": 33, "update": 32.32, "loss": "81.215", "ntokens": "14590.8", "nsentences": "85.44", "nll_loss": "0.476", "wps": "8258.7", "ups": "0.57", "wpb": "14590.8", "bsz": "85.4", "num_updates": "56600", "lr": "3e-05", "gnorm": "115.773", "loss_scale": "16", "train_wall": "353", "gb_free": "32", "wall": "100217"}
[2024-07-08 14:11:52,223][train_inner][INFO] - {"epoch": 33, "update": 32.434, "loss": "81.472", "ntokens": "14582.5", "nsentences": "85.72", "nll_loss": "0.479", "wps": "8370", "ups": "0.57", "wpb": "14582.5", "bsz": "85.7", "num_updates": "56800", "lr": "3e-05", "gnorm": "120.22", "loss_scale": "16", "train_wall": "348", "gb_free": "32.6", "wall": "100566"}
[2024-07-08 14:17:38,680][train_inner][INFO] - {"epoch": 33, "update": 32.548, "loss": "84.358", "ntokens": "14633.3", "nsentences": "84.32", "nll_loss": "0.486", "wps": "8450.8", "ups": "0.58", "wpb": "14633.3", "bsz": "84.3", "num_updates": "57000", "lr": "3e-05", "gnorm": "120.84", "loss_scale": "16", "train_wall": "346", "gb_free": "32.1", "wall": "100912"}
[2024-07-08 14:23:31,098][train_inner][INFO] - {"epoch": 33, "update": 32.662, "loss": "80.023", "ntokens": "14590.6", "nsentences": "85.36", "nll_loss": "0.468", "wps": "8282.1", "ups": "0.57", "wpb": "14590.6", "bsz": "85.4", "num_updates": "57200", "lr": "3e-05", "gnorm": "117.836", "loss_scale": "16", "train_wall": "352", "gb_free": "32.5", "wall": "101265"}
[2024-07-08 14:29:20,661][train_inner][INFO] - {"epoch": 33, "update": 32.776, "loss": "81.355", "ntokens": "14663.9", "nsentences": "85.32", "nll_loss": "0.473", "wps": "8392.2", "ups": "0.57", "wpb": "14663.9", "bsz": "85.3", "num_updates": "57400", "lr": "3e-05", "gnorm": "116.977", "loss_scale": "16", "train_wall": "349", "gb_free": "33.4", "wall": "101614"}
[2024-07-08 14:35:12,431][train_inner][INFO] - {"epoch": 33, "update": 32.89, "loss": "82.456", "ntokens": "14452.4", "nsentences": "82.715", "nll_loss": "0.472", "wps": "8217.4", "ups": "0.57", "wpb": "14452.4", "bsz": "82.7", "num_updates": "57600", "lr": "3e-05", "gnorm": "120.489", "loss_scale": "16", "train_wall": "351", "gb_free": "31.9", "wall": "101966"}
[2024-07-08 14:40:45,413][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 14:40:45,494][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 14:41:17,688][dev-other][INFO] - {"epoch": 33, "dev-other_loss": "20.68", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.22", "dev-other_uer": "3.399", "dev-other_wer": "8.913", "dev-other_raw_wer": "8.913", "dev-other_wps": "8652.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "57792", "dev-other_best_wer": "8.889"}
[2024-07-08 14:41:17,689][fairseq_cli.train][INFO] - end of epoch 33 (average epoch stats below)
[2024-07-08 14:41:17,691][train][INFO] - {"epoch": 33, "train_loss": "81.837", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.476", "train_wps": "8220.6", "train_ups": "0.56", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "57792", "train_lr": "3e-05", "train_gnorm": "118.324", "train_loss_scale": "32", "train_train_wall": "3068", "train_gb_free": "31.7", "train_wall": "102331"}
[2024-07-08 14:41:17,693][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 14:41:18,430][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 14:41:18,434][fairseq.trainer][INFO] - begin training epoch 34
[2024-07-08 14:41:18,434][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 14:41:33,141][train_inner][INFO] - {"epoch": 34, "update": 33.005, "loss": "80.092", "ntokens": "14533.8", "nsentences": "85.68", "nll_loss": "0.472", "wps": "7635.6", "ups": "0.53", "wpb": "14533.8", "bsz": "85.7", "num_updates": "57800", "lr": "3e-05", "gnorm": "116.256", "loss_scale": "32", "train_wall": "347", "gb_free": "31.7", "wall": "102347"}
[2024-07-08 14:43:37,603][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-08 14:47:22,791][train_inner][INFO] - {"epoch": 34, "update": 33.119, "loss": "83.948", "ntokens": "14504.2", "nsentences": "83.84", "nll_loss": "0.485", "wps": "8296.6", "ups": "0.57", "wpb": "14504.2", "bsz": "83.8", "num_updates": "58000", "lr": "3e-05", "gnorm": "118.449", "loss_scale": "16", "train_wall": "349", "gb_free": "31.4", "wall": "102697"}
[2024-07-08 14:53:09,108][train_inner][INFO] - {"epoch": 34, "update": 33.233, "loss": "79.764", "ntokens": "14610.5", "nsentences": "86.76", "nll_loss": "0.474", "wps": "8439.3", "ups": "0.58", "wpb": "14610.5", "bsz": "86.8", "num_updates": "58200", "lr": "3e-05", "gnorm": "116.556", "loss_scale": "16", "train_wall": "346", "gb_free": "29.4", "wall": "103043"}
[2024-07-08 14:58:48,795][train_inner][INFO] - {"epoch": 34, "update": 33.348, "loss": "82.13", "ntokens": "14679.9", "nsentences": "84.64", "nll_loss": "0.474", "wps": "8643.6", "ups": "0.59", "wpb": "14679.9", "bsz": "84.6", "num_updates": "58400", "lr": "3e-05", "gnorm": "119.752", "loss_scale": "16", "train_wall": "339", "gb_free": "32.6", "wall": "103383"}
[2024-07-08 15:04:42,455][train_inner][INFO] - {"epoch": 34, "update": 33.462, "loss": "77.465", "ntokens": "14610.6", "nsentences": "84.76", "nll_loss": "0.449", "wps": "8264.4", "ups": "0.57", "wpb": "14610.6", "bsz": "84.8", "num_updates": "58600", "lr": "3e-05", "gnorm": "116.259", "loss_scale": "16", "train_wall": "353", "gb_free": "32.1", "wall": "103736"}
[2024-07-08 15:10:40,239][train_inner][INFO] - {"epoch": 34, "update": 33.576, "loss": "78.838", "ntokens": "14580.4", "nsentences": "85.635", "nll_loss": "0.463", "wps": "8152.8", "ups": "0.56", "wpb": "14580.4", "bsz": "85.6", "num_updates": "58800", "lr": "3e-05", "gnorm": "115.091", "loss_scale": "16", "train_wall": "357", "gb_free": "33.4", "wall": "104094"}
[2024-07-08 15:16:40,200][train_inner][INFO] - {"epoch": 34, "update": 33.69, "loss": "80.7", "ntokens": "14504.3", "nsentences": "82.68", "nll_loss": "0.46", "wps": "8060.6", "ups": "0.56", "wpb": "14504.3", "bsz": "82.7", "num_updates": "59000", "lr": "3e-05", "gnorm": "116.393", "loss_scale": "16", "train_wall": "359", "gb_free": "31.8", "wall": "104454"}
[2024-07-08 15:22:25,249][train_inner][INFO] - {"epoch": 34, "update": 33.804, "loss": "80.338", "ntokens": "14579.4", "nsentences": "85.52", "nll_loss": "0.471", "wps": "8451", "ups": "0.58", "wpb": "14579.4", "bsz": "85.5", "num_updates": "59200", "lr": "3e-05", "gnorm": "116.933", "loss_scale": "16", "train_wall": "344", "gb_free": "32.6", "wall": "104799"}
[2024-07-08 15:28:22,417][train_inner][INFO] - {"epoch": 34, "update": 33.918, "loss": "78.716", "ntokens": "14588.1", "nsentences": "85.08", "nll_loss": "0.459", "wps": "8170.6", "ups": "0.56", "wpb": "14588.1", "bsz": "85.1", "num_updates": "59400", "lr": "3e-05", "gnorm": "115.712", "loss_scale": "16", "train_wall": "357", "gb_free": "32.3", "wall": "105156"}
[2024-07-08 15:32:24,677][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 15:32:24,682][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 15:32:56,829][dev-other][INFO] - {"epoch": 34, "dev-other_loss": "21.233", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.226", "dev-other_uer": "3.36", "dev-other_wer": "8.92", "dev-other_raw_wer": "8.92", "dev-other_wps": "8701", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "59543", "dev-other_best_wer": "8.889"}
[2024-07-08 15:32:56,830][fairseq_cli.train][INFO] - end of epoch 34 (average epoch stats below)
[2024-07-08 15:32:56,834][train][INFO] - {"epoch": 34, "train_loss": "80.529", "train_ntokens": "14577.3", "train_nsentences": "84.8698", "train_nll_loss": "0.469", "train_wps": "8236.1", "train_ups": "0.56", "train_wpb": "14577.3", "train_bsz": "84.9", "train_num_updates": "59543", "train_lr": "3e-05", "train_gnorm": "117.178", "train_loss_scale": "16", "train_train_wall": "3061", "train_gb_free": "33.7", "train_wall": "105431"}
[2024-07-08 15:32:56,836][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 15:32:57,531][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 15:32:57,538][fairseq.trainer][INFO] - begin training epoch 35
[2024-07-08 15:32:57,538][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 15:34:39,142][train_inner][INFO] - {"epoch": 35, "update": 34.033, "loss": "82.47", "ntokens": "14544.5", "nsentences": "85.28", "nll_loss": "0.484", "wps": "7721.9", "ups": "0.53", "wpb": "14544.5", "bsz": "85.3", "num_updates": "59600", "lr": "3e-05", "gnorm": "119.429", "loss_scale": "16", "train_wall": "343", "gb_free": "33.1", "wall": "105533"}
[2024-07-08 15:38:17,356][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-08 15:40:25,137][train_inner][INFO] - {"epoch": 35, "update": 34.147, "loss": "80.827", "ntokens": "14609.2", "nsentences": "85.16", "nll_loss": "0.471", "wps": "8446.1", "ups": "0.58", "wpb": "14609.2", "bsz": "85.2", "num_updates": "59800", "lr": "3e-05", "gnorm": "120.702", "loss_scale": "8", "train_wall": "345", "gb_free": "32.9", "wall": "105879"}
[2024-07-08 15:46:22,605][train_inner][INFO] - {"epoch": 35, "update": 34.261, "loss": "76.936", "ntokens": "14594", "nsentences": "86.96", "nll_loss": "0.458", "wps": "8165.6", "ups": "0.56", "wpb": "14594", "bsz": "87", "num_updates": "60000", "lr": "3e-05", "gnorm": "115.47", "loss_scale": "8", "train_wall": "357", "gb_free": "30.7", "wall": "106236"}
[2024-07-08 15:52:08,133][train_inner][INFO] - {"epoch": 35, "update": 34.376, "loss": "81.034", "ntokens": "14616.6", "nsentences": "83.76", "nll_loss": "0.464", "wps": "8462.3", "ups": "0.58", "wpb": "14616.6", "bsz": "83.8", "num_updates": "60200", "lr": "2.97019e-05", "gnorm": "119.35", "loss_scale": "8", "train_wall": "345", "gb_free": "32.3", "wall": "106582"}
[2024-07-08 15:58:00,711][train_inner][INFO] - {"epoch": 35, "update": 34.49, "loss": "82.922", "ntokens": "14581.9", "nsentences": "84.6", "nll_loss": "0.481", "wps": "8273.9", "ups": "0.57", "wpb": "14581.9", "bsz": "84.6", "num_updates": "60400", "lr": "2.94068e-05", "gnorm": "119.122", "loss_scale": "8", "train_wall": "352", "gb_free": "32", "wall": "106934"}
[2024-07-08 16:03:49,072][train_inner][INFO] - {"epoch": 35, "update": 34.604, "loss": "79.811", "ntokens": "14610.5", "nsentences": "85.6", "nll_loss": "0.468", "wps": "8388.6", "ups": "0.57", "wpb": "14610.5", "bsz": "85.6", "num_updates": "60600", "lr": "2.91146e-05", "gnorm": "116.332", "loss_scale": "8", "train_wall": "348", "gb_free": "32.4", "wall": "107283"}
[2024-07-08 16:09:37,123][train_inner][INFO] - {"epoch": 35, "update": 34.718, "loss": "78.4", "ntokens": "14574.2", "nsentences": "85.12", "nll_loss": "0.458", "wps": "8375.1", "ups": "0.57", "wpb": "14574.2", "bsz": "85.1", "num_updates": "60800", "lr": "2.88253e-05", "gnorm": "117.153", "loss_scale": "8", "train_wall": "347", "gb_free": "32.6", "wall": "107631"}
[2024-07-08 16:15:28,898][train_inner][INFO] - {"epoch": 35, "update": 34.832, "loss": "80.748", "ntokens": "14593.6", "nsentences": "84.2", "nll_loss": "0.466", "wps": "8297.5", "ups": "0.57", "wpb": "14593.6", "bsz": "84.2", "num_updates": "61000", "lr": "2.85389e-05", "gnorm": "118.166", "loss_scale": "8", "train_wall": "351", "gb_free": "31", "wall": "107983"}
[2024-07-08 16:21:21,703][train_inner][INFO] - {"epoch": 35, "update": 34.946, "loss": "82.02", "ntokens": "14587.9", "nsentences": "84.24", "nll_loss": "0.474", "wps": "8271.3", "ups": "0.57", "wpb": "14587.9", "bsz": "84.2", "num_updates": "61200", "lr": "2.82553e-05", "gnorm": "121.617", "loss_scale": "8", "train_wall": "352", "gb_free": "30.8", "wall": "108335"}
[2024-07-08 16:24:05,551][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 16:24:05,557][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 16:24:37,590][dev-other][INFO] - {"epoch": 35, "dev-other_loss": "20.544", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.218", "dev-other_uer": "3.329", "dev-other_wer": "8.785", "dev-other_raw_wer": "8.785", "dev-other_wps": "8704.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "61294", "dev-other_best_wer": "8.785"}
[2024-07-08 16:24:37,592][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 35 @ 61294 updates
[2024-07-08 16:24:37,593][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-08 16:24:39,222][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-08 16:24:39,759][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 35 @ 61294 updates, score 8.785) (writing took 2.167273949831724 seconds)
[2024-07-08 16:24:39,759][fairseq_cli.train][INFO] - end of epoch 35 (average epoch stats below)
[2024-07-08 16:24:39,763][train][INFO] - {"epoch": 35, "train_loss": "80.299", "train_ntokens": "14576.6", "train_nsentences": "84.8652", "train_nll_loss": "0.468", "train_wps": "8225.6", "train_ups": "0.56", "train_wpb": "14576.6", "train_bsz": "84.9", "train_num_updates": "61294", "train_lr": "2.8123e-05", "train_gnorm": "118.323", "train_loss_scale": "8", "train_train_wall": "3063", "train_gb_free": "34.3", "train_wall": "108534"}
[2024-07-08 16:24:39,764][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 16:24:40,001][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 16:24:40,004][fairseq.trainer][INFO] - begin training epoch 36
[2024-07-08 16:24:40,005][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 16:27:44,939][train_inner][INFO] - {"epoch": 36, "update": 35.061, "loss": "83.075", "ntokens": "14389.4", "nsentences": "82.195", "nll_loss": "0.475", "wps": "7509.8", "ups": "0.52", "wpb": "14389.4", "bsz": "82.2", "num_updates": "61400", "lr": "2.79746e-05", "gnorm": "119.958", "loss_scale": "8", "train_wall": "348", "gb_free": "32.5", "wall": "108719"}
[2024-07-08 16:33:32,681][train_inner][INFO] - {"epoch": 36, "update": 35.175, "loss": "79.015", "ntokens": "14608.3", "nsentences": "85.6", "nll_loss": "0.463", "wps": "8403.7", "ups": "0.58", "wpb": "14608.3", "bsz": "85.6", "num_updates": "61600", "lr": "2.76966e-05", "gnorm": "118.008", "loss_scale": "8", "train_wall": "347", "gb_free": "33", "wall": "109066"}
[2024-07-08 16:39:18,743][train_inner][INFO] - {"epoch": 36, "update": 35.289, "loss": "79.652", "ntokens": "14536.4", "nsentences": "85.8", "nll_loss": "0.47", "wps": "8401.3", "ups": "0.58", "wpb": "14536.4", "bsz": "85.8", "num_updates": "61800", "lr": "2.74214e-05", "gnorm": "117.162", "loss_scale": "16", "train_wall": "346", "gb_free": "33.4", "wall": "109413"}
[2024-07-08 16:45:04,783][train_inner][INFO] - {"epoch": 36, "update": 35.403, "loss": "82.908", "ntokens": "14544.9", "nsentences": "83.56", "nll_loss": "0.476", "wps": "8407.1", "ups": "0.58", "wpb": "14544.9", "bsz": "83.6", "num_updates": "62000", "lr": "2.7149e-05", "gnorm": "120.567", "loss_scale": "16", "train_wall": "345", "gb_free": "32.3", "wall": "109759"}
[2024-07-08 16:50:53,341][train_inner][INFO] - {"epoch": 36, "update": 35.517, "loss": "84.737", "ntokens": "14572.6", "nsentences": "82.8", "nll_loss": "0.481", "wps": "8361.9", "ups": "0.57", "wpb": "14572.6", "bsz": "82.8", "num_updates": "62200", "lr": "2.68792e-05", "gnorm": "120.393", "loss_scale": "16", "train_wall": "348", "gb_free": "32.6", "wall": "110107"}
[2024-07-08 16:56:37,051][train_inner][INFO] - {"epoch": 36, "update": 35.631, "loss": "79.158", "ntokens": "14730.1", "nsentences": "87.48", "nll_loss": "0.47", "wps": "8573", "ups": "0.58", "wpb": "14730.1", "bsz": "87.5", "num_updates": "62400", "lr": "2.66122e-05", "gnorm": "116.65", "loss_scale": "16", "train_wall": "343", "gb_free": "32.7", "wall": "110451"}
[2024-07-08 17:01:22,551][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-08 17:02:25,533][train_inner][INFO] - {"epoch": 36, "update": 35.746, "loss": "79.377", "ntokens": "14524.5", "nsentences": "85.955", "nll_loss": "0.47", "wps": "8336.3", "ups": "0.57", "wpb": "14524.5", "bsz": "86", "num_updates": "62600", "lr": "2.63477e-05", "gnorm": "117.11", "loss_scale": "8", "train_wall": "348", "gb_free": "32.7", "wall": "110799"}
[2024-07-08 17:08:13,776][train_inner][INFO] - {"epoch": 36, "update": 35.86, "loss": "82.051", "ntokens": "14636.5", "nsentences": "84.2", "nll_loss": "0.472", "wps": "8407.9", "ups": "0.57", "wpb": "14636.5", "bsz": "84.2", "num_updates": "62800", "lr": "2.60859e-05", "gnorm": "119.117", "loss_scale": "8", "train_wall": "348", "gb_free": "32.1", "wall": "111147"}
[2024-07-08 17:14:00,324][train_inner][INFO] - {"epoch": 36, "update": 35.974, "loss": "79.31", "ntokens": "14573.7", "nsentences": "85.08", "nll_loss": "0.463", "wps": "8411.3", "ups": "0.58", "wpb": "14573.7", "bsz": "85.1", "num_updates": "63000", "lr": "2.58267e-05", "gnorm": "118.368", "loss_scale": "8", "train_wall": "346", "gb_free": "31.5", "wall": "111494"}
[2024-07-08 17:15:20,902][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 17:15:20,908][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 17:15:53,002][dev-other][INFO] - {"epoch": 36, "dev-other_loss": "20.44", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.217", "dev-other_uer": "3.303", "dev-other_wer": "8.667", "dev-other_raw_wer": "8.667", "dev-other_wps": "8698.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "63045", "dev-other_best_wer": "8.667"}
[2024-07-08 17:15:53,003][fairseq_cli.train][INFO] - end of epoch 36 (average epoch stats below)
[2024-07-08 17:15:53,007][train][INFO] - {"epoch": 36, "train_loss": "80.846", "train_ntokens": "14577.1", "train_nsentences": "84.8195", "train_nll_loss": "0.47", "train_wps": "8305.4", "train_ups": "0.57", "train_wpb": "14577.1", "train_bsz": "84.8", "train_num_updates": "63045", "train_lr": "2.57688e-05", "train_gnorm": "118.766", "train_loss_scale": "8", "train_train_wall": "3036", "train_gb_free": "33", "train_wall": "111607"}
[2024-07-08 17:15:53,009][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 17:15:53,697][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 17:15:53,701][fairseq.trainer][INFO] - begin training epoch 37
[2024-07-08 17:15:53,702][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 17:20:17,823][train_inner][INFO] - {"epoch": 37, "update": 36.088, "loss": "81.894", "ntokens": "14436.8", "nsentences": "83.4", "nll_loss": "0.473", "wps": "7650.5", "ups": "0.53", "wpb": "14436.8", "bsz": "83.4", "num_updates": "63200", "lr": "2.55701e-05", "gnorm": "122.557", "loss_scale": "8", "train_wall": "344", "gb_free": "32.9", "wall": "111872"}
[2024-07-08 17:26:09,759][train_inner][INFO] - {"epoch": 37, "update": 36.203, "loss": "78.551", "ntokens": "14594.6", "nsentences": "84.04", "nll_loss": "0.452", "wps": "8296.6", "ups": "0.57", "wpb": "14594.6", "bsz": "84", "num_updates": "63400", "lr": "2.53161e-05", "gnorm": "118.033", "loss_scale": "8", "train_wall": "351", "gb_free": "32.7", "wall": "112223"}
[2024-07-08 17:31:59,850][train_inner][INFO] - {"epoch": 37, "update": 36.317, "loss": "78.975", "ntokens": "14583.9", "nsentences": "85.72", "nll_loss": "0.464", "wps": "8332.8", "ups": "0.57", "wpb": "14583.9", "bsz": "85.7", "num_updates": "63600", "lr": "2.50645e-05", "gnorm": "118.514", "loss_scale": "8", "train_wall": "349", "gb_free": "32.2", "wall": "112574"}
[2024-07-08 17:37:46,625][train_inner][INFO] - {"epoch": 37, "update": 36.431, "loss": "76.29", "ntokens": "14693.8", "nsentences": "87.195", "nll_loss": "0.453", "wps": "8474.8", "ups": "0.58", "wpb": "14693.8", "bsz": "87.2", "num_updates": "63800", "lr": "2.48155e-05", "gnorm": "117.253", "loss_scale": "8", "train_wall": "346", "gb_free": "32.2", "wall": "112920"}
[2024-07-08 17:43:35,478][train_inner][INFO] - {"epoch": 37, "update": 36.545, "loss": "82.422", "ntokens": "14526.7", "nsentences": "83.84", "nll_loss": "0.476", "wps": "8328.5", "ups": "0.57", "wpb": "14526.7", "bsz": "83.8", "num_updates": "64000", "lr": "2.45689e-05", "gnorm": "119.802", "loss_scale": "8", "train_wall": "348", "gb_free": "31.2", "wall": "113269"}
[2024-07-08 17:49:21,317][train_inner][INFO] - {"epoch": 37, "update": 36.659, "loss": "79.061", "ntokens": "14534.5", "nsentences": "84.8", "nll_loss": "0.461", "wps": "8405.5", "ups": "0.58", "wpb": "14534.5", "bsz": "84.8", "num_updates": "64200", "lr": "2.43248e-05", "gnorm": "117.54", "loss_scale": "8", "train_wall": "345", "gb_free": "31.8", "wall": "113615"}
[2024-07-08 17:55:10,037][train_inner][INFO] - {"epoch": 37, "update": 36.773, "loss": "81.415", "ntokens": "14615.7", "nsentences": "84.44", "nll_loss": "0.47", "wps": "8382.7", "ups": "0.57", "wpb": "14615.7", "bsz": "84.4", "num_updates": "64400", "lr": "2.40831e-05", "gnorm": "119.458", "loss_scale": "8", "train_wall": "348", "gb_free": "32.2", "wall": "113964"}
[2024-07-08 18:01:08,165][train_inner][INFO] - {"epoch": 37, "update": 36.888, "loss": "80.116", "ntokens": "14582", "nsentences": "84.6", "nll_loss": "0.465", "wps": "8145.1", "ups": "0.56", "wpb": "14582", "bsz": "84.6", "num_updates": "64600", "lr": "2.38438e-05", "gnorm": "116.192", "loss_scale": "8", "train_wall": "358", "gb_free": "30.9", "wall": "114322"}
[2024-07-08 18:06:58,831][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 18:06:58,896][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 18:07:31,021][dev-other][INFO] - {"epoch": 37, "dev-other_loss": "21.184", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.225", "dev-other_uer": "3.391", "dev-other_wer": "8.873", "dev-other_raw_wer": "8.873", "dev-other_wps": "8680", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "64797", "dev-other_best_wer": "8.785"}
[2024-07-08 18:07:31,022][fairseq_cli.train][INFO] - end of epoch 37 (average epoch stats below)
[2024-07-08 18:07:31,027][train][INFO] - {"epoch": 37, "train_loss": "79.626", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.464", "train_wps": "8243.9", "train_ups": "0.57", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "64797", "train_lr": "2.36104e-05", "train_gnorm": "118.236", "train_loss_scale": "16", "train_train_wall": "3060", "train_gb_free": "32.5", "train_wall": "114705"}
[2024-07-08 18:07:31,047][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 18:07:31,765][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 18:07:31,769][fairseq.trainer][INFO] - begin training epoch 38
[2024-07-08 18:07:31,769][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 18:07:37,813][train_inner][INFO] - {"epoch": 38, "update": 37.002, "loss": "76.903", "ntokens": "14549.2", "nsentences": "85.32", "nll_loss": "0.451", "wps": "7468.4", "ups": "0.51", "wpb": "14549.2", "bsz": "85.3", "num_updates": "64800", "lr": "2.36069e-05", "gnorm": "115.561", "loss_scale": "16", "train_wall": "356", "gb_free": "32.2", "wall": "114712"}
[2024-07-08 18:08:16,428][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-08 18:13:21,152][train_inner][INFO] - {"epoch": 38, "update": 37.116, "loss": "80.24", "ntokens": "14537.2", "nsentences": "84.44", "nll_loss": "0.466", "wps": "8468.3", "ups": "0.58", "wpb": "14537.2", "bsz": "84.4", "num_updates": "65000", "lr": "2.33723e-05", "gnorm": "118.521", "loss_scale": "8", "train_wall": "343", "gb_free": "32", "wall": "115055"}
[2024-07-08 18:19:18,792][train_inner][INFO] - {"epoch": 38, "update": 37.231, "loss": "77.941", "ntokens": "14641.9", "nsentences": "85.84", "nll_loss": "0.457", "wps": "8188.3", "ups": "0.56", "wpb": "14641.9", "bsz": "85.8", "num_updates": "65200", "lr": "2.31401e-05", "gnorm": "113.604", "loss_scale": "8", "train_wall": "357", "gb_free": "31.6", "wall": "115413"}
[2024-07-08 18:25:06,442][train_inner][INFO] - {"epoch": 38, "update": 37.345, "loss": "80.152", "ntokens": "14646.2", "nsentences": "86.28", "nll_loss": "0.472", "wps": "8427.2", "ups": "0.58", "wpb": "14646.2", "bsz": "86.3", "num_updates": "65400", "lr": "2.29102e-05", "gnorm": "122.163", "loss_scale": "8", "train_wall": "347", "gb_free": "32.8", "wall": "115760"}
[2024-07-08 18:31:05,292][train_inner][INFO] - {"epoch": 38, "update": 37.459, "loss": "77.437", "ntokens": "14580.5", "nsentences": "83.12", "nll_loss": "0.441", "wps": "8126.5", "ups": "0.56", "wpb": "14580.5", "bsz": "83.1", "num_updates": "65600", "lr": "2.26825e-05", "gnorm": "118.586", "loss_scale": "8", "train_wall": "358", "gb_free": "29.2", "wall": "116119"}
[2024-07-08 18:36:56,663][train_inner][INFO] - {"epoch": 38, "update": 37.573, "loss": "76.631", "ntokens": "14657.8", "nsentences": "87.075", "nll_loss": "0.455", "wps": "8343.4", "ups": "0.57", "wpb": "14657.8", "bsz": "87.1", "num_updates": "65800", "lr": "2.24572e-05", "gnorm": "116.345", "loss_scale": "8", "train_wall": "351", "gb_free": "33.5", "wall": "116470"}
[2024-07-08 18:42:50,832][train_inner][INFO] - {"epoch": 38, "update": 37.687, "loss": "78.551", "ntokens": "14543.1", "nsentences": "83.96", "nll_loss": "0.453", "wps": "8212.7", "ups": "0.56", "wpb": "14543.1", "bsz": "84", "num_updates": "66000", "lr": "2.2234e-05", "gnorm": "118.083", "loss_scale": "8", "train_wall": "354", "gb_free": "32.7", "wall": "116825"}
[2024-07-08 18:48:38,087][train_inner][INFO] - {"epoch": 38, "update": 37.801, "loss": "82.954", "ntokens": "14537.1", "nsentences": "81.2", "nll_loss": "0.463", "wps": "8372.8", "ups": "0.58", "wpb": "14537.1", "bsz": "81.2", "num_updates": "66200", "lr": "2.20131e-05", "gnorm": "121.6", "loss_scale": "8", "train_wall": "347", "gb_free": "32.2", "wall": "117172"}
[2024-07-08 18:54:29,170][train_inner][INFO] - {"epoch": 38, "update": 37.916, "loss": "75.543", "ntokens": "14515.1", "nsentences": "86.92", "nll_loss": "0.452", "wps": "8269.1", "ups": "0.57", "wpb": "14515.1", "bsz": "86.9", "num_updates": "66400", "lr": "2.17944e-05", "gnorm": "115.234", "loss_scale": "8", "train_wall": "351", "gb_free": "32.2", "wall": "117523"}
[2024-07-08 18:58:51,918][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 18:58:51,925][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 18:59:24,051][dev-other][INFO] - {"epoch": 38, "dev-other_loss": "20.25", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.215", "dev-other_uer": "3.322", "dev-other_wer": "8.685", "dev-other_raw_wer": "8.685", "dev-other_wps": "8705.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "66548", "dev-other_best_wer": "8.685"}
[2024-07-08 18:59:24,051][fairseq_cli.train][INFO] - end of epoch 38 (average epoch stats below)
[2024-07-08 18:59:24,056][train][INFO] - {"epoch": 38, "train_loss": "78.919", "train_ntokens": "14577.4", "train_nsentences": "84.8698", "train_nll_loss": "0.459", "train_wps": "8199.5", "train_ups": "0.56", "train_wpb": "14577.4", "train_bsz": "84.9", "train_num_updates": "66548", "train_lr": "2.16339e-05", "train_gnorm": "118.274", "train_loss_scale": "8", "train_train_wall": "3075", "train_gb_free": "32.1", "train_wall": "117818"}
[2024-07-08 18:59:24,057][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 18:59:24,738][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 18:59:24,742][fairseq.trainer][INFO] - begin training epoch 39
[2024-07-08 18:59:24,742][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 19:00:51,366][train_inner][INFO] - {"epoch": 39, "update": 38.03, "loss": "81.604", "ntokens": "14547.6", "nsentences": "85.6", "nll_loss": "0.48", "wps": "7614.6", "ups": "0.52", "wpb": "14547.6", "bsz": "85.6", "num_updates": "66600", "lr": "2.15778e-05", "gnorm": "120.963", "loss_scale": "8", "train_wall": "349", "gb_free": "30.6", "wall": "117905"}
[2024-07-08 19:06:35,137][train_inner][INFO] - {"epoch": 39, "update": 38.144, "loss": "82.91", "ntokens": "14577.2", "nsentences": "84.2", "nll_loss": "0.479", "wps": "8482.9", "ups": "0.58", "wpb": "14577.2", "bsz": "84.2", "num_updates": "66800", "lr": "2.13634e-05", "gnorm": "118.722", "loss_scale": "8", "train_wall": "343", "gb_free": "32.2", "wall": "118249"}
[2024-07-08 19:12:24,619][train_inner][INFO] - {"epoch": 39, "update": 38.258, "loss": "80.174", "ntokens": "14630.6", "nsentences": "84.315", "nll_loss": "0.462", "wps": "8374.9", "ups": "0.57", "wpb": "14630.6", "bsz": "84.3", "num_updates": "67000", "lr": "2.11512e-05", "gnorm": "118.556", "loss_scale": "16", "train_wall": "349", "gb_free": "32.5", "wall": "118598"}
[2024-07-08 19:18:17,963][train_inner][INFO] - {"epoch": 39, "update": 38.372, "loss": "78.517", "ntokens": "14477.2", "nsentences": "83.6", "nll_loss": "0.453", "wps": "8201.9", "ups": "0.57", "wpb": "14477.2", "bsz": "83.6", "num_updates": "67200", "lr": "2.0941e-05", "gnorm": "119.539", "loss_scale": "16", "train_wall": "352", "gb_free": "32.5", "wall": "118951"}
[2024-07-08 19:23:55,578][train_inner][INFO] - {"epoch": 39, "update": 38.486, "loss": "79.144", "ntokens": "14627.9", "nsentences": "86.24", "nll_loss": "0.467", "wps": "8667.7", "ups": "0.59", "wpb": "14627.9", "bsz": "86.2", "num_updates": "67400", "lr": "2.07329e-05", "gnorm": "117.744", "loss_scale": "16", "train_wall": "337", "gb_free": "31.8", "wall": "119289"}
[2024-07-08 19:29:51,395][train_inner][INFO] - {"epoch": 39, "update": 38.6, "loss": "78.988", "ntokens": "14498.1", "nsentences": "84.08", "nll_loss": "0.458", "wps": "8151.1", "ups": "0.56", "wpb": "14498.1", "bsz": "84.1", "num_updates": "67600", "lr": "2.05269e-05", "gnorm": "117.766", "loss_scale": "16", "train_wall": "355", "gb_free": "31.9", "wall": "119645"}
[2024-07-08 19:35:32,240][train_inner][INFO] - {"epoch": 39, "update": 38.715, "loss": "80.082", "ntokens": "14596.6", "nsentences": "85.84", "nll_loss": "0.471", "wps": "8565.5", "ups": "0.59", "wpb": "14596.6", "bsz": "85.8", "num_updates": "67800", "lr": "2.0323e-05", "gnorm": "119.391", "loss_scale": "16", "train_wall": "340", "gb_free": "31.3", "wall": "119986"}
[2024-07-08 19:41:17,026][train_inner][INFO] - {"epoch": 39, "update": 38.829, "loss": "80.5", "ntokens": "14656", "nsentences": "85.96", "nll_loss": "0.472", "wps": "8502", "ups": "0.58", "wpb": "14656", "bsz": "86", "num_updates": "68000", "lr": "2.0121e-05", "gnorm": "117.011", "loss_scale": "16", "train_wall": "344", "gb_free": "33.1", "wall": "120331"}
[2024-07-08 19:47:09,245][train_inner][INFO] - {"epoch": 39, "update": 38.943, "loss": "79.948", "ntokens": "14603.7", "nsentences": "85.4", "nll_loss": "0.468", "wps": "8294.1", "ups": "0.57", "wpb": "14603.7", "bsz": "85.4", "num_updates": "68200", "lr": "1.99211e-05", "gnorm": "116.664", "loss_scale": "16", "train_wall": "352", "gb_free": "33.5", "wall": "120683"}
[2024-07-08 19:50:01,568][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 19:50:01,627][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 19:50:33,718][dev-other][INFO] - {"epoch": 39, "dev-other_loss": "21.288", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.226", "dev-other_uer": "3.365", "dev-other_wer": "8.803", "dev-other_raw_wer": "8.803", "dev-other_wps": "8689.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "68300", "dev-other_best_wer": "8.785"}
[2024-07-08 19:50:33,721][fairseq_cli.train][INFO] - end of epoch 39 (average epoch stats below)
[2024-07-08 19:50:33,725][train][INFO] - {"epoch": 39, "train_loss": "80.03", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.466", "train_wps": "8320.1", "train_ups": "0.57", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "68300", "train_lr": "1.98219e-05", "train_gnorm": "118.569", "train_loss_scale": "16", "train_train_wall": "3031", "train_gb_free": "33.1", "train_wall": "120888"}
[2024-07-08 19:50:33,727][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 19:50:34,408][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 19:50:34,412][fairseq.trainer][INFO] - begin training epoch 40
[2024-07-08 19:50:34,412][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 19:53:27,565][train_inner][INFO] - {"epoch": 40, "update": 39.057, "loss": "77.488", "ntokens": "14546.7", "nsentences": "85.64", "nll_loss": "0.456", "wps": "7692.2", "ups": "0.53", "wpb": "14546.7", "bsz": "85.6", "num_updates": "68400", "lr": "1.97232e-05", "gnorm": "120.159", "loss_scale": "16", "train_wall": "345", "gb_free": "30.7", "wall": "121061"}
[2024-07-08 19:59:17,316][train_inner][INFO] - {"epoch": 40, "update": 39.171, "loss": "77.056", "ntokens": "14613.4", "nsentences": "86.28", "nll_loss": "0.455", "wps": "8358.2", "ups": "0.57", "wpb": "14613.4", "bsz": "86.3", "num_updates": "68600", "lr": "1.95272e-05", "gnorm": "119.471", "loss_scale": "16", "train_wall": "349", "gb_free": "32.3", "wall": "121411"}
[2024-07-08 20:05:02,330][train_inner][INFO] - {"epoch": 40, "update": 39.285, "loss": "79.392", "ntokens": "14552.1", "nsentences": "83.52", "nll_loss": "0.456", "wps": "8437.4", "ups": "0.58", "wpb": "14552.1", "bsz": "83.5", "num_updates": "68800", "lr": "1.93332e-05", "gnorm": "120.938", "loss_scale": "16", "train_wall": "344", "gb_free": "31.5", "wall": "121756"}
[2024-07-08 20:10:50,781][train_inner][INFO] - {"epoch": 40, "update": 39.4, "loss": "75.709", "ntokens": "14702.2", "nsentences": "86.955", "nll_loss": "0.448", "wps": "8440.8", "ups": "0.57", "wpb": "14702.2", "bsz": "87", "num_updates": "69000", "lr": "1.91411e-05", "gnorm": "117.103", "loss_scale": "32", "train_wall": "348", "gb_free": "33.1", "wall": "122104"}
[2024-07-08 20:16:43,604][train_inner][INFO] - {"epoch": 40, "update": 39.514, "loss": "80.38", "ntokens": "14519.3", "nsentences": "82.48", "nll_loss": "0.457", "wps": "8230.6", "ups": "0.57", "wpb": "14519.3", "bsz": "82.5", "num_updates": "69200", "lr": "1.89509e-05", "gnorm": "121.112", "loss_scale": "32", "train_wall": "352", "gb_free": "32.1", "wall": "122457"}
[2024-07-08 20:19:51,988][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-08 20:22:36,604][train_inner][INFO] - {"epoch": 40, "update": 39.628, "loss": "77.324", "ntokens": "14534.7", "nsentences": "84.12", "nll_loss": "0.448", "wps": "8235.2", "ups": "0.57", "wpb": "14534.7", "bsz": "84.1", "num_updates": "69400", "lr": "1.87626e-05", "gnorm": "118.751", "loss_scale": "16", "train_wall": "352", "gb_free": "31.6", "wall": "122810"}
[2024-07-08 20:28:19,981][train_inner][INFO] - {"epoch": 40, "update": 39.743, "loss": "80.16", "ntokens": "14653.7", "nsentences": "84.8", "nll_loss": "0.464", "wps": "8535.2", "ups": "0.58", "wpb": "14653.7", "bsz": "84.8", "num_updates": "69600", "lr": "1.85762e-05", "gnorm": "118.479", "loss_scale": "16", "train_wall": "343", "gb_free": "32.2", "wall": "123154"}
[2024-07-08 20:34:20,593][train_inner][INFO] - {"epoch": 40, "update": 39.857, "loss": "76.561", "ntokens": "14531.1", "nsentences": "84.52", "nll_loss": "0.445", "wps": "8060.6", "ups": "0.55", "wpb": "14531.1", "bsz": "84.5", "num_updates": "69800", "lr": "1.83916e-05", "gnorm": "115.296", "loss_scale": "16", "train_wall": "360", "gb_free": "32.9", "wall": "123514"}
[2024-07-08 20:40:08,949][train_inner][INFO] - {"epoch": 40, "update": 39.971, "loss": "77.76", "ntokens": "14536.2", "nsentences": "84.44", "nll_loss": "0.452", "wps": "8346", "ups": "0.57", "wpb": "14536.2", "bsz": "84.4", "num_updates": "70000", "lr": "1.82089e-05", "gnorm": "118.393", "loss_scale": "16", "train_wall": "348", "gb_free": "32.4", "wall": "123863"}
[2024-07-08 20:41:34,232][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 20:41:34,296][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 20:42:06,301][dev-other][INFO] - {"epoch": 40, "dev-other_loss": "20.626", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.219", "dev-other_uer": "3.33", "dev-other_wer": "8.75", "dev-other_raw_wer": "8.75", "dev-other_wps": "8704.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "70051", "dev-other_best_wer": "8.75"}
[2024-07-08 20:42:06,303][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 40 @ 70051 updates
[2024-07-08 20:42:06,304][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-08 20:42:07,944][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-08 20:42:08,583][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 40 @ 70051 updates, score 8.75) (writing took 2.2800393886864185 seconds)
[2024-07-08 20:42:08,583][fairseq_cli.train][INFO] - end of epoch 40 (average epoch stats below)
[2024-07-08 20:42:08,588][train][INFO] - {"epoch": 40, "train_loss": "77.924", "train_ntokens": "14577.6", "train_nsentences": "84.8195", "train_nll_loss": "0.453", "train_wps": "8247.7", "train_ups": "0.57", "train_wpb": "14577.6", "train_bsz": "84.8", "train_num_updates": "70051", "train_lr": "1.81626e-05", "train_gnorm": "118.633", "train_loss_scale": "16", "train_train_wall": "3054", "train_gb_free": "34.8", "train_wall": "123982"}
[2024-07-08 20:42:08,589][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 20:42:08,866][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 20:42:08,869][fairseq.trainer][INFO] - begin training epoch 41
[2024-07-08 20:42:08,869][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 20:46:31,892][train_inner][INFO] - {"epoch": 41, "update": 40.085, "loss": "82.693", "ntokens": "14557.4", "nsentences": "83.36", "nll_loss": "0.474", "wps": "7603.1", "ups": "0.52", "wpb": "14557.4", "bsz": "83.4", "num_updates": "70200", "lr": "1.80279e-05", "gnorm": "120.164", "loss_scale": "16", "train_wall": "348", "gb_free": "31.4", "wall": "124246"}
[2024-07-08 20:52:14,129][train_inner][INFO] - {"epoch": 41, "update": 40.199, "loss": "79.113", "ntokens": "14538.4", "nsentences": "85.68", "nll_loss": "0.466", "wps": "8496.3", "ups": "0.58", "wpb": "14538.4", "bsz": "85.7", "num_updates": "70400", "lr": "1.78488e-05", "gnorm": "117.238", "loss_scale": "16", "train_wall": "342", "gb_free": "33.1", "wall": "124588"}
[2024-07-08 20:58:15,172][train_inner][INFO] - {"epoch": 41, "update": 40.313, "loss": "77.272", "ntokens": "14617.5", "nsentences": "84.6", "nll_loss": "0.447", "wps": "8097.6", "ups": "0.55", "wpb": "14617.5", "bsz": "84.6", "num_updates": "70600", "lr": "1.76715e-05", "gnorm": "116.711", "loss_scale": "16", "train_wall": "360", "gb_free": "33", "wall": "124949"}
[2024-07-08 21:04:02,629][train_inner][INFO] - {"epoch": 41, "update": 40.428, "loss": "78.76", "ntokens": "14558.3", "nsentences": "85.16", "nll_loss": "0.461", "wps": "8380.2", "ups": "0.58", "wpb": "14558.3", "bsz": "85.2", "num_updates": "70800", "lr": "1.74959e-05", "gnorm": "117.97", "loss_scale": "16", "train_wall": "347", "gb_free": "31.1", "wall": "125296"}
[2024-07-08 21:09:48,531][train_inner][INFO] - {"epoch": 41, "update": 40.542, "loss": "79.064", "ntokens": "14630.9", "nsentences": "86", "nll_loss": "0.465", "wps": "8460.8", "ups": "0.58", "wpb": "14630.9", "bsz": "86", "num_updates": "71000", "lr": "1.7322e-05", "gnorm": "118.735", "loss_scale": "16", "train_wall": "345", "gb_free": "32.9", "wall": "125642"}
[2024-07-08 21:15:42,793][train_inner][INFO] - {"epoch": 41, "update": 40.656, "loss": "77.333", "ntokens": "14588.1", "nsentences": "86.44", "nll_loss": "0.458", "wps": "8237.5", "ups": "0.56", "wpb": "14588.1", "bsz": "86.4", "num_updates": "71200", "lr": "1.71499e-05", "gnorm": "117.216", "loss_scale": "16", "train_wall": "354", "gb_free": "32", "wall": "125997"}
[2024-07-08 21:21:36,093][train_inner][INFO] - {"epoch": 41, "update": 40.77, "loss": "77.595", "ntokens": "14587.8", "nsentences": "85.56", "nll_loss": "0.455", "wps": "8258.7", "ups": "0.57", "wpb": "14587.8", "bsz": "85.6", "num_updates": "71400", "lr": "1.69795e-05", "gnorm": "116.932", "loss_scale": "32", "train_wall": "353", "gb_free": "32.8", "wall": "126350"}
[2024-07-08 21:22:19,189][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-08 21:27:24,794][train_inner][INFO] - {"epoch": 41, "update": 40.885, "loss": "78.551", "ntokens": "14530.7", "nsentences": "82.24", "nll_loss": "0.445", "wps": "8336", "ups": "0.57", "wpb": "14530.7", "bsz": "82.2", "num_updates": "71600", "lr": "1.68108e-05", "gnorm": "119.184", "loss_scale": "16", "train_wall": "348", "gb_free": "32.5", "wall": "126699"}
[2024-07-08 21:33:15,897][train_inner][INFO] - {"epoch": 41, "update": 40.999, "loss": "79.418", "ntokens": "14572.9", "nsentences": "84.555", "nll_loss": "0.461", "wps": "8301.6", "ups": "0.57", "wpb": "14572.9", "bsz": "84.6", "num_updates": "71800", "lr": "1.66438e-05", "gnorm": "119.276", "loss_scale": "16", "train_wall": "351", "gb_free": "32.8", "wall": "127050"}
[2024-07-08 21:33:18,926][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 21:33:18,927][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 21:33:51,151][dev-other][INFO] - {"epoch": 41, "dev-other_loss": "20.413", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.217", "dev-other_uer": "3.361", "dev-other_wer": "8.801", "dev-other_raw_wer": "8.801", "dev-other_wps": "8659.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "71802", "dev-other_best_wer": "8.75"}
[2024-07-08 21:33:51,152][fairseq_cli.train][INFO] - end of epoch 41 (average epoch stats below)
[2024-07-08 21:33:51,166][train][INFO] - {"epoch": 41, "train_loss": "78.852", "train_ntokens": "14576.7", "train_nsentences": "84.8652", "train_nll_loss": "0.459", "train_wps": "8226.7", "train_ups": "0.56", "train_wpb": "14576.7", "train_bsz": "84.9", "train_num_updates": "71802", "train_lr": "1.66421e-05", "train_gnorm": "118.184", "train_loss_scale": "16", "train_train_wall": "3065", "train_gb_free": "32.3", "train_wall": "127085"}
[2024-07-08 21:33:51,168][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 21:33:51,883][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 21:33:51,887][fairseq.trainer][INFO] - begin training epoch 42
[2024-07-08 21:33:51,887][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 21:39:44,543][train_inner][INFO] - {"epoch": 42, "update": 41.113, "loss": "75.811", "ntokens": "14479.9", "nsentences": "83.4", "nll_loss": "0.437", "wps": "7452.5", "ups": "0.51", "wpb": "14479.9", "bsz": "83.4", "num_updates": "72000", "lr": "1.64784e-05", "gnorm": "120.463", "loss_scale": "16", "train_wall": "355", "gb_free": "33", "wall": "127438"}
[2024-07-08 21:45:42,363][train_inner][INFO] - {"epoch": 42, "update": 41.227, "loss": "75.851", "ntokens": "14665.7", "nsentences": "84.88", "nll_loss": "0.439", "wps": "8199", "ups": "0.56", "wpb": "14665.7", "bsz": "84.9", "num_updates": "72200", "lr": "1.63147e-05", "gnorm": "115.637", "loss_scale": "16", "train_wall": "357", "gb_free": "32", "wall": "127796"}
[2024-07-08 21:51:39,859][train_inner][INFO] - {"epoch": 42, "update": 41.341, "loss": "77.839", "ntokens": "14604", "nsentences": "84.92", "nll_loss": "0.453", "wps": "8170.5", "ups": "0.56", "wpb": "14604", "bsz": "84.9", "num_updates": "72400", "lr": "1.61526e-05", "gnorm": "114.931", "loss_scale": "16", "train_wall": "357", "gb_free": "32.5", "wall": "128154"}
[2024-07-08 21:57:30,041][train_inner][INFO] - {"epoch": 42, "update": 41.455, "loss": "80.25", "ntokens": "14585.3", "nsentences": "83.96", "nll_loss": "0.462", "wps": "8331.9", "ups": "0.57", "wpb": "14585.3", "bsz": "84", "num_updates": "72600", "lr": "1.59921e-05", "gnorm": "118.635", "loss_scale": "16", "train_wall": "350", "gb_free": "32.6", "wall": "128504"}
[2024-07-08 22:02:18,670][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-08 22:03:15,745][train_inner][INFO] - {"epoch": 42, "update": 41.57, "loss": "77.321", "ntokens": "14479.6", "nsentences": "85.28", "nll_loss": "0.455", "wps": "8377.2", "ups": "0.58", "wpb": "14479.6", "bsz": "85.3", "num_updates": "72800", "lr": "1.58332e-05", "gnorm": "118.432", "loss_scale": "8", "train_wall": "345", "gb_free": "32.7", "wall": "128850"}
[2024-07-08 22:09:06,319][train_inner][INFO] - {"epoch": 42, "update": 41.684, "loss": "78.7", "ntokens": "14607.8", "nsentences": "84.515", "nll_loss": "0.455", "wps": "8334.6", "ups": "0.57", "wpb": "14607.8", "bsz": "84.5", "num_updates": "73000", "lr": "1.56759e-05", "gnorm": "117.528", "loss_scale": "8", "train_wall": "350", "gb_free": "30.7", "wall": "129200"}
[2024-07-08 22:14:59,588][train_inner][INFO] - {"epoch": 42, "update": 41.799, "loss": "77.549", "ntokens": "14568.8", "nsentences": "83.84", "nll_loss": "0.446", "wps": "8248.3", "ups": "0.57", "wpb": "14568.8", "bsz": "83.8", "num_updates": "73200", "lr": "1.55201e-05", "gnorm": "118.562", "loss_scale": "8", "train_wall": "353", "gb_free": "31.8", "wall": "129553"}
[2024-07-08 22:20:46,309][train_inner][INFO] - {"epoch": 42, "update": 41.913, "loss": "76.308", "ntokens": "14637.8", "nsentences": "87.12", "nll_loss": "0.454", "wps": "8444.2", "ups": "0.58", "wpb": "14637.8", "bsz": "87.1", "num_updates": "73400", "lr": "1.53659e-05", "gnorm": "115.599", "loss_scale": "8", "train_wall": "346", "gb_free": "32.2", "wall": "129900"}
[2024-07-08 22:25:12,255][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 22:25:12,265][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 22:25:44,423][dev-other][INFO] - {"epoch": 42, "dev-other_loss": "20.931", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.222", "dev-other_uer": "3.347", "dev-other_wer": "8.777", "dev-other_raw_wer": "8.777", "dev-other_wps": "8684.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "73553", "dev-other_best_wer": "8.75"}
[2024-07-08 22:25:44,425][fairseq_cli.train][INFO] - end of epoch 42 (average epoch stats below)
[2024-07-08 22:25:44,442][train][INFO] - {"epoch": 42, "train_loss": "77.387", "train_ntokens": "14577.7", "train_nsentences": "84.8698", "train_nll_loss": "0.451", "train_wps": "8199", "train_ups": "0.56", "train_wpb": "14577.7", "train_bsz": "84.9", "train_num_updates": "73553", "train_lr": "1.5249e-05", "train_gnorm": "117.438", "train_loss_scale": "8", "train_train_wall": "3075", "train_gb_free": "33.4", "train_wall": "130198"}
[2024-07-08 22:25:44,443][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 22:25:45,142][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 22:25:45,146][fairseq.trainer][INFO] - begin training epoch 43
[2024-07-08 22:25:45,146][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 22:27:10,820][train_inner][INFO] - {"epoch": 43, "update": 42.027, "loss": "76.998", "ntokens": "14525.5", "nsentences": "85.315", "nll_loss": "0.452", "wps": "7556.8", "ups": "0.52", "wpb": "14525.5", "bsz": "85.3", "num_updates": "73600", "lr": "1.52132e-05", "gnorm": "118.312", "loss_scale": "8", "train_wall": "351", "gb_free": "31.6", "wall": "130285"}
[2024-07-08 22:32:57,529][train_inner][INFO] - {"epoch": 43, "update": 42.141, "loss": "76.284", "ntokens": "14600.1", "nsentences": "84.8", "nll_loss": "0.443", "wps": "8422.5", "ups": "0.58", "wpb": "14600.1", "bsz": "84.8", "num_updates": "73800", "lr": "1.50621e-05", "gnorm": "117.671", "loss_scale": "8", "train_wall": "346", "gb_free": "32.4", "wall": "130631"}
[2024-07-08 22:38:46,909][train_inner][INFO] - {"epoch": 43, "update": 42.255, "loss": "78.928", "ntokens": "14722.4", "nsentences": "84.4", "nll_loss": "0.452", "wps": "8429.4", "ups": "0.57", "wpb": "14722.4", "bsz": "84.4", "num_updates": "74000", "lr": "1.49124e-05", "gnorm": "117.831", "loss_scale": "8", "train_wall": "349", "gb_free": "32", "wall": "130981"}
[2024-07-08 22:44:36,232][train_inner][INFO] - {"epoch": 43, "update": 42.369, "loss": "76.415", "ntokens": "14536", "nsentences": "84.56", "nll_loss": "0.445", "wps": "8322.6", "ups": "0.57", "wpb": "14536", "bsz": "84.6", "num_updates": "74200", "lr": "1.47642e-05", "gnorm": "118.002", "loss_scale": "8", "train_wall": "349", "gb_free": "30.5", "wall": "131330"}
[2024-07-08 22:50:24,867][train_inner][INFO] - {"epoch": 43, "update": 42.483, "loss": "74.328", "ntokens": "14565.1", "nsentences": "85.8", "nll_loss": "0.438", "wps": "8355.7", "ups": "0.57", "wpb": "14565.1", "bsz": "85.8", "num_updates": "74400", "lr": "1.46175e-05", "gnorm": "118.195", "loss_scale": "8", "train_wall": "348", "gb_free": "31.4", "wall": "131679"}
[2024-07-08 22:56:10,170][train_inner][INFO] - {"epoch": 43, "update": 42.598, "loss": "78.009", "ntokens": "14533.2", "nsentences": "84.56", "nll_loss": "0.454", "wps": "8417.9", "ups": "0.58", "wpb": "14533.2", "bsz": "84.6", "num_updates": "74600", "lr": "1.44723e-05", "gnorm": "120.704", "loss_scale": "8", "train_wall": "345", "gb_free": "31.6", "wall": "132024"}
[2024-07-08 23:02:03,393][train_inner][INFO] - {"epoch": 43, "update": 42.712, "loss": "75", "ntokens": "14655", "nsentences": "85.44", "nll_loss": "0.437", "wps": "8299.7", "ups": "0.57", "wpb": "14655", "bsz": "85.4", "num_updates": "74800", "lr": "1.43285e-05", "gnorm": "117.421", "loss_scale": "8", "train_wall": "353", "gb_free": "32.5", "wall": "132377"}
[2024-07-08 23:07:52,224][train_inner][INFO] - {"epoch": 43, "update": 42.826, "loss": "76.888", "ntokens": "14577.1", "nsentences": "86.56", "nll_loss": "0.457", "wps": "8358.2", "ups": "0.57", "wpb": "14577.1", "bsz": "86.6", "num_updates": "75000", "lr": "1.41861e-05", "gnorm": "114.961", "loss_scale": "16", "train_wall": "348", "gb_free": "31.7", "wall": "132726"}
[2024-07-08 23:13:50,258][train_inner][INFO] - {"epoch": 43, "update": 42.94, "loss": "77.833", "ntokens": "14498", "nsentences": "83.6", "nll_loss": "0.449", "wps": "8100.4", "ups": "0.56", "wpb": "14498", "bsz": "83.6", "num_updates": "75200", "lr": "1.40452e-05", "gnorm": "117.52", "loss_scale": "16", "train_wall": "357", "gb_free": "32", "wall": "133084"}
[2024-07-08 23:16:53,259][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-08 23:16:53,265][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 23:17:25,506][dev-other][INFO] - {"epoch": 43, "dev-other_loss": "20.948", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.223", "dev-other_uer": "3.364", "dev-other_wer": "8.758", "dev-other_raw_wer": "8.758", "dev-other_wps": "8680.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "75305", "dev-other_best_wer": "8.75"}
[2024-07-08 23:17:25,507][fairseq_cli.train][INFO] - end of epoch 43 (average epoch stats below)
[2024-07-08 23:17:25,511][train][INFO] - {"epoch": 43, "train_loss": "76.898", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.448", "train_wps": "8235.8", "train_ups": "0.56", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "75305", "train_lr": "1.39717e-05", "train_gnorm": "117.958", "train_loss_scale": "16", "train_train_wall": "3063", "train_gb_free": "32.9", "train_wall": "133299"}
[2024-07-08 23:17:25,512][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-08 23:17:26,201][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-08 23:17:26,206][fairseq.trainer][INFO] - begin training epoch 44
[2024-07-08 23:17:26,207][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-08 23:20:15,280][train_inner][INFO] - {"epoch": 44, "update": 43.054, "loss": "76.466", "ntokens": "14606.7", "nsentences": "85.4", "nll_loss": "0.447", "wps": "7587.7", "ups": "0.52", "wpb": "14606.7", "bsz": "85.4", "num_updates": "75400", "lr": "1.39056e-05", "gnorm": "118.218", "loss_scale": "16", "train_wall": "351", "gb_free": "31.8", "wall": "133469"}
[2024-07-08 23:26:08,348][train_inner][INFO] - {"epoch": 44, "update": 43.168, "loss": "79.395", "ntokens": "14536", "nsentences": "83.28", "nll_loss": "0.455", "wps": "8234.4", "ups": "0.57", "wpb": "14536", "bsz": "83.3", "num_updates": "75600", "lr": "1.37674e-05", "gnorm": "119.738", "loss_scale": "16", "train_wall": "353", "gb_free": "31.4", "wall": "133822"}
[2024-07-08 23:29:10,425][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-08 23:32:03,861][train_inner][INFO] - {"epoch": 44, "update": 43.283, "loss": "77.774", "ntokens": "14580.8", "nsentences": "83.475", "nll_loss": "0.445", "wps": "8202.9", "ups": "0.56", "wpb": "14580.8", "bsz": "83.5", "num_updates": "75800", "lr": "1.36307e-05", "gnorm": "118.301", "loss_scale": "8", "train_wall": "355", "gb_free": "32.6", "wall": "134178"}
[2024-07-08 23:38:01,660][train_inner][INFO] - {"epoch": 44, "update": 43.397, "loss": "75.65", "ntokens": "14520.7", "nsentences": "84.56", "nll_loss": "0.441", "wps": "8118.5", "ups": "0.56", "wpb": "14520.7", "bsz": "84.6", "num_updates": "76000", "lr": "1.34952e-05", "gnorm": "118.075", "loss_scale": "8", "train_wall": "357", "gb_free": "33.1", "wall": "134535"}
[2024-07-08 23:43:48,285][train_inner][INFO] - {"epoch": 44, "update": 43.511, "loss": "77.558", "ntokens": "14540.6", "nsentences": "85.04", "nll_loss": "0.454", "wps": "8390.1", "ups": "0.58", "wpb": "14540.6", "bsz": "85", "num_updates": "76200", "lr": "1.33611e-05", "gnorm": "118.798", "loss_scale": "8", "train_wall": "346", "gb_free": "32.4", "wall": "134882"}
[2024-07-08 23:49:26,548][train_inner][INFO] - {"epoch": 44, "update": 43.626, "loss": "80.052", "ntokens": "14622.4", "nsentences": "85.24", "nll_loss": "0.467", "wps": "8648", "ups": "0.59", "wpb": "14622.4", "bsz": "85.2", "num_updates": "76400", "lr": "1.32284e-05", "gnorm": "119.119", "loss_scale": "8", "train_wall": "338", "gb_free": "32.5", "wall": "135220"}
[2024-07-08 23:55:06,857][train_inner][INFO] - {"epoch": 44, "update": 43.74, "loss": "77.462", "ntokens": "14615.1", "nsentences": "87.24", "nll_loss": "0.462", "wps": "8589.8", "ups": "0.59", "wpb": "14615.1", "bsz": "87.2", "num_updates": "76600", "lr": "1.30969e-05", "gnorm": "116.322", "loss_scale": "8", "train_wall": "340", "gb_free": "32.9", "wall": "135561"}
[2024-07-09 00:00:55,148][train_inner][INFO] - {"epoch": 44, "update": 43.854, "loss": "75.767", "ntokens": "14553.4", "nsentences": "85.24", "nll_loss": "0.444", "wps": "8358.8", "ups": "0.57", "wpb": "14553.4", "bsz": "85.2", "num_updates": "76800", "lr": "1.29668e-05", "gnorm": "119.548", "loss_scale": "8", "train_wall": "348", "gb_free": "31.7", "wall": "135909"}
[2024-07-09 00:06:38,517][train_inner][INFO] - {"epoch": 44, "update": 43.968, "loss": "79.922", "ntokens": "14573.8", "nsentences": "83.96", "nll_loss": "0.46", "wps": "8489", "ups": "0.58", "wpb": "14573.8", "bsz": "84", "num_updates": "77000", "lr": "1.2838e-05", "gnorm": "118.886", "loss_scale": "8", "train_wall": "343", "gb_free": "31.5", "wall": "136252"}
[2024-07-09 00:08:13,740][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 00:08:13,747][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 00:08:45,897][dev-other][INFO] - {"epoch": 44, "dev-other_loss": "21.552", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.229", "dev-other_uer": "3.357", "dev-other_wer": "8.761", "dev-other_raw_wer": "8.761", "dev-other_wps": "8667", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "77056", "dev-other_best_wer": "8.75"}
[2024-07-09 00:08:45,897][fairseq_cli.train][INFO] - end of epoch 44 (average epoch stats below)
[2024-07-09 00:08:45,900][train][INFO] - {"epoch": 44, "train_loss": "77.565", "train_ntokens": "14577.2", "train_nsentences": "84.8652", "train_nll_loss": "0.452", "train_wps": "8286.2", "train_ups": "0.57", "train_wpb": "14577.2", "train_bsz": "84.9", "train_num_updates": "77056", "train_lr": "1.28021e-05", "train_gnorm": "118.515", "train_loss_scale": "8", "train_train_wall": "3042", "train_gb_free": "33.4", "train_wall": "136380"}
[2024-07-09 00:08:45,901][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 00:08:46,568][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 00:08:46,572][fairseq.trainer][INFO] - begin training epoch 45
[2024-07-09 00:08:46,572][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 00:12:52,778][train_inner][INFO] - {"epoch": 45, "update": 44.082, "loss": "75.533", "ntokens": "14614", "nsentences": "86.8", "nll_loss": "0.449", "wps": "7809.7", "ups": "0.53", "wpb": "14614", "bsz": "86.8", "num_updates": "77200", "lr": "1.27104e-05", "gnorm": "118.732", "loss_scale": "8", "train_wall": "341", "gb_free": "32.5", "wall": "136627"}
[2024-07-09 00:18:39,688][train_inner][INFO] - {"epoch": 45, "update": 44.196, "loss": "77.468", "ntokens": "14626.7", "nsentences": "84.68", "nll_loss": "0.448", "wps": "8434.3", "ups": "0.58", "wpb": "14626.7", "bsz": "84.7", "num_updates": "77400", "lr": "1.25841e-05", "gnorm": "120.005", "loss_scale": "8", "train_wall": "346", "gb_free": "29.7", "wall": "136973"}
[2024-07-09 00:24:26,230][train_inner][INFO] - {"epoch": 45, "update": 44.311, "loss": "78.735", "ntokens": "14599.8", "nsentences": "83.355", "nll_loss": "0.45", "wps": "8426.4", "ups": "0.58", "wpb": "14599.8", "bsz": "83.4", "num_updates": "77600", "lr": "1.24591e-05", "gnorm": "119.651", "loss_scale": "8", "train_wall": "346", "gb_free": "31.7", "wall": "137320"}
[2024-07-09 00:30:19,115][train_inner][INFO] - {"epoch": 45, "update": 44.425, "loss": "73.603", "ntokens": "14576.2", "nsentences": "86.4", "nll_loss": "0.436", "wps": "8263", "ups": "0.57", "wpb": "14576.2", "bsz": "86.4", "num_updates": "77800", "lr": "1.23353e-05", "gnorm": "115.99", "loss_scale": "16", "train_wall": "352", "gb_free": "30.9", "wall": "137673"}
[2024-07-09 00:36:06,815][train_inner][INFO] - {"epoch": 45, "update": 44.539, "loss": "75.358", "ntokens": "14654.7", "nsentences": "87.04", "nll_loss": "0.448", "wps": "8431.5", "ups": "0.58", "wpb": "14654.7", "bsz": "87", "num_updates": "78000", "lr": "1.22127e-05", "gnorm": "114.821", "loss_scale": "16", "train_wall": "347", "gb_free": "32.1", "wall": "138021"}
[2024-07-09 00:42:00,662][train_inner][INFO] - {"epoch": 45, "update": 44.653, "loss": "76.752", "ntokens": "14563", "nsentences": "83.92", "nll_loss": "0.442", "wps": "8233.6", "ups": "0.57", "wpb": "14563", "bsz": "83.9", "num_updates": "78200", "lr": "1.20914e-05", "gnorm": "120.904", "loss_scale": "16", "train_wall": "353", "gb_free": "33.3", "wall": "138374"}
[2024-07-09 00:47:45,747][train_inner][INFO] - {"epoch": 45, "update": 44.767, "loss": "79.965", "ntokens": "14442.2", "nsentences": "82.84", "nll_loss": "0.459", "wps": "8370.5", "ups": "0.58", "wpb": "14442.2", "bsz": "82.8", "num_updates": "78400", "lr": "1.19712e-05", "gnorm": "119.683", "loss_scale": "16", "train_wall": "345", "gb_free": "31.7", "wall": "138720"}
[2024-07-09 00:53:40,599][train_inner][INFO] - {"epoch": 45, "update": 44.881, "loss": "76.222", "ntokens": "14574.4", "nsentences": "85.64", "nll_loss": "0.448", "wps": "8214.6", "ups": "0.56", "wpb": "14574.4", "bsz": "85.6", "num_updates": "78600", "lr": "1.18523e-05", "gnorm": "116.166", "loss_scale": "16", "train_wall": "354", "gb_free": "32", "wall": "139074"}
[2024-07-09 00:59:08,129][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-09 00:59:36,347][train_inner][INFO] - {"epoch": 45, "update": 44.996, "loss": "80.092", "ntokens": "14584.4", "nsentences": "83.44", "nll_loss": "0.458", "wps": "8199.5", "ups": "0.56", "wpb": "14584.4", "bsz": "83.4", "num_updates": "78800", "lr": "1.17345e-05", "gnorm": "120.022", "loss_scale": "8", "train_wall": "355", "gb_free": "32.8", "wall": "139430"}
[2024-07-09 00:59:48,901][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 00:59:48,902][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 01:00:21,000][dev-other][INFO] - {"epoch": 45, "dev-other_loss": "20.349", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.216", "dev-other_uer": "3.347", "dev-other_wer": "8.781", "dev-other_raw_wer": "8.781", "dev-other_wps": "8693.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "78807", "dev-other_best_wer": "8.75"}
[2024-07-09 01:00:21,001][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 45 @ 78807 updates
[2024-07-09 01:00:21,002][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_last.pt
[2024-07-09 01:00:22,809][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_last.pt
[2024-07-09 01:00:22,836][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_last.pt (epoch 45 @ 78807 updates, score 8.781) (writing took 1.834616508334875 seconds)
[2024-07-09 01:00:22,836][fairseq_cli.train][INFO] - end of epoch 45 (average epoch stats below)
[2024-07-09 01:00:22,915][train][INFO] - {"epoch": 45, "train_loss": "77.139", "train_ntokens": "14576.9", "train_nsentences": "84.8698", "train_nll_loss": "0.449", "train_wps": "8241.7", "train_ups": "0.57", "train_wpb": "14576.9", "train_bsz": "84.9", "train_num_updates": "78807", "train_lr": "1.17304e-05", "train_gnorm": "118.409", "train_loss_scale": "8", "train_train_wall": "3057", "train_gb_free": "32.7", "train_wall": "139477"}
[2024-07-09 01:00:22,917][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 01:00:23,351][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 01:00:23,355][fairseq.trainer][INFO] - begin training epoch 46
[2024-07-09 01:00:23,355][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 01:06:00,284][train_inner][INFO] - {"epoch": 46, "update": 45.11, "loss": "73.885", "ntokens": "14534.2", "nsentences": "86.04", "nll_loss": "0.437", "wps": "7576", "ups": "0.52", "wpb": "14534.2", "bsz": "86", "num_updates": "79000", "lr": "1.16179e-05", "gnorm": "116.807", "loss_scale": "8", "train_wall": "349", "gb_free": "29.7", "wall": "139814"}
[2024-07-09 01:11:48,501][train_inner][INFO] - {"epoch": 46, "update": 45.224, "loss": "76.478", "ntokens": "14568.2", "nsentences": "85.92", "nll_loss": "0.451", "wps": "8367.7", "ups": "0.57", "wpb": "14568.2", "bsz": "85.9", "num_updates": "79200", "lr": "1.15025e-05", "gnorm": "119.873", "loss_scale": "8", "train_wall": "348", "gb_free": "33.2", "wall": "140162"}
[2024-07-09 01:17:38,641][train_inner][INFO] - {"epoch": 46, "update": 45.338, "loss": "77.067", "ntokens": "14669.1", "nsentences": "86.195", "nll_loss": "0.453", "wps": "8379.2", "ups": "0.57", "wpb": "14669.1", "bsz": "86.2", "num_updates": "79400", "lr": "1.13882e-05", "gnorm": "116.215", "loss_scale": "8", "train_wall": "350", "gb_free": "32.2", "wall": "140512"}
[2024-07-09 01:23:28,339][train_inner][INFO] - {"epoch": 46, "update": 45.453, "loss": "78.025", "ntokens": "14647.3", "nsentences": "84.8", "nll_loss": "0.452", "wps": "8378.7", "ups": "0.57", "wpb": "14647.3", "bsz": "84.8", "num_updates": "79600", "lr": "1.1275e-05", "gnorm": "119.243", "loss_scale": "8", "train_wall": "349", "gb_free": "31.4", "wall": "140862"}
[2024-07-09 01:29:15,174][train_inner][INFO] - {"epoch": 46, "update": 45.567, "loss": "78.734", "ntokens": "14513.2", "nsentences": "84.28", "nll_loss": "0.457", "wps": "8371", "ups": "0.58", "wpb": "14513.2", "bsz": "84.3", "num_updates": "79800", "lr": "1.1163e-05", "gnorm": "120.553", "loss_scale": "8", "train_wall": "346", "gb_free": "31.4", "wall": "141209"}
[2024-07-09 01:35:02,879][train_inner][INFO] - {"epoch": 46, "update": 45.681, "loss": "79.999", "ntokens": "14503.4", "nsentences": "82.68", "nll_loss": "0.456", "wps": "8344.7", "ups": "0.58", "wpb": "14503.4", "bsz": "82.7", "num_updates": "80000", "lr": "1.10521e-05", "gnorm": "122.012", "loss_scale": "8", "train_wall": "347", "gb_free": "30.3", "wall": "141557"}
[2024-07-09 01:40:50,802][train_inner][INFO] - {"epoch": 46, "update": 45.795, "loss": "78.355", "ntokens": "14481.2", "nsentences": "82.88", "nll_loss": "0.448", "wps": "8324.8", "ups": "0.57", "wpb": "14481.2", "bsz": "82.9", "num_updates": "80200", "lr": "1.09423e-05", "gnorm": "120.707", "loss_scale": "8", "train_wall": "347", "gb_free": "33.1", "wall": "141905"}
[2024-07-09 01:46:38,390][train_inner][INFO] - {"epoch": 46, "update": 45.909, "loss": "79.779", "ntokens": "14606.7", "nsentences": "84.52", "nll_loss": "0.462", "wps": "8408", "ups": "0.58", "wpb": "14606.7", "bsz": "84.5", "num_updates": "80400", "lr": "1.08336e-05", "gnorm": "120.971", "loss_scale": "8", "train_wall": "347", "gb_free": "31", "wall": "142252"}
[2024-07-09 01:51:10,810][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 01:51:10,816][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 01:51:42,973][dev-other][INFO] - {"epoch": 46, "dev-other_loss": "20.609", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.219", "dev-other_uer": "3.293", "dev-other_wer": "8.608", "dev-other_raw_wer": "8.608", "dev-other_wps": "8714.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "80559", "dev-other_best_wer": "8.608"}
[2024-07-09 01:51:42,973][fairseq_cli.train][INFO] - end of epoch 46 (average epoch stats below)
[2024-07-09 01:51:42,980][train][INFO] - {"epoch": 46, "train_loss": "77.583", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.452", "train_wps": "8292", "train_ups": "0.57", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "80559", "train_lr": "1.07479e-05", "train_gnorm": "119.48", "train_loss_scale": "8", "train_train_wall": "3042", "train_gb_free": "34.3", "train_wall": "142557"}
[2024-07-09 01:51:42,982][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 01:51:43,674][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 01:51:43,679][fairseq.trainer][INFO] - begin training epoch 47
[2024-07-09 01:51:43,679][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 01:52:59,553][train_inner][INFO] - {"epoch": 47, "update": 46.023, "loss": "74.189", "ntokens": "14621", "nsentences": "86.56", "nll_loss": "0.439", "wps": "7673.3", "ups": "0.52", "wpb": "14621", "bsz": "86.6", "num_updates": "80600", "lr": "1.07259e-05", "gnorm": "117.179", "loss_scale": "8", "train_wall": "347", "gb_free": "32.8", "wall": "142633"}
[2024-07-09 01:58:42,482][train_inner][INFO] - {"epoch": 47, "update": 46.138, "loss": "76.781", "ntokens": "14626.6", "nsentences": "85.88", "nll_loss": "0.451", "wps": "8531", "ups": "0.58", "wpb": "14626.6", "bsz": "85.9", "num_updates": "80800", "lr": "1.06193e-05", "gnorm": "120.425", "loss_scale": "8", "train_wall": "342", "gb_free": "32.1", "wall": "142976"}
[2024-07-09 02:04:33,552][train_inner][INFO] - {"epoch": 47, "update": 46.252, "loss": "75.38", "ntokens": "14487.3", "nsentences": "84.8", "nll_loss": "0.441", "wps": "8255.1", "ups": "0.57", "wpb": "14487.3", "bsz": "84.8", "num_updates": "81000", "lr": "1.05138e-05", "gnorm": "117.655", "loss_scale": "16", "train_wall": "350", "gb_free": "32.7", "wall": "143327"}
[2024-07-09 02:10:20,126][train_inner][INFO] - {"epoch": 47, "update": 46.366, "loss": "76.304", "ntokens": "14601.2", "nsentences": "86.32", "nll_loss": "0.451", "wps": "8427.6", "ups": "0.58", "wpb": "14601.2", "bsz": "86.3", "num_updates": "81200", "lr": "1.04094e-05", "gnorm": "117.64", "loss_scale": "16", "train_wall": "346", "gb_free": "32.1", "wall": "143674"}
[2024-07-09 02:16:05,898][train_inner][INFO] - {"epoch": 47, "update": 46.48, "loss": "75.206", "ntokens": "14561.6", "nsentences": "84.92", "nll_loss": "0.439", "wps": "8423.2", "ups": "0.58", "wpb": "14561.6", "bsz": "84.9", "num_updates": "81400", "lr": "1.03059e-05", "gnorm": "119.911", "loss_scale": "16", "train_wall": "345", "gb_free": "31.3", "wall": "144020"}
[2024-07-09 02:22:00,897][train_inner][INFO] - {"epoch": 47, "update": 46.594, "loss": "75.914", "ntokens": "14615.2", "nsentences": "84.28", "nll_loss": "0.438", "wps": "8235.7", "ups": "0.56", "wpb": "14615.2", "bsz": "84.3", "num_updates": "81600", "lr": "1.02035e-05", "gnorm": "118.182", "loss_scale": "16", "train_wall": "354", "gb_free": "31.4", "wall": "144375"}
[2024-07-09 02:27:50,005][train_inner][INFO] - {"epoch": 47, "update": 46.708, "loss": "78.276", "ntokens": "14574.2", "nsentences": "83.28", "nll_loss": "0.447", "wps": "8349.7", "ups": "0.57", "wpb": "14574.2", "bsz": "83.3", "num_updates": "81800", "lr": "1.01021e-05", "gnorm": "120.365", "loss_scale": "16", "train_wall": "349", "gb_free": "33.1", "wall": "144724"}
[2024-07-09 02:33:41,962][train_inner][INFO] - {"epoch": 47, "update": 46.822, "loss": "76.657", "ntokens": "14562.4", "nsentences": "83.48", "nll_loss": "0.439", "wps": "8275.3", "ups": "0.57", "wpb": "14562.4", "bsz": "83.5", "num_updates": "82000", "lr": "1.00018e-05", "gnorm": "118.24", "loss_scale": "16", "train_wall": "351", "gb_free": "32.2", "wall": "145076"}
[2024-07-09 02:39:40,207][train_inner][INFO] - {"epoch": 47, "update": 46.937, "loss": "75.034", "ntokens": "14639.5", "nsentences": "85.32", "nll_loss": "0.437", "wps": "8175.1", "ups": "0.56", "wpb": "14639.5", "bsz": "85.3", "num_updates": "82200", "lr": "9.90239e-06", "gnorm": "117.576", "loss_scale": "16", "train_wall": "358", "gb_free": "32.4", "wall": "145434"}
[2024-07-09 02:42:53,806][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 02:42:53,897][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 02:43:25,896][dev-other][INFO] - {"epoch": 47, "dev-other_loss": "20.4", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.217", "dev-other_uer": "3.27", "dev-other_wer": "8.642", "dev-other_raw_wer": "8.642", "dev-other_wps": "8686.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "82311", "dev-other_best_wer": "8.642"}
[2024-07-09 02:43:25,897][fairseq_cli.train][INFO] - end of epoch 47 (average epoch stats below)
[2024-07-09 02:43:25,917][train][INFO] - {"epoch": 47, "train_loss": "76.027", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.443", "train_wps": "8230.9", "train_ups": "0.56", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "82311", "train_lr": "9.84766e-06", "train_gnorm": "118.589", "train_loss_scale": "16", "train_train_wall": "3065", "train_gb_free": "33.1", "train_wall": "145660"}
[2024-07-09 02:43:25,919][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 02:43:26,630][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 02:43:26,643][fairseq.trainer][INFO] - begin training epoch 48
[2024-07-09 02:43:26,643][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 02:46:05,052][train_inner][INFO] - {"epoch": 48, "update": 47.051, "loss": "76.464", "ntokens": "14498.7", "nsentences": "84.315", "nll_loss": "0.445", "wps": "7535.1", "ups": "0.52", "wpb": "14498.7", "bsz": "84.3", "num_updates": "82400", "lr": "9.804e-06", "gnorm": "119.215", "loss_scale": "16", "train_wall": "351", "gb_free": "31.9", "wall": "145819"}
[2024-07-09 02:51:57,754][train_inner][INFO] - {"epoch": 48, "update": 47.165, "loss": "75.677", "ntokens": "14546.6", "nsentences": "84.2", "nll_loss": "0.438", "wps": "8248.9", "ups": "0.57", "wpb": "14546.6", "bsz": "84.2", "num_updates": "82600", "lr": "9.70659e-06", "gnorm": "117.845", "loss_scale": "16", "train_wall": "352", "gb_free": "32.5", "wall": "146172"}
[2024-07-09 02:57:52,239][train_inner][INFO] - {"epoch": 48, "update": 47.279, "loss": "74.931", "ntokens": "14492.8", "nsentences": "83.995", "nll_loss": "0.434", "wps": "8178.5", "ups": "0.56", "wpb": "14492.8", "bsz": "84", "num_updates": "82800", "lr": "9.61014e-06", "gnorm": "120.288", "loss_scale": "16", "train_wall": "354", "gb_free": "32.1", "wall": "146526"}
[2024-07-09 03:01:45,299][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-09 03:03:39,317][train_inner][INFO] - {"epoch": 48, "update": 47.394, "loss": "75.798", "ntokens": "14570.4", "nsentences": "86.08", "nll_loss": "0.448", "wps": "8397.8", "ups": "0.58", "wpb": "14570.4", "bsz": "86.1", "num_updates": "83000", "lr": "9.51466e-06", "gnorm": "117.686", "loss_scale": "16", "train_wall": "346", "gb_free": "32.9", "wall": "146873"}
[2024-07-09 03:09:29,597][train_inner][INFO] - {"epoch": 48, "update": 47.508, "loss": "75.653", "ntokens": "14565.9", "nsentences": "84.8", "nll_loss": "0.44", "wps": "8318.6", "ups": "0.57", "wpb": "14565.9", "bsz": "84.8", "num_updates": "83200", "lr": "9.42012e-06", "gnorm": "119.484", "loss_scale": "16", "train_wall": "350", "gb_free": "33.8", "wall": "147223"}
[2024-07-09 03:15:16,037][train_inner][INFO] - {"epoch": 48, "update": 47.622, "loss": "78.026", "ntokens": "14550.4", "nsentences": "84.52", "nll_loss": "0.453", "wps": "8402.2", "ups": "0.58", "wpb": "14550.4", "bsz": "84.5", "num_updates": "83400", "lr": "9.32652e-06", "gnorm": "120.316", "loss_scale": "16", "train_wall": "346", "gb_free": "29.9", "wall": "147570"}
[2024-07-09 03:21:05,163][train_inner][INFO] - {"epoch": 48, "update": 47.736, "loss": "75.642", "ntokens": "14612", "nsentences": "84.64", "nll_loss": "0.438", "wps": "8372.9", "ups": "0.57", "wpb": "14612", "bsz": "84.6", "num_updates": "83600", "lr": "9.23385e-06", "gnorm": "118.369", "loss_scale": "16", "train_wall": "348", "gb_free": "32.7", "wall": "147919"}
[2024-07-09 03:26:48,954][train_inner][INFO] - {"epoch": 48, "update": 47.85, "loss": "77.684", "ntokens": "14673", "nsentences": "84.76", "nll_loss": "0.449", "wps": "8536.6", "ups": "0.58", "wpb": "14673", "bsz": "84.8", "num_updates": "83800", "lr": "9.1421e-06", "gnorm": "121.999", "loss_scale": "16", "train_wall": "343", "gb_free": "32", "wall": "148263"}
[2024-07-09 03:32:30,127][train_inner][INFO] - {"epoch": 48, "update": 47.965, "loss": "78.559", "ntokens": "14629.2", "nsentences": "85.32", "nll_loss": "0.458", "wps": "8576.1", "ups": "0.59", "wpb": "14629.2", "bsz": "85.3", "num_updates": "84000", "lr": "9.05126e-06", "gnorm": "118.995", "loss_scale": "16", "train_wall": "341", "gb_free": "33", "wall": "148604"}
[2024-07-09 03:34:16,105][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 03:34:16,110][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 03:34:48,201][dev-other][INFO] - {"epoch": 48, "dev-other_loss": "20.542", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.218", "dev-other_uer": "3.359", "dev-other_wer": "8.773", "dev-other_raw_wer": "8.773", "dev-other_wps": "8702.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "84062", "dev-other_best_wer": "8.75"}
[2024-07-09 03:34:48,201][fairseq_cli.train][INFO] - end of epoch 48 (average epoch stats below)
[2024-07-09 03:34:48,204][train][INFO] - {"epoch": 48, "train_loss": "76.549", "train_ntokens": "14577.1", "train_nsentences": "84.8607", "train_nll_loss": "0.446", "train_wps": "8281", "train_ups": "0.57", "train_wpb": "14577.1", "train_bsz": "84.9", "train_num_updates": "84062", "train_lr": "9.02329e-06", "train_gnorm": "119.254", "train_loss_scale": "16", "train_train_wall": "3044", "train_gb_free": "32.7", "train_wall": "148742"}
[2024-07-09 03:34:48,205][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 03:34:48,894][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 03:34:48,898][fairseq.trainer][INFO] - begin training epoch 49
[2024-07-09 03:34:48,898][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 03:38:52,378][train_inner][INFO] - {"epoch": 49, "update": 48.079, "loss": "76.838", "ntokens": "14493.3", "nsentences": "84.44", "nll_loss": "0.448", "wps": "7583.3", "ups": "0.52", "wpb": "14493.3", "bsz": "84.4", "num_updates": "84200", "lr": "8.96133e-06", "gnorm": "120.218", "loss_scale": "16", "train_wall": "349", "gb_free": "31.5", "wall": "148986"}
[2024-07-09 03:44:32,926][train_inner][INFO] - {"epoch": 49, "update": 48.193, "loss": "75.36", "ntokens": "14557.4", "nsentences": "86.52", "nll_loss": "0.448", "wps": "8549.7", "ups": "0.59", "wpb": "14557.4", "bsz": "86.5", "num_updates": "84400", "lr": "8.87229e-06", "gnorm": "120.304", "loss_scale": "16", "train_wall": "340", "gb_free": "30.6", "wall": "149327"}
[2024-07-09 03:50:18,445][train_inner][INFO] - {"epoch": 49, "update": 48.307, "loss": "76.486", "ntokens": "14497.3", "nsentences": "83.92", "nll_loss": "0.443", "wps": "8393.4", "ups": "0.58", "wpb": "14497.3", "bsz": "83.9", "num_updates": "84600", "lr": "8.78413e-06", "gnorm": "121.787", "loss_scale": "16", "train_wall": "345", "gb_free": "31.9", "wall": "149672"}
[2024-07-09 03:55:57,473][train_inner][INFO] - {"epoch": 49, "update": 48.421, "loss": "76.582", "ntokens": "14524.7", "nsentences": "85.355", "nll_loss": "0.45", "wps": "8568.7", "ups": "0.59", "wpb": "14524.7", "bsz": "85.4", "num_updates": "84800", "lr": "8.69685e-06", "gnorm": "118.651", "loss_scale": "16", "train_wall": "338", "gb_free": "31.5", "wall": "150011"}
[2024-07-09 04:01:49,515][train_inner][INFO] - {"epoch": 49, "update": 48.535, "loss": "78.88", "ntokens": "14610.4", "nsentences": "84.48", "nll_loss": "0.456", "wps": "8300.6", "ups": "0.57", "wpb": "14610.4", "bsz": "84.5", "num_updates": "85000", "lr": "8.61044e-06", "gnorm": "119.748", "loss_scale": "32", "train_wall": "351", "gb_free": "31.7", "wall": "150363"}
[2024-07-09 04:02:08,633][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-09 04:07:12,703][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-09 04:07:40,199][train_inner][INFO] - {"epoch": 49, "update": 48.651, "loss": "75.341", "ntokens": "14687.6", "nsentences": "86.6", "nll_loss": "0.444", "wps": "8377.9", "ups": "0.57", "wpb": "14687.6", "bsz": "86.6", "num_updates": "85200", "lr": "8.52489e-06", "gnorm": "114.715", "loss_scale": "8", "train_wall": "350", "gb_free": "31.7", "wall": "150714"}
[2024-07-09 04:13:35,450][train_inner][INFO] - {"epoch": 49, "update": 48.765, "loss": "73.141", "ntokens": "14577.3", "nsentences": "84.4", "nll_loss": "0.423", "wps": "8207.5", "ups": "0.56", "wpb": "14577.3", "bsz": "84.4", "num_updates": "85400", "lr": "8.44018e-06", "gnorm": "115.087", "loss_scale": "8", "train_wall": "355", "gb_free": "30.4", "wall": "151069"}
[2024-07-09 04:19:31,808][train_inner][INFO] - {"epoch": 49, "update": 48.879, "loss": "76.898", "ntokens": "14568.2", "nsentences": "83.12", "nll_loss": "0.439", "wps": "8177.7", "ups": "0.56", "wpb": "14568.2", "bsz": "83.1", "num_updates": "85600", "lr": "8.35632e-06", "gnorm": "120.826", "loss_scale": "8", "train_wall": "356", "gb_free": "31.6", "wall": "151426"}
[2024-07-09 04:25:28,221][train_inner][INFO] - {"epoch": 49, "update": 48.993, "loss": "74.645", "ntokens": "14699.6", "nsentences": "85.84", "nll_loss": "0.436", "wps": "8250.3", "ups": "0.56", "wpb": "14699.6", "bsz": "85.8", "num_updates": "85800", "lr": "8.27329e-06", "gnorm": "114.347", "loss_scale": "8", "train_wall": "356", "gb_free": "32.1", "wall": "151782"}
[2024-07-09 04:25:45,742][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 04:25:45,744][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 04:26:17,982][dev-other][INFO] - {"epoch": 49, "dev-other_loss": "20.939", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.223", "dev-other_uer": "3.322", "dev-other_wer": "8.634", "dev-other_raw_wer": "8.634", "dev-other_wps": "8653.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "85812", "dev-other_best_wer": "8.634"}
[2024-07-09 04:26:17,982][fairseq_cli.train][INFO] - end of epoch 49 (average epoch stats below)
[2024-07-09 04:26:17,985][train][INFO] - {"epoch": 49, "train_loss": "75.861", "train_ntokens": "14578.4", "train_nsentences": "84.8771", "train_nll_loss": "0.442", "train_wps": "8257", "train_ups": "0.57", "train_wpb": "14578.4", "train_bsz": "84.9", "train_num_updates": "85812", "train_lr": "8.26834e-06", "train_gnorm": "118.543", "train_loss_scale": "8", "train_train_wall": "3052", "train_gb_free": "33.7", "train_wall": "151832"}
[2024-07-09 04:26:17,987][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 04:26:18,703][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 04:26:18,706][fairseq.trainer][INFO] - begin training epoch 50
[2024-07-09 04:26:18,707][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 04:31:46,053][train_inner][INFO] - {"epoch": 50, "update": 49.107, "loss": "77.905", "ntokens": "14550.7", "nsentences": "82.48", "nll_loss": "0.442", "wps": "7703.2", "ups": "0.53", "wpb": "14550.7", "bsz": "82.5", "num_updates": "86000", "lr": "8.19109e-06", "gnorm": "124.694", "loss_scale": "8", "train_wall": "344", "gb_free": "32.2", "wall": "152160"}
[2024-07-09 04:37:35,649][train_inner][INFO] - {"epoch": 50, "update": 49.221, "loss": "77.778", "ntokens": "14578.7", "nsentences": "82.6", "nll_loss": "0.441", "wps": "8341.3", "ups": "0.57", "wpb": "14578.7", "bsz": "82.6", "num_updates": "86200", "lr": "8.1097e-06", "gnorm": "120.061", "loss_scale": "8", "train_wall": "349", "gb_free": "32.3", "wall": "152509"}
[2024-07-09 04:43:27,219][train_inner][INFO] - {"epoch": 50, "update": 49.336, "loss": "77.055", "ntokens": "14586.1", "nsentences": "85.92", "nll_loss": "0.454", "wps": "8299.2", "ups": "0.57", "wpb": "14586.1", "bsz": "85.9", "num_updates": "86400", "lr": "8.02912e-06", "gnorm": "115.891", "loss_scale": "8", "train_wall": "351", "gb_free": "32.3", "wall": "152861"}
[2024-07-09 04:49:22,659][train_inner][INFO] - {"epoch": 50, "update": 49.45, "loss": "73.854", "ntokens": "14663.3", "nsentences": "85.08", "nll_loss": "0.429", "wps": "8252.4", "ups": "0.56", "wpb": "14663.3", "bsz": "85.1", "num_updates": "86600", "lr": "7.94934e-06", "gnorm": "118.93", "loss_scale": "8", "train_wall": "355", "gb_free": "32.3", "wall": "153216"}
[2024-07-09 04:55:10,779][train_inner][INFO] - {"epoch": 50, "update": 49.564, "loss": "75.364", "ntokens": "14692", "nsentences": "87.555", "nll_loss": "0.449", "wps": "8441.3", "ups": "0.57", "wpb": "14692", "bsz": "87.6", "num_updates": "86800", "lr": "7.87036e-06", "gnorm": "117.08", "loss_scale": "8", "train_wall": "348", "gb_free": "32.5", "wall": "153565"}
[2024-07-09 05:00:56,466][train_inner][INFO] - {"epoch": 50, "update": 49.678, "loss": "72.063", "ntokens": "14638.8", "nsentences": "89.24", "nll_loss": "0.439", "wps": "8469.6", "ups": "0.58", "wpb": "14638.8", "bsz": "89.2", "num_updates": "87000", "lr": "7.79216e-06", "gnorm": "116.334", "loss_scale": "8", "train_wall": "345", "gb_free": "32.3", "wall": "153910"}
[2024-07-09 05:06:53,374][train_inner][INFO] - {"epoch": 50, "update": 49.792, "loss": "77.237", "ntokens": "14500.6", "nsentences": "83", "nll_loss": "0.442", "wps": "8127.4", "ups": "0.56", "wpb": "14500.6", "bsz": "83", "num_updates": "87200", "lr": "7.71473e-06", "gnorm": "120.216", "loss_scale": "8", "train_wall": "356", "gb_free": "31.7", "wall": "154267"}
[2024-07-09 05:12:48,708][train_inner][INFO] - {"epoch": 50, "update": 49.906, "loss": "71.938", "ntokens": "14439.4", "nsentences": "84.2", "nll_loss": "0.419", "wps": "8129", "ups": "0.56", "wpb": "14439.4", "bsz": "84.2", "num_updates": "87400", "lr": "7.63808e-06", "gnorm": "117.522", "loss_scale": "16", "train_wall": "355", "gb_free": "32.5", "wall": "154622"}
[2024-07-09 05:17:39,332][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 05:17:39,340][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 05:18:11,418][dev-other][INFO] - {"epoch": 50, "dev-other_loss": "20.918", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.222", "dev-other_uer": "3.347", "dev-other_wer": "8.728", "dev-other_raw_wer": "8.728", "dev-other_wps": "8707.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "87564", "dev-other_best_wer": "8.728"}
[2024-07-09 05:18:11,420][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 50 @ 87564 updates
[2024-07-09 05:18:11,421][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-09 05:18:13,271][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-09 05:18:13,847][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 50 @ 87564 updates, score 8.728) (writing took 2.4274928644299507 seconds)
[2024-07-09 05:18:13,847][fairseq_cli.train][INFO] - end of epoch 50 (average epoch stats below)
[2024-07-09 05:18:13,851][train][INFO] - {"epoch": 50, "train_loss": "75.503", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.44", "train_wps": "8196.7", "train_ups": "0.56", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "87564", "train_lr": "7.57579e-06", "train_gnorm": "118.729", "train_loss_scale": "16", "train_train_wall": "3075", "train_gb_free": "33.8", "train_wall": "154948"}
[2024-07-09 05:18:13,852][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 05:18:14,123][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 05:18:14,126][fairseq.trainer][INFO] - begin training epoch 51
[2024-07-09 05:18:14,126][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 05:19:15,505][train_inner][INFO] - {"epoch": 51, "update": 50.021, "loss": "75.323", "ntokens": "14602.1", "nsentences": "85.36", "nll_loss": "0.44", "wps": "7550.4", "ups": "0.52", "wpb": "14602.1", "bsz": "85.4", "num_updates": "87600", "lr": "7.56219e-06", "gnorm": "117.4", "loss_scale": "16", "train_wall": "351", "gb_free": "32", "wall": "155009"}
[2024-07-09 05:25:10,641][train_inner][INFO] - {"epoch": 51, "update": 50.135, "loss": "74.807", "ntokens": "14599.2", "nsentences": "84.56", "nll_loss": "0.433", "wps": "8221.9", "ups": "0.56", "wpb": "14599.2", "bsz": "84.6", "num_updates": "87800", "lr": "7.48705e-06", "gnorm": "116.068", "loss_scale": "16", "train_wall": "355", "gb_free": "31.9", "wall": "155364"}
[2024-07-09 05:31:02,429][train_inner][INFO] - {"epoch": 51, "update": 50.249, "loss": "76.167", "ntokens": "14549.8", "nsentences": "84.4", "nll_loss": "0.442", "wps": "8272.2", "ups": "0.57", "wpb": "14549.8", "bsz": "84.4", "num_updates": "88000", "lr": "7.41266e-06", "gnorm": "119.527", "loss_scale": "16", "train_wall": "351", "gb_free": "31.8", "wall": "155716"}
[2024-07-09 05:36:48,061][train_inner][INFO] - {"epoch": 51, "update": 50.363, "loss": "77.739", "ntokens": "14434.3", "nsentences": "82.555", "nll_loss": "0.445", "wps": "8352.7", "ups": "0.58", "wpb": "14434.3", "bsz": "82.6", "num_updates": "88200", "lr": "7.339e-06", "gnorm": "122.67", "loss_scale": "16", "train_wall": "345", "gb_free": "32", "wall": "156062"}
[2024-07-09 05:42:34,986][train_inner][INFO] - {"epoch": 51, "update": 50.477, "loss": "77.041", "ntokens": "14575.5", "nsentences": "85.92", "nll_loss": "0.454", "wps": "8402.9", "ups": "0.58", "wpb": "14575.5", "bsz": "85.9", "num_updates": "88400", "lr": "7.26608e-06", "gnorm": "119.883", "loss_scale": "16", "train_wall": "346", "gb_free": "30", "wall": "156409"}
[2024-07-09 05:48:23,594][train_inner][INFO] - {"epoch": 51, "update": 50.591, "loss": "71.935", "ntokens": "14616.9", "nsentences": "87.92", "nll_loss": "0.433", "wps": "8386.1", "ups": "0.57", "wpb": "14616.9", "bsz": "87.9", "num_updates": "88600", "lr": "7.19389e-06", "gnorm": "114.995", "loss_scale": "16", "train_wall": "348", "gb_free": "32.1", "wall": "156757"}
[2024-07-09 05:54:14,416][train_inner][INFO] - {"epoch": 51, "update": 50.705, "loss": "77.276", "ntokens": "14618.6", "nsentences": "84.24", "nll_loss": "0.445", "wps": "8335.5", "ups": "0.57", "wpb": "14618.6", "bsz": "84.2", "num_updates": "88800", "lr": "7.12241e-06", "gnorm": "118.205", "loss_scale": "16", "train_wall": "350", "gb_free": "32.8", "wall": "157108"}
[2024-07-09 06:00:02,515][train_inner][INFO] - {"epoch": 51, "update": 50.82, "loss": "74.851", "ntokens": "14666", "nsentences": "86.04", "nll_loss": "0.439", "wps": "8426.6", "ups": "0.57", "wpb": "14666", "bsz": "86", "num_updates": "89000", "lr": "7.05164e-06", "gnorm": "116.685", "loss_scale": "16", "train_wall": "348", "gb_free": "32.7", "wall": "157456"}
[2024-07-09 06:05:55,618][train_inner][INFO] - {"epoch": 51, "update": 50.934, "loss": "74.699", "ntokens": "14566.2", "nsentences": "82.36", "nll_loss": "0.422", "wps": "8250.6", "ups": "0.57", "wpb": "14566.2", "bsz": "82.4", "num_updates": "89200", "lr": "6.98157e-06", "gnorm": "121.687", "loss_scale": "16", "train_wall": "353", "gb_free": "33.2", "wall": "157809"}
[2024-07-09 06:09:19,665][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 06:09:19,672][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 06:09:51,769][dev-other][INFO] - {"epoch": 51, "dev-other_loss": "20.915", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.222", "dev-other_uer": "3.307", "dev-other_wer": "8.683", "dev-other_raw_wer": "8.683", "dev-other_wps": "8711.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "89316", "dev-other_best_wer": "8.683"}
[2024-07-09 06:09:51,770][fairseq_cli.train][INFO] - end of epoch 51 (average epoch stats below)
[2024-07-09 06:09:51,776][train][INFO] - {"epoch": 51, "train_loss": "75.239", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.438", "train_wps": "8244.2", "train_ups": "0.57", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "89316", "train_lr": "6.94125e-06", "train_gnorm": "118.441", "train_loss_scale": "32", "train_train_wall": "3061", "train_gb_free": "33.1", "train_wall": "158046"}
[2024-07-09 06:09:51,777][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 06:09:52,465][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 06:09:52,468][fairseq.trainer][INFO] - begin training epoch 52
[2024-07-09 06:09:52,468][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 06:12:17,347][train_inner][INFO] - {"epoch": 52, "update": 51.048, "loss": "74.315", "ntokens": "14526.7", "nsentences": "84.36", "nll_loss": "0.432", "wps": "7611.2", "ups": "0.52", "wpb": "14526.7", "bsz": "84.4", "num_updates": "89400", "lr": "6.9122e-06", "gnorm": "117.115", "loss_scale": "32", "train_wall": "348", "gb_free": "30.4", "wall": "158191"}
[2024-07-09 06:12:32,780][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-09 06:18:11,265][train_inner][INFO] - {"epoch": 52, "update": 51.163, "loss": "74.484", "ntokens": "14518.9", "nsentences": "84.2", "nll_loss": "0.432", "wps": "8204.9", "ups": "0.57", "wpb": "14518.9", "bsz": "84.2", "num_updates": "89600", "lr": "6.84352e-06", "gnorm": "117.94", "loss_scale": "16", "train_wall": "353", "gb_free": "30", "wall": "158545"}
[2024-07-09 06:18:23,936][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-09 06:23:54,241][train_inner][INFO] - {"epoch": 52, "update": 51.277, "loss": "78.063", "ntokens": "14627.8", "nsentences": "83.68", "nll_loss": "0.447", "wps": "8530.2", "ups": "0.58", "wpb": "14627.8", "bsz": "83.7", "num_updates": "89800", "lr": "6.77553e-06", "gnorm": "123.237", "loss_scale": "8", "train_wall": "342", "gb_free": "32.5", "wall": "158888"}
[2024-07-09 06:29:52,537][train_inner][INFO] - {"epoch": 52, "update": 51.392, "loss": "73.564", "ntokens": "14561.7", "nsentences": "84.755", "nll_loss": "0.428", "wps": "8128.5", "ups": "0.56", "wpb": "14561.7", "bsz": "84.8", "num_updates": "90000", "lr": "6.7082e-06", "gnorm": "116.867", "loss_scale": "8", "train_wall": "358", "gb_free": "32.8", "wall": "159246"}
[2024-07-09 06:35:48,186][train_inner][INFO] - {"epoch": 52, "update": 51.506, "loss": "75.249", "ntokens": "14674.4", "nsentences": "85.4", "nll_loss": "0.438", "wps": "8252.4", "ups": "0.56", "wpb": "14674.4", "bsz": "85.4", "num_updates": "90200", "lr": "6.64155e-06", "gnorm": "117.771", "loss_scale": "8", "train_wall": "355", "gb_free": "30.5", "wall": "159602"}
[2024-07-09 06:41:39,745][train_inner][INFO] - {"epoch": 52, "update": 51.62, "loss": "76.039", "ntokens": "14559.7", "nsentences": "84.12", "nll_loss": "0.439", "wps": "8283.2", "ups": "0.57", "wpb": "14559.7", "bsz": "84.1", "num_updates": "90400", "lr": "6.57556e-06", "gnorm": "117.065", "loss_scale": "8", "train_wall": "351", "gb_free": "32.7", "wall": "159954"}
[2024-07-09 06:47:32,409][train_inner][INFO] - {"epoch": 52, "update": 51.734, "loss": "72.039", "ntokens": "14587.7", "nsentences": "87.56", "nll_loss": "0.432", "wps": "8274.5", "ups": "0.57", "wpb": "14587.7", "bsz": "87.6", "num_updates": "90600", "lr": "6.51022e-06", "gnorm": "115.273", "loss_scale": "8", "train_wall": "352", "gb_free": "32.4", "wall": "160306"}
[2024-07-09 06:53:25,105][train_inner][INFO] - {"epoch": 52, "update": 51.848, "loss": "72.316", "ntokens": "14600", "nsentences": "85.88", "nll_loss": "0.425", "wps": "8281.1", "ups": "0.57", "wpb": "14600.1", "bsz": "85.9", "num_updates": "90800", "lr": "6.44554e-06", "gnorm": "116.915", "loss_scale": "8", "train_wall": "352", "gb_free": "32.1", "wall": "160659"}
[2024-07-09 06:59:16,546][train_inner][INFO] - {"epoch": 52, "update": 51.962, "loss": "76.298", "ntokens": "14533.3", "nsentences": "83.96", "nll_loss": "0.441", "wps": "8272.5", "ups": "0.57", "wpb": "14533.3", "bsz": "84", "num_updates": "91000", "lr": "6.38149e-06", "gnorm": "118.528", "loss_scale": "8", "train_wall": "351", "gb_free": "32.6", "wall": "161010"}
[2024-07-09 07:01:08,875][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 07:01:08,949][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 07:01:40,977][dev-other][INFO] - {"epoch": 52, "dev-other_loss": "20.308", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.216", "dev-other_uer": "3.303", "dev-other_wer": "8.646", "dev-other_raw_wer": "8.646", "dev-other_wps": "8704.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "91066", "dev-other_best_wer": "8.646"}
[2024-07-09 07:01:40,978][fairseq_cli.train][INFO] - end of epoch 52 (average epoch stats below)
[2024-07-09 07:01:40,980][train][INFO] - {"epoch": 52, "train_loss": "75.011", "train_ntokens": "14578.5", "train_nsentences": "84.8269", "train_nll_loss": "0.436", "train_wps": "8205.4", "train_ups": "0.56", "train_wpb": "14578.5", "train_bsz": "84.8", "train_num_updates": "91066", "train_lr": "6.3605e-06", "train_gnorm": "118.244", "train_loss_scale": "8", "train_train_wall": "3071", "train_gb_free": "33.5", "train_wall": "161155"}
[2024-07-09 07:01:40,982][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 07:01:41,692][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 07:01:41,709][fairseq.trainer][INFO] - begin training epoch 53
[2024-07-09 07:01:41,710][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 07:05:35,759][train_inner][INFO] - {"epoch": 53, "update": 52.076, "loss": "77.35", "ntokens": "14517.9", "nsentences": "83.8", "nll_loss": "0.446", "wps": "7657.5", "ups": "0.53", "wpb": "14517.9", "bsz": "83.8", "num_updates": "91200", "lr": "6.31809e-06", "gnorm": "121.612", "loss_scale": "8", "train_wall": "346", "gb_free": "31.6", "wall": "161390"}
[2024-07-09 07:11:27,798][train_inner][INFO] - {"epoch": 53, "update": 52.191, "loss": "76.862", "ntokens": "14509.1", "nsentences": "84.36", "nll_loss": "0.447", "wps": "8243.1", "ups": "0.57", "wpb": "14509.1", "bsz": "84.4", "num_updates": "91400", "lr": "6.25531e-06", "gnorm": "118.693", "loss_scale": "8", "train_wall": "351", "gb_free": "33.2", "wall": "161742"}
[2024-07-09 07:17:22,371][train_inner][INFO] - {"epoch": 53, "update": 52.305, "loss": "74.732", "ntokens": "14696.5", "nsentences": "87.035", "nll_loss": "0.443", "wps": "8290", "ups": "0.56", "wpb": "14696.6", "bsz": "87", "num_updates": "91600", "lr": "6.19316e-06", "gnorm": "116.876", "loss_scale": "8", "train_wall": "354", "gb_free": "31.7", "wall": "162096"}
[2024-07-09 07:23:11,848][train_inner][INFO] - {"epoch": 53, "update": 52.419, "loss": "74.982", "ntokens": "14501", "nsentences": "84.52", "nll_loss": "0.437", "wps": "8298.9", "ups": "0.57", "wpb": "14501.1", "bsz": "84.5", "num_updates": "91800", "lr": "6.13162e-06", "gnorm": "118.614", "loss_scale": "16", "train_wall": "349", "gb_free": "31.7", "wall": "162446"}
[2024-07-09 07:29:01,557][train_inner][INFO] - {"epoch": 53, "update": 52.533, "loss": "77.32", "ntokens": "14619.2", "nsentences": "84.04", "nll_loss": "0.444", "wps": "8361", "ups": "0.57", "wpb": "14619.2", "bsz": "84", "num_updates": "92000", "lr": "6.0707e-06", "gnorm": "119.382", "loss_scale": "16", "train_wall": "349", "gb_free": "29.9", "wall": "162795"}
[2024-07-09 07:35:02,508][train_inner][INFO] - {"epoch": 53, "update": 52.647, "loss": "74.067", "ntokens": "14628.8", "nsentences": "84.72", "nll_loss": "0.429", "wps": "8107.6", "ups": "0.55", "wpb": "14628.8", "bsz": "84.7", "num_updates": "92200", "lr": "6.01038e-06", "gnorm": "117.438", "loss_scale": "16", "train_wall": "360", "gb_free": "32.3", "wall": "163156"}
[2024-07-09 07:40:51,455][train_inner][INFO] - {"epoch": 53, "update": 52.761, "loss": "74.284", "ntokens": "14595.2", "nsentences": "85.36", "nll_loss": "0.434", "wps": "8365.8", "ups": "0.57", "wpb": "14595.2", "bsz": "85.4", "num_updates": "92400", "lr": "5.95066e-06", "gnorm": "118.481", "loss_scale": "16", "train_wall": "348", "gb_free": "32.7", "wall": "163505"}
[2024-07-09 07:46:39,037][train_inner][INFO] - {"epoch": 53, "update": 52.876, "loss": "77.22", "ntokens": "14576.8", "nsentences": "84.32", "nll_loss": "0.447", "wps": "8387.9", "ups": "0.58", "wpb": "14576.8", "bsz": "84.3", "num_updates": "92600", "lr": "5.89153e-06", "gnorm": "119.344", "loss_scale": "16", "train_wall": "347", "gb_free": "31.2", "wall": "163853"}
[2024-07-09 07:52:29,480][train_inner][INFO] - {"epoch": 53, "update": 52.99, "loss": "73.138", "ntokens": "14530.1", "nsentences": "84.72", "nll_loss": "0.426", "wps": "8292.6", "ups": "0.57", "wpb": "14530.1", "bsz": "84.7", "num_updates": "92800", "lr": "5.83299e-06", "gnorm": "118.915", "loss_scale": "16", "train_wall": "350", "gb_free": "29.9", "wall": "164203"}
[2024-07-09 07:52:58,073][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 07:52:58,074][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 07:53:30,195][dev-other][INFO] - {"epoch": 53, "dev-other_loss": "20.625", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.219", "dev-other_uer": "3.302", "dev-other_wer": "8.632", "dev-other_raw_wer": "8.632", "dev-other_wps": "8683.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "92818", "dev-other_best_wer": "8.632"}
[2024-07-09 07:53:30,195][fairseq_cli.train][INFO] - end of epoch 53 (average epoch stats below)
[2024-07-09 07:53:30,199][train][INFO] - {"epoch": 53, "train_loss": "75.304", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.438", "train_wps": "8214.2", "train_ups": "0.56", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "92818", "train_lr": "5.82775e-06", "train_gnorm": "118.501", "train_loss_scale": "16", "train_train_wall": "3071", "train_gb_free": "32.6", "train_wall": "164264"}
[2024-07-09 07:53:30,200][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 07:53:30,940][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 07:53:30,945][fairseq.trainer][INFO] - begin training epoch 54
[2024-07-09 07:53:30,945][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 07:58:54,863][train_inner][INFO] - {"epoch": 54, "update": 53.104, "loss": "72.128", "ntokens": "14627.3", "nsentences": "86.8", "nll_loss": "0.428", "wps": "7591.2", "ups": "0.52", "wpb": "14627.3", "bsz": "86.8", "num_updates": "93000", "lr": "5.77504e-06", "gnorm": "113.227", "loss_scale": "16", "train_wall": "352", "gb_free": "31.7", "wall": "164589"}
[2024-07-09 08:04:40,753][train_inner][INFO] - {"epoch": 54, "update": 53.218, "loss": "76.864", "ntokens": "14566", "nsentences": "85.04", "nll_loss": "0.449", "wps": "8424.2", "ups": "0.58", "wpb": "14566", "bsz": "85", "num_updates": "93200", "lr": "5.71766e-06", "gnorm": "121.038", "loss_scale": "16", "train_wall": "345", "gb_free": "31.7", "wall": "164934"}
[2024-07-09 08:10:27,519][train_inner][INFO] - {"epoch": 54, "update": 53.332, "loss": "80.515", "ntokens": "14500.1", "nsentences": "80.8", "nll_loss": "0.449", "wps": "8365.4", "ups": "0.58", "wpb": "14500.1", "bsz": "80.8", "num_updates": "93400", "lr": "5.66084e-06", "gnorm": "123.337", "loss_scale": "16", "train_wall": "346", "gb_free": "32.5", "wall": "165281"}
[2024-07-09 08:16:18,456][train_inner][INFO] - {"epoch": 54, "update": 53.446, "loss": "74.899", "ntokens": "14600.1", "nsentences": "85.395", "nll_loss": "0.438", "wps": "8322.7", "ups": "0.57", "wpb": "14600.1", "bsz": "85.4", "num_updates": "93600", "lr": "5.6046e-06", "gnorm": "118.251", "loss_scale": "16", "train_wall": "350", "gb_free": "31.9", "wall": "165632"}
[2024-07-09 08:22:03,619][train_inner][INFO] - {"epoch": 54, "update": 53.561, "loss": "77.649", "ntokens": "14579.7", "nsentences": "85.56", "nll_loss": "0.456", "wps": "8448.3", "ups": "0.58", "wpb": "14579.7", "bsz": "85.6", "num_updates": "93800", "lr": "5.54891e-06", "gnorm": "119.017", "loss_scale": "32", "train_wall": "345", "gb_free": "32.6", "wall": "165977"}
[2024-07-09 08:27:53,611][train_inner][INFO] - {"epoch": 54, "update": 53.675, "loss": "73.877", "ntokens": "14498.5", "nsentences": "85.28", "nll_loss": "0.435", "wps": "8287.2", "ups": "0.57", "wpb": "14498.5", "bsz": "85.3", "num_updates": "94000", "lr": "5.49378e-06", "gnorm": "118.527", "loss_scale": "32", "train_wall": "349", "gb_free": "31.6", "wall": "166327"}
[2024-07-09 08:33:50,506][train_inner][INFO] - {"epoch": 54, "update": 53.789, "loss": "75.173", "ntokens": "14669.3", "nsentences": "84.16", "nll_loss": "0.431", "wps": "8220.9", "ups": "0.56", "wpb": "14669.3", "bsz": "84.2", "num_updates": "94200", "lr": "5.43919e-06", "gnorm": "116.242", "loss_scale": "32", "train_wall": "356", "gb_free": "32.4", "wall": "166684"}
[2024-07-09 08:39:36,274][train_inner][INFO] - {"epoch": 54, "update": 53.903, "loss": "75.731", "ntokens": "14539.2", "nsentences": "86.44", "nll_loss": "0.45", "wps": "8411.6", "ups": "0.58", "wpb": "14539.2", "bsz": "86.4", "num_updates": "94400", "lr": "5.38514e-06", "gnorm": "119.177", "loss_scale": "32", "train_wall": "345", "gb_free": "33.6", "wall": "167030"}
[2024-07-09 08:44:37,694][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 08:44:37,784][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 08:45:09,865][dev-other][INFO] - {"epoch": 54, "dev-other_loss": "20.613", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.219", "dev-other_uer": "3.319", "dev-other_wer": "8.677", "dev-other_raw_wer": "8.677", "dev-other_wps": "8697.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "94570", "dev-other_best_wer": "8.677"}
[2024-07-09 08:45:09,865][fairseq_cli.train][INFO] - end of epoch 54 (average epoch stats below)
[2024-07-09 08:45:09,920][train][INFO] - {"epoch": 54, "train_loss": "76.078", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.443", "train_wps": "8239.5", "train_ups": "0.57", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "94570", "train_lr": "5.33963e-06", "train_gnorm": "118.7", "train_loss_scale": "32", "train_train_wall": "3061", "train_gb_free": "32.1", "train_wall": "167364"}
[2024-07-09 08:45:09,922][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 08:45:10,516][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 08:45:10,520][fairseq.trainer][INFO] - begin training epoch 55
[2024-07-09 08:45:10,520][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 08:46:04,523][train_inner][INFO] - {"epoch": 55, "update": 54.017, "loss": "76.319", "ntokens": "14588.3", "nsentences": "84.84", "nll_loss": "0.444", "wps": "7515.5", "ups": "0.52", "wpb": "14588.3", "bsz": "84.8", "num_updates": "94600", "lr": "5.33164e-06", "gnorm": "118.594", "loss_scale": "32", "train_wall": "355", "gb_free": "33.4", "wall": "167418"}
[2024-07-09 08:51:56,253][train_inner][INFO] - {"epoch": 55, "update": 54.131, "loss": "73.801", "ntokens": "14640.6", "nsentences": "85.64", "nll_loss": "0.432", "wps": "8325.1", "ups": "0.57", "wpb": "14640.6", "bsz": "85.6", "num_updates": "94800", "lr": "5.27866e-06", "gnorm": "116.939", "loss_scale": "32", "train_wall": "351", "gb_free": "32", "wall": "167770"}
[2024-07-09 08:57:47,405][train_inner][INFO] - {"epoch": 55, "update": 54.245, "loss": "75.893", "ntokens": "14587.5", "nsentences": "84.44", "nll_loss": "0.439", "wps": "8308.6", "ups": "0.57", "wpb": "14587.5", "bsz": "84.4", "num_updates": "95000", "lr": "5.22621e-06", "gnorm": "119.294", "loss_scale": "32", "train_wall": "351", "gb_free": "33.7", "wall": "168121"}
[2024-07-09 09:03:46,153][train_inner][INFO] - {"epoch": 55, "update": 54.36, "loss": "72.152", "ntokens": "14651.4", "nsentences": "86.115", "nll_loss": "0.424", "wps": "8169.7", "ups": "0.56", "wpb": "14651.4", "bsz": "86.1", "num_updates": "95200", "lr": "5.17428e-06", "gnorm": "115.358", "loss_scale": "32", "train_wall": "358", "gb_free": "32.4", "wall": "168480"}
[2024-07-09 09:09:33,689][train_inner][INFO] - {"epoch": 55, "update": 54.474, "loss": "73.511", "ntokens": "14630.2", "nsentences": "86.64", "nll_loss": "0.435", "wps": "8421.2", "ups": "0.58", "wpb": "14630.2", "bsz": "86.6", "num_updates": "95400", "lr": "5.12287e-06", "gnorm": "118.2", "loss_scale": "32", "train_wall": "347", "gb_free": "31.6", "wall": "168827"}
[2024-07-09 09:15:16,595][train_inner][INFO] - {"epoch": 55, "update": 54.588, "loss": "76.09", "ntokens": "14430.1", "nsentences": "83.8", "nll_loss": "0.442", "wps": "8418.4", "ups": "0.58", "wpb": "14430.1", "bsz": "83.8", "num_updates": "95600", "lr": "5.07197e-06", "gnorm": "120.403", "loss_scale": "32", "train_wall": "342", "gb_free": "33", "wall": "169170"}
[2024-07-09 09:16:13,826][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-09 09:21:08,968][train_inner][INFO] - {"epoch": 55, "update": 54.703, "loss": "75.766", "ntokens": "14663.4", "nsentences": "84.64", "nll_loss": "0.437", "wps": "8324.5", "ups": "0.57", "wpb": "14663.4", "bsz": "84.6", "num_updates": "95800", "lr": "5.02158e-06", "gnorm": "118.95", "loss_scale": "16", "train_wall": "352", "gb_free": "32.1", "wall": "169523"}
[2024-07-09 09:27:00,547][train_inner][INFO] - {"epoch": 55, "update": 54.817, "loss": "76.953", "ntokens": "14555", "nsentences": "84.48", "nll_loss": "0.447", "wps": "8280", "ups": "0.57", "wpb": "14555", "bsz": "84.5", "num_updates": "96000", "lr": "4.97168e-06", "gnorm": "119.169", "loss_scale": "16", "train_wall": "351", "gb_free": "32.5", "wall": "169874"}
[2024-07-09 09:32:51,833][train_inner][INFO] - {"epoch": 55, "update": 54.931, "loss": "76.303", "ntokens": "14563.7", "nsentences": "83.96", "nll_loss": "0.44", "wps": "8293.4", "ups": "0.57", "wpb": "14563.7", "bsz": "84", "num_updates": "96200", "lr": "4.92228e-06", "gnorm": "119.553", "loss_scale": "16", "train_wall": "351", "gb_free": "32.4", "wall": "170226"}
[2024-07-09 09:36:15,759][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 09:36:15,826][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 09:36:47,865][dev-other][INFO] - {"epoch": 55, "dev-other_loss": "21.276", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.226", "dev-other_uer": "3.348", "dev-other_wer": "8.675", "dev-other_raw_wer": "8.675", "dev-other_wps": "8691.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "96321", "dev-other_best_wer": "8.675"}
[2024-07-09 09:36:47,867][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 55 @ 96321 updates
[2024-07-09 09:36:47,868][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-09 09:36:49,388][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-09 09:36:50,084][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 55 @ 96321 updates, score 8.675) (writing took 2.216729409992695 seconds)
[2024-07-09 09:36:50,084][fairseq_cli.train][INFO] - end of epoch 55 (average epoch stats below)
[2024-07-09 09:36:50,088][train][INFO] - {"epoch": 55, "train_loss": "75.093", "train_ntokens": "14577.7", "train_nsentences": "84.8698", "train_nll_loss": "0.437", "train_wps": "8233.6", "train_ups": "0.56", "train_wpb": "14577.7", "train_bsz": "84.9", "train_num_updates": "96321", "train_lr": "4.89263e-06", "train_gnorm": "118.737", "train_loss_scale": "16", "train_train_wall": "3060", "train_gb_free": "33.2", "train_wall": "170464"}
[2024-07-09 09:36:50,089][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 09:36:50,371][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 09:36:50,374][fairseq.trainer][INFO] - begin training epoch 56
[2024-07-09 09:36:50,374][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 09:39:05,246][train_inner][INFO] - {"epoch": 56, "update": 55.045, "loss": "77.063", "ntokens": "14601.4", "nsentences": "84.28", "nll_loss": "0.445", "wps": "7822.8", "ups": "0.54", "wpb": "14601.4", "bsz": "84.3", "num_updates": "96400", "lr": "4.87337e-06", "gnorm": "121.294", "loss_scale": "16", "train_wall": "338", "gb_free": "31.6", "wall": "170599"}
[2024-07-09 09:45:05,734][train_inner][INFO] - {"epoch": 56, "update": 55.159, "loss": "74.786", "ntokens": "14489", "nsentences": "82.64", "nll_loss": "0.427", "wps": "8040.1", "ups": "0.55", "wpb": "14489", "bsz": "82.6", "num_updates": "96600", "lr": "4.82495e-06", "gnorm": "119.923", "loss_scale": "16", "train_wall": "360", "gb_free": "31.9", "wall": "170959"}
[2024-07-09 09:51:03,636][train_inner][INFO] - {"epoch": 56, "update": 55.273, "loss": "71.956", "ntokens": "14746.8", "nsentences": "88.24", "nll_loss": "0.431", "wps": "8241.7", "ups": "0.56", "wpb": "14746.8", "bsz": "88.2", "num_updates": "96800", "lr": "4.77701e-06", "gnorm": "112.402", "loss_scale": "16", "train_wall": "357", "gb_free": "33.3", "wall": "171317"}
[2024-07-09 09:56:46,432][train_inner][INFO] - {"epoch": 56, "update": 55.388, "loss": "76.936", "ntokens": "14499.6", "nsentences": "82.92", "nll_loss": "0.44", "wps": "8459.8", "ups": "0.58", "wpb": "14499.6", "bsz": "82.9", "num_updates": "97000", "lr": "4.72955e-06", "gnorm": "122.463", "loss_scale": "16", "train_wall": "342", "gb_free": "32", "wall": "171660"}
[2024-07-09 10:02:33,111][train_inner][INFO] - {"epoch": 56, "update": 55.502, "loss": "73.802", "ntokens": "14710.9", "nsentences": "86.76", "nll_loss": "0.435", "wps": "8487", "ups": "0.58", "wpb": "14710.9", "bsz": "86.8", "num_updates": "97200", "lr": "4.68255e-06", "gnorm": "116.885", "loss_scale": "16", "train_wall": "346", "gb_free": "31.9", "wall": "172007"}
[2024-07-09 10:07:29,662][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-09 10:08:22,094][train_inner][INFO] - {"epoch": 56, "update": 55.616, "loss": "77.574", "ntokens": "14545.4", "nsentences": "83.68", "nll_loss": "0.446", "wps": "8336.1", "ups": "0.57", "wpb": "14545.4", "bsz": "83.7", "num_updates": "97400", "lr": "4.63603e-06", "gnorm": "120.176", "loss_scale": "8", "train_wall": "348", "gb_free": "32.6", "wall": "172356"}
[2024-07-09 10:14:14,764][train_inner][INFO] - {"epoch": 56, "update": 55.731, "loss": "74.792", "ntokens": "14459.7", "nsentences": "84.16", "nll_loss": "0.435", "wps": "8200.3", "ups": "0.57", "wpb": "14459.7", "bsz": "84.2", "num_updates": "97600", "lr": "4.58996e-06", "gnorm": "118.904", "loss_scale": "8", "train_wall": "352", "gb_free": "32", "wall": "172709"}
[2024-07-09 10:20:08,331][train_inner][INFO] - {"epoch": 56, "update": 55.845, "loss": "71.849", "ntokens": "14554.5", "nsentences": "87.04", "nll_loss": "0.43", "wps": "8234.6", "ups": "0.57", "wpb": "14554.5", "bsz": "87", "num_updates": "97800", "lr": "4.54436e-06", "gnorm": "116.241", "loss_scale": "8", "train_wall": "353", "gb_free": "31.1", "wall": "173062"}
[2024-07-09 10:25:56,931][train_inner][INFO] - {"epoch": 56, "update": 55.959, "loss": "76.434", "ntokens": "14533.3", "nsentences": "84.675", "nll_loss": "0.445", "wps": "8338.4", "ups": "0.57", "wpb": "14533.3", "bsz": "84.7", "num_updates": "98000", "lr": "4.4992e-06", "gnorm": "120.768", "loss_scale": "8", "train_wall": "348", "gb_free": "32.7", "wall": "173411"}
[2024-07-09 10:28:01,083][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 10:28:01,149][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 10:28:33,371][dev-other][INFO] - {"epoch": 56, "dev-other_loss": "20.915", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.222", "dev-other_uer": "3.325", "dev-other_wer": "8.648", "dev-other_raw_wer": "8.648", "dev-other_wps": "8672", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "98072", "dev-other_best_wer": "8.648"}
[2024-07-09 10:28:33,372][fairseq_cli.train][INFO] - end of epoch 56 (average epoch stats below)
[2024-07-09 10:28:33,398][train][INFO] - {"epoch": 56, "train_loss": "74.964", "train_ntokens": "14577.5", "train_nsentences": "84.8744", "train_nll_loss": "0.436", "train_wps": "8225.2", "train_ups": "0.56", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "98072", "train_lr": "4.48306e-06", "train_gnorm": "118.816", "train_loss_scale": "8", "train_train_wall": "3066", "train_gb_free": "33", "train_wall": "173567"}
[2024-07-09 10:28:33,400][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 10:28:34,113][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 10:28:34,117][fairseq.trainer][INFO] - begin training epoch 57
[2024-07-09 10:28:34,117][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 10:32:17,441][train_inner][INFO] - {"epoch": 57, "update": 56.073, "loss": "76.416", "ntokens": "14507.2", "nsentences": "83.96", "nll_loss": "0.442", "wps": "7625.3", "ups": "0.53", "wpb": "14507.2", "bsz": "84", "num_updates": "98200", "lr": "4.4545e-06", "gnorm": "122.747", "loss_scale": "8", "train_wall": "347", "gb_free": "32.9", "wall": "173791"}
[2024-07-09 10:38:10,366][train_inner][INFO] - {"epoch": 57, "update": 56.187, "loss": "75.923", "ntokens": "14532.9", "nsentences": "83.88", "nll_loss": "0.438", "wps": "8237.5", "ups": "0.57", "wpb": "14532.9", "bsz": "83.9", "num_updates": "98400", "lr": "4.41024e-06", "gnorm": "118.236", "loss_scale": "8", "train_wall": "352", "gb_free": "33.4", "wall": "174144"}
[2024-07-09 10:43:59,570][train_inner][INFO] - {"epoch": 57, "update": 56.301, "loss": "75.651", "ntokens": "14592.8", "nsentences": "84.12", "nll_loss": "0.436", "wps": "8358", "ups": "0.57", "wpb": "14592.8", "bsz": "84.1", "num_updates": "98600", "lr": "4.36642e-06", "gnorm": "120.304", "loss_scale": "8", "train_wall": "349", "gb_free": "33.1", "wall": "174493"}
[2024-07-09 10:49:46,686][train_inner][INFO] - {"epoch": 57, "update": 56.416, "loss": "76.783", "ntokens": "14562.2", "nsentences": "85.64", "nll_loss": "0.452", "wps": "8390.7", "ups": "0.58", "wpb": "14562.2", "bsz": "85.6", "num_updates": "98800", "lr": "4.32303e-06", "gnorm": "118.537", "loss_scale": "8", "train_wall": "347", "gb_free": "32", "wall": "174840"}
[2024-07-09 10:55:41,051][train_inner][INFO] - {"epoch": 57, "update": 56.53, "loss": "76.166", "ntokens": "14539.4", "nsentences": "83.035", "nll_loss": "0.435", "wps": "8206.1", "ups": "0.56", "wpb": "14539.4", "bsz": "83", "num_updates": "99000", "lr": "4.28008e-06", "gnorm": "120.953", "loss_scale": "8", "train_wall": "354", "gb_free": "31.9", "wall": "175195"}
[2024-07-09 11:01:35,223][train_inner][INFO] - {"epoch": 57, "update": 56.644, "loss": "73.328", "ntokens": "14754.6", "nsentences": "88.24", "nll_loss": "0.439", "wps": "8332.2", "ups": "0.56", "wpb": "14754.6", "bsz": "88.2", "num_updates": "99200", "lr": "4.23755e-06", "gnorm": "114.22", "loss_scale": "8", "train_wall": "354", "gb_free": "31.7", "wall": "175549"}
[2024-07-09 11:07:27,373][train_inner][INFO] - {"epoch": 57, "update": 56.758, "loss": "71.356", "ntokens": "14568.8", "nsentences": "87.6", "nll_loss": "0.429", "wps": "8274.4", "ups": "0.57", "wpb": "14568.8", "bsz": "87.6", "num_updates": "99400", "lr": "4.19545e-06", "gnorm": "115.266", "loss_scale": "8", "train_wall": "352", "gb_free": "33.1", "wall": "175901"}
[2024-07-09 11:13:12,642][train_inner][INFO] - {"epoch": 57, "update": 56.872, "loss": "77.586", "ntokens": "14595.7", "nsentences": "83.76", "nll_loss": "0.445", "wps": "8454.9", "ups": "0.58", "wpb": "14595.7", "bsz": "83.8", "num_updates": "99600", "lr": "4.15376e-06", "gnorm": "121.056", "loss_scale": "16", "train_wall": "345", "gb_free": "32.2", "wall": "176246"}
[2024-07-09 11:19:01,885][train_inner][INFO] - {"epoch": 57, "update": 56.986, "loss": "76.551", "ntokens": "14537.2", "nsentences": "82.6", "nll_loss": "0.435", "wps": "8325.2", "ups": "0.57", "wpb": "14537.2", "bsz": "82.6", "num_updates": "99800", "lr": "4.11249e-06", "gnorm": "119.374", "loss_scale": "16", "train_wall": "349", "gb_free": "32.7", "wall": "176596"}
[2024-07-09 11:19:41,336][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 11:19:41,338][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 11:20:13,447][dev-other][INFO] - {"epoch": 57, "dev-other_loss": "21.092", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.224", "dev-other_uer": "3.289", "dev-other_wer": "8.614", "dev-other_raw_wer": "8.614", "dev-other_wps": "8696.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "99824", "dev-other_best_wer": "8.614"}
[2024-07-09 11:20:13,448][fairseq_cli.train][INFO] - end of epoch 57 (average epoch stats below)
[2024-07-09 11:20:13,450][train][INFO] - {"epoch": 57, "train_loss": "75.481", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.439", "train_wps": "8238.5", "train_ups": "0.57", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "99824", "train_lr": "4.10756e-06", "train_gnorm": "118.847", "train_loss_scale": "16", "train_train_wall": "3062", "train_gb_free": "31.7", "train_wall": "176667"}
[2024-07-09 11:20:13,452][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 11:20:14,191][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 11:20:14,200][fairseq.trainer][INFO] - begin training epoch 58
[2024-07-09 11:20:14,200][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 11:25:22,913][train_inner][INFO] - {"epoch": 58, "update": 57.1, "loss": "74.181", "ntokens": "14632.6", "nsentences": "85.96", "nll_loss": "0.436", "wps": "7680.8", "ups": "0.52", "wpb": "14632.6", "bsz": "86", "num_updates": "100000", "lr": "4.07163e-06", "gnorm": "119.335", "loss_scale": "16", "train_wall": "347", "gb_free": "32.9", "wall": "176977"}
[2024-07-09 11:31:03,848][train_inner][INFO] - {"epoch": 58, "update": 57.215, "loss": "80.83", "ntokens": "14486", "nsentences": "81.64", "nll_loss": "0.456", "wps": "8499.3", "ups": "0.59", "wpb": "14486", "bsz": "81.6", "num_updates": "100200", "lr": "4.03117e-06", "gnorm": "124.882", "loss_scale": "16", "train_wall": "340", "gb_free": "32.7", "wall": "177318"}
[2024-07-09 11:36:53,424][train_inner][INFO] - {"epoch": 58, "update": 57.329, "loss": "75.828", "ntokens": "14449.6", "nsentences": "82.28", "nll_loss": "0.432", "wps": "8267.3", "ups": "0.57", "wpb": "14449.6", "bsz": "82.3", "num_updates": "100400", "lr": "3.99112e-06", "gnorm": "123.006", "loss_scale": "16", "train_wall": "349", "gb_free": "32.3", "wall": "177667"}
[2024-07-09 11:42:37,270][train_inner][INFO] - {"epoch": 58, "update": 57.443, "loss": "75.468", "ntokens": "14576.5", "nsentences": "85.04", "nll_loss": "0.44", "wps": "8478.7", "ups": "0.58", "wpb": "14576.5", "bsz": "85", "num_updates": "100600", "lr": "3.95146e-06", "gnorm": "118.917", "loss_scale": "16", "train_wall": "343", "gb_free": "30.5", "wall": "178011"}
[2024-07-09 11:47:32,716][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-09 11:48:24,123][train_inner][INFO] - {"epoch": 58, "update": 57.558, "loss": "75.294", "ntokens": "14632.2", "nsentences": "86.08", "nll_loss": "0.443", "wps": "8437.8", "ups": "0.58", "wpb": "14632.2", "bsz": "86.1", "num_updates": "100800", "lr": "3.9122e-06", "gnorm": "119.39", "loss_scale": "8", "train_wall": "346", "gb_free": "32.1", "wall": "178358"}
[2024-07-09 11:54:09,997][train_inner][INFO] - {"epoch": 58, "update": 57.672, "loss": "74.334", "ntokens": "14528.7", "nsentences": "84.84", "nll_loss": "0.434", "wps": "8402.8", "ups": "0.58", "wpb": "14528.7", "bsz": "84.8", "num_updates": "101000", "lr": "3.87333e-06", "gnorm": "120.116", "loss_scale": "8", "train_wall": "345", "gb_free": "32", "wall": "178704"}
[2024-07-09 12:00:08,073][train_inner][INFO] - {"epoch": 58, "update": 57.786, "loss": "73.261", "ntokens": "14678.5", "nsentences": "86.28", "nll_loss": "0.431", "wps": "8198.8", "ups": "0.56", "wpb": "14678.5", "bsz": "86.3", "num_updates": "101200", "lr": "3.83484e-06", "gnorm": "114.23", "loss_scale": "8", "train_wall": "358", "gb_free": "32", "wall": "179062"}
[2024-07-09 12:05:58,908][train_inner][INFO] - {"epoch": 58, "update": 57.9, "loss": "74.363", "ntokens": "14648", "nsentences": "86.44", "nll_loss": "0.439", "wps": "8350.6", "ups": "0.57", "wpb": "14648", "bsz": "86.4", "num_updates": "101400", "lr": "3.79674e-06", "gnorm": "116.983", "loss_scale": "8", "train_wall": "350", "gb_free": "29.8", "wall": "179413"}
[2024-07-09 12:11:13,165][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 12:11:13,171][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 12:11:45,286][dev-other][INFO] - {"epoch": 58, "dev-other_loss": "20.501", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.218", "dev-other_uer": "3.308", "dev-other_wer": "8.604", "dev-other_raw_wer": "8.604", "dev-other_wps": "8697.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "101575", "dev-other_best_wer": "8.604"}
[2024-07-09 12:11:45,287][fairseq_cli.train][INFO] - end of epoch 58 (average epoch stats below)
[2024-07-09 12:11:45,297][train][INFO] - {"epoch": 58, "train_loss": "75.167", "train_ntokens": "14578.7", "train_nsentences": "84.8789", "train_nll_loss": "0.438", "train_wps": "8256.4", "train_ups": "0.57", "train_wpb": "14578.7", "train_bsz": "84.9", "train_num_updates": "101575", "train_lr": "3.76371e-06", "train_gnorm": "119.18", "train_loss_scale": "8", "train_train_wall": "3054", "train_gb_free": "32.4", "train_wall": "179759"}
[2024-07-09 12:11:45,298][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 12:11:45,973][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 12:11:45,978][fairseq.trainer][INFO] - begin training epoch 59
[2024-07-09 12:11:45,978][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 12:12:31,518][train_inner][INFO] - {"epoch": 59, "update": 58.014, "loss": "73.604", "ntokens": "14535.4", "nsentences": "84.755", "nll_loss": "0.429", "wps": "7406.1", "ups": "0.51", "wpb": "14535.4", "bsz": "84.8", "num_updates": "101600", "lr": "3.75901e-06", "gnorm": "116.996", "loss_scale": "8", "train_wall": "359", "gb_free": "32.7", "wall": "179805"}
[2024-07-09 12:18:22,081][train_inner][INFO] - {"epoch": 59, "update": 58.128, "loss": "76.962", "ntokens": "14442.2", "nsentences": "82.2", "nll_loss": "0.438", "wps": "8239.6", "ups": "0.57", "wpb": "14442.2", "bsz": "82.2", "num_updates": "101800", "lr": "3.72166e-06", "gnorm": "122.584", "loss_scale": "8", "train_wall": "350", "gb_free": "31.1", "wall": "180156"}
[2024-07-09 12:24:08,072][train_inner][INFO] - {"epoch": 59, "update": 58.243, "loss": "74.757", "ntokens": "14471.5", "nsentences": "85.04", "nll_loss": "0.439", "wps": "8365.5", "ups": "0.58", "wpb": "14471.5", "bsz": "85", "num_updates": "102000", "lr": "3.68468e-06", "gnorm": "118.747", "loss_scale": "8", "train_wall": "345", "gb_free": "33.1", "wall": "180502"}
[2024-07-09 12:29:58,888][train_inner][INFO] - {"epoch": 59, "update": 58.357, "loss": "77.188", "ntokens": "14599.4", "nsentences": "83.12", "nll_loss": "0.439", "wps": "8323.4", "ups": "0.57", "wpb": "14599.4", "bsz": "83.1", "num_updates": "102200", "lr": "3.64807e-06", "gnorm": "119.504", "loss_scale": "8", "train_wall": "350", "gb_free": "29.4", "wall": "180853"}
[2024-07-09 12:35:50,304][train_inner][INFO] - {"epoch": 59, "update": 58.471, "loss": "73.865", "ntokens": "14625.4", "nsentences": "86.04", "nll_loss": "0.435", "wps": "8323.9", "ups": "0.57", "wpb": "14625.4", "bsz": "86", "num_updates": "102400", "lr": "3.61183e-06", "gnorm": "116.776", "loss_scale": "8", "train_wall": "351", "gb_free": "32.5", "wall": "181204"}
[2024-07-09 12:41:38,682][train_inner][INFO] - {"epoch": 59, "update": 58.585, "loss": "72.346", "ntokens": "14665.6", "nsentences": "87.24", "nll_loss": "0.43", "wps": "8419.6", "ups": "0.57", "wpb": "14665.6", "bsz": "87.2", "num_updates": "102600", "lr": "3.57594e-06", "gnorm": "116.21", "loss_scale": "8", "train_wall": "348", "gb_free": "31.1", "wall": "181552"}
[2024-07-09 12:47:29,895][train_inner][INFO] - {"epoch": 59, "update": 58.699, "loss": "74.383", "ntokens": "14547.4", "nsentences": "84.795", "nll_loss": "0.434", "wps": "8284.4", "ups": "0.57", "wpb": "14547.4", "bsz": "84.8", "num_updates": "102800", "lr": "3.54041e-06", "gnorm": "116.455", "loss_scale": "8", "train_wall": "351", "gb_free": "31.7", "wall": "181904"}
[2024-07-09 12:53:12,769][train_inner][INFO] - {"epoch": 59, "update": 58.813, "loss": "76.288", "ntokens": "14668.9", "nsentences": "84.4", "nll_loss": "0.439", "wps": "8558.4", "ups": "0.58", "wpb": "14668.9", "bsz": "84.4", "num_updates": "103000", "lr": "3.50523e-06", "gnorm": "119.479", "loss_scale": "16", "train_wall": "342", "gb_free": "32.5", "wall": "182246"}
[2024-07-09 12:58:50,597][train_inner][INFO] - {"epoch": 59, "update": 58.928, "loss": "73.402", "ntokens": "14633.4", "nsentences": "86.84", "nll_loss": "0.436", "wps": "8663.6", "ups": "0.59", "wpb": "14633.4", "bsz": "86.8", "num_updates": "103200", "lr": "3.4704e-06", "gnorm": "121.311", "loss_scale": "16", "train_wall": "337", "gb_free": "33.2", "wall": "182584"}
[2024-07-09 13:02:28,494][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 13:02:28,519][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 13:03:00,552][dev-other][INFO] - {"epoch": 59, "dev-other_loss": "20.786", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.221", "dev-other_uer": "3.307", "dev-other_wer": "8.632", "dev-other_raw_wer": "8.632", "dev-other_wps": "8721.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "103327", "dev-other_best_wer": "8.632"}
[2024-07-09 13:03:00,575][fairseq_cli.train][INFO] - end of epoch 59 (average epoch stats below)
[2024-07-09 13:03:00,581][train][INFO] - {"epoch": 59, "train_loss": "74.892", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.436", "train_wps": "8304.9", "train_ups": "0.57", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "103327", "train_lr": "3.44846e-06", "train_gnorm": "118.959", "train_loss_scale": "16", "train_train_wall": "3037", "train_gb_free": "33.2", "train_wall": "182834"}
[2024-07-09 13:03:00,582][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 13:03:01,292][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 13:03:01,295][fairseq.trainer][INFO] - begin training epoch 60
[2024-07-09 13:03:01,296][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 13:05:10,852][train_inner][INFO] - {"epoch": 60, "update": 59.042, "loss": "74.634", "ntokens": "14604.1", "nsentences": "84.08", "nll_loss": "0.43", "wps": "7683.8", "ups": "0.53", "wpb": "14604.1", "bsz": "84.1", "num_updates": "103400", "lr": "3.43592e-06", "gnorm": "120.048", "loss_scale": "16", "train_wall": "347", "gb_free": "31.7", "wall": "182965"}
[2024-07-09 13:11:04,517][train_inner][INFO] - {"epoch": 60, "update": 59.156, "loss": "74.549", "ntokens": "14661.3", "nsentences": "85.8", "nll_loss": "0.436", "wps": "8291.5", "ups": "0.57", "wpb": "14661.3", "bsz": "85.8", "num_updates": "103600", "lr": "3.40178e-06", "gnorm": "116.799", "loss_scale": "16", "train_wall": "353", "gb_free": "30.7", "wall": "183318"}
[2024-07-09 13:17:03,169][train_inner][INFO] - {"epoch": 60, "update": 59.27, "loss": "70.628", "ntokens": "14700", "nsentences": "87", "nll_loss": "0.418", "wps": "8197.6", "ups": "0.56", "wpb": "14700", "bsz": "87", "num_updates": "103800", "lr": "3.36798e-06", "gnorm": "115.527", "loss_scale": "16", "train_wall": "358", "gb_free": "33.2", "wall": "183677"}
[2024-07-09 13:20:35,983][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-09 13:22:57,179][train_inner][INFO] - {"epoch": 60, "update": 59.385, "loss": "72.197", "ntokens": "14581.2", "nsentences": "85.88", "nll_loss": "0.425", "wps": "8238", "ups": "0.56", "wpb": "14581.2", "bsz": "85.9", "num_updates": "104000", "lr": "3.33451e-06", "gnorm": "116.984", "loss_scale": "8", "train_wall": "353", "gb_free": "32.5", "wall": "184031"}
[2024-07-09 13:28:41,157][train_inner][INFO] - {"epoch": 60, "update": 59.499, "loss": "72.829", "ntokens": "14563.1", "nsentences": "85.76", "nll_loss": "0.429", "wps": "8467.8", "ups": "0.58", "wpb": "14563.1", "bsz": "85.8", "num_updates": "104200", "lr": "3.30138e-06", "gnorm": "116.459", "loss_scale": "8", "train_wall": "343", "gb_free": "30.2", "wall": "184375"}
[2024-07-09 13:34:29,102][train_inner][INFO] - {"epoch": 60, "update": 59.613, "loss": "72.695", "ntokens": "14548.3", "nsentences": "86.675", "nll_loss": "0.433", "wps": "8364.2", "ups": "0.57", "wpb": "14548.3", "bsz": "86.7", "num_updates": "104400", "lr": "3.26858e-06", "gnorm": "116.885", "loss_scale": "8", "train_wall": "347", "gb_free": "33.2", "wall": "184723"}
[2024-07-09 13:40:18,728][train_inner][INFO] - {"epoch": 60, "update": 59.727, "loss": "75.192", "ntokens": "14564.3", "nsentences": "82.96", "nll_loss": "0.428", "wps": "8331.6", "ups": "0.57", "wpb": "14564.3", "bsz": "83", "num_updates": "104600", "lr": "3.2361e-06", "gnorm": "118.893", "loss_scale": "8", "train_wall": "349", "gb_free": "32", "wall": "185073"}
[2024-07-09 13:46:10,987][train_inner][INFO] - {"epoch": 60, "update": 59.841, "loss": "76.987", "ntokens": "14503.4", "nsentences": "82.44", "nll_loss": "0.438", "wps": "8234.7", "ups": "0.57", "wpb": "14503.4", "bsz": "82.4", "num_updates": "104800", "lr": "3.20395e-06", "gnorm": "121.409", "loss_scale": "8", "train_wall": "352", "gb_free": "32.2", "wall": "185425"}
[2024-07-09 13:51:57,648][train_inner][INFO] - {"epoch": 60, "update": 59.955, "loss": "78.342", "ntokens": "14566", "nsentences": "85.2", "nll_loss": "0.458", "wps": "8403.9", "ups": "0.58", "wpb": "14566", "bsz": "85.2", "num_updates": "105000", "lr": "3.17211e-06", "gnorm": "122.311", "loss_scale": "8", "train_wall": "346", "gb_free": "31.4", "wall": "185771"}
[2024-07-09 13:54:06,813][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 13:54:06,883][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 13:54:38,820][dev-other][INFO] - {"epoch": 60, "dev-other_loss": "20.746", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.221", "dev-other_uer": "3.308", "dev-other_wer": "8.622", "dev-other_raw_wer": "8.622", "dev-other_wps": "8719.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "105078", "dev-other_best_wer": "8.622"}
[2024-07-09 13:54:38,821][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 60 @ 105078 updates
[2024-07-09 13:54:38,822][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-09 13:54:40,353][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-09 13:54:40,957][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 60 @ 105078 updates, score 8.622) (writing took 2.1353751085698605 seconds)
[2024-07-09 13:54:40,957][fairseq_cli.train][INFO] - end of epoch 60 (average epoch stats below)
[2024-07-09 13:54:40,965][train][INFO] - {"epoch": 60, "train_loss": "74.376", "train_ntokens": "14576.8", "train_nsentences": "84.8652", "train_nll_loss": "0.433", "train_wps": "8232.5", "train_ups": "0.56", "train_wpb": "14576.8", "train_bsz": "84.9", "train_num_updates": "105078", "train_lr": "3.15978e-06", "train_gnorm": "118.822", "train_loss_scale": "8", "train_train_wall": "3060", "train_gb_free": "32.1", "train_wall": "185935"}
[2024-07-09 13:54:40,967][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 13:54:41,242][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 13:54:41,245][fairseq.trainer][INFO] - begin training epoch 61
[2024-07-09 13:54:41,245][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 13:58:08,765][train_inner][INFO] - {"epoch": 61, "update": 60.07, "loss": "78.355", "ntokens": "14409.5", "nsentences": "81.76", "nll_loss": "0.445", "wps": "7765.7", "ups": "0.54", "wpb": "14409.5", "bsz": "81.8", "num_updates": "105200", "lr": "3.1406e-06", "gnorm": "125.302", "loss_scale": "8", "train_wall": "336", "gb_free": "31.3", "wall": "186143"}
[2024-07-09 14:03:57,602][train_inner][INFO] - {"epoch": 61, "update": 60.184, "loss": "73.22", "ntokens": "14503.3", "nsentences": "84.52", "nll_loss": "0.427", "wps": "8316", "ups": "0.57", "wpb": "14503.3", "bsz": "84.5", "num_updates": "105400", "lr": "3.10939e-06", "gnorm": "119.234", "loss_scale": "8", "train_wall": "348", "gb_free": "31.4", "wall": "186491"}
[2024-07-09 14:09:46,896][train_inner][INFO] - {"epoch": 61, "update": 60.298, "loss": "73.033", "ntokens": "14445.4", "nsentences": "85.92", "nll_loss": "0.434", "wps": "8271.5", "ups": "0.57", "wpb": "14445.4", "bsz": "85.9", "num_updates": "105600", "lr": "3.0785e-06", "gnorm": "118.31", "loss_scale": "8", "train_wall": "349", "gb_free": "31.7", "wall": "186841"}
[2024-07-09 14:15:27,922][train_inner][INFO] - {"epoch": 61, "update": 60.412, "loss": "76.896", "ntokens": "14699.9", "nsentences": "84.64", "nll_loss": "0.443", "wps": "8622.9", "ups": "0.59", "wpb": "14699.9", "bsz": "84.6", "num_updates": "105800", "lr": "3.04791e-06", "gnorm": "119.813", "loss_scale": "8", "train_wall": "340", "gb_free": "31", "wall": "187182"}
[2024-07-09 14:21:18,350][train_inner][INFO] - {"epoch": 61, "update": 60.526, "loss": "75.511", "ntokens": "14525.7", "nsentences": "83.8", "nll_loss": "0.436", "wps": "8290.9", "ups": "0.57", "wpb": "14525.7", "bsz": "83.8", "num_updates": "106000", "lr": "3.01762e-06", "gnorm": "118.168", "loss_scale": "16", "train_wall": "350", "gb_free": "33.2", "wall": "187532"}
[2024-07-09 14:27:10,002][train_inner][INFO] - {"epoch": 61, "update": 60.64, "loss": "75.514", "ntokens": "14700", "nsentences": "84.6", "nll_loss": "0.435", "wps": "8362.4", "ups": "0.57", "wpb": "14700", "bsz": "84.6", "num_updates": "106200", "lr": "2.98764e-06", "gnorm": "120.412", "loss_scale": "16", "train_wall": "351", "gb_free": "29.7", "wall": "187884"}
[2024-07-09 14:33:02,335][train_inner][INFO] - {"epoch": 61, "update": 60.755, "loss": "73.437", "ntokens": "14599.8", "nsentences": "86", "nll_loss": "0.433", "wps": "8287.8", "ups": "0.57", "wpb": "14599.8", "bsz": "86", "num_updates": "106400", "lr": "2.95795e-06", "gnorm": "116.769", "loss_scale": "16", "train_wall": "352", "gb_free": "32.6", "wall": "188236"}
[2024-07-09 14:38:57,748][train_inner][INFO] - {"epoch": 61, "update": 60.869, "loss": "71.942", "ntokens": "14638.1", "nsentences": "86.075", "nll_loss": "0.423", "wps": "8237.6", "ups": "0.56", "wpb": "14638.1", "bsz": "86.1", "num_updates": "106600", "lr": "2.92856e-06", "gnorm": "116.227", "loss_scale": "16", "train_wall": "355", "gb_free": "32.3", "wall": "188592"}
[2024-07-09 14:44:53,883][train_inner][INFO] - {"epoch": 61, "update": 60.983, "loss": "74.485", "ntokens": "14607.1", "nsentences": "83.84", "nll_loss": "0.428", "wps": "8204.8", "ups": "0.56", "wpb": "14607.1", "bsz": "83.8", "num_updates": "106800", "lr": "2.89946e-06", "gnorm": "117.398", "loss_scale": "16", "train_wall": "356", "gb_free": "31.9", "wall": "188948"}
[2024-07-09 14:45:45,307][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 14:45:45,308][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 14:46:17,386][dev-other][INFO] - {"epoch": 61, "dev-other_loss": "20.707", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.22", "dev-other_uer": "3.275", "dev-other_wer": "8.528", "dev-other_raw_wer": "8.528", "dev-other_wps": "8715.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "106830", "dev-other_best_wer": "8.528"}
[2024-07-09 14:46:17,387][fairseq_cli.train][INFO] - end of epoch 61 (average epoch stats below)
[2024-07-09 14:46:17,390][train][INFO] - {"epoch": 61, "train_loss": "74.301", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.433", "train_wps": "8248.2", "train_ups": "0.57", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "106830", "train_lr": "2.89513e-06", "train_gnorm": "118.542", "train_loss_scale": "16", "train_train_wall": "3059", "train_gb_free": "32.6", "train_wall": "189031"}
[2024-07-09 14:46:17,391][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 14:46:18,108][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 14:46:18,114][fairseq.trainer][INFO] - begin training epoch 62
[2024-07-09 14:46:18,114][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 14:51:21,203][train_inner][INFO] - {"epoch": 62, "update": 61.097, "loss": "72.597", "ntokens": "14526.8", "nsentences": "83.68", "nll_loss": "0.418", "wps": "7502.8", "ups": "0.52", "wpb": "14526.8", "bsz": "83.7", "num_updates": "107000", "lr": "2.87066e-06", "gnorm": "119.459", "loss_scale": "16", "train_wall": "354", "gb_free": "32", "wall": "189335"}
[2024-07-09 14:57:05,491][train_inner][INFO] - {"epoch": 62, "update": 61.211, "loss": "75.378", "ntokens": "14478", "nsentences": "83.64", "nll_loss": "0.435", "wps": "8410.7", "ups": "0.58", "wpb": "14478", "bsz": "83.6", "num_updates": "107200", "lr": "2.84213e-06", "gnorm": "120.515", "loss_scale": "16", "train_wall": "344", "gb_free": "32.6", "wall": "189679"}
[2024-07-09 15:02:49,492][train_inner][INFO] - {"epoch": 62, "update": 61.325, "loss": "75.697", "ntokens": "14582.2", "nsentences": "86.52", "nll_loss": "0.449", "wps": "8478.3", "ups": "0.58", "wpb": "14582.2", "bsz": "86.5", "num_updates": "107400", "lr": "2.81389e-06", "gnorm": "118.313", "loss_scale": "16", "train_wall": "343", "gb_free": "33.7", "wall": "190023"}
[2024-07-09 15:08:47,441][train_inner][INFO] - {"epoch": 62, "update": 61.439, "loss": "73.443", "ntokens": "14616.5", "nsentences": "84.56", "nll_loss": "0.425", "wps": "8169.3", "ups": "0.56", "wpb": "14616.5", "bsz": "84.6", "num_updates": "107600", "lr": "2.78593e-06", "gnorm": "116.202", "loss_scale": "16", "train_wall": "357", "gb_free": "31.7", "wall": "190381"}
[2024-07-09 15:14:35,039][train_inner][INFO] - {"epoch": 62, "update": 61.554, "loss": "75.98", "ntokens": "14472.4", "nsentences": "82.88", "nll_loss": "0.435", "wps": "8329.3", "ups": "0.58", "wpb": "14472.4", "bsz": "82.9", "num_updates": "107800", "lr": "2.75825e-06", "gnorm": "122.543", "loss_scale": "16", "train_wall": "347", "gb_free": "32.8", "wall": "190729"}
[2024-07-09 15:16:59,712][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-09 15:20:29,479][train_inner][INFO] - {"epoch": 62, "update": 61.668, "loss": "72.878", "ntokens": "14669.8", "nsentences": "86.16", "nll_loss": "0.428", "wps": "8279.4", "ups": "0.56", "wpb": "14669.8", "bsz": "86.2", "num_updates": "108000", "lr": "2.73085e-06", "gnorm": "117.282", "loss_scale": "8", "train_wall": "354", "gb_free": "32.5", "wall": "191083"}
[2024-07-09 15:26:23,604][train_inner][INFO] - {"epoch": 62, "update": 61.783, "loss": "74.238", "ntokens": "14553.4", "nsentences": "84.8", "nll_loss": "0.433", "wps": "8219.6", "ups": "0.56", "wpb": "14553.4", "bsz": "84.8", "num_updates": "108200", "lr": "2.70371e-06", "gnorm": "118.467", "loss_scale": "8", "train_wall": "354", "gb_free": "31.7", "wall": "191437"}
[2024-07-09 15:32:15,524][train_inner][INFO] - {"epoch": 62, "update": 61.897, "loss": "71.302", "ntokens": "14669.3", "nsentences": "87.515", "nll_loss": "0.425", "wps": "8336.9", "ups": "0.57", "wpb": "14669.3", "bsz": "87.5", "num_updates": "108400", "lr": "2.67685e-06", "gnorm": "116.423", "loss_scale": "8", "train_wall": "351", "gb_free": "32.7", "wall": "191789"}
[2024-07-09 15:37:21,913][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 15:37:21,920][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 15:37:53,973][dev-other][INFO] - {"epoch": 62, "dev-other_loss": "21.132", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.225", "dev-other_uer": "3.314", "dev-other_wer": "8.553", "dev-other_raw_wer": "8.553", "dev-other_wps": "8715.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "108581", "dev-other_best_wer": "8.553"}
[2024-07-09 15:37:53,974][fairseq_cli.train][INFO] - end of epoch 62 (average epoch stats below)
[2024-07-09 15:37:53,978][train][INFO] - {"epoch": 62, "train_loss": "74.341", "train_ntokens": "14576.4", "train_nsentences": "84.8652", "train_nll_loss": "0.433", "train_wps": "8242.4", "train_ups": "0.57", "train_wpb": "14576.4", "train_bsz": "84.9", "train_num_updates": "108581", "train_lr": "2.65277e-06", "train_gnorm": "118.895", "train_loss_scale": "8", "train_train_wall": "3059", "train_gb_free": "33.6", "train_wall": "192128"}
[2024-07-09 15:37:53,986][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 15:37:54,737][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 15:37:54,741][fairseq.trainer][INFO] - begin training epoch 63
[2024-07-09 15:37:54,741][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 15:38:28,557][train_inner][INFO] - {"epoch": 63, "update": 62.011, "loss": "76.923", "ntokens": "14560.9", "nsentences": "83.52", "nll_loss": "0.441", "wps": "7806.9", "ups": "0.54", "wpb": "14560.9", "bsz": "83.5", "num_updates": "108600", "lr": "2.65025e-06", "gnorm": "121.239", "loss_scale": "8", "train_wall": "340", "gb_free": "30.9", "wall": "192162"}
[2024-07-09 15:44:24,702][train_inner][INFO] - {"epoch": 63, "update": 62.125, "loss": "75.943", "ntokens": "14514.6", "nsentences": "82.64", "nll_loss": "0.432", "wps": "8151.1", "ups": "0.56", "wpb": "14514.6", "bsz": "82.6", "num_updates": "108800", "lr": "2.62392e-06", "gnorm": "119.115", "loss_scale": "8", "train_wall": "356", "gb_free": "33.7", "wall": "192518"}
[2024-07-09 15:50:11,131][train_inner][INFO] - {"epoch": 63, "update": 62.239, "loss": "77.978", "ntokens": "14611.6", "nsentences": "82.2", "nll_loss": "0.439", "wps": "8435.8", "ups": "0.58", "wpb": "14611.6", "bsz": "82.2", "num_updates": "109000", "lr": "2.59785e-06", "gnorm": "121.171", "loss_scale": "8", "train_wall": "346", "gb_free": "33.1", "wall": "192865"}
[2024-07-09 15:56:05,000][train_inner][INFO] - {"epoch": 63, "update": 62.353, "loss": "70.978", "ntokens": "14682.3", "nsentences": "88.04", "nll_loss": "0.426", "wps": "8298.4", "ups": "0.57", "wpb": "14682.3", "bsz": "88", "num_updates": "109200", "lr": "2.57203e-06", "gnorm": "113.948", "loss_scale": "8", "train_wall": "353", "gb_free": "32.2", "wall": "193219"}
[2024-07-09 16:02:02,352][train_inner][INFO] - {"epoch": 63, "update": 62.467, "loss": "74.896", "ntokens": "14689.7", "nsentences": "84.84", "nll_loss": "0.433", "wps": "8221.6", "ups": "0.56", "wpb": "14689.7", "bsz": "84.8", "num_updates": "109400", "lr": "2.54648e-06", "gnorm": "118.346", "loss_scale": "8", "train_wall": "357", "gb_free": "31.8", "wall": "193576"}
[2024-07-09 16:07:55,860][train_inner][INFO] - {"epoch": 63, "update": 62.582, "loss": "73.738", "ntokens": "14514.3", "nsentences": "85.04", "nll_loss": "0.432", "wps": "8211.9", "ups": "0.57", "wpb": "14514.3", "bsz": "85", "num_updates": "109600", "lr": "2.52118e-06", "gnorm": "117.491", "loss_scale": "8", "train_wall": "353", "gb_free": "32.1", "wall": "193930"}
[2024-07-09 16:13:48,236][train_inner][INFO] - {"epoch": 63, "update": 62.696, "loss": "71.897", "ntokens": "14616.9", "nsentences": "87.64", "nll_loss": "0.431", "wps": "8296.4", "ups": "0.57", "wpb": "14616.9", "bsz": "87.6", "num_updates": "109800", "lr": "2.49613e-06", "gnorm": "114.932", "loss_scale": "8", "train_wall": "352", "gb_free": "31.7", "wall": "194282"}
[2024-07-09 16:19:41,897][train_inner][INFO] - {"epoch": 63, "update": 62.81, "loss": "73.218", "ntokens": "14550.9", "nsentences": "84.12", "nll_loss": "0.423", "wps": "8229", "ups": "0.57", "wpb": "14550.9", "bsz": "84.1", "num_updates": "110000", "lr": "2.47132e-06", "gnorm": "119.318", "loss_scale": "16", "train_wall": "353", "gb_free": "31.6", "wall": "194636"}
[2024-07-09 16:25:33,368][train_inner][INFO] - {"epoch": 63, "update": 62.924, "loss": "74.401", "ntokens": "14492.7", "nsentences": "84.72", "nll_loss": "0.435", "wps": "8247.2", "ups": "0.57", "wpb": "14492.7", "bsz": "84.7", "num_updates": "110200", "lr": "2.44677e-06", "gnorm": "119.272", "loss_scale": "16", "train_wall": "351", "gb_free": "32", "wall": "194987"}
[2024-07-09 16:29:30,752][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 16:29:30,758][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 16:30:02,902][dev-other][INFO] - {"epoch": 63, "dev-other_loss": "20.697", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.22", "dev-other_uer": "3.272", "dev-other_wer": "8.514", "dev-other_raw_wer": "8.514", "dev-other_wps": "8676.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "110333", "dev-other_best_wer": "8.514"}
[2024-07-09 16:30:02,903][fairseq_cli.train][INFO] - end of epoch 63 (average epoch stats below)
[2024-07-09 16:30:02,905][train][INFO] - {"epoch": 63, "train_loss": "73.992", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.431", "train_wps": "8162.5", "train_ups": "0.56", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "110333", "train_lr": "2.43057e-06", "train_gnorm": "117.813", "train_loss_scale": "16", "train_train_wall": "3091", "train_gb_free": "32.7", "train_wall": "195257"}
[2024-07-09 16:30:02,907][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 16:30:03,658][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 16:30:03,663][fairseq.trainer][INFO] - begin training epoch 64
[2024-07-09 16:30:03,663][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 16:32:04,398][train_inner][INFO] - {"epoch": 64, "update": 63.038, "loss": "73.221", "ntokens": "14526.8", "nsentences": "84.475", "nll_loss": "0.426", "wps": "7430.2", "ups": "0.51", "wpb": "14526.8", "bsz": "84.5", "num_updates": "110400", "lr": "2.42246e-06", "gnorm": "116.913", "loss_scale": "16", "train_wall": "357", "gb_free": "30.9", "wall": "195378"}
[2024-07-09 16:37:58,529][train_inner][INFO] - {"epoch": 64, "update": 63.152, "loss": "71.475", "ntokens": "14681.6", "nsentences": "86.96", "nll_loss": "0.423", "wps": "8293.3", "ups": "0.56", "wpb": "14681.6", "bsz": "87", "num_updates": "110600", "lr": "2.39839e-06", "gnorm": "116.203", "loss_scale": "16", "train_wall": "354", "gb_free": "33", "wall": "195732"}
[2024-07-09 16:43:57,191][train_inner][INFO] - {"epoch": 64, "update": 63.267, "loss": "74.264", "ntokens": "14576.7", "nsentences": "83.76", "nll_loss": "0.427", "wps": "8128.6", "ups": "0.56", "wpb": "14576.7", "bsz": "83.8", "num_updates": "110800", "lr": "2.37456e-06", "gnorm": "117.925", "loss_scale": "16", "train_wall": "358", "gb_free": "30.2", "wall": "196091"}
[2024-07-09 16:49:41,601][train_inner][INFO] - {"epoch": 64, "update": 63.381, "loss": "74.987", "ntokens": "14535.6", "nsentences": "85.6", "nll_loss": "0.442", "wps": "8441.3", "ups": "0.58", "wpb": "14535.6", "bsz": "85.6", "num_updates": "111000", "lr": "2.35096e-06", "gnorm": "117.06", "loss_scale": "16", "train_wall": "344", "gb_free": "31.3", "wall": "196435"}
[2024-07-09 16:55:34,405][train_inner][INFO] - {"epoch": 64, "update": 63.495, "loss": "75.391", "ntokens": "14585.9", "nsentences": "83.76", "nll_loss": "0.433", "wps": "8268.9", "ups": "0.57", "wpb": "14585.9", "bsz": "83.8", "num_updates": "111200", "lr": "2.3276e-06", "gnorm": "116.76", "loss_scale": "16", "train_wall": "352", "gb_free": "33.4", "wall": "196788"}
[2024-07-09 17:01:28,463][train_inner][INFO] - {"epoch": 64, "update": 63.609, "loss": "74.077", "ntokens": "14664.2", "nsentences": "85.675", "nll_loss": "0.433", "wps": "8283.7", "ups": "0.56", "wpb": "14664.2", "bsz": "85.7", "num_updates": "111400", "lr": "2.30448e-06", "gnorm": "119.086", "loss_scale": "16", "train_wall": "354", "gb_free": "31.7", "wall": "197142"}
[2024-07-09 17:07:16,802][train_inner][INFO] - {"epoch": 64, "update": 63.723, "loss": "73.788", "ntokens": "14620.4", "nsentences": "84.96", "nll_loss": "0.429", "wps": "8394.6", "ups": "0.57", "wpb": "14620.4", "bsz": "85", "num_updates": "111600", "lr": "2.28158e-06", "gnorm": "118.532", "loss_scale": "16", "train_wall": "348", "gb_free": "32.6", "wall": "197491"}
[2024-07-09 17:13:03,209][train_inner][INFO] - {"epoch": 64, "update": 63.837, "loss": "74.465", "ntokens": "14632.8", "nsentences": "87", "nll_loss": "0.443", "wps": "8448.5", "ups": "0.58", "wpb": "14632.8", "bsz": "87", "num_updates": "111800", "lr": "2.25891e-06", "gnorm": "116.915", "loss_scale": "16", "train_wall": "346", "gb_free": "31.8", "wall": "197837"}
[2024-07-09 17:18:45,250][train_inner][INFO] - {"epoch": 64, "update": 63.951, "loss": "77.814", "ntokens": "14372.8", "nsentences": "81.76", "nll_loss": "0.443", "wps": "8404.3", "ups": "0.58", "wpb": "14372.8", "bsz": "81.8", "num_updates": "112000", "lr": "2.23646e-06", "gnorm": "124.699", "loss_scale": "32", "train_wall": "341", "gb_free": "31.2", "wall": "198179"}
[2024-07-09 17:21:16,306][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 17:21:16,310][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 17:21:48,480][dev-other][INFO] - {"epoch": 64, "dev-other_loss": "20.509", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.218", "dev-other_uer": "3.295", "dev-other_wer": "8.532", "dev-other_raw_wer": "8.532", "dev-other_wps": "8682.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "112085", "dev-other_best_wer": "8.532"}
[2024-07-09 17:21:48,480][fairseq_cli.train][INFO] - end of epoch 64 (average epoch stats below)
[2024-07-09 17:21:48,483][train][INFO] - {"epoch": 64, "train_loss": "74.475", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.434", "train_wps": "8223.9", "train_ups": "0.56", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "112085", "train_lr": "2.22699e-06", "train_gnorm": "118.317", "train_loss_scale": "32", "train_train_wall": "3068", "train_gb_free": "32", "train_wall": "198362"}
[2024-07-09 17:21:48,485][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 17:21:49,177][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 17:21:49,181][fairseq.trainer][INFO] - begin training epoch 65
[2024-07-09 17:21:49,181][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 17:23:12,437][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-09 17:25:08,691][train_inner][INFO] - {"epoch": 65, "update": 64.066, "loss": "72.974", "ntokens": "14463", "nsentences": "84.6", "nll_loss": "0.427", "wps": "7543.9", "ups": "0.52", "wpb": "14463", "bsz": "84.6", "num_updates": "112200", "lr": "2.21424e-06", "gnorm": "118.168", "loss_scale": "16", "train_wall": "350", "gb_free": "31.2", "wall": "198562"}
[2024-07-09 17:31:07,016][train_inner][INFO] - {"epoch": 65, "update": 64.18, "loss": "71.575", "ntokens": "14710.7", "nsentences": "87.32", "nll_loss": "0.425", "wps": "8211", "ups": "0.56", "wpb": "14710.7", "bsz": "87.3", "num_updates": "112400", "lr": "2.19224e-06", "gnorm": "114.947", "loss_scale": "16", "train_wall": "358", "gb_free": "31.4", "wall": "198921"}
[2024-07-09 17:36:57,263][train_inner][INFO] - {"epoch": 65, "update": 64.295, "loss": "74.622", "ntokens": "14499.8", "nsentences": "84.16", "nll_loss": "0.433", "wps": "8279.9", "ups": "0.57", "wpb": "14499.8", "bsz": "84.2", "num_updates": "112600", "lr": "2.17046e-06", "gnorm": "121.736", "loss_scale": "16", "train_wall": "350", "gb_free": "29.9", "wall": "199271"}
[2024-07-09 17:42:43,556][train_inner][INFO] - {"epoch": 65, "update": 64.409, "loss": "78.06", "ntokens": "14509.2", "nsentences": "82.84", "nll_loss": "0.446", "wps": "8380", "ups": "0.58", "wpb": "14509.2", "bsz": "82.8", "num_updates": "112800", "lr": "2.14889e-06", "gnorm": "122.476", "loss_scale": "16", "train_wall": "346", "gb_free": "30.9", "wall": "199617"}
[2024-07-09 17:48:24,101][train_inner][INFO] - {"epoch": 65, "update": 64.523, "loss": "72.959", "ntokens": "14612.5", "nsentences": "88.36", "nll_loss": "0.441", "wps": "8582", "ups": "0.59", "wpb": "14612.5", "bsz": "88.4", "num_updates": "113000", "lr": "2.12754e-06", "gnorm": "115.339", "loss_scale": "16", "train_wall": "340", "gb_free": "31.9", "wall": "199958"}
[2024-07-09 17:54:10,647][train_inner][INFO] - {"epoch": 65, "update": 64.637, "loss": "74.622", "ntokens": "14614.2", "nsentences": "83.92", "nll_loss": "0.429", "wps": "8434.4", "ups": "0.58", "wpb": "14614.2", "bsz": "83.9", "num_updates": "113200", "lr": "2.1064e-06", "gnorm": "119.88", "loss_scale": "16", "train_wall": "346", "gb_free": "31.2", "wall": "200304"}
[2024-07-09 17:59:55,320][train_inner][INFO] - {"epoch": 65, "update": 64.751, "loss": "75.134", "ntokens": "14490.7", "nsentences": "82.4", "nll_loss": "0.427", "wps": "8408.5", "ups": "0.58", "wpb": "14490.7", "bsz": "82.4", "num_updates": "113400", "lr": "2.08547e-06", "gnorm": "123.323", "loss_scale": "16", "train_wall": "344", "gb_free": "31.2", "wall": "200649"}
[2024-07-09 18:05:45,199][train_inner][INFO] - {"epoch": 65, "update": 64.865, "loss": "72.523", "ntokens": "14675.8", "nsentences": "87.275", "nll_loss": "0.431", "wps": "8389.3", "ups": "0.57", "wpb": "14675.8", "bsz": "87.3", "num_updates": "113600", "lr": "2.06475e-06", "gnorm": "115.593", "loss_scale": "16", "train_wall": "349", "gb_free": "31.6", "wall": "200999"}
[2024-07-09 18:11:38,589][train_inner][INFO] - {"epoch": 65, "update": 64.979, "loss": "74.593", "ntokens": "14593.5", "nsentences": "83.04", "nll_loss": "0.424", "wps": "8259.3", "ups": "0.57", "wpb": "14593.5", "bsz": "83", "num_updates": "113800", "lr": "2.04424e-06", "gnorm": "120.677", "loss_scale": "16", "train_wall": "353", "gb_free": "32.5", "wall": "201352"}
[2024-07-09 18:12:43,734][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 18:12:43,735][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 18:13:15,873][dev-other][INFO] - {"epoch": 65, "dev-other_loss": "20.536", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.218", "dev-other_uer": "3.262", "dev-other_wer": "8.597", "dev-other_raw_wer": "8.597", "dev-other_wps": "8687.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "113836", "dev-other_best_wer": "8.597"}
[2024-07-09 18:13:15,875][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 65 @ 113836 updates
[2024-07-09 18:13:15,876][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-09 18:13:17,581][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-09 18:13:18,044][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 65 @ 113836 updates, score 8.597) (writing took 2.1688396967947483 seconds)
[2024-07-09 18:13:18,044][fairseq_cli.train][INFO] - end of epoch 65 (average epoch stats below)
[2024-07-09 18:13:18,047][train][INFO] - {"epoch": 65, "train_loss": "74.113", "train_ntokens": "14576.3", "train_nsentences": "84.8607", "train_nll_loss": "0.431", "train_wps": "8261.1", "train_ups": "0.57", "train_wpb": "14576.3", "train_bsz": "84.9", "train_num_updates": "113836", "train_lr": "2.04056e-06", "train_gnorm": "119.28", "train_loss_scale": "16", "train_train_wall": "3050", "train_gb_free": "31.1", "train_wall": "201452"}
[2024-07-09 18:13:18,049][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 18:13:18,304][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 18:13:18,308][fairseq.trainer][INFO] - begin training epoch 66
[2024-07-09 18:13:18,308][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 18:17:58,517][train_inner][INFO] - {"epoch": 66, "update": 65.094, "loss": "73.786", "ntokens": "14591.7", "nsentences": "86.4", "nll_loss": "0.437", "wps": "7681.5", "ups": "0.53", "wpb": "14591.7", "bsz": "86.4", "num_updates": "114000", "lr": "2.02392e-06", "gnorm": "118.647", "loss_scale": "16", "train_wall": "345", "gb_free": "31.7", "wall": "201732"}
[2024-07-09 18:23:55,024][train_inner][INFO] - {"epoch": 66, "update": 65.208, "loss": "72.527", "ntokens": "14546.8", "nsentences": "85.4", "nll_loss": "0.426", "wps": "8160.9", "ups": "0.56", "wpb": "14546.8", "bsz": "85.4", "num_updates": "114200", "lr": "2.00381e-06", "gnorm": "117.64", "loss_scale": "32", "train_wall": "356", "gb_free": "33.2", "wall": "202089"}
[2024-07-09 18:29:37,404][train_inner][INFO] - {"epoch": 66, "update": 65.322, "loss": "77.877", "ntokens": "14527.8", "nsentences": "83.12", "nll_loss": "0.446", "wps": "8486.5", "ups": "0.58", "wpb": "14527.8", "bsz": "83.1", "num_updates": "114400", "lr": "1.9839e-06", "gnorm": "122.009", "loss_scale": "32", "train_wall": "342", "gb_free": "33.3", "wall": "202431"}
[2024-07-09 18:32:09,707][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-09 18:35:21,135][train_inner][INFO] - {"epoch": 66, "update": 65.437, "loss": "75.099", "ntokens": "14615.6", "nsentences": "85.48", "nll_loss": "0.439", "wps": "8504.3", "ups": "0.58", "wpb": "14615.6", "bsz": "85.5", "num_updates": "114600", "lr": "1.96419e-06", "gnorm": "119.989", "loss_scale": "16", "train_wall": "343", "gb_free": "32.4", "wall": "202775"}
[2024-07-09 18:41:11,473][train_inner][INFO] - {"epoch": 66, "update": 65.551, "loss": "74.931", "ntokens": "14585.6", "nsentences": "85.52", "nll_loss": "0.439", "wps": "8326.7", "ups": "0.57", "wpb": "14585.6", "bsz": "85.5", "num_updates": "114800", "lr": "1.94468e-06", "gnorm": "117.224", "loss_scale": "16", "train_wall": "350", "gb_free": "32.6", "wall": "203125"}
[2024-07-09 18:47:02,822][train_inner][INFO] - {"epoch": 66, "update": 65.665, "loss": "77.012", "ntokens": "14549.5", "nsentences": "82.76", "nll_loss": "0.438", "wps": "8283.7", "ups": "0.57", "wpb": "14549.5", "bsz": "82.8", "num_updates": "115000", "lr": "1.92535e-06", "gnorm": "121.449", "loss_scale": "16", "train_wall": "351", "gb_free": "32.6", "wall": "203477"}
[2024-07-09 18:52:54,747][train_inner][INFO] - {"epoch": 66, "update": 65.779, "loss": "77.264", "ntokens": "14540.7", "nsentences": "83.235", "nll_loss": "0.442", "wps": "8263.8", "ups": "0.57", "wpb": "14540.7", "bsz": "83.2", "num_updates": "115200", "lr": "1.90622e-06", "gnorm": "119.257", "loss_scale": "16", "train_wall": "351", "gb_free": "30.5", "wall": "203829"}
[2024-07-09 18:58:39,293][train_inner][INFO] - {"epoch": 66, "update": 65.893, "loss": "74.86", "ntokens": "14615.8", "nsentences": "86.2", "nll_loss": "0.442", "wps": "8484.6", "ups": "0.58", "wpb": "14615.8", "bsz": "86.2", "num_updates": "115400", "lr": "1.88728e-06", "gnorm": "116.757", "loss_scale": "16", "train_wall": "344", "gb_free": "33.1", "wall": "204173"}
[2024-07-09 19:03:53,371][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 19:03:53,376][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 19:04:25,619][dev-other][INFO] - {"epoch": 66, "dev-other_loss": "20.202", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.215", "dev-other_uer": "3.27", "dev-other_wer": "8.575", "dev-other_raw_wer": "8.575", "dev-other_wps": "8657.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "115587", "dev-other_best_wer": "8.575"}
[2024-07-09 19:04:25,629][fairseq_cli.train][INFO] - end of epoch 66 (average epoch stats below)
[2024-07-09 19:04:25,632][train][INFO] - {"epoch": 66, "train_loss": "75.81", "train_ntokens": "14577.6", "train_nsentences": "84.8698", "train_nll_loss": "0.441", "train_wps": "8321", "train_ups": "0.57", "train_wpb": "14577.6", "train_bsz": "84.9", "train_num_updates": "115587", "train_lr": "1.86974e-06", "train_gnorm": "119.399", "train_loss_scale": "16", "train_train_wall": "3030", "train_gb_free": "33.1", "train_wall": "204519"}
[2024-07-09 19:04:25,634][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 19:04:26,337][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 19:04:26,341][fairseq.trainer][INFO] - begin training epoch 67
[2024-07-09 19:04:26,341][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 19:04:49,227][train_inner][INFO] - {"epoch": 67, "update": 66.007, "loss": "78.559", "ntokens": "14580.4", "nsentences": "85.48", "nll_loss": "0.461", "wps": "7882.9", "ups": "0.54", "wpb": "14580.4", "bsz": "85.5", "num_updates": "115600", "lr": "1.86853e-06", "gnorm": "121.445", "loss_scale": "16", "train_wall": "336", "gb_free": "31.9", "wall": "204543"}
[2024-07-09 19:10:40,978][train_inner][INFO] - {"epoch": 67, "update": 66.122, "loss": "73.923", "ntokens": "14628", "nsentences": "85.6", "nll_loss": "0.433", "wps": "8317.4", "ups": "0.57", "wpb": "14628", "bsz": "85.6", "num_updates": "115800", "lr": "1.84996e-06", "gnorm": "116.919", "loss_scale": "16", "train_wall": "351", "gb_free": "32.9", "wall": "204895"}
[2024-07-09 19:16:34,934][train_inner][INFO] - {"epoch": 67, "update": 66.236, "loss": "75.258", "ntokens": "14584", "nsentences": "84.76", "nll_loss": "0.437", "wps": "8240.8", "ups": "0.57", "wpb": "14584", "bsz": "84.8", "num_updates": "116000", "lr": "1.83158e-06", "gnorm": "117.354", "loss_scale": "16", "train_wall": "353", "gb_free": "30.8", "wall": "205249"}
[2024-07-09 19:22:23,234][train_inner][INFO] - {"epoch": 67, "update": 66.35, "loss": "74.35", "ntokens": "14500.4", "nsentences": "83.835", "nll_loss": "0.43", "wps": "8328.7", "ups": "0.57", "wpb": "14500.4", "bsz": "83.8", "num_updates": "116200", "lr": "1.81338e-06", "gnorm": "120.235", "loss_scale": "16", "train_wall": "348", "gb_free": "30.5", "wall": "205597"}
[2024-07-09 19:28:11,694][train_inner][INFO] - {"epoch": 67, "update": 66.464, "loss": "75.081", "ntokens": "14563.8", "nsentences": "85.52", "nll_loss": "0.441", "wps": "8359.3", "ups": "0.57", "wpb": "14563.8", "bsz": "85.5", "num_updates": "116400", "lr": "1.79537e-06", "gnorm": "119.162", "loss_scale": "16", "train_wall": "348", "gb_free": "32.3", "wall": "205945"}
[2024-07-09 19:34:13,036][train_inner][INFO] - {"epoch": 67, "update": 66.578, "loss": "74.051", "ntokens": "14575.9", "nsentences": "83.76", "nll_loss": "0.426", "wps": "8068.7", "ups": "0.55", "wpb": "14575.9", "bsz": "83.8", "num_updates": "116600", "lr": "1.77753e-06", "gnorm": "116.571", "loss_scale": "32", "train_wall": "361", "gb_free": "32.4", "wall": "206307"}
[2024-07-09 19:34:37,701][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-09 19:40:05,325][train_inner][INFO] - {"epoch": 67, "update": 66.693, "loss": "72.485", "ntokens": "14620.6", "nsentences": "86.08", "nll_loss": "0.427", "wps": "8301.5", "ups": "0.57", "wpb": "14620.6", "bsz": "86.1", "num_updates": "116800", "lr": "1.75987e-06", "gnorm": "118.497", "loss_scale": "16", "train_wall": "352", "gb_free": "31.5", "wall": "206659"}
[2024-07-09 19:45:49,145][train_inner][INFO] - {"epoch": 67, "update": 66.807, "loss": "74.041", "ntokens": "14578.5", "nsentences": "84.28", "nll_loss": "0.428", "wps": "8480.5", "ups": "0.58", "wpb": "14578.5", "bsz": "84.3", "num_updates": "117000", "lr": "1.74238e-06", "gnorm": "122.941", "loss_scale": "16", "train_wall": "343", "gb_free": "32.4", "wall": "207003"}
[2024-07-09 19:51:47,241][train_inner][INFO] - {"epoch": 67, "update": 66.921, "loss": "70.954", "ntokens": "14632.8", "nsentences": "85.6", "nll_loss": "0.415", "wps": "8172.7", "ups": "0.56", "wpb": "14632.8", "bsz": "85.6", "num_updates": "117200", "lr": "1.72507e-06", "gnorm": "115.966", "loss_scale": "16", "train_wall": "358", "gb_free": "32.8", "wall": "207361"}
[2024-07-09 19:55:48,084][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 19:55:48,156][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 19:56:20,184][dev-other][INFO] - {"epoch": 67, "dev-other_loss": "20.165", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.214", "dev-other_uer": "3.286", "dev-other_wer": "8.561", "dev-other_raw_wer": "8.561", "dev-other_wps": "8693", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "117338", "dev-other_best_wer": "8.561"}
[2024-07-09 19:56:20,185][fairseq_cli.train][INFO] - end of epoch 67 (average epoch stats below)
[2024-07-09 19:56:20,187][train][INFO] - {"epoch": 67, "train_loss": "73.93", "train_ntokens": "14578.1", "train_nsentences": "84.8789", "train_nll_loss": "0.43", "train_wps": "8195.8", "train_ups": "0.56", "train_wpb": "14578.1", "train_bsz": "84.9", "train_num_updates": "117338", "train_lr": "1.71322e-06", "train_gnorm": "118.481", "train_loss_scale": "16", "train_train_wall": "3077", "train_gb_free": "33.8", "train_wall": "207634"}
[2024-07-09 19:56:20,189][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 19:56:20,943][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 19:56:20,946][fairseq.trainer][INFO] - begin training epoch 68
[2024-07-09 19:56:20,947][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 19:58:10,062][train_inner][INFO] - {"epoch": 68, "update": 67.035, "loss": "75.894", "ntokens": "14474", "nsentences": "83.68", "nll_loss": "0.439", "wps": "7561.9", "ups": "0.52", "wpb": "14474", "bsz": "83.7", "num_updates": "117400", "lr": "1.70793e-06", "gnorm": "120.52", "loss_scale": "16", "train_wall": "349", "gb_free": "31.8", "wall": "207744"}
[2024-07-09 20:03:52,856][train_inner][INFO] - {"epoch": 68, "update": 67.15, "loss": "74.907", "ntokens": "14674.9", "nsentences": "85.075", "nll_loss": "0.434", "wps": "8562.1", "ups": "0.58", "wpb": "14674.9", "bsz": "85.1", "num_updates": "117600", "lr": "1.69096e-06", "gnorm": "121.323", "loss_scale": "16", "train_wall": "342", "gb_free": "32.3", "wall": "208087"}
[2024-07-09 20:09:38,341][train_inner][INFO] - {"epoch": 68, "update": 67.264, "loss": "73.806", "ntokens": "14655.1", "nsentences": "85.72", "nll_loss": "0.432", "wps": "8485.9", "ups": "0.58", "wpb": "14655.1", "bsz": "85.7", "num_updates": "117800", "lr": "1.67416e-06", "gnorm": "119.448", "loss_scale": "16", "train_wall": "345", "gb_free": "32.6", "wall": "208432"}
[2024-07-09 20:15:24,493][train_inner][INFO] - {"epoch": 68, "update": 67.378, "loss": "71.56", "ntokens": "14641.2", "nsentences": "88.12", "nll_loss": "0.431", "wps": "8462.8", "ups": "0.58", "wpb": "14641.2", "bsz": "88.1", "num_updates": "118000", "lr": "1.65752e-06", "gnorm": "115.219", "loss_scale": "16", "train_wall": "345", "gb_free": "34", "wall": "208778"}
[2024-07-09 20:21:23,019][train_inner][INFO] - {"epoch": 68, "update": 67.492, "loss": "72.61", "ntokens": "14508.2", "nsentences": "83.16", "nll_loss": "0.416", "wps": "8095", "ups": "0.56", "wpb": "14508.2", "bsz": "83.2", "num_updates": "118200", "lr": "1.64105e-06", "gnorm": "117.083", "loss_scale": "16", "train_wall": "358", "gb_free": "31.4", "wall": "209137"}
[2024-07-09 20:27:13,703][train_inner][INFO] - {"epoch": 68, "update": 67.606, "loss": "74.848", "ntokens": "14523.3", "nsentences": "84.56", "nll_loss": "0.436", "wps": "8283.2", "ups": "0.57", "wpb": "14523.3", "bsz": "84.6", "num_updates": "118400", "lr": "1.62475e-06", "gnorm": "118.069", "loss_scale": "16", "train_wall": "350", "gb_free": "30.6", "wall": "209487"}
[2024-07-09 20:33:05,310][train_inner][INFO] - {"epoch": 68, "update": 67.72, "loss": "76.024", "ntokens": "14563.4", "nsentences": "83.84", "nll_loss": "0.438", "wps": "8284.1", "ups": "0.57", "wpb": "14563.4", "bsz": "83.8", "num_updates": "118600", "lr": "1.6086e-06", "gnorm": "119.82", "loss_scale": "16", "train_wall": "351", "gb_free": "33.1", "wall": "209839"}
[2024-07-09 20:35:35,310][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-09 20:39:06,464][train_inner][INFO] - {"epoch": 68, "update": 67.835, "loss": "73.054", "ntokens": "14549.8", "nsentences": "84", "nll_loss": "0.422", "wps": "8057.6", "ups": "0.55", "wpb": "14549.8", "bsz": "84", "num_updates": "118800", "lr": "1.59262e-06", "gnorm": "117.338", "loss_scale": "16", "train_wall": "361", "gb_free": "30.8", "wall": "210200"}
[2024-07-09 20:44:57,450][train_inner][INFO] - {"epoch": 68, "update": 67.949, "loss": "73.821", "ntokens": "14582.4", "nsentences": "85.04", "nll_loss": "0.43", "wps": "8311.1", "ups": "0.57", "wpb": "14582.4", "bsz": "85", "num_updates": "119000", "lr": "1.57679e-06", "gnorm": "117.447", "loss_scale": "16", "train_wall": "350", "gb_free": "30.4", "wall": "210551"}
[2024-07-09 20:47:28,627][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 20:47:28,632][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 20:48:00,460][dev-other][INFO] - {"epoch": 68, "dev-other_loss": "20.824", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.221", "dev-other_uer": "3.305", "dev-other_wer": "8.624", "dev-other_raw_wer": "8.624", "dev-other_wps": "8794.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "119089", "dev-other_best_wer": "8.597"}
[2024-07-09 20:48:00,460][fairseq_cli.train][INFO] - end of epoch 68 (average epoch stats below)
[2024-07-09 20:48:00,463][train][INFO] - {"epoch": 68, "train_loss": "73.942", "train_ntokens": "14578", "train_nsentences": "84.8195", "train_nll_loss": "0.43", "train_wps": "8233.5", "train_ups": "0.56", "train_wpb": "14578", "train_bsz": "84.8", "train_num_updates": "119089", "train_lr": "1.5698e-06", "train_gnorm": "118.533", "train_loss_scale": "16", "train_train_wall": "3062", "train_gb_free": "30.8", "train_wall": "210734"}
[2024-07-09 20:48:00,465][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 20:48:01,179][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 20:48:01,190][fairseq.trainer][INFO] - begin training epoch 69
[2024-07-09 20:48:01,190][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 20:51:14,495][train_inner][INFO] - {"epoch": 69, "update": 68.063, "loss": "76.591", "ntokens": "14489.5", "nsentences": "84", "nll_loss": "0.444", "wps": "7686", "ups": "0.53", "wpb": "14489.5", "bsz": "84", "num_updates": "119200", "lr": "1.56113e-06", "gnorm": "120.363", "loss_scale": "16", "train_wall": "344", "gb_free": "30.7", "wall": "210928"}
[2024-07-09 20:57:05,902][train_inner][INFO] - {"epoch": 69, "update": 68.178, "loss": "76.362", "ntokens": "14464.7", "nsentences": "83.08", "nll_loss": "0.439", "wps": "8234.2", "ups": "0.57", "wpb": "14464.7", "bsz": "83.1", "num_updates": "119400", "lr": "1.54562e-06", "gnorm": "121.938", "loss_scale": "16", "train_wall": "351", "gb_free": "33.7", "wall": "211280"}
[2024-07-09 20:58:30,269][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-09 21:03:01,882][train_inner][INFO] - {"epoch": 69, "update": 68.292, "loss": "71.2", "ntokens": "14727.8", "nsentences": "86.8", "nll_loss": "0.42", "wps": "8274.8", "ups": "0.56", "wpb": "14727.8", "bsz": "86.8", "num_updates": "119600", "lr": "1.53026e-06", "gnorm": "114.209", "loss_scale": "8", "train_wall": "355", "gb_free": "32.9", "wall": "211636"}
[2024-07-09 21:08:42,855][train_inner][INFO] - {"epoch": 69, "update": 68.406, "loss": "77.93", "ntokens": "14533.2", "nsentences": "83.32", "nll_loss": "0.447", "wps": "8524.8", "ups": "0.59", "wpb": "14533.2", "bsz": "83.3", "num_updates": "119800", "lr": "1.51505e-06", "gnorm": "122.162", "loss_scale": "8", "train_wall": "340", "gb_free": "31.5", "wall": "211977"}
[2024-07-09 21:14:34,241][train_inner][INFO] - {"epoch": 69, "update": 68.521, "loss": "69.767", "ntokens": "14764.3", "nsentences": "88.435", "nll_loss": "0.418", "wps": "8403.9", "ups": "0.57", "wpb": "14764.3", "bsz": "88.4", "num_updates": "120000", "lr": "1.5e-06", "gnorm": "114.01", "loss_scale": "8", "train_wall": "351", "gb_free": "31.5", "wall": "212328"}
[2024-07-09 21:14:34,245][fairseq_cli.train][INFO] - Stopping training due to num_updates: 120000 >= max_update: 120000
[2024-07-09 21:14:34,245][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 21:14:34,246][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 21:15:06,537][dev-other][INFO] - {"epoch": 69, "dev-other_loss": "20.451", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.217", "dev-other_uer": "3.28", "dev-other_wer": "8.53", "dev-other_raw_wer": "8.53", "dev-other_wps": "8726.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "120000", "dev-other_best_wer": "8.53"}
[2024-07-09 21:15:06,539][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 69 @ 120000 updates
[2024-07-09 21:15:06,540][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-09 21:15:07,674][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-09 21:15:08,176][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/pretrain_on_base_imls-ssl_4gpu_8update_960h_400k_update_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 69 @ 120000 updates, score 8.53) (writing took 1.6370844319462776 seconds)
[2024-07-09 21:15:08,178][fairseq_cli.train][INFO] - end of epoch 69 (average epoch stats below)
[2024-07-09 21:15:08,181][train][INFO] - {"epoch": 69, "train_loss": "74.183", "train_ntokens": "14603.9", "train_nsentences": "85.1976", "train_nll_loss": "0.433", "train_wps": "8173.5", "train_ups": "0.56", "train_wpb": "14603.9", "train_bsz": "85.2", "train_num_updates": "120000", "train_lr": "1.5e-06", "train_gnorm": "118.324", "train_loss_scale": "8", "train_train_wall": "1590", "train_gb_free": "31.5", "train_wall": "212362"}
[2024-07-09 21:15:08,181][fairseq_cli.train][INFO] - done training in 212336.5 seconds
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
fine tune base offical hubert model  using train-other-500 supervision data
[2024-07-09 21:15:22,201][fairseq.distributed.utils][INFO] - Rank 0, device_id: 0
2024-07-09 21:15:27 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:28610
2024-07-09 21:15:27 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:28610
2024-07-09 21:15:27 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:28610
2024-07-09 21:15:27 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2024-07-09 21:15:28 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2024-07-09 21:15:32 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:28610
2024-07-09 21:15:32 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2024-07-09 21:15:32 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2024-07-09 21:15:32 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-07-09 21:15:32 | INFO | fairseq.distributed.utils | initialized host pgpu13 as rank 0
2024-07-09 21:15:32 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-07-09 21:15:32 | INFO | fairseq.distributed.utils | initialized host pgpu13 as rank 2
2024-07-09 21:15:32 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-07-09 21:15:32 | INFO | fairseq.distributed.utils | initialized host pgpu13 as rank 1
2024-07-09 21:15:32 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-07-09 21:15:32 | INFO | fairseq.distributed.utils | initialized host pgpu13 as rank 3
[2024-07-09 21:15:35,209][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/mntcephfs/lab_data/maduo/exp//finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/t-hubert', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:28610', 'distributed_port': 28610, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3200000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train-other-500', 'valid_subset': 'dev-other', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3200000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 120000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [2], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/mntcephfs/lab_data/maduo/exp//finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'wer', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'hubert_ctc', 'w2v_path': '/mntcephfs/lab_data/maduo/model_hub/librispeech/hubert_base_librispeech_offical_no_finetune//hubert_base_ls960.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.1, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_embed_dim': 768, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 0, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'normalize': False, 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'w2v_args': None, 'autoregressive': False}, 'task': {'_name': 'hubert_pretraining', 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'fine_tuning': True, 'labels': ['ltr'], 'label_dir': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'label_rate': -1.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': None, 'min_sample_size': None, 'single_target': True, 'random_crop': True, 'pad_audio': False}, 'criterion': {'_name': 'ctc', 'zero_infinity': True, 'sentence_avg': True, 'post_process': 'letter', 'wer_kenlm_model': None, 'wer_lexicon': None, 'wer_lm_weight': 2.0, 'wer_word_score': -1.0, 'wer_sil_weight': 0.0, 'wer_args': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05], 'amsgrad': False}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 12000, 'hold_steps': 48000, 'decay_steps': 60000, 'phase_ratio': None, 'init_lr_scale': 0.01, 'final_lr_scale': 0.05, 'max_update': 120000.0, 'lr': [3e-05]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': '/mntcephfs/lab_data/maduo/model_hub/librispeech/hubert_base_librispeech_offical_no_finetune//finetune.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-07-09 21:15:35,212][fairseq.tasks.hubert_pretraining][INFO] - current directory is /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/t-hubert
[2024-07-09 21:15:35,212][fairseq.tasks.hubert_pretraining][INFO] - HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'fine_tuning': True, 'labels': ['ltr'], 'label_dir': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'label_rate': -1.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': None, 'min_sample_size': None, 'single_target': True, 'random_crop': True, 'pad_audio': False}
[2024-07-09 21:15:35,215][fairseq.models.hubert.hubert_asr][INFO] - cfg: {'_name': 'hubert_ctc', 'w2v_path': '/mntcephfs/lab_data/maduo/model_hub/librispeech/hubert_base_librispeech_offical_no_finetune//hubert_base_ls960.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.1, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_embed_dim': 768, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 0, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'normalize': False, 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'w2v_args': None, 'autoregressive': False}, task: <fairseq.tasks.hubert_pretraining.HubertPretrainingTask object at 0x1554074f3c70>
[2024-07-09 21:15:35,216][fairseq.models.hubert.hubert_asr][INFO] - mdddd:::/mntcephfs/lab_data/maduo/model_hub/librispeech/hubert_base_librispeech_offical_no_finetune//hubert_base_ls960.pt
[2024-07-09 21:15:38,703][fairseq.tasks.hubert_pretraining][INFO] - current directory is /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/t-hubert
[2024-07-09 21:15:38,703][fairseq.tasks.hubert_pretraining][INFO] - HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
[2024-07-09 21:15:38,711][fairseq.models.hubert.hubert][INFO] - HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
[2024-07-09 21:15:43,736][fairseq_cli.train][INFO] - HubertCtc(
  (w2v_encoder): HubertEncoder(
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (proj): Linear(in_features=768, out_features=32, bias=True)
  )
)
[2024-07-09 21:15:43,738][fairseq_cli.train][INFO] - task: HubertPretrainingTask
[2024-07-09 21:15:43,738][fairseq_cli.train][INFO] - model: HubertCtc
[2024-07-09 21:15:43,738][fairseq_cli.train][INFO] - criterion: CtcCriterion
[2024-07-09 21:15:43,745][fairseq_cli.train][INFO] - num. shared model params: 94,525,344 (num. trained: 94,525,344)
[2024-07-09 21:15:43,746][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-07-09 21:15:43,759][fairseq.data.audio.hubert_dataset][INFO] - max_keep=None, min_keep=None, loaded 2864, skipped 0 short and 0 long, longest-loaded=562480, shortest-loaded=17040
[2024-07-09 21:15:43,761][fairseq.data.audio.hubert_dataset][INFO] - /mntcephfs/lab_data/maduo/datasets/format/librispeech//dev-other.ltr is sequence label. skipped
[2024-07-09 21:15:43,761][fairseq.data.audio.hubert_dataset][INFO] - pad_audio=False, random_crop=True, normalize=False, max_sample_size=9223372036854775807
[2024-07-09 21:15:47,254][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:2 to store for rank: 0
[2024-07-09 21:15:47,426][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
[2024-07-09 21:15:47,427][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias <- w2v_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
[2024-07-09 21:15:47,427][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias <- w2v_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
[2024-07-09 21:15:47,427][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias <- w2v_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
[2024-07-09 21:15:47,427][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias <- w2v_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
[2024-07-09 21:15:47,427][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias <- w2v_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
[2024-07-09 21:15:47,427][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias <- w2v_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
[2024-07-09 21:15:48,028][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2024-07-09 21:15:48,028][fairseq.utils][INFO] - rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
[2024-07-09 21:15:48,028][fairseq.utils][INFO] - rank   1: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
[2024-07-09 21:15:48,028][fairseq.utils][INFO] - rank   2: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
[2024-07-09 21:15:48,028][fairseq.utils][INFO] - rank   3: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
[2024-07-09 21:15:48,028][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2024-07-09 21:15:48,028][fairseq_cli.train][INFO] - training on 4 devices (GPUs/TPUs)
[2024-07-09 21:15:48,028][fairseq_cli.train][INFO] - max tokens per device = 3200000 and max sentences per device = None
[2024-07-09 21:15:48,029][fairseq.trainer][INFO] - Preparing to load checkpoint /mntcephfs/lab_data/maduo/exp//finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_last.pt
[2024-07-09 21:15:48,029][fairseq.trainer][INFO] - No existing checkpoint found /mntcephfs/lab_data/maduo/exp//finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_last.pt
[2024-07-09 21:15:48,029][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-07-09 21:15:48,123][fairseq.data.audio.hubert_dataset][INFO] - max_keep=None, min_keep=None, loaded 148688, skipped 0 short and 0 long, longest-loaded=446720, shortest-loaded=13280
[2024-07-09 21:15:48,223][fairseq.data.audio.hubert_dataset][INFO] - /mntcephfs/lab_data/maduo/datasets/format/librispeech//train-other-500.ltr is sequence label. skipped
[2024-07-09 21:15:48,223][fairseq.data.audio.hubert_dataset][INFO] - pad_audio=False, random_crop=True, normalize=False, max_sample_size=9223372036854775807
[2024-07-09 21:15:48,276][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 21:15:48,277][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2024-07-09 21:15:48,277][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = False
[2024-07-09 21:15:48,277][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2024-07-09 21:15:49,136][fairseq_cli.train][INFO] - begin dry-run validation on "dev-other" subset
[2024-07-09 21:15:49,137][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 21:15:49,137][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2024-07-09 21:15:49,137][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = False
[2024-07-09 21:15:49,137][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2024-07-09 21:16:13,350][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 21:16:13,355][fairseq.trainer][INFO] - begin training epoch 1
[2024-07-09 21:16:13,355][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 21:16:38,681][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2024-07-09 21:16:39,089][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2024-07-09 21:16:39,477][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-09 21:16:39,893][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-09 21:17:06,502][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-07-09 21:17:38,833][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-07-09 21:17:52,366][train_inner][INFO] - {"epoch": 1, "update": 0.118, "loss": "2177.25", "ntokens": "14501.6", "nsentences": "81.92", "nll_loss": "12.299", "wps": "40038", "ups": "2.76", "wpb": "14501.6", "bsz": "81.9", "num_updates": "200", "lr": "7.95e-07", "gnorm": "1543.94", "loss_scale": "2", "train_wall": "76", "gb_free": "31.1", "wall": "124"}
[2024-07-09 21:18:02,176][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-07-09 21:19:03,287][train_inner][INFO] - {"epoch": 1, "update": 0.232, "loss": "1235.61", "ntokens": "14577.3", "nsentences": "85.44", "nll_loss": "7.242", "wps": "41111.2", "ups": "2.82", "wpb": "14577.3", "bsz": "85.4", "num_updates": "400", "lr": "1.29e-06", "gnorm": "2242.91", "loss_scale": "1", "train_wall": "70", "gb_free": "33.4", "wall": "195"}
[2024-07-09 21:20:12,511][train_inner][INFO] - {"epoch": 1, "update": 0.346, "loss": "800.413", "ntokens": "14580.9", "nsentences": "83.76", "nll_loss": "4.598", "wps": "42132.7", "ups": "2.89", "wpb": "14580.9", "bsz": "83.8", "num_updates": "600", "lr": "1.785e-06", "gnorm": "658.67", "loss_scale": "1", "train_wall": "69", "gb_free": "32", "wall": "264"}
[2024-07-09 21:21:20,574][train_inner][INFO] - {"epoch": 1, "update": 0.461, "loss": "721.116", "ntokens": "14447.7", "nsentences": "85.08", "nll_loss": "4.247", "wps": "42458.2", "ups": "2.94", "wpb": "14447.7", "bsz": "85.1", "num_updates": "800", "lr": "2.28e-06", "gnorm": "241.374", "loss_scale": "1", "train_wall": "68", "gb_free": "32.3", "wall": "333"}
[2024-07-09 21:22:28,928][train_inner][INFO] - {"epoch": 1, "update": 0.575, "loss": "715.343", "ntokens": "14638.4", "nsentences": "85.435", "nll_loss": "4.175", "wps": "42835.4", "ups": "2.93", "wpb": "14638.4", "bsz": "85.4", "num_updates": "1000", "lr": "2.775e-06", "gnorm": "162.335", "loss_scale": "1", "train_wall": "68", "gb_free": "32.8", "wall": "401"}
[2024-07-09 21:23:36,605][train_inner][INFO] - {"epoch": 1, "update": 0.689, "loss": "710.555", "ntokens": "14631.9", "nsentences": "85.6", "nll_loss": "4.157", "wps": "43252.7", "ups": "2.96", "wpb": "14631.9", "bsz": "85.6", "num_updates": "1200", "lr": "3.27e-06", "gnorm": "189.493", "loss_scale": "1", "train_wall": "67", "gb_free": "32", "wall": "469"}
[2024-07-09 21:24:44,129][train_inner][INFO] - {"epoch": 1, "update": 0.803, "loss": "701.598", "ntokens": "14645", "nsentences": "86.28", "nll_loss": "4.133", "wps": "43421.2", "ups": "2.96", "wpb": "14645.1", "bsz": "86.3", "num_updates": "1400", "lr": "3.765e-06", "gnorm": "212.299", "loss_scale": "1", "train_wall": "67", "gb_free": "32.3", "wall": "536"}
[2024-07-09 21:25:51,229][train_inner][INFO] - {"epoch": 1, "update": 0.917, "loss": "706.918", "ntokens": "14558.1", "nsentences": "85.08", "nll_loss": "4.131", "wps": "43421.8", "ups": "2.98", "wpb": "14558.1", "bsz": "85.1", "num_updates": "1600", "lr": "4.26e-06", "gnorm": "177.071", "loss_scale": "1", "train_wall": "67", "gb_free": "33.1", "wall": "603"}
[2024-07-09 21:26:40,480][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 21:26:40,481][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 21:26:51,526][dev-other][INFO] - {"epoch": 1, "dev-other_loss": "396.854", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "4.219", "dev-other_uer": "100", "dev-other_wer": "100", "dev-other_raw_wer": "100", "dev-other_wps": "26840", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "1745"}
[2024-07-09 21:26:51,527][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2024-07-09 21:26:51,529][train][INFO] - {"epoch": 1, "train_loss": "944.004", "train_ntokens": "14576.1", "train_nsentences": "84.8178", "train_nll_loss": "5.493", "train_wps": "41588.8", "train_ups": "2.85", "train_wpb": "14576.1", "train_bsz": "84.8", "train_num_updates": "1745", "train_lr": "4.61887e-06", "train_gnorm": "636.409", "train_loss_scale": "1", "train_train_wall": "600", "train_gb_free": "32.6", "train_wall": "663"}
[2024-07-09 21:26:51,530][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 21:26:52,250][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 21:26:52,264][fairseq.trainer][INFO] - begin training epoch 2
[2024-07-09 21:26:52,264][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 21:27:10,786][train_inner][INFO] - {"epoch": 2, "update": 1.031, "loss": "713.496", "ntokens": "14603.6", "nsentences": "84.36", "nll_loss": "4.122", "wps": "36715.9", "ups": "2.51", "wpb": "14603.6", "bsz": "84.4", "num_updates": "1800", "lr": "4.755e-06", "gnorm": "179.098", "loss_scale": "1", "train_wall": "67", "gb_free": "32.2", "wall": "683"}
[2024-07-09 21:28:17,736][train_inner][INFO] - {"epoch": 2, "update": 1.146, "loss": "699.382", "ntokens": "14623.9", "nsentences": "86.16", "nll_loss": "4.121", "wps": "43688.7", "ups": "2.99", "wpb": "14623.9", "bsz": "86.2", "num_updates": "2000", "lr": "5.25e-06", "gnorm": "157.238", "loss_scale": "1", "train_wall": "66", "gb_free": "33.8", "wall": "750"}
[2024-07-09 21:29:24,258][train_inner][INFO] - {"epoch": 2, "update": 1.26, "loss": "717.503", "ntokens": "14506.3", "nsentences": "83.16", "nll_loss": "4.113", "wps": "43674.1", "ups": "3.01", "wpb": "14506.3", "bsz": "83.2", "num_updates": "2200", "lr": "5.745e-06", "gnorm": "207.08", "loss_scale": "1", "train_wall": "66", "gb_free": "31.6", "wall": "816"}
[2024-07-09 21:30:30,543][train_inner][INFO] - {"epoch": 2, "update": 1.374, "loss": "701.079", "ntokens": "14598.3", "nsentences": "85.76", "nll_loss": "4.119", "wps": "44061", "ups": "3.02", "wpb": "14598.3", "bsz": "85.8", "num_updates": "2400", "lr": "6.24e-06", "gnorm": "156.454", "loss_scale": "2", "train_wall": "66", "gb_free": "32.5", "wall": "883"}
[2024-07-09 21:31:36,744][train_inner][INFO] - {"epoch": 2, "update": 1.488, "loss": "701.675", "ntokens": "14640.4", "nsentences": "85.72", "nll_loss": "4.108", "wps": "44235.1", "ups": "3.02", "wpb": "14640.4", "bsz": "85.7", "num_updates": "2600", "lr": "6.735e-06", "gnorm": "155.731", "loss_scale": "2", "train_wall": "66", "gb_free": "32.6", "wall": "949"}
[2024-07-09 21:32:42,837][train_inner][INFO] - {"epoch": 2, "update": 1.602, "loss": "720.709", "ntokens": "14464.6", "nsentences": "82.24", "nll_loss": "4.098", "wps": "43772.2", "ups": "3.03", "wpb": "14464.6", "bsz": "82.2", "num_updates": "2800", "lr": "7.23e-06", "gnorm": "146.327", "loss_scale": "2", "train_wall": "66", "gb_free": "32.8", "wall": "1015"}
[2024-07-09 21:33:49,264][train_inner][INFO] - {"epoch": 2, "update": 1.716, "loss": "674.358", "ntokens": "14596.3", "nsentences": "85.96", "nll_loss": "3.971", "wps": "43972", "ups": "3.01", "wpb": "14596.3", "bsz": "86", "num_updates": "3000", "lr": "7.725e-06", "gnorm": "170.644", "loss_scale": "2", "train_wall": "66", "gb_free": "32.5", "wall": "1081"}
[2024-07-09 21:34:55,418][train_inner][INFO] - {"epoch": 2, "update": 1.83, "loss": "627.404", "ntokens": "14666.9", "nsentences": "85.52", "nll_loss": "3.658", "wps": "44387.9", "ups": "3.03", "wpb": "14666.9", "bsz": "85.5", "num_updates": "3200", "lr": "8.22e-06", "gnorm": "192.309", "loss_scale": "2", "train_wall": "66", "gb_free": "30.8", "wall": "1147"}
[2024-07-09 21:36:01,501][train_inner][INFO] - {"epoch": 2, "update": 1.945, "loss": "549.156", "ntokens": "14610.4", "nsentences": "86.075", "nll_loss": "3.235", "wps": "44221.6", "ups": "3.03", "wpb": "14610.4", "bsz": "86.1", "num_updates": "3400", "lr": "8.715e-06", "gnorm": "175.646", "loss_scale": "2", "train_wall": "66", "gb_free": "31.8", "wall": "1213"}
[2024-07-09 21:36:33,331][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 21:36:33,332][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 21:36:43,968][dev-other][INFO] - {"epoch": 2, "dev-other_loss": "179.488", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "1.908", "dev-other_uer": "44.592", "dev-other_wer": "87.601", "dev-other_raw_wer": "87.601", "dev-other_wps": "27914", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "3497"}
[2024-07-09 21:36:43,968][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2024-07-09 21:36:43,971][train][INFO] - {"epoch": 2, "train_loss": "665.144", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "3.872", "train_wps": "43109.6", "train_ups": "2.96", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "3497", "train_lr": "8.95507e-06", "train_gnorm": "170.913", "train_loss_scale": "2", "train_train_wall": "576", "train_gb_free": "32.6", "train_wall": "1256"}
[2024-07-09 21:36:43,973][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 21:36:44,664][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 21:36:44,686][fairseq.trainer][INFO] - begin training epoch 3
[2024-07-09 21:36:44,686][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 21:37:18,807][train_inner][INFO] - {"epoch": 3, "update": 2.059, "loss": "465.481", "ntokens": "14443.2", "nsentences": "83.08", "nll_loss": "2.678", "wps": "37368.9", "ups": "2.59", "wpb": "14443.2", "bsz": "83.1", "num_updates": "3600", "lr": "9.21e-06", "gnorm": "177.992", "loss_scale": "2", "train_wall": "65", "gb_free": "32.1", "wall": "1291"}
[2024-07-09 21:38:24,087][train_inner][INFO] - {"epoch": 3, "update": 2.173, "loss": "390.976", "ntokens": "14485.4", "nsentences": "83.515", "nll_loss": "2.254", "wps": "44389.3", "ups": "3.06", "wpb": "14485.4", "bsz": "83.5", "num_updates": "3800", "lr": "9.705e-06", "gnorm": "163.243", "loss_scale": "2", "train_wall": "65", "gb_free": "31.5", "wall": "1356"}
[2024-07-09 21:39:29,690][train_inner][INFO] - {"epoch": 3, "update": 2.287, "loss": "329.321", "ntokens": "14599.2", "nsentences": "84.76", "nll_loss": "1.912", "wps": "44512.1", "ups": "3.05", "wpb": "14599.2", "bsz": "84.8", "num_updates": "4000", "lr": "1.02e-05", "gnorm": "165.913", "loss_scale": "2", "train_wall": "65", "gb_free": "31.2", "wall": "1422"}
[2024-07-09 21:40:35,647][train_inner][INFO] - {"epoch": 3, "update": 2.401, "loss": "307.09", "ntokens": "14595.3", "nsentences": "82.88", "nll_loss": "1.744", "wps": "44259.8", "ups": "3.03", "wpb": "14595.3", "bsz": "82.9", "num_updates": "4200", "lr": "1.0695e-05", "gnorm": "165.521", "loss_scale": "2", "train_wall": "65", "gb_free": "32.7", "wall": "1488"}
[2024-07-09 21:41:42,149][train_inner][INFO] - {"epoch": 3, "update": 2.515, "loss": "252.18", "ntokens": "14753.8", "nsentences": "90.76", "nll_loss": "1.551", "wps": "44420.6", "ups": "3.01", "wpb": "14753.8", "bsz": "90.8", "num_updates": "4400", "lr": "1.119e-05", "gnorm": "156.758", "loss_scale": "4", "train_wall": "66", "gb_free": "32.3", "wall": "1554"}
[2024-07-09 21:42:47,561][train_inner][INFO] - {"epoch": 3, "update": 2.63, "loss": "250.236", "ntokens": "14679.4", "nsentences": "87.68", "nll_loss": "1.495", "wps": "44904.5", "ups": "3.06", "wpb": "14679.4", "bsz": "87.7", "num_updates": "4600", "lr": "1.1685e-05", "gnorm": "163.115", "loss_scale": "4", "train_wall": "65", "gb_free": "32.3", "wall": "1620"}
[2024-07-09 21:43:52,879][train_inner][INFO] - {"epoch": 3, "update": 2.744, "loss": "236.329", "ntokens": "14558", "nsentences": "83.84", "nll_loss": "1.361", "wps": "44624.7", "ups": "3.07", "wpb": "14558", "bsz": "83.8", "num_updates": "4800", "lr": "1.218e-05", "gnorm": "150.435", "loss_scale": "4", "train_wall": "65", "gb_free": "31.6", "wall": "1685"}
[2024-07-09 21:44:57,010][train_inner][INFO] - {"epoch": 3, "update": 2.858, "loss": "243.418", "ntokens": "14451", "nsentences": "83.08", "nll_loss": "1.399", "wps": "45072.1", "ups": "3.12", "wpb": "14451", "bsz": "83.1", "num_updates": "5000", "lr": "1.2675e-05", "gnorm": "161.22", "loss_scale": "4", "train_wall": "64", "gb_free": "32.5", "wall": "1749"}
[2024-07-09 21:46:01,478][train_inner][INFO] - {"epoch": 3, "update": 2.972, "loss": "216.766", "ntokens": "14594.8", "nsentences": "83.64", "nll_loss": "1.242", "wps": "45282.3", "ups": "3.1", "wpb": "14594.8", "bsz": "83.6", "num_updates": "5200", "lr": "1.317e-05", "gnorm": "149.854", "loss_scale": "4", "train_wall": "64", "gb_free": "32.5", "wall": "1813"}
[2024-07-09 21:46:17,393][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 21:46:17,394][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 21:46:28,146][dev-other][INFO] - {"epoch": 3, "dev-other_loss": "54.164", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.576", "dev-other_uer": "10.775", "dev-other_wer": "34.965", "dev-other_raw_wer": "34.965", "dev-other_wps": "27644.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "5249"}
[2024-07-09 21:46:28,146][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)
[2024-07-09 21:46:28,149][train][INFO] - {"epoch": 3, "train_loss": "285.487", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "1.662", "train_wps": "43719.5", "train_ups": "3", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "5249", "train_lr": "1.32913e-05", "train_gnorm": "160.697", "train_loss_scale": "4", "train_train_wall": "568", "train_gb_free": "32.7", "train_wall": "1840"}
[2024-07-09 21:46:28,150][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 21:46:28,914][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 21:46:28,918][fairseq.trainer][INFO] - begin training epoch 4
[2024-07-09 21:46:28,918][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 21:47:18,208][train_inner][INFO] - {"epoch": 4, "update": 3.086, "loss": "207.079", "ntokens": "14521.1", "nsentences": "84.915", "nll_loss": "1.211", "wps": "37856.7", "ups": "2.61", "wpb": "14521.1", "bsz": "84.9", "num_updates": "5400", "lr": "1.3665e-05", "gnorm": "149.58", "loss_scale": "4", "train_wall": "65", "gb_free": "32.9", "wall": "1890"}
[2024-07-09 21:48:22,239][train_inner][INFO] - {"epoch": 4, "update": 3.2, "loss": "205.807", "ntokens": "14510.9", "nsentences": "82.4", "nll_loss": "1.169", "wps": "45333.5", "ups": "3.12", "wpb": "14510.9", "bsz": "82.4", "num_updates": "5600", "lr": "1.416e-05", "gnorm": "151.153", "loss_scale": "4", "train_wall": "64", "gb_free": "33.2", "wall": "1954"}
[2024-07-09 21:49:27,131][train_inner][INFO] - {"epoch": 4, "update": 3.314, "loss": "184.779", "ntokens": "14544.1", "nsentences": "84.68", "nll_loss": "1.076", "wps": "44830", "ups": "3.08", "wpb": "14544.1", "bsz": "84.7", "num_updates": "5800", "lr": "1.4655e-05", "gnorm": "146.028", "loss_scale": "4", "train_wall": "64", "gb_free": "31.9", "wall": "2019"}
[2024-07-09 21:50:32,412][train_inner][INFO] - {"epoch": 4, "update": 3.429, "loss": "189.406", "ntokens": "14609.8", "nsentences": "86.96", "nll_loss": "1.127", "wps": "44762.7", "ups": "3.06", "wpb": "14609.8", "bsz": "87", "num_updates": "6000", "lr": "1.515e-05", "gnorm": "148.685", "loss_scale": "4", "train_wall": "65", "gb_free": "31.5", "wall": "2084"}
[2024-07-09 21:51:38,163][train_inner][INFO] - {"epoch": 4, "update": 3.543, "loss": "175.022", "ntokens": "14666.9", "nsentences": "86.88", "nll_loss": "1.037", "wps": "44617.4", "ups": "3.04", "wpb": "14666.9", "bsz": "86.9", "num_updates": "6200", "lr": "1.5645e-05", "gnorm": "142.504", "loss_scale": "4", "train_wall": "65", "gb_free": "32.2", "wall": "2150"}
[2024-07-09 21:52:43,309][train_inner][INFO] - {"epoch": 4, "update": 3.657, "loss": "181.044", "ntokens": "14561.3", "nsentences": "84.48", "nll_loss": "1.05", "wps": "44752.8", "ups": "3.07", "wpb": "14561.3", "bsz": "84.5", "num_updates": "6400", "lr": "1.614e-05", "gnorm": "145.753", "loss_scale": "8", "train_wall": "65", "gb_free": "32.2", "wall": "2215"}
[2024-07-09 21:53:48,769][train_inner][INFO] - {"epoch": 4, "update": 3.771, "loss": "176.431", "ntokens": "14557.8", "nsentences": "82.92", "nll_loss": "1.005", "wps": "44482.6", "ups": "3.06", "wpb": "14557.8", "bsz": "82.9", "num_updates": "6600", "lr": "1.6635e-05", "gnorm": "143.103", "loss_scale": "8", "train_wall": "65", "gb_free": "33", "wall": "2281"}
[2024-07-09 21:54:53,968][train_inner][INFO] - {"epoch": 4, "update": 3.885, "loss": "171.788", "ntokens": "14542.1", "nsentences": "82.16", "nll_loss": "0.971", "wps": "44613.8", "ups": "3.07", "wpb": "14542.1", "bsz": "82.2", "num_updates": "6800", "lr": "1.713e-05", "gnorm": "145.2", "loss_scale": "8", "train_wall": "65", "gb_free": "31.3", "wall": "2346"}
[2024-07-09 21:55:58,723][train_inner][INFO] - {"epoch": 4, "update": 3.999, "loss": "163.332", "ntokens": "14677.6", "nsentences": "88", "nll_loss": "0.979", "wps": "45336.4", "ups": "3.09", "wpb": "14677.6", "bsz": "88", "num_updates": "7000", "lr": "1.7625e-05", "gnorm": "141.811", "loss_scale": "8", "train_wall": "64", "gb_free": "32.6", "wall": "2411"}
[2024-07-09 21:55:58,941][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 21:55:58,942][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 21:56:09,671][dev-other][INFO] - {"epoch": 4, "dev-other_loss": "38.543", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.41", "dev-other_uer": "7.246", "dev-other_wer": "22.77", "dev-other_raw_wer": "22.77", "dev-other_wps": "27826.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "7001"}
[2024-07-09 21:56:09,671][fairseq_cli.train][INFO] - end of epoch 4 (average epoch stats below)
[2024-07-09 21:56:09,675][train][INFO] - {"epoch": 4, "train_loss": "183.14", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "1.066", "train_wps": "43918.9", "train_ups": "3.01", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "7001", "train_lr": "1.76275e-05", "train_gnorm": "146.136", "train_loss_scale": "8", "train_train_wall": "566", "train_gb_free": "31.5", "train_wall": "2422"}
[2024-07-09 21:56:09,676][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 21:56:10,386][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 21:56:10,391][fairseq.trainer][INFO] - begin training epoch 5
[2024-07-09 21:56:10,391][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 21:57:15,404][train_inner][INFO] - {"epoch": 5, "update": 4.114, "loss": "163.318", "ntokens": "14473.2", "nsentences": "83.96", "nll_loss": "0.947", "wps": "37752.1", "ups": "2.61", "wpb": "14473.2", "bsz": "84", "num_updates": "7200", "lr": "1.812e-05", "gnorm": "143.368", "loss_scale": "8", "train_wall": "65", "gb_free": "32.7", "wall": "2487"}
[2024-07-09 21:58:19,807][train_inner][INFO] - {"epoch": 5, "update": 4.228, "loss": "162.517", "ntokens": "14493.4", "nsentences": "84.16", "nll_loss": "0.944", "wps": "45012.7", "ups": "3.11", "wpb": "14493.4", "bsz": "84.2", "num_updates": "7400", "lr": "1.8615e-05", "gnorm": "144.559", "loss_scale": "8", "train_wall": "64", "gb_free": "31.8", "wall": "2552"}
[2024-07-09 21:59:25,174][train_inner][INFO] - {"epoch": 5, "update": 4.342, "loss": "157.456", "ntokens": "14720.6", "nsentences": "85.64", "nll_loss": "0.916", "wps": "45044.2", "ups": "3.06", "wpb": "14720.6", "bsz": "85.6", "num_updates": "7600", "lr": "1.911e-05", "gnorm": "140.346", "loss_scale": "8", "train_wall": "65", "gb_free": "31.6", "wall": "2617"}
[2024-07-09 22:00:07,738][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-07-09 22:00:30,189][train_inner][INFO] - {"epoch": 5, "update": 4.457, "loss": "156.412", "ntokens": "14618.3", "nsentences": "84.88", "nll_loss": "0.908", "wps": "44973.3", "ups": "3.08", "wpb": "14618.3", "bsz": "84.9", "num_updates": "7800", "lr": "1.9605e-05", "gnorm": "143.866", "loss_scale": "4", "train_wall": "65", "gb_free": "30.4", "wall": "2682"}
[2024-07-09 22:01:34,893][train_inner][INFO] - {"epoch": 5, "update": 4.571, "loss": "156.676", "ntokens": "14470.3", "nsentences": "83.12", "nll_loss": "0.9", "wps": "44731.3", "ups": "3.09", "wpb": "14470.3", "bsz": "83.1", "num_updates": "8000", "lr": "2.01e-05", "gnorm": "145.318", "loss_scale": "4", "train_wall": "64", "gb_free": "32.1", "wall": "2747"}
[2024-07-09 22:02:39,520][train_inner][INFO] - {"epoch": 5, "update": 4.685, "loss": "151.985", "ntokens": "14644.3", "nsentences": "86.64", "nll_loss": "0.899", "wps": "45323.6", "ups": "3.09", "wpb": "14644.3", "bsz": "86.6", "num_updates": "8200", "lr": "2.0595e-05", "gnorm": "138.78", "loss_scale": "4", "train_wall": "64", "gb_free": "33.1", "wall": "2811"}
[2024-07-09 22:03:43,976][train_inner][INFO] - {"epoch": 5, "update": 4.799, "loss": "153.621", "ntokens": "14639.3", "nsentences": "87.28", "nll_loss": "0.916", "wps": "45500.3", "ups": "3.11", "wpb": "14639.3", "bsz": "87.3", "num_updates": "8400", "lr": "2.109e-05", "gnorm": "153.676", "loss_scale": "4", "train_wall": "64", "gb_free": "33.3", "wall": "2876"}
[2024-07-09 22:04:48,577][train_inner][INFO] - {"epoch": 5, "update": 4.913, "loss": "144.798", "ntokens": "14557.9", "nsentences": "85.395", "nll_loss": "0.849", "wps": "45074.9", "ups": "3.1", "wpb": "14557.9", "bsz": "85.4", "num_updates": "8600", "lr": "2.1585e-05", "gnorm": "139.819", "loss_scale": "4", "train_wall": "64", "gb_free": "32.7", "wall": "2941"}
[2024-07-09 22:05:37,106][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 22:05:37,107][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 22:05:47,926][dev-other][INFO] - {"epoch": 5, "dev-other_loss": "33.192", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.353", "dev-other_uer": "6.033", "dev-other_wer": "18.045", "dev-other_raw_wer": "18.045", "dev-other_wps": "27411.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "8752"}
[2024-07-09 22:05:47,927][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 8752 updates
[2024-07-09 22:05:47,928][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-09 22:05:49,199][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-09 22:05:49,654][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 5 @ 8752 updates, score 18.045) (writing took 1.7272172011435032 seconds)
[2024-07-09 22:05:49,655][fairseq_cli.train][INFO] - end of epoch 5 (average epoch stats below)
[2024-07-09 22:05:49,690][train][INFO] - {"epoch": 5, "train_loss": "156.104", "train_ntokens": "14577.8", "train_nsentences": "84.8744", "train_nll_loss": "0.909", "train_wps": "44011.4", "train_ups": "3.02", "train_wpb": "14577.8", "train_bsz": "84.9", "train_num_updates": "8752", "train_lr": "2.19612e-05", "train_gnorm": "144.325", "train_loss_scale": "4", "train_train_wall": "562", "train_gb_free": "33.9", "train_wall": "3002"}
[2024-07-09 22:05:49,691][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 22:05:49,944][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 22:05:49,947][fairseq.trainer][INFO] - begin training epoch 6
[2024-07-09 22:05:49,947][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 22:06:05,388][train_inner][INFO] - {"epoch": 6, "update": 5.027, "loss": "157.138", "ntokens": "14474.8", "nsentences": "81.32", "nll_loss": "0.883", "wps": "37692.3", "ups": "2.6", "wpb": "14474.8", "bsz": "81.3", "num_updates": "8800", "lr": "2.208e-05", "gnorm": "149.536", "loss_scale": "4", "train_wall": "63", "gb_free": "32.7", "wall": "3017"}
[2024-07-09 22:07:10,126][train_inner][INFO] - {"epoch": 6, "update": 5.142, "loss": "152.481", "ntokens": "14673.9", "nsentences": "84.64", "nll_loss": "0.88", "wps": "45339.6", "ups": "3.09", "wpb": "14673.9", "bsz": "84.6", "num_updates": "9000", "lr": "2.2575e-05", "gnorm": "153.532", "loss_scale": "4", "train_wall": "64", "gb_free": "32.1", "wall": "3082"}
[2024-07-09 22:08:14,572][train_inner][INFO] - {"epoch": 6, "update": 5.256, "loss": "142.37", "ntokens": "14531.5", "nsentences": "85.6", "nll_loss": "0.839", "wps": "45103.5", "ups": "3.1", "wpb": "14531.5", "bsz": "85.6", "num_updates": "9200", "lr": "2.307e-05", "gnorm": "139.6", "loss_scale": "4", "train_wall": "64", "gb_free": "31.3", "wall": "3147"}
[2024-07-09 22:09:19,443][train_inner][INFO] - {"epoch": 6, "update": 5.37, "loss": "139.5", "ntokens": "14678", "nsentences": "86.44", "nll_loss": "0.822", "wps": "45297.1", "ups": "3.09", "wpb": "14678", "bsz": "86.4", "num_updates": "9400", "lr": "2.3565e-05", "gnorm": "139.197", "loss_scale": "4", "train_wall": "64", "gb_free": "32.4", "wall": "3211"}
[2024-07-09 22:10:24,386][train_inner][INFO] - {"epoch": 6, "update": 5.484, "loss": "143.361", "ntokens": "14583.1", "nsentences": "84.04", "nll_loss": "0.826", "wps": "44913.4", "ups": "3.08", "wpb": "14583.1", "bsz": "84", "num_updates": "9600", "lr": "2.406e-05", "gnorm": "143.854", "loss_scale": "4", "train_wall": "64", "gb_free": "31.7", "wall": "3276"}
[2024-07-09 22:11:29,058][train_inner][INFO] - {"epoch": 6, "update": 5.598, "loss": "138.981", "ntokens": "14587.2", "nsentences": "85.12", "nll_loss": "0.811", "wps": "45115.1", "ups": "3.09", "wpb": "14587.2", "bsz": "85.1", "num_updates": "9800", "lr": "2.4555e-05", "gnorm": "139.914", "loss_scale": "8", "train_wall": "64", "gb_free": "30.7", "wall": "3341"}
[2024-07-09 22:12:33,638][train_inner][INFO] - {"epoch": 6, "update": 5.712, "loss": "143.202", "ntokens": "14631.2", "nsentences": "84.035", "nll_loss": "0.822", "wps": "45359.6", "ups": "3.1", "wpb": "14631.2", "bsz": "84", "num_updates": "10000", "lr": "2.505e-05", "gnorm": "142.716", "loss_scale": "8", "train_wall": "64", "gb_free": "31.8", "wall": "3406"}
[2024-07-09 22:13:38,196][train_inner][INFO] - {"epoch": 6, "update": 5.826, "loss": "137.811", "ntokens": "14570.1", "nsentences": "85.04", "nll_loss": "0.804", "wps": "45188.9", "ups": "3.1", "wpb": "14570.1", "bsz": "85", "num_updates": "10200", "lr": "2.5545e-05", "gnorm": "141.516", "loss_scale": "8", "train_wall": "64", "gb_free": "32.5", "wall": "3470"}
[2024-07-09 22:14:42,980][train_inner][INFO] - {"epoch": 6, "update": 5.941, "loss": "135.747", "ntokens": "14530.4", "nsentences": "86.72", "nll_loss": "0.81", "wps": "44874.4", "ups": "3.09", "wpb": "14530.4", "bsz": "86.7", "num_updates": "10400", "lr": "2.604e-05", "gnorm": "144.474", "loss_scale": "8", "train_wall": "64", "gb_free": "32.8", "wall": "3535"}
[2024-07-09 22:15:16,215][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 22:15:16,216][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 22:15:26,959][dev-other][INFO] - {"epoch": 6, "dev-other_loss": "29.939", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.318", "dev-other_uer": "5.366", "dev-other_wer": "15.628", "dev-other_raw_wer": "15.628", "dev-other_wps": "27687", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "10504", "dev-other_best_wer": "15.628"}
[2024-07-09 22:15:26,959][fairseq_cli.train][INFO] - end of epoch 6 (average epoch stats below)
[2024-07-09 22:15:26,962][train][INFO] - {"epoch": 6, "train_loss": "141.841", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.826", "train_wps": "44242.5", "train_ups": "3.03", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "10504", "train_lr": "2.62974e-05", "train_gnorm": "143.528", "train_loss_scale": "8", "train_train_wall": "562", "train_gb_free": "33.1", "train_wall": "3579"}
[2024-07-09 22:15:26,963][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 22:15:27,692][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 22:15:27,696][fairseq.trainer][INFO] - begin training epoch 7
[2024-07-09 22:15:27,696][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 22:15:58,719][train_inner][INFO] - {"epoch": 7, "update": 6.055, "loss": "136.908", "ntokens": "14481", "nsentences": "84.16", "nll_loss": "0.796", "wps": "38242.3", "ups": "2.64", "wpb": "14481", "bsz": "84.2", "num_updates": "10600", "lr": "2.6535e-05", "gnorm": "145.309", "loss_scale": "8", "train_wall": "64", "gb_free": "32.8", "wall": "3611"}
[2024-07-09 22:17:03,545][train_inner][INFO] - {"epoch": 7, "update": 6.169, "loss": "134.697", "ntokens": "14591.6", "nsentences": "84.96", "nll_loss": "0.784", "wps": "45020.1", "ups": "3.09", "wpb": "14591.6", "bsz": "85", "num_updates": "10800", "lr": "2.703e-05", "gnorm": "141.008", "loss_scale": "8", "train_wall": "64", "gb_free": "32.2", "wall": "3676"}
[2024-07-09 22:18:07,596][train_inner][INFO] - {"epoch": 7, "update": 6.283, "loss": "136.931", "ntokens": "14524.2", "nsentences": "84.235", "nll_loss": "0.794", "wps": "45355.9", "ups": "3.12", "wpb": "14524.2", "bsz": "84.2", "num_updates": "11000", "lr": "2.7525e-05", "gnorm": "141.575", "loss_scale": "8", "train_wall": "64", "gb_free": "32.6", "wall": "3740"}
[2024-07-09 22:19:11,547][train_inner][INFO] - {"epoch": 7, "update": 6.397, "loss": "136.211", "ntokens": "14614.6", "nsentences": "83.44", "nll_loss": "0.778", "wps": "45708.4", "ups": "3.13", "wpb": "14614.6", "bsz": "83.4", "num_updates": "11200", "lr": "2.802e-05", "gnorm": "142.233", "loss_scale": "8", "train_wall": "63", "gb_free": "32", "wall": "3804"}
[2024-07-09 22:20:16,214][train_inner][INFO] - {"epoch": 7, "update": 6.511, "loss": "128.207", "ntokens": "14649.7", "nsentences": "86.96", "nll_loss": "0.761", "wps": "45312.9", "ups": "3.09", "wpb": "14649.7", "bsz": "87", "num_updates": "11400", "lr": "2.8515e-05", "gnorm": "137.886", "loss_scale": "8", "train_wall": "64", "gb_free": "29.5", "wall": "3868"}
[2024-07-09 22:20:36,944][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-07-09 22:21:20,298][train_inner][INFO] - {"epoch": 7, "update": 6.626, "loss": "136.293", "ntokens": "14536.5", "nsentences": "82.84", "nll_loss": "0.777", "wps": "45380", "ups": "3.12", "wpb": "14536.5", "bsz": "82.8", "num_updates": "11600", "lr": "2.901e-05", "gnorm": "147.128", "loss_scale": "4", "train_wall": "64", "gb_free": "32", "wall": "3932"}
[2024-07-09 22:22:24,176][train_inner][INFO] - {"epoch": 7, "update": 6.74, "loss": "137.75", "ntokens": "14594.8", "nsentences": "84.4", "nll_loss": "0.797", "wps": "45706.9", "ups": "3.13", "wpb": "14594.8", "bsz": "84.4", "num_updates": "11800", "lr": "2.9505e-05", "gnorm": "144.006", "loss_scale": "4", "train_wall": "63", "gb_free": "31.7", "wall": "3996"}
[2024-07-09 22:23:28,932][train_inner][INFO] - {"epoch": 7, "update": 6.854, "loss": "124.406", "ntokens": "14728.4", "nsentences": "87.52", "nll_loss": "0.739", "wps": "45540.3", "ups": "3.09", "wpb": "14728.4", "bsz": "87.5", "num_updates": "12000", "lr": "3e-05", "gnorm": "136.16", "loss_scale": "4", "train_wall": "64", "gb_free": "32.8", "wall": "4061"}
[2024-07-09 22:24:33,195][train_inner][INFO] - {"epoch": 7, "update": 6.969, "loss": "133.896", "ntokens": "14451.5", "nsentences": "84.08", "nll_loss": "0.779", "wps": "45022.7", "ups": "3.12", "wpb": "14451.5", "bsz": "84.1", "num_updates": "12200", "lr": "3e-05", "gnorm": "145.035", "loss_scale": "4", "train_wall": "64", "gb_free": "31.9", "wall": "4125"}
[2024-07-09 22:24:50,601][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 22:24:50,602][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 22:25:01,356][dev-other][INFO] - {"epoch": 7, "dev-other_loss": "28.186", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.3", "dev-other_uer": "5.024", "dev-other_wer": "14.413", "dev-other_raw_wer": "14.413", "dev-other_wps": "27651.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "12255", "dev-other_best_wer": "14.413"}
[2024-07-09 22:25:01,356][fairseq_cli.train][INFO] - end of epoch 7 (average epoch stats below)
[2024-07-09 22:25:01,359][train][INFO] - {"epoch": 7, "train_loss": "133.385", "train_ntokens": "14576.5", "train_nsentences": "84.8652", "train_nll_loss": "0.777", "train_wps": "44435.4", "train_ups": "3.05", "train_wpb": "14576.5", "train_bsz": "84.9", "train_num_updates": "12255", "train_lr": "3e-05", "train_gnorm": "141.745", "train_loss_scale": "4", "train_train_wall": "558", "train_gb_free": "33.9", "train_wall": "4153"}
[2024-07-09 22:25:01,360][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 22:25:02,080][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 22:25:02,083][fairseq.trainer][INFO] - begin training epoch 8
[2024-07-09 22:25:02,084][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 22:25:49,387][train_inner][INFO] - {"epoch": 8, "update": 7.083, "loss": "127.32", "ntokens": "14577.4", "nsentences": "86.035", "nll_loss": "0.751", "wps": "38299.7", "ups": "2.63", "wpb": "14577.4", "bsz": "86", "num_updates": "12400", "lr": "3e-05", "gnorm": "137.872", "loss_scale": "4", "train_wall": "64", "gb_free": "33.4", "wall": "4201"}
[2024-07-09 22:26:53,674][train_inner][INFO] - {"epoch": 8, "update": 7.197, "loss": "131.309", "ntokens": "14583.3", "nsentences": "83.64", "nll_loss": "0.753", "wps": "45399.6", "ups": "3.11", "wpb": "14583.3", "bsz": "83.6", "num_updates": "12600", "lr": "3e-05", "gnorm": "145.059", "loss_scale": "4", "train_wall": "64", "gb_free": "32", "wall": "4266"}
[2024-07-09 22:27:57,594][train_inner][INFO] - {"epoch": 8, "update": 7.311, "loss": "122.325", "ntokens": "14537.9", "nsentences": "86.36", "nll_loss": "0.727", "wps": "45491.8", "ups": "3.13", "wpb": "14537.9", "bsz": "86.4", "num_updates": "12800", "lr": "3e-05", "gnorm": "136.384", "loss_scale": "4", "train_wall": "63", "gb_free": "31.9", "wall": "4330"}
[2024-07-09 22:29:02,256][train_inner][INFO] - {"epoch": 8, "update": 7.425, "loss": "127.523", "ntokens": "14684.1", "nsentences": "85.36", "nll_loss": "0.741", "wps": "45421.3", "ups": "3.09", "wpb": "14684.1", "bsz": "85.4", "num_updates": "13000", "lr": "3e-05", "gnorm": "139.381", "loss_scale": "4", "train_wall": "64", "gb_free": "32.2", "wall": "4394"}
[2024-07-09 22:30:06,505][train_inner][INFO] - {"epoch": 8, "update": 7.539, "loss": "130.585", "ntokens": "14483.5", "nsentences": "82.8", "nll_loss": "0.747", "wps": "45089.4", "ups": "3.11", "wpb": "14483.5", "bsz": "82.8", "num_updates": "13200", "lr": "3e-05", "gnorm": "143.287", "loss_scale": "4", "train_wall": "64", "gb_free": "31.7", "wall": "4458"}
[2024-07-09 22:31:11,243][train_inner][INFO] - {"epoch": 8, "update": 7.654, "loss": "121.924", "ntokens": "14667.5", "nsentences": "86.96", "nll_loss": "0.723", "wps": "45317.8", "ups": "3.09", "wpb": "14667.5", "bsz": "87", "num_updates": "13400", "lr": "3e-05", "gnorm": "136.778", "loss_scale": "4", "train_wall": "64", "gb_free": "32.1", "wall": "4523"}
[2024-07-09 22:32:15,139][train_inner][INFO] - {"epoch": 8, "update": 7.768, "loss": "132.112", "ntokens": "14504.9", "nsentences": "82.84", "nll_loss": "0.755", "wps": "45405.3", "ups": "3.13", "wpb": "14504.9", "bsz": "82.8", "num_updates": "13600", "lr": "3e-05", "gnorm": "142.266", "loss_scale": "8", "train_wall": "63", "gb_free": "33", "wall": "4587"}
[2024-07-09 22:33:18,666][train_inner][INFO] - {"epoch": 8, "update": 7.882, "loss": "125.908", "ntokens": "14535", "nsentences": "83.68", "nll_loss": "0.725", "wps": "45766.4", "ups": "3.15", "wpb": "14535", "bsz": "83.7", "num_updates": "13800", "lr": "3e-05", "gnorm": "138.341", "loss_scale": "8", "train_wall": "63", "gb_free": "32.4", "wall": "4651"}
[2024-07-09 22:34:23,202][train_inner][INFO] - {"epoch": 8, "update": 7.996, "loss": "122.577", "ntokens": "14598.9", "nsentences": "86.2", "nll_loss": "0.724", "wps": "45247.2", "ups": "3.1", "wpb": "14598.9", "bsz": "86.2", "num_updates": "14000", "lr": "3e-05", "gnorm": "140.998", "loss_scale": "8", "train_wall": "64", "gb_free": "29.9", "wall": "4715"}
[2024-07-09 22:34:25,307][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 22:34:25,308][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 22:34:36,033][dev-other][INFO] - {"epoch": 8, "dev-other_loss": "28.006", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.298", "dev-other_uer": "4.872", "dev-other_wer": "13.767", "dev-other_raw_wer": "13.767", "dev-other_wps": "27763.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "14007", "dev-other_best_wer": "13.767"}
[2024-07-09 22:34:36,034][fairseq_cli.train][INFO] - end of epoch 8 (average epoch stats below)
[2024-07-09 22:34:36,043][train][INFO] - {"epoch": 8, "train_loss": "126.576", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.737", "train_wps": "44442.2", "train_ups": "3.05", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "14007", "train_lr": "3e-05", "train_gnorm": "140.01", "train_loss_scale": "8", "train_train_wall": "559", "train_gb_free": "32.1", "train_wall": "4728"}
[2024-07-09 22:34:36,045][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 22:34:36,721][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 22:34:36,725][fairseq.trainer][INFO] - begin training epoch 9
[2024-07-09 22:34:36,725][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 22:35:39,511][train_inner][INFO] - {"epoch": 9, "update": 8.11, "loss": "123.97", "ntokens": "14557.6", "nsentences": "85.32", "nll_loss": "0.727", "wps": "38190.1", "ups": "2.62", "wpb": "14557.6", "bsz": "85.3", "num_updates": "14200", "lr": "3e-05", "gnorm": "137.087", "loss_scale": "8", "train_wall": "64", "gb_free": "30.5", "wall": "4791"}
[2024-07-09 22:36:44,821][train_inner][INFO] - {"epoch": 9, "update": 8.224, "loss": "118.267", "ntokens": "14653.1", "nsentences": "86.04", "nll_loss": "0.694", "wps": "44921.1", "ups": "3.07", "wpb": "14653.1", "bsz": "86", "num_updates": "14400", "lr": "3e-05", "gnorm": "134.917", "loss_scale": "8", "train_wall": "65", "gb_free": "32.6", "wall": "4857"}
[2024-07-09 22:37:49,414][train_inner][INFO] - {"epoch": 9, "update": 8.338, "loss": "120.238", "ntokens": "14634.7", "nsentences": "86.08", "nll_loss": "0.707", "wps": "45319.1", "ups": "3.1", "wpb": "14634.7", "bsz": "86.1", "num_updates": "14600", "lr": "3e-05", "gnorm": "139.385", "loss_scale": "8", "train_wall": "64", "gb_free": "31.2", "wall": "4921"}
[2024-07-09 22:38:52,846][train_inner][INFO] - {"epoch": 9, "update": 8.453, "loss": "125.318", "ntokens": "14458.7", "nsentences": "83.2", "nll_loss": "0.721", "wps": "45591.5", "ups": "3.15", "wpb": "14458.7", "bsz": "83.2", "num_updates": "14800", "lr": "3e-05", "gnorm": "141.725", "loss_scale": "8", "train_wall": "63", "gb_free": "31.5", "wall": "4985"}
[2024-07-09 22:39:57,232][train_inner][INFO] - {"epoch": 9, "update": 8.567, "loss": "123.969", "ntokens": "14635.4", "nsentences": "84.195", "nll_loss": "0.713", "wps": "45465.3", "ups": "3.11", "wpb": "14635.4", "bsz": "84.2", "num_updates": "15000", "lr": "3e-05", "gnorm": "140.012", "loss_scale": "8", "train_wall": "64", "gb_free": "32.8", "wall": "5049"}
[2024-07-09 22:41:01,261][train_inner][INFO] - {"epoch": 9, "update": 8.681, "loss": "126.208", "ntokens": "14504.5", "nsentences": "81.8", "nll_loss": "0.712", "wps": "45310.7", "ups": "3.12", "wpb": "14504.5", "bsz": "81.8", "num_updates": "15200", "lr": "3e-05", "gnorm": "142.743", "loss_scale": "8", "train_wall": "64", "gb_free": "32.6", "wall": "5113"}
[2024-07-09 22:42:05,571][train_inner][INFO] - {"epoch": 9, "update": 8.795, "loss": "120.956", "ntokens": "14603.8", "nsentences": "87.36", "nll_loss": "0.724", "wps": "45420.8", "ups": "3.11", "wpb": "14603.8", "bsz": "87.4", "num_updates": "15400", "lr": "3e-05", "gnorm": "133.804", "loss_scale": "8", "train_wall": "64", "gb_free": "32.7", "wall": "5178"}
[2024-07-09 22:43:09,873][train_inner][INFO] - {"epoch": 9, "update": 8.909, "loss": "122.24", "ntokens": "14548.8", "nsentences": "82.96", "nll_loss": "0.697", "wps": "45256.3", "ups": "3.11", "wpb": "14548.8", "bsz": "83", "num_updates": "15600", "lr": "3e-05", "gnorm": "138.92", "loss_scale": "16", "train_wall": "64", "gb_free": "32.7", "wall": "5242"}
[2024-07-09 22:44:01,062][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 22:44:01,064][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 22:44:11,830][dev-other][INFO] - {"epoch": 9, "dev-other_loss": "26.529", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.282", "dev-other_uer": "4.683", "dev-other_wer": "13.251", "dev-other_raw_wer": "13.251", "dev-other_wps": "27871.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "15759", "dev-other_best_wer": "13.251"}
[2024-07-09 22:44:11,831][fairseq_cli.train][INFO] - end of epoch 9 (average epoch stats below)
[2024-07-09 22:44:11,838][train][INFO] - {"epoch": 9, "train_loss": "122.127", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.711", "train_wps": "44356.3", "train_ups": "3.04", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "15759", "train_lr": "3e-05", "train_gnorm": "138.257", "train_loss_scale": "16", "train_train_wall": "560", "train_gb_free": "32.3", "train_wall": "5304"}
[2024-07-09 22:44:11,840][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 22:44:12,527][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 22:44:12,532][fairseq.trainer][INFO] - begin training epoch 10
[2024-07-09 22:44:12,532][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 22:44:25,756][train_inner][INFO] - {"epoch": 10, "update": 9.023, "loss": "118.628", "ntokens": "14511.8", "nsentences": "85.76", "nll_loss": "0.701", "wps": "38286.1", "ups": "2.64", "wpb": "14511.8", "bsz": "85.8", "num_updates": "15800", "lr": "3e-05", "gnorm": "136.555", "loss_scale": "16", "train_wall": "64", "gb_free": "31.3", "wall": "5318"}
[2024-07-09 22:45:30,797][train_inner][INFO] - {"epoch": 10, "update": 9.138, "loss": "115.028", "ntokens": "14601.6", "nsentences": "85", "nll_loss": "0.67", "wps": "44902.7", "ups": "3.08", "wpb": "14601.6", "bsz": "85", "num_updates": "16000", "lr": "3e-05", "gnorm": "136.189", "loss_scale": "16", "train_wall": "65", "gb_free": "32.2", "wall": "5383"}
[2024-07-09 22:46:34,087][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-09 22:46:35,785][train_inner][INFO] - {"epoch": 10, "update": 9.252, "loss": "117.006", "ntokens": "14624.8", "nsentences": "85.56", "nll_loss": "0.685", "wps": "45035.5", "ups": "3.08", "wpb": "14624.8", "bsz": "85.6", "num_updates": "16200", "lr": "3e-05", "gnorm": "134.502", "loss_scale": "8", "train_wall": "64", "gb_free": "32.5", "wall": "5448"}
[2024-07-09 22:47:40,271][train_inner][INFO] - {"epoch": 10, "update": 9.366, "loss": "120.121", "ntokens": "14605.1", "nsentences": "86.12", "nll_loss": "0.708", "wps": "45299.4", "ups": "3.1", "wpb": "14605.1", "bsz": "86.1", "num_updates": "16400", "lr": "3e-05", "gnorm": "137.724", "loss_scale": "8", "train_wall": "64", "gb_free": "32.6", "wall": "5512"}
[2024-07-09 22:48:44,324][train_inner][INFO] - {"epoch": 10, "update": 9.481, "loss": "118.253", "ntokens": "14606.6", "nsentences": "84.76", "nll_loss": "0.686", "wps": "45613", "ups": "3.12", "wpb": "14606.6", "bsz": "84.8", "num_updates": "16600", "lr": "3e-05", "gnorm": "135.057", "loss_scale": "8", "train_wall": "64", "gb_free": "33.3", "wall": "5576"}
[2024-07-09 22:49:48,049][train_inner][INFO] - {"epoch": 10, "update": 9.595, "loss": "123.835", "ntokens": "14504.6", "nsentences": "83.6", "nll_loss": "0.714", "wps": "45568.4", "ups": "3.14", "wpb": "14504.6", "bsz": "83.6", "num_updates": "16800", "lr": "3e-05", "gnorm": "141.509", "loss_scale": "8", "train_wall": "63", "gb_free": "31.5", "wall": "5640"}
[2024-07-09 22:50:52,420][train_inner][INFO] - {"epoch": 10, "update": 9.709, "loss": "113.634", "ntokens": "14666", "nsentences": "86.68", "nll_loss": "0.672", "wps": "45571.7", "ups": "3.11", "wpb": "14666", "bsz": "86.7", "num_updates": "17000", "lr": "3e-05", "gnorm": "133.866", "loss_scale": "8", "train_wall": "64", "gb_free": "32.6", "wall": "5704"}
[2024-07-09 22:51:56,833][train_inner][INFO] - {"epoch": 10, "update": 9.823, "loss": "118.946", "ntokens": "14573.4", "nsentences": "84.32", "nll_loss": "0.688", "wps": "45296.8", "ups": "3.11", "wpb": "14573.4", "bsz": "84.3", "num_updates": "17200", "lr": "3e-05", "gnorm": "138.431", "loss_scale": "8", "train_wall": "64", "gb_free": "29.8", "wall": "5769"}
[2024-07-09 22:53:00,515][train_inner][INFO] - {"epoch": 10, "update": 9.937, "loss": "119.842", "ntokens": "14552.7", "nsentences": "84.875", "nll_loss": "0.699", "wps": "45716.6", "ups": "3.14", "wpb": "14552.7", "bsz": "84.9", "num_updates": "17400", "lr": "3e-05", "gnorm": "136.597", "loss_scale": "8", "train_wall": "63", "gb_free": "31.5", "wall": "5832"}
[2024-07-09 22:53:35,720][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 22:53:35,721][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 22:53:46,499][dev-other][INFO] - {"epoch": 10, "dev-other_loss": "26.261", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.279", "dev-other_uer": "4.615", "dev-other_wer": "12.91", "dev-other_raw_wer": "12.91", "dev-other_wps": "27637.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "17510", "dev-other_best_wer": "12.91"}
[2024-07-09 22:53:46,500][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 10 @ 17510 updates
[2024-07-09 22:53:46,501][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-09 22:53:47,847][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-09 22:53:48,441][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 10 @ 17510 updates, score 12.91) (writing took 1.94059219956398 seconds)
[2024-07-09 22:53:48,441][fairseq_cli.train][INFO] - end of epoch 10 (average epoch stats below)
[2024-07-09 22:53:48,446][train][INFO] - {"epoch": 10, "train_loss": "118.434", "train_ntokens": "14577", "train_nsentences": "84.8561", "train_nll_loss": "0.689", "train_wps": "44266.8", "train_ups": "3.04", "train_wpb": "14577", "train_bsz": "84.9", "train_num_updates": "17510", "train_lr": "3e-05", "train_gnorm": "136.827", "train_loss_scale": "8", "train_train_wall": "559", "train_gb_free": "33.5", "train_wall": "5880"}
[2024-07-09 22:53:48,447][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 22:53:48,693][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 22:53:48,697][fairseq.trainer][INFO] - begin training epoch 11
[2024-07-09 22:53:48,697][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 22:54:17,999][train_inner][INFO] - {"epoch": 11, "update": 10.051, "loss": "114.441", "ntokens": "14599.7", "nsentences": "86.32", "nll_loss": "0.677", "wps": "37687.8", "ups": "2.58", "wpb": "14599.7", "bsz": "86.3", "num_updates": "17600", "lr": "3e-05", "gnorm": "132.748", "loss_scale": "8", "train_wall": "64", "gb_free": "31.9", "wall": "5910"}
[2024-07-09 22:55:22,490][train_inner][INFO] - {"epoch": 11, "update": 10.166, "loss": "114.955", "ntokens": "14532.2", "nsentences": "84.8", "nll_loss": "0.671", "wps": "45070.5", "ups": "3.1", "wpb": "14532.2", "bsz": "84.8", "num_updates": "17800", "lr": "3e-05", "gnorm": "134.77", "loss_scale": "8", "train_wall": "64", "gb_free": "31.7", "wall": "5974"}
[2024-07-09 22:56:26,901][train_inner][INFO] - {"epoch": 11, "update": 10.28, "loss": "112.703", "ntokens": "14579.2", "nsentences": "85", "nll_loss": "0.657", "wps": "45319.4", "ups": "3.11", "wpb": "14579.2", "bsz": "85", "num_updates": "18000", "lr": "3e-05", "gnorm": "133.354", "loss_scale": "8", "train_wall": "64", "gb_free": "31.9", "wall": "6039"}
[2024-07-09 22:57:31,205][train_inner][INFO] - {"epoch": 11, "update": 10.394, "loss": "116.068", "ntokens": "14584.4", "nsentences": "84.6", "nll_loss": "0.673", "wps": "45365", "ups": "3.11", "wpb": "14584.4", "bsz": "84.6", "num_updates": "18200", "lr": "3e-05", "gnorm": "137.381", "loss_scale": "8", "train_wall": "64", "gb_free": "32.7", "wall": "6103"}
[2024-07-09 22:58:00,280][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-09 22:58:36,196][train_inner][INFO] - {"epoch": 11, "update": 10.509, "loss": "112.104", "ntokens": "14507.4", "nsentences": "84", "nll_loss": "0.649", "wps": "44648.7", "ups": "3.08", "wpb": "14507.4", "bsz": "84", "num_updates": "18400", "lr": "3e-05", "gnorm": "135.131", "loss_scale": "8", "train_wall": "65", "gb_free": "33.4", "wall": "6168"}
[2024-07-09 22:59:40,596][train_inner][INFO] - {"epoch": 11, "update": 10.623, "loss": "115.67", "ntokens": "14587.6", "nsentences": "84.4", "nll_loss": "0.669", "wps": "45307.6", "ups": "3.11", "wpb": "14587.6", "bsz": "84.4", "num_updates": "18600", "lr": "3e-05", "gnorm": "136.053", "loss_scale": "8", "train_wall": "64", "gb_free": "31.8", "wall": "6233"}
[2024-07-09 23:00:43,769][train_inner][INFO] - {"epoch": 11, "update": 10.737, "loss": "116.513", "ntokens": "14500.4", "nsentences": "83.88", "nll_loss": "0.674", "wps": "45957", "ups": "3.17", "wpb": "14500.4", "bsz": "83.9", "num_updates": "18800", "lr": "3e-05", "gnorm": "136.345", "loss_scale": "8", "train_wall": "63", "gb_free": "33.5", "wall": "6296"}
[2024-07-09 23:01:47,719][train_inner][INFO] - {"epoch": 11, "update": 10.851, "loss": "119.214", "ntokens": "14596", "nsentences": "84", "nll_loss": "0.686", "wps": "45656", "ups": "3.13", "wpb": "14596", "bsz": "84", "num_updates": "19000", "lr": "3e-05", "gnorm": "140.969", "loss_scale": "8", "train_wall": "64", "gb_free": "32.2", "wall": "6360"}
[2024-07-09 23:02:52,042][train_inner][INFO] - {"epoch": 11, "update": 10.965, "loss": "111.348", "ntokens": "14691.5", "nsentences": "87.515", "nll_loss": "0.663", "wps": "45683.2", "ups": "3.11", "wpb": "14691.5", "bsz": "87.5", "num_updates": "19200", "lr": "3e-05", "gnorm": "130.565", "loss_scale": "8", "train_wall": "64", "gb_free": "32", "wall": "6424"}
[2024-07-09 23:03:11,271][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 23:03:11,272][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 23:03:22,043][dev-other][INFO] - {"epoch": 11, "dev-other_loss": "25.946", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.276", "dev-other_uer": "4.521", "dev-other_wer": "12.645", "dev-other_raw_wer": "12.645", "dev-other_wps": "27713", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "19261", "dev-other_best_wer": "12.645"}
[2024-07-09 23:03:22,043][fairseq_cli.train][INFO] - end of epoch 11 (average epoch stats below)
[2024-07-09 23:03:22,049][train][INFO] - {"epoch": 11, "train_loss": "114.851", "train_ntokens": "14576.6", "train_nsentences": "84.8515", "train_nll_loss": "0.669", "train_wps": "44497.3", "train_ups": "3.05", "train_wpb": "14576.6", "train_bsz": "84.9", "train_num_updates": "19261", "train_lr": "3e-05", "train_gnorm": "135.525", "train_loss_scale": "8", "train_train_wall": "558", "train_gb_free": "31.4", "train_wall": "6454"}
[2024-07-09 23:03:22,051][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 23:03:22,747][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 23:03:22,752][fairseq.trainer][INFO] - begin training epoch 12
[2024-07-09 23:03:22,752][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 23:04:07,701][train_inner][INFO] - {"epoch": 12, "update": 11.079, "loss": "115.918", "ntokens": "14508.3", "nsentences": "82.28", "nll_loss": "0.657", "wps": "38362.1", "ups": "2.64", "wpb": "14508.3", "bsz": "82.3", "num_updates": "19400", "lr": "3e-05", "gnorm": "139.519", "loss_scale": "8", "train_wall": "64", "gb_free": "32.1", "wall": "6500"}
[2024-07-09 23:05:11,632][train_inner][INFO] - {"epoch": 12, "update": 11.193, "loss": "115.568", "ntokens": "14612.2", "nsentences": "85.32", "nll_loss": "0.675", "wps": "45715.9", "ups": "3.13", "wpb": "14612.2", "bsz": "85.3", "num_updates": "19600", "lr": "3e-05", "gnorm": "133.633", "loss_scale": "8", "train_wall": "63", "gb_free": "32.7", "wall": "6564"}
[2024-07-09 23:06:15,873][train_inner][INFO] - {"epoch": 12, "update": 11.308, "loss": "112.777", "ntokens": "14536", "nsentences": "84.52", "nll_loss": "0.656", "wps": "45258.7", "ups": "3.11", "wpb": "14536", "bsz": "84.5", "num_updates": "19800", "lr": "3e-05", "gnorm": "136.178", "loss_scale": "8", "train_wall": "64", "gb_free": "32.6", "wall": "6628"}
[2024-07-09 23:07:19,984][train_inner][INFO] - {"epoch": 12, "update": 11.422, "loss": "109.72", "ntokens": "14548.3", "nsentences": "85.56", "nll_loss": "0.645", "wps": "45389.5", "ups": "3.12", "wpb": "14548.3", "bsz": "85.6", "num_updates": "20000", "lr": "3e-05", "gnorm": "132.934", "loss_scale": "8", "train_wall": "64", "gb_free": "33.1", "wall": "6692"}
[2024-07-09 23:08:24,517][train_inner][INFO] - {"epoch": 12, "update": 11.536, "loss": "112.655", "ntokens": "14699", "nsentences": "85.68", "nll_loss": "0.657", "wps": "45558.2", "ups": "3.1", "wpb": "14699", "bsz": "85.7", "num_updates": "20200", "lr": "3e-05", "gnorm": "133.937", "loss_scale": "8", "train_wall": "64", "gb_free": "32.9", "wall": "6756"}
[2024-07-09 23:09:27,627][train_inner][INFO] - {"epoch": 12, "update": 11.65, "loss": "116.295", "ntokens": "14484.9", "nsentences": "83.72", "nll_loss": "0.672", "wps": "45909", "ups": "3.17", "wpb": "14484.9", "bsz": "83.7", "num_updates": "20400", "lr": "3e-05", "gnorm": "136.012", "loss_scale": "16", "train_wall": "63", "gb_free": "32", "wall": "6820"}
[2024-07-09 23:10:31,264][train_inner][INFO] - {"epoch": 12, "update": 11.764, "loss": "115.058", "ntokens": "14592.6", "nsentences": "84.92", "nll_loss": "0.67", "wps": "45866.1", "ups": "3.14", "wpb": "14592.6", "bsz": "84.9", "num_updates": "20600", "lr": "3e-05", "gnorm": "135.323", "loss_scale": "16", "train_wall": "63", "gb_free": "32.1", "wall": "6883"}
[2024-07-09 23:10:40,724][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-09 23:11:36,228][train_inner][INFO] - {"epoch": 12, "update": 11.879, "loss": "110.309", "ntokens": "14708", "nsentences": "87.08", "nll_loss": "0.653", "wps": "45286.1", "ups": "3.08", "wpb": "14708", "bsz": "87.1", "num_updates": "20800", "lr": "3e-05", "gnorm": "133.87", "loss_scale": "8", "train_wall": "64", "gb_free": "31", "wall": "6948"}
[2024-07-09 23:12:40,629][train_inner][INFO] - {"epoch": 12, "update": 11.993, "loss": "114.616", "ntokens": "14497.3", "nsentences": "83.275", "nll_loss": "0.658", "wps": "45026.1", "ups": "3.11", "wpb": "14497.3", "bsz": "83.3", "num_updates": "21000", "lr": "3e-05", "gnorm": "137.275", "loss_scale": "8", "train_wall": "64", "gb_free": "32.6", "wall": "7013"}
[2024-07-09 23:12:44,306][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 23:12:44,307][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 23:12:55,030][dev-other][INFO] - {"epoch": 12, "dev-other_loss": "25.41", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.27", "dev-other_uer": "4.447", "dev-other_wer": "12.476", "dev-other_raw_wer": "12.476", "dev-other_wps": "27652.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "21012", "dev-other_best_wer": "12.476"}
[2024-07-09 23:12:55,031][fairseq_cli.train][INFO] - end of epoch 12 (average epoch stats below)
[2024-07-09 23:12:55,034][train][INFO] - {"epoch": 12, "train_loss": "113.34", "train_ntokens": "14578.3", "train_nsentences": "84.8789", "train_nll_loss": "0.66", "train_wps": "44550.5", "train_ups": "3.06", "train_wpb": "14578.3", "train_bsz": "84.9", "train_num_updates": "21012", "train_lr": "3e-05", "train_gnorm": "135.24", "train_loss_scale": "8", "train_train_wall": "557", "train_gb_free": "32.3", "train_wall": "7027"}
[2024-07-09 23:12:55,035][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 23:12:55,752][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 23:12:55,769][fairseq.trainer][INFO] - begin training epoch 13
[2024-07-09 23:12:55,769][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 23:13:56,761][train_inner][INFO] - {"epoch": 13, "update": 12.107, "loss": "110.19", "ntokens": "14629.9", "nsentences": "86.68", "nll_loss": "0.653", "wps": "38443.7", "ups": "2.63", "wpb": "14629.9", "bsz": "86.7", "num_updates": "21200", "lr": "3e-05", "gnorm": "136.095", "loss_scale": "8", "train_wall": "64", "gb_free": "31.7", "wall": "7089"}
[2024-07-09 23:15:00,332][train_inner][INFO] - {"epoch": 13, "update": 12.221, "loss": "115.458", "ntokens": "14498.8", "nsentences": "82.28", "nll_loss": "0.655", "wps": "45618.5", "ups": "3.15", "wpb": "14498.8", "bsz": "82.3", "num_updates": "21400", "lr": "3e-05", "gnorm": "138.746", "loss_scale": "8", "train_wall": "63", "gb_free": "31.1", "wall": "7152"}
[2024-07-09 23:16:04,292][train_inner][INFO] - {"epoch": 13, "update": 12.336, "loss": "110.224", "ntokens": "14499.1", "nsentences": "84.275", "nll_loss": "0.641", "wps": "45389.1", "ups": "3.13", "wpb": "14499.1", "bsz": "84.3", "num_updates": "21600", "lr": "3e-05", "gnorm": "134.714", "loss_scale": "8", "train_wall": "63", "gb_free": "32.3", "wall": "7216"}
[2024-07-09 23:17:08,683][train_inner][INFO] - {"epoch": 13, "update": 12.45, "loss": "112.073", "ntokens": "14588.1", "nsentences": "85.56", "nll_loss": "0.657", "wps": "45364.1", "ups": "3.11", "wpb": "14588.1", "bsz": "85.6", "num_updates": "21800", "lr": "3e-05", "gnorm": "136.988", "loss_scale": "8", "train_wall": "64", "gb_free": "32.9", "wall": "7281"}
[2024-07-09 23:18:12,999][train_inner][INFO] - {"epoch": 13, "update": 12.564, "loss": "111.809", "ntokens": "14585.1", "nsentences": "85.36", "nll_loss": "0.654", "wps": "45406.5", "ups": "3.11", "wpb": "14585.1", "bsz": "85.4", "num_updates": "22000", "lr": "3e-05", "gnorm": "132.701", "loss_scale": "8", "train_wall": "64", "gb_free": "31.9", "wall": "7345"}
[2024-07-09 23:19:16,995][train_inner][INFO] - {"epoch": 13, "update": 12.678, "loss": "114.666", "ntokens": "14509.5", "nsentences": "83.36", "nll_loss": "0.659", "wps": "45399.9", "ups": "3.13", "wpb": "14509.5", "bsz": "83.4", "num_updates": "22200", "lr": "3e-05", "gnorm": "135.135", "loss_scale": "8", "train_wall": "63", "gb_free": "32.9", "wall": "7409"}
[2024-07-09 23:20:21,107][train_inner][INFO] - {"epoch": 13, "update": 12.792, "loss": "110.906", "ntokens": "14577.3", "nsentences": "83.76", "nll_loss": "0.637", "wps": "45478", "ups": "3.12", "wpb": "14577.3", "bsz": "83.8", "num_updates": "22400", "lr": "3e-05", "gnorm": "133.288", "loss_scale": "8", "train_wall": "64", "gb_free": "32.5", "wall": "7473"}
[2024-07-09 23:21:25,440][train_inner][INFO] - {"epoch": 13, "update": 12.906, "loss": "108.808", "ntokens": "14570.9", "nsentences": "84.68", "nll_loss": "0.632", "wps": "45302.4", "ups": "3.11", "wpb": "14570.9", "bsz": "84.7", "num_updates": "22600", "lr": "3e-05", "gnorm": "135.175", "loss_scale": "8", "train_wall": "64", "gb_free": "33.8", "wall": "7537"}
[2024-07-09 23:22:18,439][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 23:22:18,440][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 23:22:29,176][dev-other][INFO] - {"epoch": 13, "dev-other_loss": "25.519", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.271", "dev-other_uer": "4.436", "dev-other_wer": "12.385", "dev-other_raw_wer": "12.385", "dev-other_wps": "27709.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "22764", "dev-other_best_wer": "12.385"}
[2024-07-09 23:22:29,177][fairseq_cli.train][INFO] - end of epoch 13 (average epoch stats below)
[2024-07-09 23:22:29,179][train][INFO] - {"epoch": 13, "train_loss": "111.385", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.648", "train_wps": "44483.4", "train_ups": "3.05", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "22764", "train_lr": "3e-05", "train_gnorm": "134.599", "train_loss_scale": "16", "train_train_wall": "558", "train_gb_free": "33.5", "train_wall": "7601"}
[2024-07-09 23:22:29,180][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 23:22:29,893][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 23:22:29,899][fairseq.trainer][INFO] - begin training epoch 14
[2024-07-09 23:22:29,899][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 23:22:41,663][train_inner][INFO] - {"epoch": 14, "update": 13.021, "loss": "108.283", "ntokens": "14628.5", "nsentences": "87.48", "nll_loss": "0.648", "wps": "38427.3", "ups": "2.63", "wpb": "14628.5", "bsz": "87.5", "num_updates": "22800", "lr": "3e-05", "gnorm": "129.124", "loss_scale": "16", "train_wall": "64", "gb_free": "32.5", "wall": "7614"}
[2024-07-09 23:23:45,211][train_inner][INFO] - {"epoch": 14, "update": 13.135, "loss": "112.531", "ntokens": "14490.5", "nsentences": "82.4", "nll_loss": "0.64", "wps": "45648.8", "ups": "3.15", "wpb": "14490.5", "bsz": "82.4", "num_updates": "23000", "lr": "3e-05", "gnorm": "137.523", "loss_scale": "16", "train_wall": "63", "gb_free": "32.1", "wall": "7677"}
[2024-07-09 23:24:48,113][train_inner][INFO] - {"epoch": 14, "update": 13.249, "loss": "109.509", "ntokens": "14494.8", "nsentences": "82.76", "nll_loss": "0.625", "wps": "46089.5", "ups": "3.18", "wpb": "14494.8", "bsz": "82.8", "num_updates": "23200", "lr": "3e-05", "gnorm": "133.954", "loss_scale": "16", "train_wall": "62", "gb_free": "33.3", "wall": "7740"}
[2024-07-09 23:25:00,789][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-09 23:25:52,403][train_inner][INFO] - {"epoch": 14, "update": 13.364, "loss": "108.65", "ntokens": "14587.8", "nsentences": "85.44", "nll_loss": "0.636", "wps": "45429.5", "ups": "3.11", "wpb": "14587.8", "bsz": "85.4", "num_updates": "23400", "lr": "3e-05", "gnorm": "132.604", "loss_scale": "8", "train_wall": "64", "gb_free": "31.6", "wall": "7804"}
[2024-07-09 23:26:56,322][train_inner][INFO] - {"epoch": 14, "update": 13.478, "loss": "110.244", "ntokens": "14612.2", "nsentences": "84.52", "nll_loss": "0.638", "wps": "45724.3", "ups": "3.13", "wpb": "14612.2", "bsz": "84.5", "num_updates": "23600", "lr": "3e-05", "gnorm": "133.151", "loss_scale": "8", "train_wall": "63", "gb_free": "32.4", "wall": "7868"}
[2024-07-09 23:28:00,233][train_inner][INFO] - {"epoch": 14, "update": 13.592, "loss": "110.246", "ntokens": "14546.5", "nsentences": "83.28", "nll_loss": "0.631", "wps": "45570.4", "ups": "3.13", "wpb": "14546.5", "bsz": "83.3", "num_updates": "23800", "lr": "3e-05", "gnorm": "133.861", "loss_scale": "8", "train_wall": "63", "gb_free": "32", "wall": "7932"}
[2024-07-09 23:29:04,223][train_inner][INFO] - {"epoch": 14, "update": 13.706, "loss": "104.533", "ntokens": "14700.8", "nsentences": "87.755", "nll_loss": "0.624", "wps": "45951.1", "ups": "3.13", "wpb": "14700.8", "bsz": "87.8", "num_updates": "24000", "lr": "3e-05", "gnorm": "128.872", "loss_scale": "8", "train_wall": "64", "gb_free": "31.7", "wall": "7996"}
[2024-07-09 23:30:08,475][train_inner][INFO] - {"epoch": 14, "update": 13.82, "loss": "107.933", "ntokens": "14599.8", "nsentences": "86.08", "nll_loss": "0.636", "wps": "45448.8", "ups": "3.11", "wpb": "14599.8", "bsz": "86.1", "num_updates": "24200", "lr": "3e-05", "gnorm": "130.535", "loss_scale": "8", "train_wall": "64", "gb_free": "32", "wall": "8060"}
[2024-07-09 23:31:12,913][train_inner][INFO] - {"epoch": 14, "update": 13.934, "loss": "108.453", "ntokens": "14663.2", "nsentences": "85.44", "nll_loss": "0.632", "wps": "45560", "ups": "3.11", "wpb": "14663.2", "bsz": "85.4", "num_updates": "24400", "lr": "3e-05", "gnorm": "134.775", "loss_scale": "8", "train_wall": "64", "gb_free": "31.8", "wall": "8125"}
[2024-07-09 23:31:49,769][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 23:31:49,770][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 23:32:00,530][dev-other][INFO] - {"epoch": 14, "dev-other_loss": "25.006", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.266", "dev-other_uer": "4.423", "dev-other_wer": "12.303", "dev-other_raw_wer": "12.303", "dev-other_wps": "27901.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "24515", "dev-other_best_wer": "12.303"}
[2024-07-09 23:32:00,530][fairseq_cli.train][INFO] - end of epoch 14 (average epoch stats below)
[2024-07-09 23:32:00,534][train][INFO] - {"epoch": 14, "train_loss": "108.777", "train_ntokens": "14575.8", "train_nsentences": "84.8515", "train_nll_loss": "0.633", "train_wps": "44670", "train_ups": "3.06", "train_wpb": "14575.8", "train_bsz": "84.9", "train_num_updates": "24515", "train_lr": "3e-05", "train_gnorm": "133.079", "train_loss_scale": "8", "train_train_wall": "555", "train_gb_free": "33.3", "train_wall": "8173"}
[2024-07-09 23:32:00,536][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 23:32:01,223][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 23:32:01,228][fairseq.trainer][INFO] - begin training epoch 15
[2024-07-09 23:32:01,228][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 23:32:29,105][train_inner][INFO] - {"epoch": 15, "update": 14.049, "loss": "105.466", "ntokens": "14591.2", "nsentences": "85.8", "nll_loss": "0.62", "wps": "38304.4", "ups": "2.63", "wpb": "14591.2", "bsz": "85.8", "num_updates": "24600", "lr": "3e-05", "gnorm": "132.008", "loss_scale": "8", "train_wall": "64", "gb_free": "32.9", "wall": "8201"}
[2024-07-09 23:33:33,408][train_inner][INFO] - {"epoch": 15, "update": 14.163, "loss": "105.091", "ntokens": "14565.4", "nsentences": "86.96", "nll_loss": "0.627", "wps": "45305.5", "ups": "3.11", "wpb": "14565.4", "bsz": "87", "num_updates": "24800", "lr": "3e-05", "gnorm": "129.403", "loss_scale": "8", "train_wall": "64", "gb_free": "31.4", "wall": "8265"}
[2024-07-09 23:34:38,020][train_inner][INFO] - {"epoch": 15, "update": 14.277, "loss": "108.666", "ntokens": "14591.9", "nsentences": "85.04", "nll_loss": "0.633", "wps": "45172", "ups": "3.1", "wpb": "14591.9", "bsz": "85", "num_updates": "25000", "lr": "3e-05", "gnorm": "132.417", "loss_scale": "8", "train_wall": "64", "gb_free": "31.9", "wall": "8330"}
[2024-07-09 23:35:41,769][train_inner][INFO] - {"epoch": 15, "update": 14.391, "loss": "112.065", "ntokens": "14582.8", "nsentences": "82.92", "nll_loss": "0.637", "wps": "45754.5", "ups": "3.14", "wpb": "14582.8", "bsz": "82.9", "num_updates": "25200", "lr": "3e-05", "gnorm": "135.957", "loss_scale": "8", "train_wall": "63", "gb_free": "32.4", "wall": "8394"}
[2024-07-09 23:36:46,143][train_inner][INFO] - {"epoch": 15, "update": 14.505, "loss": "107.712", "ntokens": "14523.9", "nsentences": "83.12", "nll_loss": "0.616", "wps": "45127.4", "ups": "3.11", "wpb": "14523.9", "bsz": "83.1", "num_updates": "25400", "lr": "3e-05", "gnorm": "132.91", "loss_scale": "16", "train_wall": "64", "gb_free": "32.7", "wall": "8458"}
[2024-07-09 23:37:41,048][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-09 23:37:50,585][train_inner][INFO] - {"epoch": 15, "update": 14.62, "loss": "105.265", "ntokens": "14729.4", "nsentences": "87.955", "nll_loss": "0.629", "wps": "45716.8", "ups": "3.1", "wpb": "14729.4", "bsz": "88", "num_updates": "25600", "lr": "3e-05", "gnorm": "129.692", "loss_scale": "8", "train_wall": "64", "gb_free": "33.3", "wall": "8523"}
[2024-07-09 23:38:54,318][train_inner][INFO] - {"epoch": 15, "update": 14.734, "loss": "108.817", "ntokens": "14565", "nsentences": "86", "nll_loss": "0.643", "wps": "45708.1", "ups": "3.14", "wpb": "14565", "bsz": "86", "num_updates": "25800", "lr": "3e-05", "gnorm": "134.452", "loss_scale": "8", "train_wall": "63", "gb_free": "31.3", "wall": "8586"}
[2024-07-09 23:39:58,505][train_inner][INFO] - {"epoch": 15, "update": 14.848, "loss": "109.734", "ntokens": "14473.6", "nsentences": "81.96", "nll_loss": "0.621", "wps": "45102.7", "ups": "3.12", "wpb": "14473.6", "bsz": "82", "num_updates": "26000", "lr": "3e-05", "gnorm": "137.568", "loss_scale": "8", "train_wall": "64", "gb_free": "31.7", "wall": "8650"}
[2024-07-09 23:41:02,273][train_inner][INFO] - {"epoch": 15, "update": 14.962, "loss": "108.479", "ntokens": "14559.2", "nsentences": "84.68", "nll_loss": "0.631", "wps": "45710.6", "ups": "3.14", "wpb": "14559.2", "bsz": "84.7", "num_updates": "26200", "lr": "3e-05", "gnorm": "134.191", "loss_scale": "8", "train_wall": "63", "gb_free": "32.1", "wall": "8714"}
[2024-07-09 23:41:23,333][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 23:41:23,335][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 23:41:34,041][dev-other][INFO] - {"epoch": 15, "dev-other_loss": "24.911", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.265", "dev-other_uer": "4.407", "dev-other_wer": "12.185", "dev-other_raw_wer": "12.185", "dev-other_wps": "27777.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "26266", "dev-other_best_wer": "12.185"}
[2024-07-09 23:41:34,042][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 15 @ 26266 updates
[2024-07-09 23:41:34,043][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-09 23:41:35,332][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-09 23:41:35,930][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 15 @ 26266 updates, score 12.185) (writing took 1.8882861398160458 seconds)
[2024-07-09 23:41:35,931][fairseq_cli.train][INFO] - end of epoch 15 (average epoch stats below)
[2024-07-09 23:41:35,968][train][INFO] - {"epoch": 15, "train_loss": "107.974", "train_ntokens": "14577.4", "train_nsentences": "84.8607", "train_nll_loss": "0.629", "train_wps": "44360.7", "train_ups": "3.04", "train_wpb": "14577.4", "train_bsz": "84.9", "train_num_updates": "26266", "train_lr": "3e-05", "train_gnorm": "133.23", "train_loss_scale": "8", "train_train_wall": "558", "train_gb_free": "33.3", "train_wall": "8748"}
[2024-07-09 23:41:35,969][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 23:41:36,225][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 23:41:36,228][fairseq.trainer][INFO] - begin training epoch 16
[2024-07-09 23:41:36,228][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 23:42:19,603][train_inner][INFO] - {"epoch": 16, "update": 15.076, "loss": "105.488", "ntokens": "14591", "nsentences": "85", "nll_loss": "0.615", "wps": "37740.4", "ups": "2.59", "wpb": "14591", "bsz": "85", "num_updates": "26400", "lr": "3e-05", "gnorm": "131.463", "loss_scale": "8", "train_wall": "64", "gb_free": "33.4", "wall": "8792"}
[2024-07-09 23:43:23,232][train_inner][INFO] - {"epoch": 16, "update": 15.191, "loss": "107.446", "ntokens": "14573.1", "nsentences": "84.72", "nll_loss": "0.625", "wps": "45826", "ups": "3.14", "wpb": "14573.1", "bsz": "84.7", "num_updates": "26600", "lr": "3e-05", "gnorm": "132.805", "loss_scale": "8", "train_wall": "63", "gb_free": "32.6", "wall": "8855"}
[2024-07-09 23:44:26,896][train_inner][INFO] - {"epoch": 16, "update": 15.305, "loss": "106.619", "ntokens": "14512.4", "nsentences": "84.155", "nll_loss": "0.618", "wps": "45643.2", "ups": "3.15", "wpb": "14512.4", "bsz": "84.2", "num_updates": "26800", "lr": "3e-05", "gnorm": "132.396", "loss_scale": "8", "train_wall": "63", "gb_free": "31.8", "wall": "8919"}
[2024-07-09 23:45:31,318][train_inner][INFO] - {"epoch": 16, "update": 15.419, "loss": "104.735", "ntokens": "14619.3", "nsentences": "86", "nll_loss": "0.616", "wps": "45436.3", "ups": "3.11", "wpb": "14619.3", "bsz": "86", "num_updates": "27000", "lr": "3e-05", "gnorm": "129.88", "loss_scale": "8", "train_wall": "64", "gb_free": "32.4", "wall": "8983"}
[2024-07-09 23:46:35,664][train_inner][INFO] - {"epoch": 16, "update": 15.533, "loss": "108.212", "ntokens": "14610.6", "nsentences": "84.2", "nll_loss": "0.624", "wps": "45415.6", "ups": "3.11", "wpb": "14610.6", "bsz": "84.2", "num_updates": "27200", "lr": "3e-05", "gnorm": "133.012", "loss_scale": "8", "train_wall": "64", "gb_free": "32.5", "wall": "9048"}
[2024-07-09 23:47:39,610][train_inner][INFO] - {"epoch": 16, "update": 15.647, "loss": "107.145", "ntokens": "14634.3", "nsentences": "86.8", "nll_loss": "0.636", "wps": "45773.2", "ups": "3.13", "wpb": "14634.3", "bsz": "86.8", "num_updates": "27400", "lr": "3e-05", "gnorm": "135.828", "loss_scale": "8", "train_wall": "63", "gb_free": "32.3", "wall": "9112"}
[2024-07-09 23:48:42,796][train_inner][INFO] - {"epoch": 16, "update": 15.761, "loss": "110.648", "ntokens": "14562.9", "nsentences": "83.32", "nll_loss": "0.633", "wps": "46099.7", "ups": "3.17", "wpb": "14562.9", "bsz": "83.3", "num_updates": "27600", "lr": "3e-05", "gnorm": "134.293", "loss_scale": "8", "train_wall": "63", "gb_free": "30.7", "wall": "9175"}
[2024-07-09 23:49:46,190][train_inner][INFO] - {"epoch": 16, "update": 15.876, "loss": "106.465", "ntokens": "14575.8", "nsentences": "85", "nll_loss": "0.621", "wps": "45988.5", "ups": "3.16", "wpb": "14575.8", "bsz": "85", "num_updates": "27800", "lr": "3e-05", "gnorm": "132.835", "loss_scale": "16", "train_wall": "63", "gb_free": "31.2", "wall": "9238"}
[2024-07-09 23:50:49,939][train_inner][INFO] - {"epoch": 16, "update": 15.99, "loss": "105.203", "ntokens": "14532.8", "nsentences": "84.84", "nll_loss": "0.614", "wps": "45598", "ups": "3.14", "wpb": "14532.8", "bsz": "84.8", "num_updates": "28000", "lr": "3e-05", "gnorm": "132.985", "loss_scale": "16", "train_wall": "63", "gb_free": "31.3", "wall": "9302"}
[2024-07-09 23:50:55,694][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-09 23:50:55,695][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 23:51:06,410][dev-other][INFO] - {"epoch": 16, "dev-other_loss": "24.542", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.261", "dev-other_uer": "4.331", "dev-other_wer": "11.973", "dev-other_raw_wer": "11.973", "dev-other_wps": "27663.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "28018", "dev-other_best_wer": "11.973"}
[2024-07-09 23:51:06,411][fairseq_cli.train][INFO] - end of epoch 16 (average epoch stats below)
[2024-07-09 23:51:06,413][train][INFO] - {"epoch": 16, "train_loss": "106.766", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.622", "train_wps": "44771.9", "train_ups": "3.07", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "28018", "train_lr": "3e-05", "train_gnorm": "132.794", "train_loss_scale": "16", "train_train_wall": "555", "train_gb_free": "33.6", "train_wall": "9318"}
[2024-07-09 23:51:06,414][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-09 23:51:07,147][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-09 23:51:07,151][fairseq.trainer][INFO] - begin training epoch 17
[2024-07-09 23:51:07,151][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-09 23:51:40,599][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-09 23:52:06,377][train_inner][INFO] - {"epoch": 17, "update": 16.104, "loss": "103.554", "ntokens": "14633.8", "nsentences": "85.96", "nll_loss": "0.608", "wps": "38291.5", "ups": "2.62", "wpb": "14633.8", "bsz": "86", "num_updates": "28200", "lr": "3e-05", "gnorm": "132.911", "loss_scale": "8", "train_wall": "64", "gb_free": "32.8", "wall": "9378"}
[2024-07-09 23:53:10,558][train_inner][INFO] - {"epoch": 17, "update": 16.219, "loss": "102.878", "ntokens": "14645.4", "nsentences": "86.6", "nll_loss": "0.608", "wps": "45641", "ups": "3.12", "wpb": "14645.4", "bsz": "86.6", "num_updates": "28400", "lr": "3e-05", "gnorm": "130.689", "loss_scale": "8", "train_wall": "64", "gb_free": "31.4", "wall": "9443"}
[2024-07-09 23:54:14,405][train_inner][INFO] - {"epoch": 17, "update": 16.333, "loss": "108.739", "ntokens": "14583.3", "nsentences": "85.64", "nll_loss": "0.639", "wps": "45730.7", "ups": "3.14", "wpb": "14583.3", "bsz": "85.6", "num_updates": "28600", "lr": "3e-05", "gnorm": "131.566", "loss_scale": "8", "train_wall": "63", "gb_free": "33.4", "wall": "9506"}
[2024-07-09 23:55:18,343][train_inner][INFO] - {"epoch": 17, "update": 16.447, "loss": "105.859", "ntokens": "14532.2", "nsentences": "83.56", "nll_loss": "0.609", "wps": "45460", "ups": "3.13", "wpb": "14532.2", "bsz": "83.6", "num_updates": "28800", "lr": "3e-05", "gnorm": "135.23", "loss_scale": "8", "train_wall": "63", "gb_free": "31.4", "wall": "9570"}
[2024-07-09 23:56:22,107][train_inner][INFO] - {"epoch": 17, "update": 16.561, "loss": "108.975", "ntokens": "14418.4", "nsentences": "82.32", "nll_loss": "0.622", "wps": "45228.9", "ups": "3.14", "wpb": "14418.4", "bsz": "82.3", "num_updates": "29000", "lr": "3e-05", "gnorm": "137.19", "loss_scale": "8", "train_wall": "63", "gb_free": "31.8", "wall": "9634"}
[2024-07-09 23:57:25,860][train_inner][INFO] - {"epoch": 17, "update": 16.675, "loss": "106.376", "ntokens": "14566", "nsentences": "84", "nll_loss": "0.613", "wps": "45697.8", "ups": "3.14", "wpb": "14566", "bsz": "84", "num_updates": "29200", "lr": "3e-05", "gnorm": "131.809", "loss_scale": "8", "train_wall": "63", "gb_free": "33.2", "wall": "9698"}
[2024-07-09 23:58:30,641][train_inner][INFO] - {"epoch": 17, "update": 16.789, "loss": "102.841", "ntokens": "14576.1", "nsentences": "87.48", "nll_loss": "0.617", "wps": "45004.8", "ups": "3.09", "wpb": "14576.1", "bsz": "87.5", "num_updates": "29400", "lr": "3e-05", "gnorm": "132.619", "loss_scale": "8", "train_wall": "64", "gb_free": "32.3", "wall": "9763"}
[2024-07-09 23:59:35,034][train_inner][INFO] - {"epoch": 17, "update": 16.904, "loss": "108.291", "ntokens": "14678.9", "nsentences": "85.08", "nll_loss": "0.628", "wps": "45639.1", "ups": "3.11", "wpb": "14678.9", "bsz": "85.1", "num_updates": "29600", "lr": "3e-05", "gnorm": "131.621", "loss_scale": "8", "train_wall": "64", "gb_free": "32.6", "wall": "9827"}
[2024-07-10 00:00:29,123][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 00:00:29,125][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 00:00:39,832][dev-other][INFO] - {"epoch": 17, "dev-other_loss": "24.541", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.261", "dev-other_uer": "4.281", "dev-other_wer": "11.761", "dev-other_raw_wer": "11.761", "dev-other_wps": "27652.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "29769", "dev-other_best_wer": "11.761"}
[2024-07-10 00:00:39,833][fairseq_cli.train][INFO] - end of epoch 17 (average epoch stats below)
[2024-07-10 00:00:39,835][train][INFO] - {"epoch": 17, "train_loss": "106.062", "train_ntokens": "14576.4", "train_nsentences": "84.8241", "train_nll_loss": "0.617", "train_wps": "44510.7", "train_ups": "3.05", "train_wpb": "14576.4", "train_bsz": "84.8", "train_num_updates": "29769", "train_lr": "3e-05", "train_gnorm": "133.04", "train_loss_scale": "8", "train_train_wall": "558", "train_gb_free": "32.9", "train_wall": "9892"}
[2024-07-10 00:00:39,836][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 00:00:40,545][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 00:00:40,549][fairseq.trainer][INFO] - begin training epoch 18
[2024-07-10 00:00:40,549][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 00:00:50,661][train_inner][INFO] - {"epoch": 18, "update": 17.018, "loss": "106.575", "ntokens": "14460.4", "nsentences": "82.595", "nll_loss": "0.609", "wps": "38244.3", "ups": "2.64", "wpb": "14460.4", "bsz": "82.6", "num_updates": "29800", "lr": "3e-05", "gnorm": "132.986", "loss_scale": "8", "train_wall": "64", "gb_free": "33.1", "wall": "9903"}
[2024-07-10 00:01:54,903][train_inner][INFO] - {"epoch": 18, "update": 17.132, "loss": "106.039", "ntokens": "14619.3", "nsentences": "85.595", "nll_loss": "0.621", "wps": "45516.7", "ups": "3.11", "wpb": "14619.3", "bsz": "85.6", "num_updates": "30000", "lr": "3e-05", "gnorm": "131.915", "loss_scale": "8", "train_wall": "64", "gb_free": "32.8", "wall": "9967"}
[2024-07-10 00:02:58,682][train_inner][INFO] - {"epoch": 18, "update": 17.246, "loss": "103.226", "ntokens": "14593.7", "nsentences": "85.24", "nll_loss": "0.603", "wps": "45769.5", "ups": "3.14", "wpb": "14593.7", "bsz": "85.2", "num_updates": "30200", "lr": "3e-05", "gnorm": "130.653", "loss_scale": "16", "train_wall": "63", "gb_free": "32.3", "wall": "10031"}
[2024-07-10 00:04:03,120][train_inner][INFO] - {"epoch": 18, "update": 17.36, "loss": "103.77", "ntokens": "14595.7", "nsentences": "84.88", "nll_loss": "0.603", "wps": "45315.9", "ups": "3.1", "wpb": "14595.7", "bsz": "84.9", "num_updates": "30400", "lr": "3e-05", "gnorm": "131.908", "loss_scale": "16", "train_wall": "64", "gb_free": "31.3", "wall": "10095"}
[2024-07-10 00:05:07,097][train_inner][INFO] - {"epoch": 18, "update": 17.474, "loss": "106.226", "ntokens": "14647.9", "nsentences": "86.24", "nll_loss": "0.625", "wps": "45795", "ups": "3.13", "wpb": "14647.9", "bsz": "86.2", "num_updates": "30600", "lr": "3e-05", "gnorm": "132.342", "loss_scale": "16", "train_wall": "64", "gb_free": "33.7", "wall": "10159"}
[2024-07-10 00:06:10,670][train_inner][INFO] - {"epoch": 18, "update": 17.588, "loss": "106.971", "ntokens": "14435.3", "nsentences": "81.08", "nll_loss": "0.601", "wps": "45415.8", "ups": "3.15", "wpb": "14435.3", "bsz": "81.1", "num_updates": "30800", "lr": "3e-05", "gnorm": "135.204", "loss_scale": "16", "train_wall": "63", "gb_free": "32.6", "wall": "10223"}
[2024-07-10 00:07:14,342][train_inner][INFO] - {"epoch": 18, "update": 17.703, "loss": "104.743", "ntokens": "14595.9", "nsentences": "85.76", "nll_loss": "0.615", "wps": "45852.2", "ups": "3.14", "wpb": "14595.9", "bsz": "85.8", "num_updates": "31000", "lr": "3e-05", "gnorm": "131.406", "loss_scale": "16", "train_wall": "63", "gb_free": "31.9", "wall": "10286"}
[2024-07-10 00:08:18,213][train_inner][INFO] - {"epoch": 18, "update": 17.817, "loss": "105.817", "ntokens": "14666.4", "nsentences": "84.96", "nll_loss": "0.613", "wps": "45927.5", "ups": "3.13", "wpb": "14666.4", "bsz": "85", "num_updates": "31200", "lr": "3e-05", "gnorm": "132.753", "loss_scale": "16", "train_wall": "63", "gb_free": "31.5", "wall": "10350"}
[2024-07-10 00:09:22,359][train_inner][INFO] - {"epoch": 18, "update": 17.931, "loss": "102.047", "ntokens": "14542.4", "nsentences": "85.44", "nll_loss": "0.6", "wps": "45358.5", "ups": "3.12", "wpb": "14542.4", "bsz": "85.4", "num_updates": "31400", "lr": "3e-05", "gnorm": "129.439", "loss_scale": "16", "train_wall": "64", "gb_free": "31.9", "wall": "10414"}
[2024-07-10 00:10:01,212][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 00:10:01,213][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 00:10:12,110][dev-other][INFO] - {"epoch": 18, "dev-other_loss": "24.814", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.264", "dev-other_uer": "4.281", "dev-other_wer": "11.736", "dev-other_raw_wer": "11.736", "dev-other_wps": "27737.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "31521", "dev-other_best_wer": "11.736"}
[2024-07-10 00:10:12,110][fairseq_cli.train][INFO] - end of epoch 18 (average epoch stats below)
[2024-07-10 00:10:12,113][train][INFO] - {"epoch": 18, "train_loss": "104.509", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.608", "train_wps": "44628.5", "train_ups": "3.06", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "31521", "train_lr": "3e-05", "train_gnorm": "131.718", "train_loss_scale": "16", "train_train_wall": "557", "train_gb_free": "31.7", "train_wall": "10464"}
[2024-07-10 00:10:12,114][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 00:10:12,849][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 00:10:12,866][fairseq.trainer][INFO] - begin training epoch 19
[2024-07-10 00:10:12,866][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 00:10:38,351][train_inner][INFO] - {"epoch": 19, "update": 18.045, "loss": "103.004", "ntokens": "14606.5", "nsentences": "85.36", "nll_loss": "0.602", "wps": "38444.2", "ups": "2.63", "wpb": "14606.6", "bsz": "85.4", "num_updates": "31600", "lr": "3e-05", "gnorm": "130.01", "loss_scale": "16", "train_wall": "64", "gb_free": "33.3", "wall": "10490"}
[2024-07-10 00:11:42,459][train_inner][INFO] - {"epoch": 19, "update": 18.159, "loss": "105.744", "ntokens": "14560.4", "nsentences": "84.36", "nll_loss": "0.613", "wps": "45471.7", "ups": "3.12", "wpb": "14560.4", "bsz": "84.4", "num_updates": "31800", "lr": "3e-05", "gnorm": "132.796", "loss_scale": "16", "train_wall": "64", "gb_free": "33.3", "wall": "10554"}
[2024-07-10 00:12:45,686][train_inner][INFO] - {"epoch": 19, "update": 18.273, "loss": "107.18", "ntokens": "14478.4", "nsentences": "83.115", "nll_loss": "0.615", "wps": "45804", "ups": "3.16", "wpb": "14478.4", "bsz": "83.1", "num_updates": "32000", "lr": "3e-05", "gnorm": "133.336", "loss_scale": "16", "train_wall": "63", "gb_free": "33", "wall": "10618"}
[2024-07-10 00:13:50,086][train_inner][INFO] - {"epoch": 19, "update": 18.388, "loss": "102.382", "ntokens": "14688.4", "nsentences": "88.28", "nll_loss": "0.615", "wps": "45619.2", "ups": "3.11", "wpb": "14688.4", "bsz": "88.3", "num_updates": "32200", "lr": "3e-05", "gnorm": "130.349", "loss_scale": "16", "train_wall": "64", "gb_free": "33.6", "wall": "10682"}
[2024-07-10 00:14:22,924][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-10 00:14:54,829][train_inner][INFO] - {"epoch": 19, "update": 18.502, "loss": "99.05", "ntokens": "14614.3", "nsentences": "86.4", "nll_loss": "0.586", "wps": "45191", "ups": "3.09", "wpb": "14614.3", "bsz": "86.4", "num_updates": "32400", "lr": "3e-05", "gnorm": "130.205", "loss_scale": "16", "train_wall": "64", "gb_free": "32.4", "wall": "10747"}
[2024-07-10 00:15:07,049][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 00:15:59,529][train_inner][INFO] - {"epoch": 19, "update": 18.617, "loss": "102.165", "ntokens": "14562.4", "nsentences": "84.48", "nll_loss": "0.593", "wps": "45061.5", "ups": "3.09", "wpb": "14562.4", "bsz": "84.5", "num_updates": "32600", "lr": "3e-05", "gnorm": "131.985", "loss_scale": "8", "train_wall": "64", "gb_free": "31.3", "wall": "10811"}
[2024-07-10 00:17:03,713][train_inner][INFO] - {"epoch": 19, "update": 18.731, "loss": "104.182", "ntokens": "14614.2", "nsentences": "84.8", "nll_loss": "0.605", "wps": "45584.6", "ups": "3.12", "wpb": "14614.2", "bsz": "84.8", "num_updates": "32800", "lr": "3e-05", "gnorm": "133.175", "loss_scale": "8", "train_wall": "64", "gb_free": "32.6", "wall": "10876"}
[2024-07-10 00:18:07,816][train_inner][INFO] - {"epoch": 19, "update": 18.845, "loss": "108.783", "ntokens": "14526", "nsentences": "83.16", "nll_loss": "0.623", "wps": "45324.8", "ups": "3.12", "wpb": "14526", "bsz": "83.2", "num_updates": "33000", "lr": "3e-05", "gnorm": "133.46", "loss_scale": "8", "train_wall": "64", "gb_free": "32.4", "wall": "10940"}
[2024-07-10 00:19:11,760][train_inner][INFO] - {"epoch": 19, "update": 18.959, "loss": "103.227", "ntokens": "14588.6", "nsentences": "83.76", "nll_loss": "0.593", "wps": "45634.2", "ups": "3.13", "wpb": "14588.6", "bsz": "83.8", "num_updates": "33200", "lr": "3e-05", "gnorm": "132.94", "loss_scale": "8", "train_wall": "63", "gb_free": "32.5", "wall": "11004"}
[2024-07-10 00:19:34,096][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 00:19:34,097][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 00:19:44,963][dev-other][INFO] - {"epoch": 19, "dev-other_loss": "24.125", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.256", "dev-other_uer": "4.162", "dev-other_wer": "11.502", "dev-other_raw_wer": "11.502", "dev-other_wps": "27664.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "33271", "dev-other_best_wer": "11.502"}
[2024-07-10 00:19:44,963][fairseq_cli.train][INFO] - end of epoch 19 (average epoch stats below)
[2024-07-10 00:19:44,967][train][INFO] - {"epoch": 19, "train_loss": "104.564", "train_ntokens": "14577.9", "train_nsentences": "84.8131", "train_nll_loss": "0.608", "train_wps": "44533.9", "train_ups": "3.05", "train_wpb": "14577.9", "train_bsz": "84.8", "train_num_updates": "33271", "train_lr": "3e-05", "train_gnorm": "132.529", "train_loss_scale": "8", "train_train_wall": "557", "train_gb_free": "32.1", "train_wall": "11037"}
[2024-07-10 00:19:44,969][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 00:19:45,640][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 00:19:45,644][fairseq.trainer][INFO] - begin training epoch 20
[2024-07-10 00:19:45,644][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 00:20:27,970][train_inner][INFO] - {"epoch": 20, "update": 19.074, "loss": "102.38", "ntokens": "14588.2", "nsentences": "87", "nll_loss": "0.611", "wps": "38285.7", "ups": "2.62", "wpb": "14588.2", "bsz": "87", "num_updates": "33400", "lr": "3e-05", "gnorm": "131.257", "loss_scale": "8", "train_wall": "64", "gb_free": "32.5", "wall": "11080"}
[2024-07-10 00:21:32,598][train_inner][INFO] - {"epoch": 20, "update": 19.188, "loss": "102.64", "ntokens": "14596.8", "nsentences": "85.04", "nll_loss": "0.598", "wps": "45175.1", "ups": "3.09", "wpb": "14596.8", "bsz": "85", "num_updates": "33600", "lr": "3e-05", "gnorm": "130.278", "loss_scale": "8", "train_wall": "64", "gb_free": "31.9", "wall": "11145"}
[2024-07-10 00:22:37,092][train_inner][INFO] - {"epoch": 20, "update": 19.302, "loss": "98.579", "ntokens": "14628.5", "nsentences": "87.72", "nll_loss": "0.591", "wps": "45396.1", "ups": "3.1", "wpb": "14628.5", "bsz": "87.7", "num_updates": "33800", "lr": "3e-05", "gnorm": "128.51", "loss_scale": "8", "train_wall": "64", "gb_free": "32.7", "wall": "11209"}
[2024-07-10 00:23:40,617][train_inner][INFO] - {"epoch": 20, "update": 19.416, "loss": "103.117", "ntokens": "14554.5", "nsentences": "84.2", "nll_loss": "0.597", "wps": "45866.7", "ups": "3.15", "wpb": "14554.5", "bsz": "84.2", "num_updates": "34000", "lr": "3e-05", "gnorm": "131.83", "loss_scale": "8", "train_wall": "63", "gb_free": "32.5", "wall": "11273"}
[2024-07-10 00:24:43,601][train_inner][INFO] - {"epoch": 20, "update": 19.53, "loss": "107.208", "ntokens": "14548.7", "nsentences": "83.44", "nll_loss": "0.615", "wps": "46201.9", "ups": "3.18", "wpb": "14548.7", "bsz": "83.4", "num_updates": "34200", "lr": "3e-05", "gnorm": "133.239", "loss_scale": "8", "train_wall": "63", "gb_free": "32.7", "wall": "11336"}
[2024-07-10 00:25:47,753][train_inner][INFO] - {"epoch": 20, "update": 19.644, "loss": "102.635", "ntokens": "14542.8", "nsentences": "83.755", "nll_loss": "0.591", "wps": "45382.2", "ups": "3.12", "wpb": "14542.8", "bsz": "83.8", "num_updates": "34400", "lr": "3e-05", "gnorm": "131.502", "loss_scale": "8", "train_wall": "64", "gb_free": "31.9", "wall": "11400"}
[2024-07-10 00:26:37,354][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 00:26:52,107][train_inner][INFO] - {"epoch": 20, "update": 19.759, "loss": "105.167", "ntokens": "14617.3", "nsentences": "84.4", "nll_loss": "0.607", "wps": "45434", "ups": "3.11", "wpb": "14617.3", "bsz": "84.4", "num_updates": "34600", "lr": "3e-05", "gnorm": "133.14", "loss_scale": "8", "train_wall": "64", "gb_free": "32.6", "wall": "11464"}
[2024-07-10 00:27:55,983][train_inner][INFO] - {"epoch": 20, "update": 19.873, "loss": "102.943", "ntokens": "14573.3", "nsentences": "84.68", "nll_loss": "0.598", "wps": "45648", "ups": "3.13", "wpb": "14573.3", "bsz": "84.7", "num_updates": "34800", "lr": "3e-05", "gnorm": "132.414", "loss_scale": "8", "train_wall": "63", "gb_free": "32.7", "wall": "11528"}
[2024-07-10 00:28:59,683][train_inner][INFO] - {"epoch": 20, "update": 19.987, "loss": "108.887", "ntokens": "14530.2", "nsentences": "83.28", "nll_loss": "0.624", "wps": "45623", "ups": "3.14", "wpb": "14530.2", "bsz": "83.3", "num_updates": "35000", "lr": "3e-05", "gnorm": "139.81", "loss_scale": "8", "train_wall": "63", "gb_free": "32.9", "wall": "11592"}
[2024-07-10 00:29:06,644][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 00:29:06,645][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 00:29:17,360][dev-other][INFO] - {"epoch": 20, "dev-other_loss": "24.74", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.263", "dev-other_uer": "4.211", "dev-other_wer": "11.533", "dev-other_raw_wer": "11.533", "dev-other_wps": "27676.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "35022", "dev-other_best_wer": "11.533"}
[2024-07-10 00:29:17,362][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 20 @ 35022 updates
[2024-07-10 00:29:17,363][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-10 00:29:18,540][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-10 00:29:19,137][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 20 @ 35022 updates, score 11.533) (writing took 1.7752675004303455 seconds)
[2024-07-10 00:29:19,137][fairseq_cli.train][INFO] - end of epoch 20 (average epoch stats below)
[2024-07-10 00:29:19,141][train][INFO] - {"epoch": 20, "train_loss": "103.261", "train_ntokens": "14577.1", "train_nsentences": "84.8744", "train_nll_loss": "0.601", "train_wps": "44454.5", "train_ups": "3.05", "train_wpb": "14577.1", "train_bsz": "84.9", "train_num_updates": "35022", "train_lr": "3e-05", "train_gnorm": "132.152", "train_loss_scale": "8", "train_train_wall": "557", "train_gb_free": "32.3", "train_wall": "11611"}
[2024-07-10 00:29:19,142][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 00:29:19,411][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 00:29:19,415][fairseq.trainer][INFO] - begin training epoch 21
[2024-07-10 00:29:19,415][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 00:30:16,801][train_inner][INFO] - {"epoch": 21, "update": 20.102, "loss": "101.693", "ntokens": "14491.3", "nsentences": "84.92", "nll_loss": "0.596", "wps": "37614", "ups": "2.6", "wpb": "14491.3", "bsz": "84.9", "num_updates": "35200", "lr": "3e-05", "gnorm": "131.271", "loss_scale": "8", "train_wall": "64", "gb_free": "33.1", "wall": "11669"}
[2024-07-10 00:31:20,567][train_inner][INFO] - {"epoch": 21, "update": 20.216, "loss": "104.657", "ntokens": "14461.9", "nsentences": "81.92", "nll_loss": "0.593", "wps": "45362.6", "ups": "3.14", "wpb": "14461.9", "bsz": "81.9", "num_updates": "35400", "lr": "3e-05", "gnorm": "134.346", "loss_scale": "8", "train_wall": "63", "gb_free": "32.2", "wall": "11733"}
[2024-07-10 00:32:24,689][train_inner][INFO] - {"epoch": 21, "update": 20.33, "loss": "102.492", "ntokens": "14569", "nsentences": "84.6", "nll_loss": "0.595", "wps": "45444.6", "ups": "3.12", "wpb": "14569", "bsz": "84.6", "num_updates": "35600", "lr": "3e-05", "gnorm": "131.916", "loss_scale": "8", "train_wall": "64", "gb_free": "32.8", "wall": "11797"}
[2024-07-10 00:33:29,027][train_inner][INFO] - {"epoch": 21, "update": 20.444, "loss": "98.4", "ntokens": "14654.4", "nsentences": "87.16", "nll_loss": "0.585", "wps": "45559.3", "ups": "3.11", "wpb": "14654.4", "bsz": "87.2", "num_updates": "35800", "lr": "3e-05", "gnorm": "129.998", "loss_scale": "8", "train_wall": "64", "gb_free": "30", "wall": "11861"}
[2024-07-10 00:34:32,927][train_inner][INFO] - {"epoch": 21, "update": 20.558, "loss": "104.105", "ntokens": "14532", "nsentences": "83.675", "nll_loss": "0.599", "wps": "45532.9", "ups": "3.13", "wpb": "14532", "bsz": "83.7", "num_updates": "36000", "lr": "3e-05", "gnorm": "132.128", "loss_scale": "8", "train_wall": "63", "gb_free": "31.3", "wall": "11925"}
[2024-07-10 00:35:37,030][train_inner][INFO] - {"epoch": 21, "update": 20.672, "loss": "102.292", "ntokens": "14619.6", "nsentences": "85.08", "nll_loss": "0.595", "wps": "45616.3", "ups": "3.12", "wpb": "14619.6", "bsz": "85.1", "num_updates": "36200", "lr": "3e-05", "gnorm": "130.597", "loss_scale": "8", "train_wall": "64", "gb_free": "32", "wall": "11989"}
[2024-07-10 00:36:41,218][train_inner][INFO] - {"epoch": 21, "update": 20.787, "loss": "100.338", "ntokens": "14673.7", "nsentences": "86.12", "nll_loss": "0.589", "wps": "45725", "ups": "3.12", "wpb": "14673.7", "bsz": "86.1", "num_updates": "36400", "lr": "3e-05", "gnorm": "132.004", "loss_scale": "8", "train_wall": "64", "gb_free": "32.3", "wall": "12053"}
[2024-07-10 00:37:44,958][train_inner][INFO] - {"epoch": 21, "update": 20.901, "loss": "102.54", "ntokens": "14594.6", "nsentences": "85.24", "nll_loss": "0.599", "wps": "45798", "ups": "3.14", "wpb": "14594.6", "bsz": "85.2", "num_updates": "36600", "lr": "3e-05", "gnorm": "130.777", "loss_scale": "8", "train_wall": "63", "gb_free": "32.4", "wall": "12117"}
[2024-07-10 00:38:40,590][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 00:38:40,591][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 00:38:51,316][dev-other][INFO] - {"epoch": 21, "dev-other_loss": "24.907", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.265", "dev-other_uer": "4.232", "dev-other_wer": "11.5", "dev-other_raw_wer": "11.5", "dev-other_wps": "27961", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "36774", "dev-other_best_wer": "11.5"}
[2024-07-10 00:38:51,317][fairseq_cli.train][INFO] - end of epoch 21 (average epoch stats below)
[2024-07-10 00:38:51,320][train][INFO] - {"epoch": 21, "train_loss": "102.141", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.595", "train_wps": "44636.3", "train_ups": "3.06", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "36774", "train_lr": "3e-05", "train_gnorm": "131.663", "train_loss_scale": "16", "train_train_wall": "557", "train_gb_free": "33.4", "train_wall": "12183"}
[2024-07-10 00:38:51,322][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 00:38:52,005][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 00:38:52,009][fairseq.trainer][INFO] - begin training epoch 22
[2024-07-10 00:38:52,009][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 00:39:00,584][train_inner][INFO] - {"epoch": 22, "update": 21.015, "loss": "102.008", "ntokens": "14551.6", "nsentences": "84.6", "nll_loss": "0.593", "wps": "38485.4", "ups": "2.64", "wpb": "14551.6", "bsz": "84.6", "num_updates": "36800", "lr": "3e-05", "gnorm": "132.084", "loss_scale": "16", "train_wall": "64", "gb_free": "31.1", "wall": "12193"}
[2024-07-10 00:40:05,247][train_inner][INFO] - {"epoch": 22, "update": 21.129, "loss": "101.378", "ntokens": "14515.3", "nsentences": "85.16", "nll_loss": "0.595", "wps": "45120.1", "ups": "3.11", "wpb": "14515.3", "bsz": "85.2", "num_updates": "37000", "lr": "3e-05", "gnorm": "130.522", "loss_scale": "16", "train_wall": "64", "gb_free": "32.4", "wall": "12257"}
[2024-07-10 00:41:09,538][train_inner][INFO] - {"epoch": 22, "update": 21.243, "loss": "98.885", "ntokens": "14605.9", "nsentences": "84.88", "nll_loss": "0.575", "wps": "45440.4", "ups": "3.11", "wpb": "14605.9", "bsz": "84.9", "num_updates": "37200", "lr": "3e-05", "gnorm": "131.235", "loss_scale": "16", "train_wall": "64", "gb_free": "31.7", "wall": "12322"}
[2024-07-10 00:42:13,645][train_inner][INFO] - {"epoch": 22, "update": 21.357, "loss": "99.634", "ntokens": "14621.4", "nsentences": "86.64", "nll_loss": "0.59", "wps": "45619.3", "ups": "3.12", "wpb": "14621.4", "bsz": "86.6", "num_updates": "37400", "lr": "3e-05", "gnorm": "128.926", "loss_scale": "16", "train_wall": "64", "gb_free": "33.4", "wall": "12386"}
[2024-07-10 00:43:17,737][train_inner][INFO] - {"epoch": 22, "update": 21.471, "loss": "105.24", "ntokens": "14632.7", "nsentences": "83.88", "nll_loss": "0.603", "wps": "45688.2", "ups": "3.12", "wpb": "14632.7", "bsz": "83.9", "num_updates": "37600", "lr": "3e-05", "gnorm": "132.152", "loss_scale": "16", "train_wall": "64", "gb_free": "33.6", "wall": "12450"}
[2024-07-10 00:44:22,262][train_inner][INFO] - {"epoch": 22, "update": 21.586, "loss": "101.588", "ntokens": "14663.8", "nsentences": "85.915", "nll_loss": "0.595", "wps": "45494.6", "ups": "3.1", "wpb": "14663.8", "bsz": "85.9", "num_updates": "37800", "lr": "3e-05", "gnorm": "129.756", "loss_scale": "16", "train_wall": "64", "gb_free": "32.7", "wall": "12514"}
[2024-07-10 00:45:25,724][train_inner][INFO] - {"epoch": 22, "update": 21.7, "loss": "101.305", "ntokens": "14638.5", "nsentences": "86.08", "nll_loss": "0.596", "wps": "46168.6", "ups": "3.15", "wpb": "14638.5", "bsz": "86.1", "num_updates": "38000", "lr": "3e-05", "gnorm": "129.996", "loss_scale": "16", "train_wall": "63", "gb_free": "31.2", "wall": "12578"}
[2024-07-10 00:46:29,552][train_inner][INFO] - {"epoch": 22, "update": 21.814, "loss": "100.565", "ntokens": "14515.2", "nsentences": "84.36", "nll_loss": "0.584", "wps": "45485.1", "ups": "3.13", "wpb": "14515.2", "bsz": "84.4", "num_updates": "38200", "lr": "3e-05", "gnorm": "131.283", "loss_scale": "16", "train_wall": "63", "gb_free": "32.7", "wall": "12642"}
[2024-07-10 00:47:33,416][train_inner][INFO] - {"epoch": 22, "update": 21.928, "loss": "101.833", "ntokens": "14538.9", "nsentences": "83.56", "nll_loss": "0.585", "wps": "45580.9", "ups": "3.14", "wpb": "14538.9", "bsz": "83.6", "num_updates": "38400", "lr": "3e-05", "gnorm": "133.215", "loss_scale": "16", "train_wall": "63", "gb_free": "33.2", "wall": "12705"}
[2024-07-10 00:48:13,005][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 00:48:13,007][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 00:48:23,780][dev-other][INFO] - {"epoch": 22, "dev-other_loss": "24.57", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.261", "dev-other_uer": "4.221", "dev-other_wer": "11.535", "dev-other_raw_wer": "11.535", "dev-other_wps": "27534.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "38526", "dev-other_best_wer": "11.533"}
[2024-07-10 00:48:23,780][fairseq_cli.train][INFO] - end of epoch 22 (average epoch stats below)
[2024-07-10 00:48:23,783][train][INFO] - {"epoch": 22, "train_loss": "101.401", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.59", "train_wps": "44614.2", "train_ups": "3.06", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "38526", "train_lr": "3e-05", "train_gnorm": "131.147", "train_loss_scale": "16", "train_train_wall": "556", "train_gb_free": "32.9", "train_wall": "12756"}
[2024-07-10 00:48:23,784][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 00:48:24,540][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 00:48:24,544][fairseq.trainer][INFO] - begin training epoch 23
[2024-07-10 00:48:24,545][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 00:48:48,364][train_inner][INFO] - {"epoch": 23, "update": 22.042, "loss": "102.334", "ntokens": "14453.4", "nsentences": "83.88", "nll_loss": "0.594", "wps": "38602.9", "ups": "2.67", "wpb": "14453.4", "bsz": "83.9", "num_updates": "38600", "lr": "3e-05", "gnorm": "132.852", "loss_scale": "16", "train_wall": "63", "gb_free": "32.8", "wall": "12780"}
[2024-07-10 00:49:06,865][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-10 00:49:52,312][train_inner][INFO] - {"epoch": 23, "update": 22.157, "loss": "105.383", "ntokens": "14578.9", "nsentences": "83.515", "nll_loss": "0.604", "wps": "45600.6", "ups": "3.13", "wpb": "14578.9", "bsz": "83.5", "num_updates": "38800", "lr": "3e-05", "gnorm": "132.606", "loss_scale": "16", "train_wall": "63", "gb_free": "31.8", "wall": "12844"}
[2024-07-10 00:50:16,517][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 00:50:56,819][train_inner][INFO] - {"epoch": 23, "update": 22.272, "loss": "98.177", "ntokens": "14622.7", "nsentences": "87.32", "nll_loss": "0.586", "wps": "45340", "ups": "3.1", "wpb": "14622.7", "bsz": "87.3", "num_updates": "39000", "lr": "3e-05", "gnorm": "128.014", "loss_scale": "8", "train_wall": "64", "gb_free": "32.7", "wall": "12909"}
[2024-07-10 00:52:00,693][train_inner][INFO] - {"epoch": 23, "update": 22.386, "loss": "99.31", "ntokens": "14506.3", "nsentences": "84.88", "nll_loss": "0.581", "wps": "45424.9", "ups": "3.13", "wpb": "14506.3", "bsz": "84.9", "num_updates": "39200", "lr": "3e-05", "gnorm": "130.612", "loss_scale": "8", "train_wall": "63", "gb_free": "32.7", "wall": "12973"}
[2024-07-10 00:53:05,090][train_inner][INFO] - {"epoch": 23, "update": 22.5, "loss": "102.168", "ntokens": "14536.2", "nsentences": "82.76", "nll_loss": "0.582", "wps": "45150", "ups": "3.11", "wpb": "14536.2", "bsz": "82.8", "num_updates": "39400", "lr": "3e-05", "gnorm": "133.168", "loss_scale": "8", "train_wall": "64", "gb_free": "32.6", "wall": "13037"}
[2024-07-10 00:54:09,465][train_inner][INFO] - {"epoch": 23, "update": 22.614, "loss": "103.207", "ntokens": "14652.2", "nsentences": "84.96", "nll_loss": "0.598", "wps": "45525.9", "ups": "3.11", "wpb": "14652.2", "bsz": "85", "num_updates": "39600", "lr": "3e-05", "gnorm": "133.055", "loss_scale": "8", "train_wall": "64", "gb_free": "32.5", "wall": "13101"}
[2024-07-10 00:55:14,374][train_inner][INFO] - {"epoch": 23, "update": 22.728, "loss": "100.303", "ntokens": "14718.7", "nsentences": "84.8", "nll_loss": "0.578", "wps": "45355.4", "ups": "3.08", "wpb": "14718.7", "bsz": "84.8", "num_updates": "39800", "lr": "3e-05", "gnorm": "130.375", "loss_scale": "8", "train_wall": "64", "gb_free": "32.5", "wall": "13166"}
[2024-07-10 00:56:18,815][train_inner][INFO] - {"epoch": 23, "update": 22.842, "loss": "100.901", "ntokens": "14542.1", "nsentences": "84.08", "nll_loss": "0.583", "wps": "45180.4", "ups": "3.11", "wpb": "14542.1", "bsz": "84.1", "num_updates": "40000", "lr": "3e-05", "gnorm": "131.999", "loss_scale": "8", "train_wall": "64", "gb_free": "31.3", "wall": "13231"}
[2024-07-10 00:57:22,569][train_inner][INFO] - {"epoch": 23, "update": 22.957, "loss": "99.247", "ntokens": "14554.1", "nsentences": "85.96", "nll_loss": "0.586", "wps": "45675.8", "ups": "3.14", "wpb": "14554.1", "bsz": "86", "num_updates": "40200", "lr": "3e-05", "gnorm": "130.32", "loss_scale": "8", "train_wall": "63", "gb_free": "31.1", "wall": "13295"}
[2024-07-10 00:57:46,506][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 00:57:46,507][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 00:57:57,241][dev-other][INFO] - {"epoch": 23, "dev-other_loss": "24.235", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.258", "dev-other_uer": "4.169", "dev-other_wer": "11.365", "dev-other_raw_wer": "11.365", "dev-other_wps": "27616.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "40276", "dev-other_best_wer": "11.365"}
[2024-07-10 00:57:57,242][fairseq_cli.train][INFO] - end of epoch 23 (average epoch stats below)
[2024-07-10 00:57:57,244][train][INFO] - {"epoch": 23, "train_loss": "101.052", "train_ntokens": "14578.9", "train_nsentences": "84.8086", "train_nll_loss": "0.588", "train_wps": "44489.9", "train_ups": "3.05", "train_wpb": "14578.9", "train_bsz": "84.8", "train_num_updates": "40276", "train_lr": "3e-05", "train_gnorm": "131.184", "train_loss_scale": "8", "train_train_wall": "558", "train_gb_free": "33", "train_wall": "13329"}
[2024-07-10 00:57:57,246][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 00:57:57,987][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 00:57:57,992][fairseq.trainer][INFO] - begin training epoch 24
[2024-07-10 00:57:57,992][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 00:58:38,126][train_inner][INFO] - {"epoch": 24, "update": 23.071, "loss": "98.324", "ntokens": "14478.3", "nsentences": "85.155", "nll_loss": "0.578", "wps": "38326.7", "ups": "2.65", "wpb": "14478.3", "bsz": "85.2", "num_updates": "40400", "lr": "3e-05", "gnorm": "128.924", "loss_scale": "8", "train_wall": "64", "gb_free": "33", "wall": "13370"}
[2024-07-10 00:59:42,285][train_inner][INFO] - {"epoch": 24, "update": 23.185, "loss": "103.5", "ntokens": "14613.1", "nsentences": "83.16", "nll_loss": "0.589", "wps": "45556.5", "ups": "3.12", "wpb": "14613.1", "bsz": "83.2", "num_updates": "40600", "lr": "3e-05", "gnorm": "132.151", "loss_scale": "8", "train_wall": "64", "gb_free": "32.9", "wall": "13434"}
[2024-07-10 01:00:46,014][train_inner][INFO] - {"epoch": 24, "update": 23.299, "loss": "99.056", "ntokens": "14557.8", "nsentences": "86.04", "nll_loss": "0.585", "wps": "45690.9", "ups": "3.14", "wpb": "14557.8", "bsz": "86", "num_updates": "40800", "lr": "3e-05", "gnorm": "129.702", "loss_scale": "8", "train_wall": "63", "gb_free": "31.4", "wall": "13498"}
[2024-07-10 01:01:50,073][train_inner][INFO] - {"epoch": 24, "update": 23.413, "loss": "99.67", "ntokens": "14574.4", "nsentences": "85", "nll_loss": "0.581", "wps": "45508.1", "ups": "3.12", "wpb": "14574.4", "bsz": "85", "num_updates": "41000", "lr": "3e-05", "gnorm": "129.351", "loss_scale": "16", "train_wall": "64", "gb_free": "31.5", "wall": "13562"}
[2024-07-10 01:02:47,057][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 01:02:54,604][train_inner][INFO] - {"epoch": 24, "update": 23.528, "loss": "98.206", "ntokens": "14492.3", "nsentences": "85", "nll_loss": "0.576", "wps": "44920.3", "ups": "3.1", "wpb": "14492.3", "bsz": "85", "num_updates": "41200", "lr": "3e-05", "gnorm": "131.284", "loss_scale": "8", "train_wall": "64", "gb_free": "33.8", "wall": "13627"}
[2024-07-10 01:03:58,929][train_inner][INFO] - {"epoch": 24, "update": 23.642, "loss": "98.337", "ntokens": "14680.8", "nsentences": "85.56", "nll_loss": "0.573", "wps": "45648.6", "ups": "3.11", "wpb": "14680.8", "bsz": "85.6", "num_updates": "41400", "lr": "3e-05", "gnorm": "129.993", "loss_scale": "8", "train_wall": "64", "gb_free": "31.5", "wall": "13691"}
[2024-07-10 01:05:03,159][train_inner][INFO] - {"epoch": 24, "update": 23.756, "loss": "99.296", "ntokens": "14548.8", "nsentences": "84.4", "nll_loss": "0.576", "wps": "45307.1", "ups": "3.11", "wpb": "14548.8", "bsz": "84.4", "num_updates": "41600", "lr": "3e-05", "gnorm": "130.99", "loss_scale": "8", "train_wall": "64", "gb_free": "32.8", "wall": "13755"}
[2024-07-10 01:06:07,660][train_inner][INFO] - {"epoch": 24, "update": 23.87, "loss": "100.541", "ntokens": "14650.3", "nsentences": "85.24", "nll_loss": "0.585", "wps": "45431.3", "ups": "3.1", "wpb": "14650.3", "bsz": "85.2", "num_updates": "41800", "lr": "3e-05", "gnorm": "130.078", "loss_scale": "8", "train_wall": "64", "gb_free": "31.9", "wall": "13820"}
[2024-07-10 01:07:11,971][train_inner][INFO] - {"epoch": 24, "update": 23.985, "loss": "100.658", "ntokens": "14598.8", "nsentences": "84.68", "nll_loss": "0.584", "wps": "45404.9", "ups": "3.11", "wpb": "14598.8", "bsz": "84.7", "num_updates": "42000", "lr": "3e-05", "gnorm": "131.365", "loss_scale": "8", "train_wall": "64", "gb_free": "32.5", "wall": "13884"}
[2024-07-10 01:07:20,523][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 01:07:20,524][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 01:07:31,239][dev-other][INFO] - {"epoch": 24, "dev-other_loss": "23.601", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.251", "dev-other_uer": "4.077", "dev-other_wer": "11.206", "dev-other_raw_wer": "11.206", "dev-other_wps": "27724.3", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "42027", "dev-other_best_wer": "11.206"}
[2024-07-10 01:07:31,240][fairseq_cli.train][INFO] - end of epoch 24 (average epoch stats below)
[2024-07-10 01:07:31,243][train][INFO] - {"epoch": 24, "train_loss": "99.667", "train_ntokens": "14577.8", "train_nsentences": "84.8195", "train_nll_loss": "0.58", "train_wps": "44470.3", "train_ups": "3.05", "train_wpb": "14577.8", "train_bsz": "84.8", "train_num_updates": "42027", "train_lr": "3e-05", "train_gnorm": "130.516", "train_loss_scale": "8", "train_train_wall": "558", "train_gb_free": "32.8", "train_wall": "13903"}
[2024-07-10 01:07:31,244][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 01:07:31,917][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 01:07:31,927][fairseq.trainer][INFO] - begin training epoch 25
[2024-07-10 01:07:31,927][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 01:08:27,628][train_inner][INFO] - {"epoch": 25, "update": 24.099, "loss": "99.995", "ntokens": "14532", "nsentences": "84.36", "nll_loss": "0.58", "wps": "38418.1", "ups": "2.64", "wpb": "14532", "bsz": "84.4", "num_updates": "42200", "lr": "3e-05", "gnorm": "131.207", "loss_scale": "8", "train_wall": "64", "gb_free": "31.6", "wall": "13960"}
[2024-07-10 01:09:31,413][train_inner][INFO] - {"epoch": 25, "update": 24.213, "loss": "98.715", "ntokens": "14621.2", "nsentences": "86.88", "nll_loss": "0.587", "wps": "45849.1", "ups": "3.14", "wpb": "14621.2", "bsz": "86.9", "num_updates": "42400", "lr": "3e-05", "gnorm": "130.664", "loss_scale": "8", "train_wall": "63", "gb_free": "32.4", "wall": "14023"}
[2024-07-10 01:10:35,439][train_inner][INFO] - {"epoch": 25, "update": 24.327, "loss": "100.393", "ntokens": "14564.4", "nsentences": "84.76", "nll_loss": "0.584", "wps": "45544.6", "ups": "3.13", "wpb": "14564.4", "bsz": "84.8", "num_updates": "42600", "lr": "3e-05", "gnorm": "129.996", "loss_scale": "8", "train_wall": "63", "gb_free": "32.2", "wall": "14087"}
[2024-07-10 01:11:39,808][train_inner][INFO] - {"epoch": 25, "update": 24.441, "loss": "102.406", "ntokens": "14611.6", "nsentences": "83.075", "nll_loss": "0.582", "wps": "45404.4", "ups": "3.11", "wpb": "14611.6", "bsz": "83.1", "num_updates": "42800", "lr": "3e-05", "gnorm": "132.869", "loss_scale": "8", "train_wall": "64", "gb_free": "32.6", "wall": "14152"}
[2024-07-10 01:12:43,726][train_inner][INFO] - {"epoch": 25, "update": 24.555, "loss": "100.21", "ntokens": "14674.5", "nsentences": "85.48", "nll_loss": "0.584", "wps": "46014.6", "ups": "3.14", "wpb": "14674.5", "bsz": "85.5", "num_updates": "43000", "lr": "3e-05", "gnorm": "130.254", "loss_scale": "8", "train_wall": "63", "gb_free": "32.6", "wall": "14216"}
[2024-07-10 01:13:47,315][train_inner][INFO] - {"epoch": 25, "update": 24.67, "loss": "96.379", "ntokens": "14497.2", "nsentences": "84.76", "nll_loss": "0.563", "wps": "45600.1", "ups": "3.15", "wpb": "14497.2", "bsz": "84.8", "num_updates": "43200", "lr": "3e-05", "gnorm": "130.347", "loss_scale": "8", "train_wall": "63", "gb_free": "33.1", "wall": "14279"}
[2024-07-10 01:14:52,032][train_inner][INFO] - {"epoch": 25, "update": 24.784, "loss": "99.669", "ntokens": "14679", "nsentences": "86.2", "nll_loss": "0.585", "wps": "45367.7", "ups": "3.09", "wpb": "14679", "bsz": "86.2", "num_updates": "43400", "lr": "3e-05", "gnorm": "130.154", "loss_scale": "16", "train_wall": "64", "gb_free": "31", "wall": "14344"}
[2024-07-10 01:15:19,623][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 01:15:56,432][train_inner][INFO] - {"epoch": 25, "update": 24.898, "loss": "98.862", "ntokens": "14511.9", "nsentences": "84", "nll_loss": "0.572", "wps": "45071.8", "ups": "3.11", "wpb": "14511.9", "bsz": "84", "num_updates": "43600", "lr": "3e-05", "gnorm": "131.073", "loss_scale": "8", "train_wall": "64", "gb_free": "32.5", "wall": "14408"}
[2024-07-10 01:16:53,097][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 01:16:53,099][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 01:17:03,790][dev-other][INFO] - {"epoch": 25, "dev-other_loss": "24.013", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.255", "dev-other_uer": "4.131", "dev-other_wer": "11.378", "dev-other_raw_wer": "11.378", "dev-other_wps": "27780.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "43778", "dev-other_best_wer": "11.378"}
[2024-07-10 01:17:03,792][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 25 @ 43778 updates
[2024-07-10 01:17:03,792][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-10 01:17:05,103][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-10 01:17:05,700][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 25 @ 43778 updates, score 11.378) (writing took 1.9088732562959194 seconds)
[2024-07-10 01:17:05,701][fairseq_cli.train][INFO] - end of epoch 25 (average epoch stats below)
[2024-07-10 01:17:05,705][train][INFO] - {"epoch": 25, "train_loss": "99.56", "train_ntokens": "14578.7", "train_nsentences": "84.8241", "train_nll_loss": "0.579", "train_wps": "44437.3", "train_ups": "3.05", "train_wpb": "14578.7", "train_bsz": "84.8", "train_num_updates": "43778", "train_lr": "3e-05", "train_gnorm": "130.902", "train_loss_scale": "8", "train_train_wall": "557", "train_gb_free": "32", "train_wall": "14478"}
[2024-07-10 01:17:05,706][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 01:17:05,955][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 01:17:05,959][fairseq.trainer][INFO] - begin training epoch 26
[2024-07-10 01:17:05,959][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 01:17:13,234][train_inner][INFO] - {"epoch": 26, "update": 25.013, "loss": "99.664", "ntokens": "14449.9", "nsentences": "83.2", "nll_loss": "0.574", "wps": "37631.1", "ups": "2.6", "wpb": "14449.9", "bsz": "83.2", "num_updates": "43800", "lr": "3e-05", "gnorm": "132.643", "loss_scale": "8", "train_wall": "63", "gb_free": "32", "wall": "14485"}
[2024-07-10 01:18:17,340][train_inner][INFO] - {"epoch": 26, "update": 25.127, "loss": "97.511", "ntokens": "14573.9", "nsentences": "85.84", "nll_loss": "0.574", "wps": "45520", "ups": "3.12", "wpb": "14573.9", "bsz": "85.8", "num_updates": "44000", "lr": "3e-05", "gnorm": "129.287", "loss_scale": "8", "train_wall": "64", "gb_free": "32.4", "wall": "14549"}
[2024-07-10 01:19:21,797][train_inner][INFO] - {"epoch": 26, "update": 25.241, "loss": "99.094", "ntokens": "14662.5", "nsentences": "84.96", "nll_loss": "0.574", "wps": "45499.5", "ups": "3.1", "wpb": "14662.6", "bsz": "85", "num_updates": "44200", "lr": "3e-05", "gnorm": "130.922", "loss_scale": "8", "train_wall": "64", "gb_free": "32.1", "wall": "14614"}
[2024-07-10 01:20:26,004][train_inner][INFO] - {"epoch": 26, "update": 25.355, "loss": "99.382", "ntokens": "14617.9", "nsentences": "84.44", "nll_loss": "0.574", "wps": "45586.5", "ups": "3.12", "wpb": "14617.9", "bsz": "84.4", "num_updates": "44400", "lr": "3e-05", "gnorm": "131.691", "loss_scale": "8", "train_wall": "64", "gb_free": "31.3", "wall": "14678"}
[2024-07-10 01:21:30,200][train_inner][INFO] - {"epoch": 26, "update": 25.469, "loss": "99.543", "ntokens": "14614.2", "nsentences": "85.6", "nll_loss": "0.583", "wps": "45577.2", "ups": "3.12", "wpb": "14614.2", "bsz": "85.6", "num_updates": "44600", "lr": "3e-05", "gnorm": "130.485", "loss_scale": "8", "train_wall": "64", "gb_free": "29.7", "wall": "14742"}
[2024-07-10 01:22:33,494][train_inner][INFO] - {"epoch": 26, "update": 25.583, "loss": "98.649", "ntokens": "14502.5", "nsentences": "86.08", "nll_loss": "0.586", "wps": "45832.8", "ups": "3.16", "wpb": "14502.5", "bsz": "86.1", "num_updates": "44800", "lr": "3e-05", "gnorm": "129.838", "loss_scale": "8", "train_wall": "63", "gb_free": "33.3", "wall": "14805"}
[2024-07-10 01:23:37,247][train_inner][INFO] - {"epoch": 26, "update": 25.697, "loss": "100.416", "ntokens": "14577.9", "nsentences": "84.12", "nll_loss": "0.579", "wps": "45741.9", "ups": "3.14", "wpb": "14577.9", "bsz": "84.1", "num_updates": "45000", "lr": "3e-05", "gnorm": "132.127", "loss_scale": "8", "train_wall": "63", "gb_free": "31.6", "wall": "14869"}
[2024-07-10 01:24:41,050][train_inner][INFO] - {"epoch": 26, "update": 25.812, "loss": "102.153", "ntokens": "14531.7", "nsentences": "83.44", "nll_loss": "0.587", "wps": "45633.2", "ups": "3.14", "wpb": "14531.7", "bsz": "83.4", "num_updates": "45200", "lr": "3e-05", "gnorm": "131.307", "loss_scale": "8", "train_wall": "63", "gb_free": "31.3", "wall": "14933"}
[2024-07-10 01:25:45,065][train_inner][INFO] - {"epoch": 26, "update": 25.926, "loss": "99.741", "ntokens": "14539.3", "nsentences": "83.955", "nll_loss": "0.576", "wps": "45473.9", "ups": "3.13", "wpb": "14539.3", "bsz": "84", "num_updates": "45400", "lr": "3e-05", "gnorm": "130.597", "loss_scale": "8", "train_wall": "63", "gb_free": "32.7", "wall": "14997"}
[2024-07-10 01:26:26,666][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 01:26:26,667][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 01:26:37,487][dev-other][INFO] - {"epoch": 26, "dev-other_loss": "23.914", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.254", "dev-other_uer": "4.133", "dev-other_wer": "11.2", "dev-other_raw_wer": "11.2", "dev-other_wps": "27649.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "45530", "dev-other_best_wer": "11.2"}
[2024-07-10 01:26:37,487][fairseq_cli.train][INFO] - end of epoch 26 (average epoch stats below)
[2024-07-10 01:26:37,493][train][INFO] - {"epoch": 26, "train_loss": "99.382", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.579", "train_wps": "44667", "train_ups": "3.06", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "45530", "train_lr": "3e-05", "train_gnorm": "130.761", "train_loss_scale": "8", "train_train_wall": "556", "train_gb_free": "33.1", "train_wall": "15049"}
[2024-07-10 01:26:37,495][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 01:26:38,176][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 01:26:38,183][fairseq.trainer][INFO] - begin training epoch 27
[2024-07-10 01:26:38,183][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 01:27:01,184][train_inner][INFO] - {"epoch": 27, "update": 26.04, "loss": "98.207", "ntokens": "14573.7", "nsentences": "84.52", "nll_loss": "0.57", "wps": "38295.3", "ups": "2.63", "wpb": "14573.7", "bsz": "84.5", "num_updates": "45600", "lr": "3e-05", "gnorm": "130.677", "loss_scale": "16", "train_wall": "64", "gb_free": "31.9", "wall": "15073"}
[2024-07-10 01:28:05,693][train_inner][INFO] - {"epoch": 27, "update": 26.154, "loss": "95.223", "ntokens": "14731.5", "nsentences": "88.32", "nll_loss": "0.571", "wps": "45675.9", "ups": "3.1", "wpb": "14731.5", "bsz": "88.3", "num_updates": "45800", "lr": "3e-05", "gnorm": "130.21", "loss_scale": "16", "train_wall": "64", "gb_free": "32", "wall": "15138"}
[2024-07-10 01:28:43,060][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 01:29:10,621][train_inner][INFO] - {"epoch": 27, "update": 26.269, "loss": "95.365", "ntokens": "14645.3", "nsentences": "85.12", "nll_loss": "0.554", "wps": "45115.7", "ups": "3.08", "wpb": "14645.3", "bsz": "85.1", "num_updates": "46000", "lr": "3e-05", "gnorm": "130.056", "loss_scale": "8", "train_wall": "64", "gb_free": "32.7", "wall": "15203"}
[2024-07-10 01:30:14,825][train_inner][INFO] - {"epoch": 27, "update": 26.383, "loss": "99.027", "ntokens": "14659.5", "nsentences": "86.04", "nll_loss": "0.581", "wps": "45713.2", "ups": "3.12", "wpb": "14659.5", "bsz": "86", "num_updates": "46200", "lr": "3e-05", "gnorm": "129.539", "loss_scale": "8", "train_wall": "64", "gb_free": "32.1", "wall": "15267"}
[2024-07-10 01:31:18,903][train_inner][INFO] - {"epoch": 27, "update": 26.497, "loss": "98.953", "ntokens": "14612.4", "nsentences": "84.08", "nll_loss": "0.569", "wps": "45659.3", "ups": "3.12", "wpb": "14612.4", "bsz": "84.1", "num_updates": "46400", "lr": "3e-05", "gnorm": "131.498", "loss_scale": "8", "train_wall": "64", "gb_free": "32.2", "wall": "15331"}
[2024-07-10 01:32:22,886][train_inner][INFO] - {"epoch": 27, "update": 26.611, "loss": "99.831", "ntokens": "14518.4", "nsentences": "83.155", "nll_loss": "0.572", "wps": "45385.1", "ups": "3.13", "wpb": "14518.4", "bsz": "83.2", "num_updates": "46600", "lr": "3e-05", "gnorm": "132.193", "loss_scale": "8", "train_wall": "64", "gb_free": "32.4", "wall": "15395"}
[2024-07-10 01:33:27,032][train_inner][INFO] - {"epoch": 27, "update": 26.725, "loss": "99.986", "ntokens": "14371", "nsentences": "82.12", "nll_loss": "0.571", "wps": "44811.8", "ups": "3.12", "wpb": "14371", "bsz": "82.1", "num_updates": "46800", "lr": "3e-05", "gnorm": "133.499", "loss_scale": "8", "train_wall": "64", "gb_free": "31.7", "wall": "15459"}
[2024-07-10 01:34:30,825][train_inner][INFO] - {"epoch": 27, "update": 26.84, "loss": "98.398", "ntokens": "14499.5", "nsentences": "85.04", "nll_loss": "0.577", "wps": "45493.9", "ups": "3.14", "wpb": "14499.5", "bsz": "85", "num_updates": "47000", "lr": "3e-05", "gnorm": "132.002", "loss_scale": "8", "train_wall": "63", "gb_free": "32.2", "wall": "15523"}
[2024-07-10 01:35:34,382][train_inner][INFO] - {"epoch": 27, "update": 26.954, "loss": "99.087", "ntokens": "14583.3", "nsentences": "85.48", "nll_loss": "0.581", "wps": "45894.7", "ups": "3.15", "wpb": "14583.3", "bsz": "85.5", "num_updates": "47200", "lr": "3e-05", "gnorm": "131.195", "loss_scale": "8", "train_wall": "63", "gb_free": "32", "wall": "15586"}
[2024-07-10 01:36:00,239][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 01:36:00,240][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 01:36:10,873][dev-other][INFO] - {"epoch": 27, "dev-other_loss": "23.704", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.252", "dev-other_uer": "4.114", "dev-other_wer": "11.125", "dev-other_raw_wer": "11.125", "dev-other_wps": "27926.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "47281", "dev-other_best_wer": "11.125"}
[2024-07-10 01:36:10,873][fairseq_cli.train][INFO] - end of epoch 27 (average epoch stats below)
[2024-07-10 01:36:10,876][train][INFO] - {"epoch": 27, "train_loss": "98.239", "train_ntokens": "14578.2", "train_nsentences": "84.8789", "train_nll_loss": "0.572", "train_wps": "44519.1", "train_ups": "3.05", "train_wpb": "14578.2", "train_bsz": "84.9", "train_num_updates": "47281", "train_lr": "3e-05", "train_gnorm": "131.329", "train_loss_scale": "8", "train_train_wall": "558", "train_gb_free": "31.4", "train_wall": "15623"}
[2024-07-10 01:36:10,877][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 01:36:11,626][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 01:36:11,630][fairseq.trainer][INFO] - begin training epoch 28
[2024-07-10 01:36:11,630][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 01:36:50,220][train_inner][INFO] - {"epoch": 28, "update": 27.068, "loss": "95.01", "ntokens": "14525.4", "nsentences": "85.64", "nll_loss": "0.56", "wps": "38309.9", "ups": "2.64", "wpb": "14525.4", "bsz": "85.6", "num_updates": "47400", "lr": "3e-05", "gnorm": "129.987", "loss_scale": "8", "train_wall": "64", "gb_free": "32.9", "wall": "15662"}
[2024-07-10 01:37:54,399][train_inner][INFO] - {"epoch": 28, "update": 27.182, "loss": "100.901", "ntokens": "14531.8", "nsentences": "81.84", "nll_loss": "0.568", "wps": "45288.1", "ups": "3.12", "wpb": "14531.8", "bsz": "81.8", "num_updates": "47600", "lr": "3e-05", "gnorm": "132.586", "loss_scale": "8", "train_wall": "64", "gb_free": "31.8", "wall": "15726"}
[2024-07-10 01:38:59,057][train_inner][INFO] - {"epoch": 28, "update": 27.296, "loss": "96.441", "ntokens": "14530", "nsentences": "84.52", "nll_loss": "0.561", "wps": "44995.8", "ups": "3.1", "wpb": "14530", "bsz": "84.5", "num_updates": "47800", "lr": "3e-05", "gnorm": "131.4", "loss_scale": "8", "train_wall": "64", "gb_free": "31.7", "wall": "15791"}
[2024-07-10 01:40:03,495][train_inner][INFO] - {"epoch": 28, "update": 27.41, "loss": "95.639", "ntokens": "14592.2", "nsentences": "86", "nll_loss": "0.564", "wps": "45296.3", "ups": "3.1", "wpb": "14592.2", "bsz": "86", "num_updates": "48000", "lr": "3e-05", "gnorm": "128.439", "loss_scale": "16", "train_wall": "64", "gb_free": "31.4", "wall": "15855"}
[2024-07-10 01:40:50,909][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 01:41:08,100][train_inner][INFO] - {"epoch": 28, "update": 27.525, "loss": "96.285", "ntokens": "14651.2", "nsentences": "86.28", "nll_loss": "0.567", "wps": "45359.7", "ups": "3.1", "wpb": "14651.2", "bsz": "86.3", "num_updates": "48200", "lr": "3e-05", "gnorm": "128.618", "loss_scale": "8", "train_wall": "64", "gb_free": "30.4", "wall": "15920"}
[2024-07-10 01:42:12,305][train_inner][INFO] - {"epoch": 28, "update": 27.639, "loss": "97.298", "ntokens": "14686.4", "nsentences": "89.44", "nll_loss": "0.593", "wps": "45751.6", "ups": "3.12", "wpb": "14686.4", "bsz": "89.4", "num_updates": "48400", "lr": "3e-05", "gnorm": "126.421", "loss_scale": "8", "train_wall": "64", "gb_free": "32.6", "wall": "15984"}
[2024-07-10 01:43:16,431][train_inner][INFO] - {"epoch": 28, "update": 27.753, "loss": "100.968", "ntokens": "14607.2", "nsentences": "83.2", "nll_loss": "0.575", "wps": "45561.6", "ups": "3.12", "wpb": "14607.2", "bsz": "83.2", "num_updates": "48600", "lr": "3e-05", "gnorm": "132.077", "loss_scale": "8", "train_wall": "64", "gb_free": "31.8", "wall": "16048"}
[2024-07-10 01:44:20,371][train_inner][INFO] - {"epoch": 28, "update": 27.868, "loss": "100.079", "ntokens": "14525.2", "nsentences": "83.24", "nll_loss": "0.574", "wps": "45436.6", "ups": "3.13", "wpb": "14525.2", "bsz": "83.2", "num_updates": "48800", "lr": "3e-05", "gnorm": "134.072", "loss_scale": "8", "train_wall": "63", "gb_free": "32.5", "wall": "16112"}
[2024-07-10 01:45:24,211][train_inner][INFO] - {"epoch": 28, "update": 27.982, "loss": "101.241", "ntokens": "14583.1", "nsentences": "83.475", "nll_loss": "0.58", "wps": "45742", "ups": "3.14", "wpb": "14583.1", "bsz": "83.5", "num_updates": "49000", "lr": "3e-05", "gnorm": "132.681", "loss_scale": "8", "train_wall": "63", "gb_free": "31.5", "wall": "16176"}
[2024-07-10 01:45:34,193][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 01:45:34,194][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 01:45:44,949][dev-other][INFO] - {"epoch": 28, "dev-other_loss": "24.031", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.255", "dev-other_uer": "4.181", "dev-other_wer": "11.286", "dev-other_raw_wer": "11.286", "dev-other_wps": "27638.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "49032", "dev-other_best_wer": "11.286"}
[2024-07-10 01:45:44,949][fairseq_cli.train][INFO] - end of epoch 28 (average epoch stats below)
[2024-07-10 01:45:44,953][train][INFO] - {"epoch": 28, "train_loss": "98.135", "train_ntokens": "14575.7", "train_nsentences": "84.8561", "train_nll_loss": "0.571", "train_wps": "44457.7", "train_ups": "3.05", "train_wpb": "14575.7", "train_bsz": "84.9", "train_num_updates": "49032", "train_lr": "3e-05", "train_gnorm": "130.692", "train_loss_scale": "8", "train_train_wall": "558", "train_gb_free": "33", "train_wall": "16197"}
[2024-07-10 01:45:44,954][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 01:45:45,636][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 01:45:45,640][fairseq.trainer][INFO] - begin training epoch 29
[2024-07-10 01:45:45,640][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 01:46:39,359][train_inner][INFO] - {"epoch": 29, "update": 28.096, "loss": "97.6", "ntokens": "14491.1", "nsentences": "84.28", "nll_loss": "0.568", "wps": "38573.9", "ups": "2.66", "wpb": "14491.1", "bsz": "84.3", "num_updates": "49200", "lr": "3e-05", "gnorm": "131.393", "loss_scale": "8", "train_wall": "63", "gb_free": "33.7", "wall": "16251"}
[2024-07-10 01:47:43,448][train_inner][INFO] - {"epoch": 29, "update": 28.21, "loss": "96.271", "ntokens": "14599.3", "nsentences": "86.04", "nll_loss": "0.567", "wps": "45609.6", "ups": "3.12", "wpb": "14599.3", "bsz": "86", "num_updates": "49400", "lr": "3e-05", "gnorm": "129.268", "loss_scale": "8", "train_wall": "64", "gb_free": "32.7", "wall": "16315"}
[2024-07-10 01:48:47,581][train_inner][INFO] - {"epoch": 29, "update": 28.324, "loss": "96.725", "ntokens": "14585", "nsentences": "85.92", "nll_loss": "0.57", "wps": "45514.3", "ups": "3.12", "wpb": "14585", "bsz": "85.9", "num_updates": "49600", "lr": "3e-05", "gnorm": "129.006", "loss_scale": "8", "train_wall": "64", "gb_free": "31.5", "wall": "16380"}
[2024-07-10 01:49:51,761][train_inner][INFO] - {"epoch": 29, "update": 28.438, "loss": "95.308", "ntokens": "14727.9", "nsentences": "88.315", "nll_loss": "0.572", "wps": "45900.5", "ups": "3.12", "wpb": "14727.9", "bsz": "88.3", "num_updates": "49800", "lr": "3e-05", "gnorm": "126.689", "loss_scale": "8", "train_wall": "64", "gb_free": "32.6", "wall": "16444"}
[2024-07-10 01:50:55,685][train_inner][INFO] - {"epoch": 29, "update": 28.553, "loss": "99.991", "ntokens": "14540.1", "nsentences": "84.76", "nll_loss": "0.583", "wps": "45496.9", "ups": "3.13", "wpb": "14540.1", "bsz": "84.8", "num_updates": "50000", "lr": "3e-05", "gnorm": "133.499", "loss_scale": "8", "train_wall": "63", "gb_free": "31.6", "wall": "16508"}
[2024-07-10 01:51:59,871][train_inner][INFO] - {"epoch": 29, "update": 28.667, "loss": "98.155", "ntokens": "14621.8", "nsentences": "84.92", "nll_loss": "0.57", "wps": "45565.1", "ups": "3.12", "wpb": "14621.8", "bsz": "84.9", "num_updates": "50200", "lr": "3e-05", "gnorm": "130.82", "loss_scale": "16", "train_wall": "64", "gb_free": "32.8", "wall": "16572"}
[2024-07-10 01:53:04,328][train_inner][INFO] - {"epoch": 29, "update": 28.781, "loss": "98.806", "ntokens": "14615.1", "nsentences": "83.36", "nll_loss": "0.564", "wps": "45401.3", "ups": "3.11", "wpb": "14615.1", "bsz": "83.4", "num_updates": "50400", "lr": "3e-05", "gnorm": "132.587", "loss_scale": "16", "train_wall": "64", "gb_free": "31.5", "wall": "16636"}
[2024-07-10 01:54:08,440][train_inner][INFO] - {"epoch": 29, "update": 28.895, "loss": "98.685", "ntokens": "14543.4", "nsentences": "83.96", "nll_loss": "0.57", "wps": "45373.8", "ups": "3.12", "wpb": "14543.4", "bsz": "84", "num_updates": "50600", "lr": "3e-05", "gnorm": "131.282", "loss_scale": "16", "train_wall": "64", "gb_free": "31.8", "wall": "16700"}
[2024-07-10 01:55:07,066][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 01:55:07,067][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 01:55:17,763][dev-other][INFO] - {"epoch": 29, "dev-other_loss": "23.404", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.249", "dev-other_uer": "4.136", "dev-other_wer": "11.184", "dev-other_raw_wer": "11.184", "dev-other_wps": "27980.7", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "50784", "dev-other_best_wer": "11.184"}
[2024-07-10 01:55:17,763][fairseq_cli.train][INFO] - end of epoch 29 (average epoch stats below)
[2024-07-10 01:55:17,771][train][INFO] - {"epoch": 29, "train_loss": "98.088", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.571", "train_wps": "44586.8", "train_ups": "3.06", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "50784", "train_lr": "3e-05", "train_gnorm": "130.839", "train_loss_scale": "16", "train_train_wall": "557", "train_gb_free": "31.7", "train_wall": "16770"}
[2024-07-10 01:55:17,772][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 01:55:18,497][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 01:55:18,500][fairseq.trainer][INFO] - begin training epoch 30
[2024-07-10 01:55:18,501][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 01:55:24,000][train_inner][INFO] - {"epoch": 30, "update": 29.009, "loss": "99.516", "ntokens": "14447.4", "nsentences": "83.16", "nll_loss": "0.573", "wps": "38245.4", "ups": "2.65", "wpb": "14447.4", "bsz": "83.2", "num_updates": "50800", "lr": "3e-05", "gnorm": "133.013", "loss_scale": "16", "train_wall": "64", "gb_free": "32.2", "wall": "16776"}
[2024-07-10 01:56:27,770][train_inner][INFO] - {"epoch": 30, "update": 29.123, "loss": "102.281", "ntokens": "14601.9", "nsentences": "82.68", "nll_loss": "0.579", "wps": "45798.8", "ups": "3.14", "wpb": "14601.9", "bsz": "82.7", "num_updates": "51000", "lr": "3e-05", "gnorm": "134.304", "loss_scale": "16", "train_wall": "63", "gb_free": "33.2", "wall": "16840"}
[2024-07-10 01:57:32,153][train_inner][INFO] - {"epoch": 30, "update": 29.237, "loss": "97.543", "ntokens": "14601.8", "nsentences": "84.84", "nll_loss": "0.567", "wps": "45362.5", "ups": "3.11", "wpb": "14601.8", "bsz": "84.8", "num_updates": "51200", "lr": "3e-05", "gnorm": "130.255", "loss_scale": "16", "train_wall": "64", "gb_free": "32.3", "wall": "16904"}
[2024-07-10 01:58:36,325][train_inner][INFO] - {"epoch": 30, "update": 29.352, "loss": "97.033", "ntokens": "14582.5", "nsentences": "84.72", "nll_loss": "0.564", "wps": "45451.9", "ups": "3.12", "wpb": "14582.5", "bsz": "84.7", "num_updates": "51400", "lr": "3e-05", "gnorm": "130.698", "loss_scale": "16", "train_wall": "64", "gb_free": "31.5", "wall": "16968"}
[2024-07-10 01:58:49,476][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 01:59:41,202][train_inner][INFO] - {"epoch": 30, "update": 29.466, "loss": "93.45", "ntokens": "14561.8", "nsentences": "85.28", "nll_loss": "0.547", "wps": "44895.1", "ups": "3.08", "wpb": "14561.8", "bsz": "85.3", "num_updates": "51600", "lr": "3e-05", "gnorm": "128.609", "loss_scale": "8", "train_wall": "64", "gb_free": "32.1", "wall": "17033"}
[2024-07-10 02:00:45,840][train_inner][INFO] - {"epoch": 30, "update": 29.58, "loss": "101.163", "ntokens": "14602.2", "nsentences": "82.36", "nll_loss": "0.571", "wps": "45224.9", "ups": "3.1", "wpb": "14602.2", "bsz": "82.4", "num_updates": "51800", "lr": "3e-05", "gnorm": "131.824", "loss_scale": "8", "train_wall": "64", "gb_free": "30.9", "wall": "17098"}
[2024-07-10 02:01:49,308][train_inner][INFO] - {"epoch": 30, "update": 29.695, "loss": "99.969", "ntokens": "14544.9", "nsentences": "83.995", "nll_loss": "0.577", "wps": "45840.1", "ups": "3.15", "wpb": "14544.9", "bsz": "84", "num_updates": "52000", "lr": "3e-05", "gnorm": "132.089", "loss_scale": "8", "train_wall": "63", "gb_free": "32.3", "wall": "17161"}
[2024-07-10 02:02:53,613][train_inner][INFO] - {"epoch": 30, "update": 29.809, "loss": "94.713", "ntokens": "14597.6", "nsentences": "85.72", "nll_loss": "0.556", "wps": "45404.5", "ups": "3.11", "wpb": "14597.6", "bsz": "85.7", "num_updates": "52200", "lr": "3e-05", "gnorm": "129.974", "loss_scale": "8", "train_wall": "64", "gb_free": "32.2", "wall": "17226"}
[2024-07-10 02:03:57,495][train_inner][INFO] - {"epoch": 30, "update": 29.923, "loss": "97.021", "ntokens": "14515", "nsentences": "85", "nll_loss": "0.568", "wps": "45446.2", "ups": "3.13", "wpb": "14515", "bsz": "85", "num_updates": "52400", "lr": "3e-05", "gnorm": "131.074", "loss_scale": "8", "train_wall": "63", "gb_free": "30.9", "wall": "17289"}
[2024-07-10 02:04:40,286][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 02:04:40,288][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 02:04:51,103][dev-other][INFO] - {"epoch": 30, "dev-other_loss": "24.108", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.256", "dev-other_uer": "4.188", "dev-other_wer": "11.186", "dev-other_raw_wer": "11.186", "dev-other_wps": "27611.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "52535", "dev-other_best_wer": "11.186"}
[2024-07-10 02:04:51,104][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 30 @ 52535 updates
[2024-07-10 02:04:51,105][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-10 02:04:52,365][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-10 02:04:52,973][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 30 @ 52535 updates, score 11.186) (writing took 1.8683042041957378 seconds)
[2024-07-10 02:04:52,973][fairseq_cli.train][INFO] - end of epoch 30 (average epoch stats below)
[2024-07-10 02:04:52,977][train][INFO] - {"epoch": 30, "train_loss": "97.204", "train_ntokens": "14576.4", "train_nsentences": "84.8652", "train_nll_loss": "0.566", "train_wps": "44372.8", "train_ups": "3.04", "train_wpb": "14576.4", "train_bsz": "84.9", "train_num_updates": "52535", "train_lr": "3e-05", "train_gnorm": "130.695", "train_loss_scale": "8", "train_train_wall": "557", "train_gb_free": "33.1", "train_wall": "17345"}
[2024-07-10 02:04:52,978][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 02:04:53,259][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 02:04:53,263][fairseq.trainer][INFO] - begin training epoch 31
[2024-07-10 02:04:53,263][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 02:05:13,872][train_inner][INFO] - {"epoch": 31, "update": 30.037, "loss": "96.762", "ntokens": "14498.3", "nsentences": "87.56", "nll_loss": "0.584", "wps": "37977.3", "ups": "2.62", "wpb": "14498.3", "bsz": "87.6", "num_updates": "52600", "lr": "3e-05", "gnorm": "127.673", "loss_scale": "8", "train_wall": "63", "gb_free": "32.1", "wall": "17366"}
[2024-07-10 02:06:18,226][train_inner][INFO] - {"epoch": 31, "update": 30.151, "loss": "94.851", "ntokens": "14689.2", "nsentences": "86.52", "nll_loss": "0.559", "wps": "45654.4", "ups": "3.11", "wpb": "14689.2", "bsz": "86.5", "num_updates": "52800", "lr": "3e-05", "gnorm": "128.59", "loss_scale": "8", "train_wall": "64", "gb_free": "32.4", "wall": "17430"}
[2024-07-10 02:07:21,963][train_inner][INFO] - {"epoch": 31, "update": 30.265, "loss": "97.071", "ntokens": "14488.6", "nsentences": "83.72", "nll_loss": "0.561", "wps": "45467", "ups": "3.14", "wpb": "14488.6", "bsz": "83.7", "num_updates": "53000", "lr": "3e-05", "gnorm": "130.793", "loss_scale": "8", "train_wall": "63", "gb_free": "33.2", "wall": "17494"}
[2024-07-10 02:08:25,899][train_inner][INFO] - {"epoch": 31, "update": 30.38, "loss": "96.189", "ntokens": "14591.6", "nsentences": "86", "nll_loss": "0.567", "wps": "45661.7", "ups": "3.13", "wpb": "14591.6", "bsz": "86", "num_updates": "53200", "lr": "3e-05", "gnorm": "128.701", "loss_scale": "8", "train_wall": "63", "gb_free": "32.9", "wall": "17558"}
[2024-07-10 02:09:30,404][train_inner][INFO] - {"epoch": 31, "update": 30.494, "loss": "93.588", "ntokens": "14607.3", "nsentences": "86.24", "nll_loss": "0.553", "wps": "45294.8", "ups": "3.1", "wpb": "14607.3", "bsz": "86.2", "num_updates": "53400", "lr": "3e-05", "gnorm": "128.768", "loss_scale": "8", "train_wall": "64", "gb_free": "31.5", "wall": "17622"}
[2024-07-10 02:10:34,848][train_inner][INFO] - {"epoch": 31, "update": 30.608, "loss": "96.276", "ntokens": "14578.6", "nsentences": "84.12", "nll_loss": "0.556", "wps": "45249.8", "ups": "3.1", "wpb": "14578.6", "bsz": "84.1", "num_updates": "53600", "lr": "3e-05", "gnorm": "129.964", "loss_scale": "16", "train_wall": "64", "gb_free": "32.5", "wall": "17687"}
[2024-07-10 02:11:09,322][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 02:11:39,219][train_inner][INFO] - {"epoch": 31, "update": 30.723, "loss": "100.273", "ntokens": "14586.7", "nsentences": "84.315", "nll_loss": "0.58", "wps": "45327.2", "ups": "3.11", "wpb": "14586.7", "bsz": "84.3", "num_updates": "53800", "lr": "3e-05", "gnorm": "130.792", "loss_scale": "8", "train_wall": "64", "gb_free": "32.4", "wall": "17751"}
[2024-07-10 02:12:43,616][train_inner][INFO] - {"epoch": 31, "update": 30.837, "loss": "96.137", "ntokens": "14577.2", "nsentences": "85.24", "nll_loss": "0.562", "wps": "45275.9", "ups": "3.11", "wpb": "14577.2", "bsz": "85.2", "num_updates": "54000", "lr": "3e-05", "gnorm": "128.815", "loss_scale": "8", "train_wall": "64", "gb_free": "31.4", "wall": "17816"}
[2024-07-10 02:13:47,312][train_inner][INFO] - {"epoch": 31, "update": 30.951, "loss": "98.262", "ntokens": "14640.4", "nsentences": "84.8", "nll_loss": "0.569", "wps": "45975", "ups": "3.14", "wpb": "14640.4", "bsz": "84.8", "num_updates": "54200", "lr": "3e-05", "gnorm": "132.778", "loss_scale": "8", "train_wall": "63", "gb_free": "30.6", "wall": "17879"}
[2024-07-10 02:14:14,730][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 02:14:14,732][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 02:14:25,599][dev-other][INFO] - {"epoch": 31, "dev-other_loss": "23.877", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.254", "dev-other_uer": "4.152", "dev-other_wer": "11.172", "dev-other_raw_wer": "11.172", "dev-other_wps": "27516.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "54286", "dev-other_best_wer": "11.172"}
[2024-07-10 02:14:25,600][fairseq_cli.train][INFO] - end of epoch 31 (average epoch stats below)
[2024-07-10 02:14:25,603][train][INFO] - {"epoch": 31, "train_loss": "96.934", "train_ntokens": "14577.8", "train_nsentences": "84.8789", "train_nll_loss": "0.564", "train_wps": "44576.9", "train_ups": "3.06", "train_wpb": "14577.8", "train_bsz": "84.9", "train_num_updates": "54286", "train_lr": "3e-05", "train_gnorm": "129.977", "train_loss_scale": "8", "train_train_wall": "557", "train_gb_free": "34.2", "train_wall": "17918"}
[2024-07-10 02:14:25,604][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 02:14:26,289][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 02:14:26,293][fairseq.trainer][INFO] - begin training epoch 32
[2024-07-10 02:14:26,293][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 02:15:03,176][train_inner][INFO] - {"epoch": 32, "update": 31.065, "loss": "96.657", "ntokens": "14545.1", "nsentences": "83.88", "nll_loss": "0.557", "wps": "38348.3", "ups": "2.64", "wpb": "14545.1", "bsz": "83.9", "num_updates": "54400", "lr": "3e-05", "gnorm": "131.966", "loss_scale": "8", "train_wall": "64", "gb_free": "31.4", "wall": "17955"}
[2024-07-10 02:16:07,438][train_inner][INFO] - {"epoch": 32, "update": 31.179, "loss": "91.833", "ntokens": "14689.5", "nsentences": "87.36", "nll_loss": "0.546", "wps": "45724.4", "ups": "3.11", "wpb": "14689.5", "bsz": "87.4", "num_updates": "54600", "lr": "3e-05", "gnorm": "128.612", "loss_scale": "8", "train_wall": "64", "gb_free": "31.4", "wall": "18019"}
[2024-07-10 02:17:11,439][train_inner][INFO] - {"epoch": 32, "update": 31.293, "loss": "94.292", "ntokens": "14519.8", "nsentences": "85.675", "nll_loss": "0.556", "wps": "45377.3", "ups": "3.13", "wpb": "14519.8", "bsz": "85.7", "num_updates": "54800", "lr": "3e-05", "gnorm": "129.183", "loss_scale": "8", "train_wall": "64", "gb_free": "32.1", "wall": "18083"}
[2024-07-10 02:18:15,482][train_inner][INFO] - {"epoch": 32, "update": 31.408, "loss": "99.034", "ntokens": "14531.5", "nsentences": "83.16", "nll_loss": "0.567", "wps": "45427", "ups": "3.13", "wpb": "14531.5", "bsz": "83.2", "num_updates": "55000", "lr": "3e-05", "gnorm": "132.954", "loss_scale": "8", "train_wall": "64", "gb_free": "32.5", "wall": "18147"}
[2024-07-10 02:19:20,167][train_inner][INFO] - {"epoch": 32, "update": 31.522, "loss": "95.792", "ntokens": "14590.6", "nsentences": "84.64", "nll_loss": "0.556", "wps": "45166.7", "ups": "3.1", "wpb": "14590.6", "bsz": "84.6", "num_updates": "55200", "lr": "3e-05", "gnorm": "130.875", "loss_scale": "8", "train_wall": "64", "gb_free": "29.9", "wall": "18212"}
[2024-07-10 02:20:24,456][train_inner][INFO] - {"epoch": 32, "update": 31.636, "loss": "92.754", "ntokens": "14591.1", "nsentences": "86.92", "nll_loss": "0.553", "wps": "45395.2", "ups": "3.11", "wpb": "14591.1", "bsz": "86.9", "num_updates": "55400", "lr": "3e-05", "gnorm": "128.076", "loss_scale": "8", "train_wall": "64", "gb_free": "32.2", "wall": "18276"}
[2024-07-10 02:21:28,473][train_inner][INFO] - {"epoch": 32, "update": 31.75, "loss": "96.008", "ntokens": "14566.9", "nsentences": "83.16", "nll_loss": "0.548", "wps": "45512.8", "ups": "3.12", "wpb": "14566.9", "bsz": "83.2", "num_updates": "55600", "lr": "3e-05", "gnorm": "132.853", "loss_scale": "8", "train_wall": "64", "gb_free": "32.5", "wall": "18340"}
[2024-07-10 02:22:32,314][train_inner][INFO] - {"epoch": 32, "update": 31.864, "loss": "98.113", "ntokens": "14635.7", "nsentences": "83.6", "nll_loss": "0.56", "wps": "45855.3", "ups": "3.13", "wpb": "14635.7", "bsz": "83.6", "num_updates": "55800", "lr": "3e-05", "gnorm": "132.418", "loss_scale": "16", "train_wall": "63", "gb_free": "33.1", "wall": "18404"}
[2024-07-10 02:23:36,132][train_inner][INFO] - {"epoch": 32, "update": 31.978, "loss": "95.346", "ntokens": "14504.6", "nsentences": "84.12", "nll_loss": "0.553", "wps": "45461.3", "ups": "3.13", "wpb": "14504.6", "bsz": "84.1", "num_updates": "56000", "lr": "3e-05", "gnorm": "129.496", "loss_scale": "16", "train_wall": "63", "gb_free": "32.3", "wall": "18468"}
[2024-07-10 02:23:48,383][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 02:23:48,384][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 02:23:59,067][dev-other][INFO] - {"epoch": 32, "dev-other_loss": "24.163", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.257", "dev-other_uer": "4.16", "dev-other_wer": "11.223", "dev-other_raw_wer": "11.223", "dev-other_wps": "27868.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "56038", "dev-other_best_wer": "11.186"}
[2024-07-10 02:23:59,067][fairseq_cli.train][INFO] - end of epoch 32 (average epoch stats below)
[2024-07-10 02:23:59,070][train][INFO] - {"epoch": 32, "train_loss": "95.246", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.554", "train_wps": "44536", "train_ups": "3.06", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "56038", "train_lr": "3e-05", "train_gnorm": "130.727", "train_loss_scale": "16", "train_train_wall": "558", "train_gb_free": "32.7", "train_wall": "18491"}
[2024-07-10 02:23:59,072][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 02:23:59,806][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 02:23:59,816][fairseq.trainer][INFO] - begin training epoch 33
[2024-07-10 02:23:59,816][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 02:24:52,029][train_inner][INFO] - {"epoch": 33, "update": 32.092, "loss": "93.857", "ntokens": "14583", "nsentences": "86.48", "nll_loss": "0.557", "wps": "38431.4", "ups": "2.64", "wpb": "14583", "bsz": "86.5", "num_updates": "56200", "lr": "3e-05", "gnorm": "131.029", "loss_scale": "16", "train_wall": "64", "gb_free": "32.3", "wall": "18544"}
[2024-07-10 02:25:55,607][train_inner][INFO] - {"epoch": 33, "update": 32.207, "loss": "98.593", "ntokens": "14535.3", "nsentences": "83.12", "nll_loss": "0.564", "wps": "45772.9", "ups": "3.15", "wpb": "14535.3", "bsz": "83.1", "num_updates": "56400", "lr": "3e-05", "gnorm": "132.002", "loss_scale": "16", "train_wall": "63", "gb_free": "31.6", "wall": "18608"}
[2024-07-10 02:26:59,695][train_inner][INFO] - {"epoch": 33, "update": 32.321, "loss": "95.691", "ntokens": "14605.8", "nsentences": "85.72", "nll_loss": "0.562", "wps": "45630.1", "ups": "3.12", "wpb": "14605.8", "bsz": "85.7", "num_updates": "56600", "lr": "3e-05", "gnorm": "127.084", "loss_scale": "16", "train_wall": "64", "gb_free": "31.4", "wall": "18672"}
[2024-07-10 02:27:14,923][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 02:28:03,932][train_inner][INFO] - {"epoch": 33, "update": 32.436, "loss": "95.589", "ntokens": "14563.4", "nsentences": "85.2", "nll_loss": "0.559", "wps": "45346.3", "ups": "3.11", "wpb": "14563.4", "bsz": "85.2", "num_updates": "56800", "lr": "3e-05", "gnorm": "131.911", "loss_scale": "8", "train_wall": "64", "gb_free": "32.6", "wall": "18736"}
[2024-07-10 02:29:08,092][train_inner][INFO] - {"epoch": 33, "update": 32.55, "loss": "98.137", "ntokens": "14625.8", "nsentences": "84.32", "nll_loss": "0.566", "wps": "45594", "ups": "3.12", "wpb": "14625.8", "bsz": "84.3", "num_updates": "57000", "lr": "3e-05", "gnorm": "130.369", "loss_scale": "8", "train_wall": "64", "gb_free": "32.3", "wall": "18800"}
[2024-07-10 02:30:12,816][train_inner][INFO] - {"epoch": 33, "update": 32.664, "loss": "94.42", "ntokens": "14610.4", "nsentences": "85.28", "nll_loss": "0.551", "wps": "45150.9", "ups": "3.09", "wpb": "14610.4", "bsz": "85.3", "num_updates": "57200", "lr": "3e-05", "gnorm": "128.453", "loss_scale": "8", "train_wall": "64", "gb_free": "29.9", "wall": "18865"}
[2024-07-10 02:31:17,400][train_inner][INFO] - {"epoch": 33, "update": 32.778, "loss": "95.771", "ntokens": "14650.6", "nsentences": "85.08", "nll_loss": "0.556", "wps": "45421.8", "ups": "3.1", "wpb": "14650.6", "bsz": "85.1", "num_updates": "57400", "lr": "3e-05", "gnorm": "130.479", "loss_scale": "8", "train_wall": "64", "gb_free": "32.5", "wall": "18929"}
[2024-07-10 02:32:21,232][train_inner][INFO] - {"epoch": 33, "update": 32.892, "loss": "95.458", "ntokens": "14449.1", "nsentences": "82.835", "nll_loss": "0.547", "wps": "45279.4", "ups": "3.13", "wpb": "14449.1", "bsz": "82.8", "num_updates": "57600", "lr": "3e-05", "gnorm": "132.928", "loss_scale": "8", "train_wall": "63", "gb_free": "33.1", "wall": "18993"}
[2024-07-10 02:33:21,587][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 02:33:21,589][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 02:33:32,312][dev-other][INFO] - {"epoch": 33, "dev-other_loss": "23.686", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.252", "dev-other_uer": "4.086", "dev-other_wer": "11.162", "dev-other_raw_wer": "11.162", "dev-other_wps": "27689.3", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "57789", "dev-other_best_wer": "11.162"}
[2024-07-10 02:33:32,313][fairseq_cli.train][INFO] - end of epoch 33 (average epoch stats below)
[2024-07-10 02:33:32,315][train][INFO] - {"epoch": 33, "train_loss": "95.98", "train_ntokens": "14577.4", "train_nsentences": "84.8104", "train_nll_loss": "0.558", "train_wps": "44527.5", "train_ups": "3.05", "train_wpb": "14577.4", "train_bsz": "84.8", "train_num_updates": "57789", "train_lr": "3e-05", "train_gnorm": "130.382", "train_loss_scale": "8", "train_train_wall": "557", "train_gb_free": "31.7", "train_wall": "19064"}
[2024-07-10 02:33:32,316][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 02:33:33,041][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 02:33:33,045][fairseq.trainer][INFO] - begin training epoch 34
[2024-07-10 02:33:33,045][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 02:33:36,833][train_inner][INFO] - {"epoch": 34, "update": 33.006, "loss": "94.718", "ntokens": "14534.2", "nsentences": "85.6", "nll_loss": "0.558", "wps": "38482.7", "ups": "2.65", "wpb": "14534.2", "bsz": "85.6", "num_updates": "57800", "lr": "3e-05", "gnorm": "129.3", "loss_scale": "8", "train_wall": "63", "gb_free": "32.2", "wall": "19069"}
[2024-07-10 02:34:40,686][train_inner][INFO] - {"epoch": 34, "update": 33.12, "loss": "97.735", "ntokens": "14515.8", "nsentences": "84.08", "nll_loss": "0.566", "wps": "45469.3", "ups": "3.13", "wpb": "14515.8", "bsz": "84.1", "num_updates": "58000", "lr": "3e-05", "gnorm": "131.49", "loss_scale": "8", "train_wall": "63", "gb_free": "32.9", "wall": "19133"}
[2024-07-10 02:35:44,927][train_inner][INFO] - {"epoch": 34, "update": 33.235, "loss": "92.931", "ntokens": "14612", "nsentences": "86.84", "nll_loss": "0.552", "wps": "45495.2", "ups": "3.11", "wpb": "14612", "bsz": "86.8", "num_updates": "58200", "lr": "3e-05", "gnorm": "128.926", "loss_scale": "8", "train_wall": "64", "gb_free": "31.6", "wall": "19197"}
[2024-07-10 02:36:49,419][train_inner][INFO] - {"epoch": 34, "update": 33.349, "loss": "96.031", "ntokens": "14665.8", "nsentences": "84.28", "nll_loss": "0.552", "wps": "45522.6", "ups": "3.1", "wpb": "14665.8", "bsz": "84.3", "num_updates": "58400", "lr": "3e-05", "gnorm": "131.17", "loss_scale": "8", "train_wall": "64", "gb_free": "32.2", "wall": "19261"}
[2024-07-10 02:37:54,246][train_inner][INFO] - {"epoch": 34, "update": 33.463, "loss": "91.73", "ntokens": "14621.8", "nsentences": "84.84", "nll_loss": "0.532", "wps": "45114.8", "ups": "3.09", "wpb": "14621.8", "bsz": "84.8", "num_updates": "58600", "lr": "3e-05", "gnorm": "130.164", "loss_scale": "8", "train_wall": "64", "gb_free": "31.4", "wall": "19326"}
[2024-07-10 02:38:58,298][train_inner][INFO] - {"epoch": 34, "update": 33.577, "loss": "93.442", "ntokens": "14561.3", "nsentences": "85.475", "nll_loss": "0.549", "wps": "45512.4", "ups": "3.13", "wpb": "14561.3", "bsz": "85.5", "num_updates": "58800", "lr": "3e-05", "gnorm": "129.362", "loss_scale": "16", "train_wall": "64", "gb_free": "32.3", "wall": "19390"}
[2024-07-10 02:39:01,804][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 02:40:02,288][train_inner][INFO] - {"epoch": 34, "update": 33.692, "loss": "97.95", "ntokens": "14517.5", "nsentences": "82.4", "nll_loss": "0.556", "wps": "45419.4", "ups": "3.13", "wpb": "14517.5", "bsz": "82.4", "num_updates": "59000", "lr": "3e-05", "gnorm": "132.033", "loss_scale": "8", "train_wall": "63", "gb_free": "32.2", "wall": "19454"}
[2024-07-10 02:41:06,010][train_inner][INFO] - {"epoch": 34, "update": 33.806, "loss": "93.719", "ntokens": "14587.2", "nsentences": "85.8", "nll_loss": "0.551", "wps": "45828.9", "ups": "3.14", "wpb": "14587.2", "bsz": "85.8", "num_updates": "59200", "lr": "3e-05", "gnorm": "128.964", "loss_scale": "8", "train_wall": "63", "gb_free": "31.6", "wall": "19518"}
[2024-07-10 02:42:09,958][train_inner][INFO] - {"epoch": 34, "update": 33.92, "loss": "95.131", "ntokens": "14583.8", "nsentences": "84.84", "nll_loss": "0.553", "wps": "45615.3", "ups": "3.13", "wpb": "14583.8", "bsz": "84.8", "num_updates": "59400", "lr": "3e-05", "gnorm": "130.909", "loss_scale": "8", "train_wall": "63", "gb_free": "31.6", "wall": "19582"}
[2024-07-10 02:42:54,056][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 02:42:54,057][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 02:43:04,857][dev-other][INFO] - {"epoch": 34, "dev-other_loss": "24.427", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.26", "dev-other_uer": "4.126", "dev-other_wer": "11.111", "dev-other_raw_wer": "11.111", "dev-other_wps": "27740", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "59540", "dev-other_best_wer": "11.111"}
[2024-07-10 02:43:04,858][fairseq_cli.train][INFO] - end of epoch 34 (average epoch stats below)
[2024-07-10 02:43:04,915][train][INFO] - {"epoch": 34, "train_loss": "94.909", "train_ntokens": "14578.2", "train_nsentences": "84.8241", "train_nll_loss": "0.552", "train_wps": "44584.4", "train_ups": "3.06", "train_wpb": "14578.2", "train_bsz": "84.8", "train_num_updates": "59540", "train_lr": "3e-05", "train_gnorm": "130.327", "train_loss_scale": "8", "train_train_wall": "556", "train_gb_free": "33.7", "train_wall": "19637"}
[2024-07-10 02:43:04,917][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 02:43:05,525][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 02:43:05,529][fairseq.trainer][INFO] - begin training epoch 35
[2024-07-10 02:43:05,529][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 02:43:25,023][train_inner][INFO] - {"epoch": 35, "update": 34.034, "loss": "94.824", "ntokens": "14544.1", "nsentences": "85.28", "nll_loss": "0.556", "wps": "38753.4", "ups": "2.66", "wpb": "14544.1", "bsz": "85.3", "num_updates": "59600", "lr": "3e-05", "gnorm": "129.519", "loss_scale": "8", "train_wall": "63", "gb_free": "31.2", "wall": "19657"}
[2024-07-10 02:44:29,326][train_inner][INFO] - {"epoch": 35, "update": 34.148, "loss": "94.345", "ntokens": "14617.7", "nsentences": "85.2", "nll_loss": "0.55", "wps": "45467.6", "ups": "3.11", "wpb": "14617.7", "bsz": "85.2", "num_updates": "59800", "lr": "3e-05", "gnorm": "131.651", "loss_scale": "8", "train_wall": "64", "gb_free": "32.1", "wall": "19721"}
[2024-07-10 02:45:33,348][train_inner][INFO] - {"epoch": 35, "update": 34.263, "loss": "90.701", "ntokens": "14596.3", "nsentences": "86.92", "nll_loss": "0.54", "wps": "45602.9", "ups": "3.12", "wpb": "14596.3", "bsz": "86.9", "num_updates": "60000", "lr": "3e-05", "gnorm": "129.79", "loss_scale": "8", "train_wall": "64", "gb_free": "31.9", "wall": "19785"}
[2024-07-10 02:46:37,770][train_inner][INFO] - {"epoch": 35, "update": 34.377, "loss": "93.223", "ntokens": "14612.8", "nsentences": "83.68", "nll_loss": "0.534", "wps": "45371.3", "ups": "3.1", "wpb": "14612.8", "bsz": "83.7", "num_updates": "60200", "lr": "2.97019e-05", "gnorm": "130.405", "loss_scale": "8", "train_wall": "64", "gb_free": "29.9", "wall": "19850"}
[2024-07-10 02:47:42,425][train_inner][INFO] - {"epoch": 35, "update": 34.491, "loss": "96.249", "ntokens": "14584.2", "nsentences": "84.68", "nll_loss": "0.559", "wps": "45171.5", "ups": "3.1", "wpb": "14584.2", "bsz": "84.7", "num_updates": "60400", "lr": "2.94068e-05", "gnorm": "130.814", "loss_scale": "8", "train_wall": "64", "gb_free": "31.3", "wall": "19914"}
[2024-07-10 02:48:46,636][train_inner][INFO] - {"epoch": 35, "update": 34.605, "loss": "93.613", "ntokens": "14616.5", "nsentences": "85.72", "nll_loss": "0.549", "wps": "45533.6", "ups": "3.12", "wpb": "14616.5", "bsz": "85.7", "num_updates": "60600", "lr": "2.91146e-05", "gnorm": "129.005", "loss_scale": "8", "train_wall": "64", "gb_free": "31.9", "wall": "19979"}
[2024-07-10 02:49:50,857][train_inner][INFO] - {"epoch": 35, "update": 34.719, "loss": "93.42", "ntokens": "14564.5", "nsentences": "85.04", "nll_loss": "0.545", "wps": "45363.9", "ups": "3.11", "wpb": "14564.5", "bsz": "85", "num_updates": "60800", "lr": "2.88253e-05", "gnorm": "129.364", "loss_scale": "8", "train_wall": "64", "gb_free": "32.1", "wall": "20043"}
[2024-07-10 02:50:54,861][train_inner][INFO] - {"epoch": 35, "update": 34.833, "loss": "95.333", "ntokens": "14602.2", "nsentences": "84.44", "nll_loss": "0.551", "wps": "45779.7", "ups": "3.14", "wpb": "14602.2", "bsz": "84.4", "num_updates": "61000", "lr": "2.85389e-05", "gnorm": "130.101", "loss_scale": "16", "train_wall": "63", "gb_free": "32.8", "wall": "20107"}
[2024-07-10 02:51:39,622][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 02:51:59,306][train_inner][INFO] - {"epoch": 35, "update": 34.948, "loss": "94.451", "ntokens": "14575.7", "nsentences": "83.92", "nll_loss": "0.544", "wps": "45239.2", "ups": "3.1", "wpb": "14575.7", "bsz": "83.9", "num_updates": "61200", "lr": "2.82553e-05", "gnorm": "132.351", "loss_scale": "8", "train_wall": "64", "gb_free": "32.4", "wall": "20171"}
[2024-07-10 02:52:27,901][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 02:52:27,902][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 02:52:38,606][dev-other][INFO] - {"epoch": 35, "dev-other_loss": "24.215", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.257", "dev-other_uer": "4.101", "dev-other_wer": "11.023", "dev-other_raw_wer": "11.023", "dev-other_wps": "27737.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "61291", "dev-other_best_wer": "11.023"}
[2024-07-10 02:52:38,607][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 35 @ 61291 updates
[2024-07-10 02:52:38,608][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-10 02:52:39,885][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-10 02:52:40,495][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 35 @ 61291 updates, score 11.023) (writing took 1.8880630210042 seconds)
[2024-07-10 02:52:40,495][fairseq_cli.train][INFO] - end of epoch 35 (average epoch stats below)
[2024-07-10 02:52:40,499][train][INFO] - {"epoch": 35, "train_loss": "93.987", "train_ntokens": "14577.2", "train_nsentences": "84.8698", "train_nll_loss": "0.547", "train_wps": "44345.9", "train_ups": "3.04", "train_wpb": "14577.2", "train_bsz": "84.9", "train_num_updates": "61291", "train_lr": "2.81273e-05", "train_gnorm": "130.435", "train_loss_scale": "8", "train_train_wall": "558", "train_gb_free": "34.3", "train_wall": "20212"}
[2024-07-10 02:52:40,501][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 02:52:40,793][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 02:52:40,796][fairseq.trainer][INFO] - begin training epoch 36
[2024-07-10 02:52:40,796][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 02:53:15,654][train_inner][INFO] - {"epoch": 36, "update": 35.062, "loss": "98.255", "ntokens": "14393.3", "nsentences": "82.315", "nll_loss": "0.562", "wps": "37711.5", "ups": "2.62", "wpb": "14393.3", "bsz": "82.3", "num_updates": "61400", "lr": "2.79746e-05", "gnorm": "132.918", "loss_scale": "8", "train_wall": "63", "gb_free": "33.1", "wall": "20248"}
[2024-07-10 02:54:20,043][train_inner][INFO] - {"epoch": 36, "update": 35.176, "loss": "92.335", "ntokens": "14603.3", "nsentences": "85.48", "nll_loss": "0.54", "wps": "45363.1", "ups": "3.11", "wpb": "14603.3", "bsz": "85.5", "num_updates": "61600", "lr": "2.76966e-05", "gnorm": "130.347", "loss_scale": "8", "train_wall": "64", "gb_free": "31.7", "wall": "20312"}
[2024-07-10 02:55:24,529][train_inner][INFO] - {"epoch": 36, "update": 35.291, "loss": "93.318", "ntokens": "14551.1", "nsentences": "85.96", "nll_loss": "0.551", "wps": "45145.7", "ups": "3.1", "wpb": "14551.1", "bsz": "86", "num_updates": "61800", "lr": "2.74214e-05", "gnorm": "128.03", "loss_scale": "8", "train_wall": "64", "gb_free": "33", "wall": "20376"}
[2024-07-10 02:56:28,106][train_inner][INFO] - {"epoch": 36, "update": 35.405, "loss": "96.933", "ntokens": "14545.6", "nsentences": "83.48", "nll_loss": "0.556", "wps": "45761.2", "ups": "3.15", "wpb": "14545.6", "bsz": "83.5", "num_updates": "62000", "lr": "2.7149e-05", "gnorm": "132", "loss_scale": "8", "train_wall": "63", "gb_free": "29.8", "wall": "20440"}
[2024-07-10 02:57:32,192][train_inner][INFO] - {"epoch": 36, "update": 35.519, "loss": "101.622", "ntokens": "14591.7", "nsentences": "83", "nll_loss": "0.578", "wps": "45542.7", "ups": "3.12", "wpb": "14591.7", "bsz": "83", "num_updates": "62200", "lr": "2.68792e-05", "gnorm": "134.137", "loss_scale": "8", "train_wall": "64", "gb_free": "31.4", "wall": "20504"}
[2024-07-10 02:58:36,553][train_inner][INFO] - {"epoch": 36, "update": 35.633, "loss": "92.394", "ntokens": "14712.9", "nsentences": "87.48", "nll_loss": "0.549", "wps": "45767.9", "ups": "3.11", "wpb": "14712.9", "bsz": "87.5", "num_updates": "62400", "lr": "2.66122e-05", "gnorm": "128.83", "loss_scale": "8", "train_wall": "64", "gb_free": "32", "wall": "20568"}
[2024-07-10 02:59:40,430][train_inner][INFO] - {"epoch": 36, "update": 35.747, "loss": "94.949", "ntokens": "14515.9", "nsentences": "86.555", "nll_loss": "0.566", "wps": "45454", "ups": "3.13", "wpb": "14515.9", "bsz": "86.6", "num_updates": "62600", "lr": "2.63477e-05", "gnorm": "130.817", "loss_scale": "8", "train_wall": "63", "gb_free": "31.4", "wall": "20632"}
[2024-07-10 03:00:43,910][train_inner][INFO] - {"epoch": 36, "update": 35.861, "loss": "95.606", "ntokens": "14630", "nsentences": "83.72", "nll_loss": "0.547", "wps": "46096.3", "ups": "3.15", "wpb": "14630", "bsz": "83.7", "num_updates": "62800", "lr": "2.60859e-05", "gnorm": "129.6", "loss_scale": "8", "train_wall": "63", "gb_free": "33.3", "wall": "20696"}
[2024-07-10 03:01:47,966][train_inner][INFO] - {"epoch": 36, "update": 35.975, "loss": "91.467", "ntokens": "14580.9", "nsentences": "85.12", "nll_loss": "0.534", "wps": "45529.2", "ups": "3.12", "wpb": "14580.9", "bsz": "85.1", "num_updates": "63000", "lr": "2.58267e-05", "gnorm": "129.712", "loss_scale": "8", "train_wall": "64", "gb_free": "32.6", "wall": "20760"}
[2024-07-10 03:02:01,606][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 03:02:01,607][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 03:02:12,370][dev-other][INFO] - {"epoch": 36, "dev-other_loss": "24.226", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.258", "dev-other_uer": "4.104", "dev-other_wer": "11.015", "dev-other_raw_wer": "11.015", "dev-other_wps": "27644.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "63043", "dev-other_best_wer": "11.015"}
[2024-07-10 03:02:12,370][fairseq_cli.train][INFO] - end of epoch 36 (average epoch stats below)
[2024-07-10 03:02:12,373][train][INFO] - {"epoch": 36, "train_loss": "94.989", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.553", "train_wps": "44660.1", "train_ups": "3.06", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "63043", "train_lr": "2.57714e-05", "train_gnorm": "130.71", "train_loss_scale": "8", "train_train_wall": "556", "train_gb_free": "33", "train_wall": "20784"}
[2024-07-10 03:02:12,374][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 03:02:13,090][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 03:02:13,106][fairseq.trainer][INFO] - begin training epoch 37
[2024-07-10 03:02:13,106][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 03:03:03,154][train_inner][INFO] - {"epoch": 37, "update": 36.09, "loss": "95.37", "ntokens": "14433.4", "nsentences": "83.4", "nll_loss": "0.551", "wps": "38425.4", "ups": "2.66", "wpb": "14433.4", "bsz": "83.4", "num_updates": "63200", "lr": "2.55701e-05", "gnorm": "132.389", "loss_scale": "16", "train_wall": "63", "gb_free": "33.3", "wall": "20835"}
[2024-07-10 03:04:07,179][train_inner][INFO] - {"epoch": 37, "update": 36.204, "loss": "92.263", "ntokens": "14589.5", "nsentences": "84.04", "nll_loss": "0.531", "wps": "45577.8", "ups": "3.12", "wpb": "14589.5", "bsz": "84", "num_updates": "63400", "lr": "2.53161e-05", "gnorm": "130.27", "loss_scale": "16", "train_wall": "64", "gb_free": "32.7", "wall": "20899"}
[2024-07-10 03:05:11,542][train_inner][INFO] - {"epoch": 37, "update": 36.318, "loss": "90.283", "ntokens": "14588.9", "nsentences": "85.72", "nll_loss": "0.53", "wps": "45336.4", "ups": "3.11", "wpb": "14588.9", "bsz": "85.7", "num_updates": "63600", "lr": "2.50645e-05", "gnorm": "129.485", "loss_scale": "16", "train_wall": "64", "gb_free": "32", "wall": "20964"}
[2024-07-10 03:06:15,956][train_inner][INFO] - {"epoch": 37, "update": 36.432, "loss": "88.622", "ntokens": "14691.9", "nsentences": "87.275", "nll_loss": "0.526", "wps": "45624.9", "ups": "3.11", "wpb": "14691.9", "bsz": "87.3", "num_updates": "63800", "lr": "2.48155e-05", "gnorm": "127.902", "loss_scale": "16", "train_wall": "64", "gb_free": "29.3", "wall": "21028"}
[2024-07-10 03:06:58,344][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 03:07:19,543][train_inner][INFO] - {"epoch": 37, "update": 36.547, "loss": "98.197", "ntokens": "14536.5", "nsentences": "83.28", "nll_loss": "0.563", "wps": "45728.4", "ups": "3.15", "wpb": "14536.6", "bsz": "83.3", "num_updates": "64000", "lr": "2.45689e-05", "gnorm": "132.444", "loss_scale": "8", "train_wall": "63", "gb_free": "33.1", "wall": "21092"}
[2024-07-10 03:08:23,517][train_inner][INFO] - {"epoch": 37, "update": 36.661, "loss": "92.986", "ntokens": "14538", "nsentences": "84.84", "nll_loss": "0.543", "wps": "45452.6", "ups": "3.13", "wpb": "14538", "bsz": "84.8", "num_updates": "64200", "lr": "2.43248e-05", "gnorm": "130.711", "loss_scale": "8", "train_wall": "64", "gb_free": "32.4", "wall": "21155"}
[2024-07-10 03:09:27,202][train_inner][INFO] - {"epoch": 37, "update": 36.775, "loss": "95.181", "ntokens": "14623.5", "nsentences": "84.6", "nll_loss": "0.551", "wps": "45928.7", "ups": "3.14", "wpb": "14623.5", "bsz": "84.6", "num_updates": "64400", "lr": "2.40831e-05", "gnorm": "130.596", "loss_scale": "8", "train_wall": "63", "gb_free": "32.2", "wall": "21219"}
[2024-07-10 03:10:31,494][train_inner][INFO] - {"epoch": 37, "update": 36.889, "loss": "94.995", "ntokens": "14576.8", "nsentences": "84.52", "nll_loss": "0.551", "wps": "45394.9", "ups": "3.11", "wpb": "14576.8", "bsz": "84.5", "num_updates": "64600", "lr": "2.38438e-05", "gnorm": "130.792", "loss_scale": "8", "train_wall": "64", "gb_free": "32.7", "wall": "21283"}
[2024-07-10 03:11:33,793][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 03:11:33,796][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 03:11:44,548][dev-other][INFO] - {"epoch": 37, "dev-other_loss": "23.455", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.249", "dev-other_uer": "4", "dev-other_wer": "10.811", "dev-other_raw_wer": "10.811", "dev-other_wps": "27666.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "64794", "dev-other_best_wer": "10.811"}
[2024-07-10 03:11:44,549][fairseq_cli.train][INFO] - end of epoch 37 (average epoch stats below)
[2024-07-10 03:11:44,568][train][INFO] - {"epoch": 37, "train_loss": "93.335", "train_ntokens": "14578.8", "train_nsentences": "84.8241", "train_nll_loss": "0.543", "train_wps": "44614.8", "train_ups": "3.06", "train_wpb": "14578.8", "train_bsz": "84.8", "train_num_updates": "64794", "train_lr": "2.3614e-05", "train_gnorm": "130.306", "train_loss_scale": "8", "train_train_wall": "556", "train_gb_free": "32.6", "train_wall": "21357"}
[2024-07-10 03:11:44,569][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 03:11:45,307][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 03:11:45,312][fairseq.trainer][INFO] - begin training epoch 38
[2024-07-10 03:11:45,312][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 03:11:47,432][train_inner][INFO] - {"epoch": 38, "update": 37.003, "loss": "91.836", "ntokens": "14544", "nsentences": "85.4", "nll_loss": "0.539", "wps": "38308.7", "ups": "2.63", "wpb": "14544", "bsz": "85.4", "num_updates": "64800", "lr": "2.36069e-05", "gnorm": "128.796", "loss_scale": "8", "train_wall": "64", "gb_free": "30.5", "wall": "21359"}
[2024-07-10 03:12:51,232][train_inner][INFO] - {"epoch": 38, "update": 37.118, "loss": "96.097", "ntokens": "14535.9", "nsentences": "84.32", "nll_loss": "0.557", "wps": "45568.4", "ups": "3.13", "wpb": "14535.9", "bsz": "84.3", "num_updates": "65000", "lr": "2.33723e-05", "gnorm": "131.433", "loss_scale": "8", "train_wall": "63", "gb_free": "31.8", "wall": "21423"}
[2024-07-10 03:13:55,025][train_inner][INFO] - {"epoch": 38, "update": 37.232, "loss": "93.22", "ntokens": "14650.1", "nsentences": "85.84", "nll_loss": "0.546", "wps": "45979.6", "ups": "3.14", "wpb": "14650.1", "bsz": "85.8", "num_updates": "65200", "lr": "2.31401e-05", "gnorm": "129.368", "loss_scale": "8", "train_wall": "63", "gb_free": "31.8", "wall": "21487"}
[2024-07-10 03:14:59,295][train_inner][INFO] - {"epoch": 38, "update": 37.346, "loss": "92.584", "ntokens": "14643", "nsentences": "86.4", "nll_loss": "0.546", "wps": "45570.4", "ups": "3.11", "wpb": "14643", "bsz": "86.4", "num_updates": "65400", "lr": "2.29102e-05", "gnorm": "131.528", "loss_scale": "8", "train_wall": "64", "gb_free": "32.7", "wall": "21551"}
[2024-07-10 03:16:03,652][train_inner][INFO] - {"epoch": 38, "update": 37.46, "loss": "93.676", "ntokens": "14587", "nsentences": "83.16", "nll_loss": "0.534", "wps": "45340.9", "ups": "3.11", "wpb": "14587", "bsz": "83.2", "num_updates": "65600", "lr": "2.26825e-05", "gnorm": "131.461", "loss_scale": "8", "train_wall": "64", "gb_free": "32.7", "wall": "21616"}
[2024-07-10 03:17:08,005][train_inner][INFO] - {"epoch": 38, "update": 37.574, "loss": "91.778", "ntokens": "14651.5", "nsentences": "86.915", "nll_loss": "0.544", "wps": "45581", "ups": "3.11", "wpb": "14651.5", "bsz": "86.9", "num_updates": "65800", "lr": "2.24572e-05", "gnorm": "129.338", "loss_scale": "8", "train_wall": "64", "gb_free": "32.4", "wall": "21680"}
[2024-07-10 03:18:11,688][train_inner][INFO] - {"epoch": 38, "update": 37.688, "loss": "92.881", "ntokens": "14557.4", "nsentences": "84.16", "nll_loss": "0.537", "wps": "45777.7", "ups": "3.14", "wpb": "14557.4", "bsz": "84.2", "num_updates": "66000", "lr": "2.2234e-05", "gnorm": "129.649", "loss_scale": "16", "train_wall": "63", "gb_free": "31.3", "wall": "21744"}
[2024-07-10 03:19:15,555][train_inner][INFO] - {"epoch": 38, "update": 37.803, "loss": "96.681", "ntokens": "14516.1", "nsentences": "80.96", "nll_loss": "0.539", "wps": "45462.4", "ups": "3.13", "wpb": "14516.1", "bsz": "81", "num_updates": "66200", "lr": "2.20131e-05", "gnorm": "135.356", "loss_scale": "16", "train_wall": "63", "gb_free": "33.1", "wall": "21808"}
[2024-07-10 03:20:19,858][train_inner][INFO] - {"epoch": 38, "update": 37.917, "loss": "89.7", "ntokens": "14536.5", "nsentences": "87.2", "nll_loss": "0.538", "wps": "45216.6", "ups": "3.11", "wpb": "14536.5", "bsz": "87.2", "num_updates": "66400", "lr": "2.17944e-05", "gnorm": "126.912", "loss_scale": "16", "train_wall": "64", "gb_free": "32.6", "wall": "21872"}
[2024-07-10 03:20:29,325][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 03:21:06,009][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 03:21:06,010][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 03:21:16,712][dev-other][INFO] - {"epoch": 38, "dev-other_loss": "23.705", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.252", "dev-other_uer": "4.058", "dev-other_wer": "10.913", "dev-other_raw_wer": "10.913", "dev-other_wps": "27749.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "66545", "dev-other_best_wer": "10.913"}
[2024-07-10 03:21:16,713][fairseq_cli.train][INFO] - end of epoch 38 (average epoch stats below)
[2024-07-10 03:21:16,715][train][INFO] - {"epoch": 38, "train_loss": "93.522", "train_ntokens": "14578", "train_nsentences": "84.815", "train_nll_loss": "0.544", "train_wps": "44614.6", "train_ups": "3.06", "train_wpb": "14578", "train_bsz": "84.8", "train_num_updates": "66545", "train_lr": "2.16372e-05", "train_gnorm": "131.083", "train_loss_scale": "8", "train_train_wall": "556", "train_gb_free": "31.9", "train_wall": "21929"}
[2024-07-10 03:21:16,717][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 03:21:17,470][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 03:21:17,476][fairseq.trainer][INFO] - begin training epoch 39
[2024-07-10 03:21:17,476][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 03:21:35,494][train_inner][INFO] - {"epoch": 39, "update": 38.031, "loss": "94.486", "ntokens": "14546.3", "nsentences": "85.16", "nll_loss": "0.553", "wps": "38477.7", "ups": "2.65", "wpb": "14546.3", "bsz": "85.2", "num_updates": "66600", "lr": "2.15778e-05", "gnorm": "133.836", "loss_scale": "8", "train_wall": "64", "gb_free": "32.7", "wall": "21947"}
[2024-07-10 03:22:39,365][train_inner][INFO] - {"epoch": 39, "update": 38.146, "loss": "95.899", "ntokens": "14564.7", "nsentences": "84", "nll_loss": "0.553", "wps": "45610.2", "ups": "3.13", "wpb": "14564.7", "bsz": "84", "num_updates": "66800", "lr": "2.13634e-05", "gnorm": "131.251", "loss_scale": "8", "train_wall": "63", "gb_free": "33", "wall": "22011"}
[2024-07-10 03:23:43,095][train_inner][INFO] - {"epoch": 39, "update": 38.26, "loss": "94.311", "ntokens": "14635.9", "nsentences": "84.235", "nll_loss": "0.543", "wps": "45933.9", "ups": "3.14", "wpb": "14635.9", "bsz": "84.2", "num_updates": "67000", "lr": "2.11512e-05", "gnorm": "130.779", "loss_scale": "8", "train_wall": "63", "gb_free": "32.1", "wall": "22075"}
[2024-07-10 03:24:46,504][train_inner][INFO] - {"epoch": 39, "update": 38.374, "loss": "92.195", "ntokens": "14475.3", "nsentences": "83.84", "nll_loss": "0.534", "wps": "45709.8", "ups": "3.16", "wpb": "14475.3", "bsz": "83.8", "num_updates": "67200", "lr": "2.0941e-05", "gnorm": "131.641", "loss_scale": "8", "train_wall": "63", "gb_free": "32.6", "wall": "22138"}
[2024-07-10 03:25:49,911][train_inner][INFO] - {"epoch": 39, "update": 38.488, "loss": "92.017", "ntokens": "14627.8", "nsentences": "86.12", "nll_loss": "0.542", "wps": "46142.7", "ups": "3.15", "wpb": "14627.8", "bsz": "86.1", "num_updates": "67400", "lr": "2.07329e-05", "gnorm": "129.181", "loss_scale": "8", "train_wall": "63", "gb_free": "31", "wall": "22202"}
[2024-07-10 03:26:53,820][train_inner][INFO] - {"epoch": 39, "update": 38.602, "loss": "93.534", "ntokens": "14493.4", "nsentences": "84.08", "nll_loss": "0.543", "wps": "45361.1", "ups": "3.13", "wpb": "14493.4", "bsz": "84.1", "num_updates": "67600", "lr": "2.05269e-05", "gnorm": "131.541", "loss_scale": "8", "train_wall": "63", "gb_free": "32.8", "wall": "22266"}
[2024-07-10 03:27:57,635][train_inner][INFO] - {"epoch": 39, "update": 38.716, "loss": "92.997", "ntokens": "14612", "nsentences": "85.76", "nll_loss": "0.546", "wps": "45798.4", "ups": "3.13", "wpb": "14612", "bsz": "85.8", "num_updates": "67800", "lr": "2.0323e-05", "gnorm": "129.854", "loss_scale": "8", "train_wall": "63", "gb_free": "32.5", "wall": "22330"}
[2024-07-10 03:29:01,710][train_inner][INFO] - {"epoch": 39, "update": 38.83, "loss": "93.044", "ntokens": "14634.4", "nsentences": "85.84", "nll_loss": "0.546", "wps": "45682.7", "ups": "3.12", "wpb": "14634.4", "bsz": "85.8", "num_updates": "68000", "lr": "2.0121e-05", "gnorm": "128.17", "loss_scale": "8", "train_wall": "64", "gb_free": "31.6", "wall": "22394"}
[2024-07-10 03:30:05,583][train_inner][INFO] - {"epoch": 39, "update": 38.945, "loss": "93.304", "ntokens": "14627.8", "nsentences": "85.76", "nll_loss": "0.547", "wps": "45806.5", "ups": "3.13", "wpb": "14627.8", "bsz": "85.8", "num_updates": "68200", "lr": "1.99211e-05", "gnorm": "129.245", "loss_scale": "8", "train_wall": "63", "gb_free": "32.5", "wall": "22458"}
[2024-07-10 03:30:36,276][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 03:30:36,278][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 03:30:47,058][dev-other][INFO] - {"epoch": 39, "dev-other_loss": "23.862", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.254", "dev-other_uer": "4.049", "dev-other_wer": "10.972", "dev-other_raw_wer": "10.972", "dev-other_wps": "27605.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "68297", "dev-other_best_wer": "10.972"}
[2024-07-10 03:30:47,058][fairseq_cli.train][INFO] - end of epoch 39 (average epoch stats below)
[2024-07-10 03:30:47,061][train][INFO] - {"epoch": 39, "train_loss": "93.34", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.543", "train_wps": "44779.8", "train_ups": "3.07", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "68297", "train_lr": "1.98249e-05", "train_gnorm": "130.369", "train_loss_scale": "8", "train_train_wall": "554", "train_gb_free": "33", "train_wall": "22499"}
[2024-07-10 03:30:47,062][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 03:30:47,794][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 03:30:47,797][fairseq.trainer][INFO] - begin training epoch 40
[2024-07-10 03:30:47,797][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 03:31:21,255][train_inner][INFO] - {"epoch": 40, "update": 39.059, "loss": "90.731", "ntokens": "14535.9", "nsentences": "85.64", "nll_loss": "0.535", "wps": "38421.4", "ups": "2.64", "wpb": "14535.9", "bsz": "85.6", "num_updates": "68400", "lr": "1.97232e-05", "gnorm": "130.654", "loss_scale": "8", "train_wall": "64", "gb_free": "32.1", "wall": "22533"}
[2024-07-10 03:32:25,936][train_inner][INFO] - {"epoch": 40, "update": 39.173, "loss": "90.164", "ntokens": "14604.1", "nsentences": "85.88", "nll_loss": "0.53", "wps": "45160.4", "ups": "3.09", "wpb": "14604.1", "bsz": "85.9", "num_updates": "68600", "lr": "1.95272e-05", "gnorm": "127.905", "loss_scale": "16", "train_wall": "64", "gb_free": "32.1", "wall": "22598"}
[2024-07-10 03:33:29,655][train_inner][INFO] - {"epoch": 40, "update": 39.287, "loss": "92.197", "ntokens": "14568.9", "nsentences": "83.76", "nll_loss": "0.53", "wps": "45798.1", "ups": "3.14", "wpb": "14568.9", "bsz": "83.8", "num_updates": "68800", "lr": "1.93332e-05", "gnorm": "130.613", "loss_scale": "16", "train_wall": "63", "gb_free": "30.8", "wall": "22662"}
[2024-07-10 03:34:34,461][train_inner][INFO] - {"epoch": 40, "update": 39.401, "loss": "88.201", "ntokens": "14709", "nsentences": "87.075", "nll_loss": "0.522", "wps": "45437.2", "ups": "3.09", "wpb": "14709", "bsz": "87.1", "num_updates": "69000", "lr": "1.91411e-05", "gnorm": "128.362", "loss_scale": "16", "train_wall": "64", "gb_free": "32", "wall": "22726"}
[2024-07-10 03:35:38,464][train_inner][INFO] - {"epoch": 40, "update": 39.515, "loss": "94.507", "ntokens": "14526.5", "nsentences": "82.56", "nll_loss": "0.537", "wps": "45395.7", "ups": "3.13", "wpb": "14526.5", "bsz": "82.6", "num_updates": "69200", "lr": "1.89509e-05", "gnorm": "131.65", "loss_scale": "16", "train_wall": "64", "gb_free": "32", "wall": "22790"}
[2024-07-10 03:36:11,952][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 03:36:43,049][train_inner][INFO] - {"epoch": 40, "update": 39.63, "loss": "91.303", "ntokens": "14527.9", "nsentences": "84.16", "nll_loss": "0.529", "wps": "44992", "ups": "3.1", "wpb": "14527.9", "bsz": "84.2", "num_updates": "69400", "lr": "1.87626e-05", "gnorm": "131.046", "loss_scale": "8", "train_wall": "64", "gb_free": "32.6", "wall": "22855"}
[2024-07-10 03:37:47,427][train_inner][INFO] - {"epoch": 40, "update": 39.744, "loss": "92.823", "ntokens": "14650", "nsentences": "84.68", "nll_loss": "0.537", "wps": "45515.6", "ups": "3.11", "wpb": "14650", "bsz": "84.7", "num_updates": "69600", "lr": "1.85762e-05", "gnorm": "129.372", "loss_scale": "8", "train_wall": "64", "gb_free": "32.2", "wall": "22919"}
[2024-07-10 03:38:50,942][train_inner][INFO] - {"epoch": 40, "update": 39.858, "loss": "92.237", "ntokens": "14510.6", "nsentences": "84.4", "nll_loss": "0.536", "wps": "45696", "ups": "3.15", "wpb": "14510.6", "bsz": "84.4", "num_updates": "69800", "lr": "1.83916e-05", "gnorm": "129.038", "loss_scale": "8", "train_wall": "63", "gb_free": "32.4", "wall": "22983"}
[2024-07-10 03:39:54,824][train_inner][INFO] - {"epoch": 40, "update": 39.973, "loss": "90.523", "ntokens": "14545.6", "nsentences": "84.48", "nll_loss": "0.526", "wps": "45543.1", "ups": "3.13", "wpb": "14545.6", "bsz": "84.5", "num_updates": "70000", "lr": "1.82089e-05", "gnorm": "129.724", "loss_scale": "8", "train_wall": "63", "gb_free": "33.3", "wall": "23047"}
[2024-07-10 03:40:09,878][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 03:40:09,879][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 03:40:20,539][dev-other][INFO] - {"epoch": 40, "dev-other_loss": "23.635", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.251", "dev-other_uer": "4.015", "dev-other_wer": "10.848", "dev-other_raw_wer": "10.848", "dev-other_wps": "27938.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "70048", "dev-other_best_wer": "10.848"}
[2024-07-10 03:40:20,540][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 40 @ 70048 updates
[2024-07-10 03:40:20,541][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-10 03:40:21,814][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-10 03:40:22,417][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 40 @ 70048 updates, score 10.848) (writing took 1.8772510439157486 seconds)
[2024-07-10 03:40:22,417][fairseq_cli.train][INFO] - end of epoch 40 (average epoch stats below)
[2024-07-10 03:40:22,440][train][INFO] - {"epoch": 40, "train_loss": "91.327", "train_ntokens": "14577.6", "train_nsentences": "84.8195", "train_nll_loss": "0.531", "train_wps": "44364.4", "train_ups": "3.04", "train_wpb": "14577.6", "train_bsz": "84.8", "train_num_updates": "70048", "train_lr": "1.81653e-05", "train_gnorm": "129.608", "train_loss_scale": "8", "train_train_wall": "558", "train_gb_free": "34.7", "train_wall": "23074"}
[2024-07-10 03:40:22,441][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 03:40:22,693][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 03:40:22,696][fairseq.trainer][INFO] - begin training epoch 41
[2024-07-10 03:40:22,696][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 03:41:11,329][train_inner][INFO] - {"epoch": 41, "update": 40.087, "loss": "96.672", "ntokens": "14558.2", "nsentences": "83.64", "nll_loss": "0.555", "wps": "38066.1", "ups": "2.61", "wpb": "14558.2", "bsz": "83.6", "num_updates": "70200", "lr": "1.80279e-05", "gnorm": "135.726", "loss_scale": "8", "train_wall": "63", "gb_free": "33.4", "wall": "23123"}
[2024-07-10 03:42:14,997][train_inner][INFO] - {"epoch": 41, "update": 40.201, "loss": "92.351", "ntokens": "14545.9", "nsentences": "85.4", "nll_loss": "0.542", "wps": "45696.4", "ups": "3.14", "wpb": "14545.9", "bsz": "85.4", "num_updates": "70400", "lr": "1.78488e-05", "gnorm": "128.868", "loss_scale": "8", "train_wall": "63", "gb_free": "31.5", "wall": "23187"}
[2024-07-10 03:43:18,855][train_inner][INFO] - {"epoch": 41, "update": 40.315, "loss": "93.278", "ntokens": "14614.2", "nsentences": "84.68", "nll_loss": "0.54", "wps": "45773.4", "ups": "3.13", "wpb": "14614.2", "bsz": "84.7", "num_updates": "70600", "lr": "1.76715e-05", "gnorm": "128.845", "loss_scale": "8", "train_wall": "63", "gb_free": "32.8", "wall": "23251"}
[2024-07-10 03:44:22,918][train_inner][INFO] - {"epoch": 41, "update": 40.429, "loss": "91.865", "ntokens": "14563.7", "nsentences": "84.92", "nll_loss": "0.536", "wps": "45471.5", "ups": "3.12", "wpb": "14563.7", "bsz": "84.9", "num_updates": "70800", "lr": "1.74959e-05", "gnorm": "129.091", "loss_scale": "8", "train_wall": "64", "gb_free": "31.2", "wall": "23315"}
[2024-07-10 03:45:27,282][train_inner][INFO] - {"epoch": 41, "update": 40.543, "loss": "90.923", "ntokens": "14623.7", "nsentences": "86.12", "nll_loss": "0.535", "wps": "45455.9", "ups": "3.11", "wpb": "14623.7", "bsz": "86.1", "num_updates": "71000", "lr": "1.7322e-05", "gnorm": "128.24", "loss_scale": "8", "train_wall": "64", "gb_free": "31.5", "wall": "23379"}
[2024-07-10 03:46:31,094][train_inner][INFO] - {"epoch": 41, "update": 40.658, "loss": "93.413", "ntokens": "14586", "nsentences": "86.52", "nll_loss": "0.554", "wps": "45721.2", "ups": "3.13", "wpb": "14586", "bsz": "86.5", "num_updates": "71200", "lr": "1.71499e-05", "gnorm": "128.969", "loss_scale": "8", "train_wall": "63", "gb_free": "33.4", "wall": "23443"}
[2024-07-10 03:47:35,141][train_inner][INFO] - {"epoch": 41, "update": 40.772, "loss": "92.841", "ntokens": "14595.9", "nsentences": "85.44", "nll_loss": "0.543", "wps": "45627", "ups": "3.13", "wpb": "14595.9", "bsz": "85.4", "num_updates": "71400", "lr": "1.69795e-05", "gnorm": "129.954", "loss_scale": "16", "train_wall": "64", "gb_free": "32.8", "wall": "23507"}
[2024-07-10 03:48:39,337][train_inner][INFO] - {"epoch": 41, "update": 40.886, "loss": "92.054", "ntokens": "14518.8", "nsentences": "82.16", "nll_loss": "0.521", "wps": "45236.9", "ups": "3.12", "wpb": "14518.8", "bsz": "82.2", "num_updates": "71600", "lr": "1.68108e-05", "gnorm": "131.831", "loss_scale": "16", "train_wall": "64", "gb_free": "32.5", "wall": "23571"}
[2024-07-10 03:49:31,328][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 03:49:43,160][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 03:49:43,161][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 03:49:53,831][dev-other][INFO] - {"epoch": 41, "dev-other_loss": "23.226", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.247", "dev-other_uer": "3.999", "dev-other_wer": "10.746", "dev-other_raw_wer": "10.746", "dev-other_wps": "27995.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "71799", "dev-other_best_wer": "10.746"}
[2024-07-10 03:49:53,831][fairseq_cli.train][INFO] - end of epoch 41 (average epoch stats below)
[2024-07-10 03:49:53,835][train][INFO] - {"epoch": 41, "train_loss": "92.583", "train_ntokens": "14577", "train_nsentences": "84.8652", "train_nll_loss": "0.539", "train_wps": "44670.5", "train_ups": "3.06", "train_wpb": "14577", "train_bsz": "84.9", "train_num_updates": "71799", "train_lr": "1.66446e-05", "train_gnorm": "130.321", "train_loss_scale": "8", "train_train_wall": "556", "train_gb_free": "32.3", "train_wall": "23646"}
[2024-07-10 03:49:53,837][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 03:49:54,521][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 03:49:54,524][fairseq.trainer][INFO] - begin training epoch 42
[2024-07-10 03:49:54,524][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 03:49:55,307][train_inner][INFO] - {"epoch": 42, "update": 41.001, "loss": "89.575", "ntokens": "14542.3", "nsentences": "84.755", "nll_loss": "0.522", "wps": "38287.1", "ups": "2.63", "wpb": "14542.3", "bsz": "84.8", "num_updates": "71800", "lr": "1.66438e-05", "gnorm": "131.34", "loss_scale": "8", "train_wall": "64", "gb_free": "32.9", "wall": "23647"}
[2024-07-10 03:50:59,924][train_inner][INFO] - {"epoch": 42, "update": 41.115, "loss": "89.428", "ntokens": "14528.9", "nsentences": "83.68", "nll_loss": "0.515", "wps": "44970.8", "ups": "3.1", "wpb": "14528.9", "bsz": "83.7", "num_updates": "72000", "lr": "1.64784e-05", "gnorm": "130.909", "loss_scale": "8", "train_wall": "64", "gb_free": "32.2", "wall": "23712"}
[2024-07-10 03:52:04,435][train_inner][INFO] - {"epoch": 42, "update": 41.229, "loss": "91.69", "ntokens": "14669.4", "nsentences": "84.64", "nll_loss": "0.529", "wps": "45481.6", "ups": "3.1", "wpb": "14669.4", "bsz": "84.6", "num_updates": "72200", "lr": "1.63147e-05", "gnorm": "129.868", "loss_scale": "8", "train_wall": "64", "gb_free": "31.6", "wall": "23776"}
[2024-07-10 03:53:08,253][train_inner][INFO] - {"epoch": 42, "update": 41.343, "loss": "91.169", "ntokens": "14583.9", "nsentences": "84.68", "nll_loss": "0.529", "wps": "45709.4", "ups": "3.13", "wpb": "14583.9", "bsz": "84.7", "num_updates": "72400", "lr": "1.61526e-05", "gnorm": "129.204", "loss_scale": "8", "train_wall": "63", "gb_free": "32.7", "wall": "23840"}
[2024-07-10 03:54:12,136][train_inner][INFO] - {"epoch": 42, "update": 41.457, "loss": "92.925", "ntokens": "14585.4", "nsentences": "84", "nll_loss": "0.535", "wps": "45669.9", "ups": "3.13", "wpb": "14585.4", "bsz": "84", "num_updates": "72600", "lr": "1.59921e-05", "gnorm": "130.888", "loss_scale": "8", "train_wall": "63", "gb_free": "33.3", "wall": "23904"}
[2024-07-10 03:55:15,769][train_inner][INFO] - {"epoch": 42, "update": 41.571, "loss": "92.789", "ntokens": "14476.1", "nsentences": "85.24", "nll_loss": "0.546", "wps": "45505.2", "ups": "3.14", "wpb": "14476.1", "bsz": "85.2", "num_updates": "72800", "lr": "1.58332e-05", "gnorm": "133.962", "loss_scale": "8", "train_wall": "63", "gb_free": "32.2", "wall": "23968"}
[2024-07-10 03:56:19,805][train_inner][INFO] - {"epoch": 42, "update": 41.686, "loss": "93.248", "ntokens": "14610.1", "nsentences": "84.555", "nll_loss": "0.54", "wps": "45639.6", "ups": "3.12", "wpb": "14610.1", "bsz": "84.6", "num_updates": "73000", "lr": "1.56759e-05", "gnorm": "130.652", "loss_scale": "8", "train_wall": "64", "gb_free": "32.8", "wall": "24032"}
[2024-07-10 03:57:23,841][train_inner][INFO] - {"epoch": 42, "update": 41.8, "loss": "92.612", "ntokens": "14585.9", "nsentences": "84.12", "nll_loss": "0.534", "wps": "45558.5", "ups": "3.12", "wpb": "14585.9", "bsz": "84.1", "num_updates": "73200", "lr": "1.55201e-05", "gnorm": "130.201", "loss_scale": "8", "train_wall": "64", "gb_free": "32.3", "wall": "24096"}
[2024-07-10 03:58:27,591][train_inner][INFO] - {"epoch": 42, "update": 41.914, "loss": "89.495", "ntokens": "14614.1", "nsentences": "86.76", "nll_loss": "0.531", "wps": "45852.6", "ups": "3.14", "wpb": "14614.1", "bsz": "86.8", "num_updates": "73400", "lr": "1.53659e-05", "gnorm": "127.639", "loss_scale": "8", "train_wall": "63", "gb_free": "32.9", "wall": "24160"}
[2024-07-10 03:59:15,485][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 03:59:15,487][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 03:59:26,174][dev-other][INFO] - {"epoch": 42, "dev-other_loss": "23.464", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.249", "dev-other_uer": "3.98", "dev-other_wer": "10.736", "dev-other_raw_wer": "10.736", "dev-other_wps": "27859.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "73551", "dev-other_best_wer": "10.736"}
[2024-07-10 03:59:26,174][fairseq_cli.train][INFO] - end of epoch 42 (average epoch stats below)
[2024-07-10 03:59:26,179][train][INFO] - {"epoch": 42, "train_loss": "91.531", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.533", "train_wps": "44623.6", "train_ups": "3.06", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "73551", "train_lr": "1.52505e-05", "train_gnorm": "130.218", "train_loss_scale": "8", "train_train_wall": "557", "train_gb_free": "33.4", "train_wall": "24218"}
[2024-07-10 03:59:26,181][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 03:59:26,925][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 03:59:26,932][fairseq.trainer][INFO] - begin training epoch 43
[2024-07-10 03:59:26,932][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 03:59:43,164][train_inner][INFO] - {"epoch": 43, "update": 42.028, "loss": "89.939", "ntokens": "14547", "nsentences": "85.755", "nll_loss": "0.53", "wps": "38500.8", "ups": "2.65", "wpb": "14547", "bsz": "85.8", "num_updates": "73600", "lr": "1.52132e-05", "gnorm": "128.527", "loss_scale": "8", "train_wall": "64", "gb_free": "31.8", "wall": "24235"}
[2024-07-10 04:00:47,548][train_inner][INFO] - {"epoch": 43, "update": 42.142, "loss": "89.997", "ntokens": "14579.9", "nsentences": "84.36", "nll_loss": "0.521", "wps": "45293.3", "ups": "3.11", "wpb": "14579.9", "bsz": "84.4", "num_updates": "73800", "lr": "1.50621e-05", "gnorm": "129.619", "loss_scale": "8", "train_wall": "64", "gb_free": "32", "wall": "24300"}
[2024-07-10 04:01:51,732][train_inner][INFO] - {"epoch": 43, "update": 42.256, "loss": "92.264", "ntokens": "14718.1", "nsentences": "84.36", "nll_loss": "0.529", "wps": "45903.3", "ups": "3.12", "wpb": "14718.1", "bsz": "84.4", "num_updates": "74000", "lr": "1.49124e-05", "gnorm": "130.699", "loss_scale": "16", "train_wall": "64", "gb_free": "31.8", "wall": "24364"}
[2024-07-10 04:02:55,926][train_inner][INFO] - {"epoch": 43, "update": 42.37, "loss": "90.403", "ntokens": "14550.6", "nsentences": "84.72", "nll_loss": "0.526", "wps": "45337.9", "ups": "3.12", "wpb": "14550.6", "bsz": "84.7", "num_updates": "74200", "lr": "1.47642e-05", "gnorm": "130.598", "loss_scale": "16", "train_wall": "64", "gb_free": "31.8", "wall": "24428"}
[2024-07-10 04:03:01,844][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 04:04:00,139][train_inner][INFO] - {"epoch": 43, "update": 42.485, "loss": "88.158", "ntokens": "14572.5", "nsentences": "85.32", "nll_loss": "0.516", "wps": "45440.2", "ups": "3.12", "wpb": "14572.5", "bsz": "85.3", "num_updates": "74400", "lr": "1.46175e-05", "gnorm": "129.706", "loss_scale": "8", "train_wall": "64", "gb_free": "31.4", "wall": "24492"}
[2024-07-10 04:05:03,754][train_inner][INFO] - {"epoch": 43, "update": 42.599, "loss": "90.488", "ntokens": "14514.1", "nsentences": "84.4", "nll_loss": "0.526", "wps": "45634.7", "ups": "3.14", "wpb": "14514.1", "bsz": "84.4", "num_updates": "74600", "lr": "1.44723e-05", "gnorm": "132.265", "loss_scale": "8", "train_wall": "63", "gb_free": "31.9", "wall": "24556"}
[2024-07-10 04:06:07,911][train_inner][INFO] - {"epoch": 43, "update": 42.713, "loss": "89.671", "ntokens": "14668.9", "nsentences": "85.56", "nll_loss": "0.523", "wps": "45780.8", "ups": "3.12", "wpb": "14668.9", "bsz": "85.6", "num_updates": "74800", "lr": "1.43285e-05", "gnorm": "128.769", "loss_scale": "8", "train_wall": "64", "gb_free": "31.8", "wall": "24620"}
[2024-07-10 04:07:11,998][train_inner][INFO] - {"epoch": 43, "update": 42.828, "loss": "90.185", "ntokens": "14578.2", "nsentences": "86.48", "nll_loss": "0.535", "wps": "45541.8", "ups": "3.12", "wpb": "14578.2", "bsz": "86.5", "num_updates": "75000", "lr": "1.41861e-05", "gnorm": "128.288", "loss_scale": "8", "train_wall": "64", "gb_free": "31.6", "wall": "24684"}
[2024-07-10 04:08:15,894][train_inner][INFO] - {"epoch": 43, "update": 42.942, "loss": "91.307", "ntokens": "14502.7", "nsentences": "83.88", "nll_loss": "0.528", "wps": "45397.9", "ups": "3.13", "wpb": "14502.7", "bsz": "83.9", "num_updates": "75200", "lr": "1.40452e-05", "gnorm": "130.813", "loss_scale": "8", "train_wall": "63", "gb_free": "31.5", "wall": "24748"}
[2024-07-10 04:08:48,242][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 04:08:48,243][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 04:08:58,932][dev-other][INFO] - {"epoch": 43, "dev-other_loss": "23.81", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.253", "dev-other_uer": "4.028", "dev-other_wer": "10.872", "dev-other_raw_wer": "10.872", "dev-other_wps": "27845.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "75302", "dev-other_best_wer": "10.848"}
[2024-07-10 04:08:58,932][fairseq_cli.train][INFO] - end of epoch 43 (average epoch stats below)
[2024-07-10 04:08:58,934][train][INFO] - {"epoch": 43, "train_loss": "90.557", "train_ntokens": "14578", "train_nsentences": "84.8104", "train_nll_loss": "0.527", "train_wps": "44567.4", "train_ups": "3.06", "train_wpb": "14578", "train_bsz": "84.8", "train_num_updates": "75302", "train_lr": "1.39738e-05", "train_gnorm": "130.272", "train_loss_scale": "8", "train_train_wall": "557", "train_gb_free": "32.9", "train_wall": "24791"}
[2024-07-10 04:08:58,936][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 04:08:59,607][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 04:08:59,610][fairseq.trainer][INFO] - begin training epoch 44
[2024-07-10 04:08:59,611][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 04:09:31,775][train_inner][INFO] - {"epoch": 44, "update": 43.056, "loss": "92.991", "ntokens": "14602.9", "nsentences": "85.16", "nll_loss": "0.542", "wps": "38491.8", "ups": "2.64", "wpb": "14602.9", "bsz": "85.2", "num_updates": "75400", "lr": "1.39056e-05", "gnorm": "130.806", "loss_scale": "8", "train_wall": "64", "gb_free": "31.8", "wall": "24824"}
[2024-07-10 04:10:36,001][train_inner][INFO] - {"epoch": 44, "update": 43.17, "loss": "91.887", "ntokens": "14550.5", "nsentences": "83.76", "nll_loss": "0.529", "wps": "45313.4", "ups": "3.11", "wpb": "14550.5", "bsz": "83.8", "num_updates": "75600", "lr": "1.37674e-05", "gnorm": "131.967", "loss_scale": "8", "train_wall": "64", "gb_free": "32.4", "wall": "24888"}
[2024-07-10 04:11:39,980][train_inner][INFO] - {"epoch": 44, "update": 43.284, "loss": "92.961", "ntokens": "14573.2", "nsentences": "83.115", "nll_loss": "0.53", "wps": "45559.8", "ups": "3.13", "wpb": "14573.2", "bsz": "83.1", "num_updates": "75800", "lr": "1.36307e-05", "gnorm": "131.73", "loss_scale": "8", "train_wall": "63", "gb_free": "32.2", "wall": "24952"}
[2024-07-10 04:12:43,610][train_inner][INFO] - {"epoch": 44, "update": 43.398, "loss": "89.306", "ntokens": "14518.2", "nsentences": "84.48", "nll_loss": "0.52", "wps": "45638.2", "ups": "3.14", "wpb": "14518.2", "bsz": "84.5", "num_updates": "76000", "lr": "1.34952e-05", "gnorm": "128.726", "loss_scale": "8", "train_wall": "63", "gb_free": "32.8", "wall": "25016"}
[2024-07-10 04:13:46,492][train_inner][INFO] - {"epoch": 44, "update": 43.513, "loss": "90.011", "ntokens": "14553", "nsentences": "85.24", "nll_loss": "0.527", "wps": "46303.8", "ups": "3.18", "wpb": "14553", "bsz": "85.2", "num_updates": "76200", "lr": "1.33611e-05", "gnorm": "128.942", "loss_scale": "8", "train_wall": "62", "gb_free": "32", "wall": "25078"}
[2024-07-10 04:14:49,643][train_inner][INFO] - {"epoch": 44, "update": 43.627, "loss": "93.155", "ntokens": "14606.8", "nsentences": "85.16", "nll_loss": "0.543", "wps": "46264.9", "ups": "3.17", "wpb": "14606.8", "bsz": "85.2", "num_updates": "76400", "lr": "1.32284e-05", "gnorm": "129.594", "loss_scale": "16", "train_wall": "63", "gb_free": "32.7", "wall": "25142"}
[2024-07-10 04:15:53,460][train_inner][INFO] - {"epoch": 44, "update": 43.741, "loss": "89.716", "ntokens": "14612", "nsentences": "87.28", "nll_loss": "0.536", "wps": "45836.1", "ups": "3.14", "wpb": "14612", "bsz": "87.3", "num_updates": "76600", "lr": "1.30969e-05", "gnorm": "128.163", "loss_scale": "16", "train_wall": "63", "gb_free": "31.5", "wall": "25205"}
[2024-07-10 04:16:57,880][train_inner][INFO] - {"epoch": 44, "update": 43.855, "loss": "88.069", "ntokens": "14549.9", "nsentences": "85.04", "nll_loss": "0.515", "wps": "45176.4", "ups": "3.1", "wpb": "14549.9", "bsz": "85", "num_updates": "76800", "lr": "1.29668e-05", "gnorm": "130.545", "loss_scale": "16", "train_wall": "64", "gb_free": "33", "wall": "25270"}
[2024-07-10 04:17:03,062][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 04:18:02,140][train_inner][INFO] - {"epoch": 44, "update": 43.97, "loss": "94.62", "ntokens": "14578.2", "nsentences": "83.4", "nll_loss": "0.541", "wps": "45427.7", "ups": "3.12", "wpb": "14578.2", "bsz": "83.4", "num_updates": "77000", "lr": "1.2838e-05", "gnorm": "130.993", "loss_scale": "8", "train_wall": "64", "gb_free": "33", "wall": "25334"}
[2024-07-10 04:18:19,062][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 04:18:19,063][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 04:18:29,716][dev-other][INFO] - {"epoch": 44, "dev-other_loss": "23.981", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.255", "dev-other_uer": "4.013", "dev-other_wer": "10.821", "dev-other_raw_wer": "10.821", "dev-other_wps": "27879", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "77053", "dev-other_best_wer": "10.821"}
[2024-07-10 04:18:29,717][fairseq_cli.train][INFO] - end of epoch 44 (average epoch stats below)
[2024-07-10 04:18:29,719][train][INFO] - {"epoch": 44, "train_loss": "91.055", "train_ntokens": "14577.9", "train_nsentences": "84.815", "train_nll_loss": "0.53", "train_wps": "44721.1", "train_ups": "3.07", "train_wpb": "14577.9", "train_bsz": "84.8", "train_num_updates": "77053", "train_lr": "1.2804e-05", "train_gnorm": "129.949", "train_loss_scale": "8", "train_train_wall": "555", "train_gb_free": "33.4", "train_wall": "25362"}
[2024-07-10 04:18:29,720][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 04:18:30,460][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 04:18:30,465][fairseq.trainer][INFO] - begin training epoch 45
[2024-07-10 04:18:30,465][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 04:19:18,068][train_inner][INFO] - {"epoch": 45, "update": 44.084, "loss": "87.416", "ntokens": "14629.9", "nsentences": "87.2", "nll_loss": "0.521", "wps": "38538.9", "ups": "2.63", "wpb": "14629.9", "bsz": "87.2", "num_updates": "77200", "lr": "1.27104e-05", "gnorm": "128.01", "loss_scale": "8", "train_wall": "64", "gb_free": "32.2", "wall": "25410"}
[2024-07-10 04:20:22,579][train_inner][INFO] - {"epoch": 45, "update": 44.198, "loss": "90.221", "ntokens": "14622.1", "nsentences": "84.76", "nll_loss": "0.523", "wps": "45338.6", "ups": "3.1", "wpb": "14622.1", "bsz": "84.8", "num_updates": "77400", "lr": "1.25841e-05", "gnorm": "131.256", "loss_scale": "8", "train_wall": "64", "gb_free": "31.5", "wall": "25475"}
[2024-07-10 04:21:26,887][train_inner][INFO] - {"epoch": 45, "update": 44.312, "loss": "92.401", "ntokens": "14593.7", "nsentences": "83.235", "nll_loss": "0.527", "wps": "45434.3", "ups": "3.11", "wpb": "14593.7", "bsz": "83.2", "num_updates": "77600", "lr": "1.24591e-05", "gnorm": "131.642", "loss_scale": "8", "train_wall": "64", "gb_free": "31.7", "wall": "25539"}
[2024-07-10 04:22:31,129][train_inner][INFO] - {"epoch": 45, "update": 44.426, "loss": "87.507", "ntokens": "14591.2", "nsentences": "86.24", "nll_loss": "0.517", "wps": "45432.3", "ups": "3.11", "wpb": "14591.2", "bsz": "86.2", "num_updates": "77800", "lr": "1.23353e-05", "gnorm": "128.301", "loss_scale": "8", "train_wall": "64", "gb_free": "32.5", "wall": "25603"}
[2024-07-10 04:23:35,701][train_inner][INFO] - {"epoch": 45, "update": 44.541, "loss": "88.332", "ntokens": "14645.7", "nsentences": "86.92", "nll_loss": "0.524", "wps": "45404.2", "ups": "3.1", "wpb": "14645.7", "bsz": "86.9", "num_updates": "78000", "lr": "1.22127e-05", "gnorm": "126.679", "loss_scale": "8", "train_wall": "64", "gb_free": "29.7", "wall": "25668"}
[2024-07-10 04:24:39,397][train_inner][INFO] - {"epoch": 45, "update": 44.655, "loss": "90.027", "ntokens": "14554", "nsentences": "84.2", "nll_loss": "0.521", "wps": "45778", "ups": "3.15", "wpb": "14554", "bsz": "84.2", "num_updates": "78200", "lr": "1.20914e-05", "gnorm": "130.044", "loss_scale": "8", "train_wall": "63", "gb_free": "31.8", "wall": "25731"}
[2024-07-10 04:25:42,447][train_inner][INFO] - {"epoch": 45, "update": 44.769, "loss": "93.384", "ntokens": "14460.1", "nsentences": "83.24", "nll_loss": "0.538", "wps": "45871.2", "ups": "3.17", "wpb": "14460.1", "bsz": "83.2", "num_updates": "78400", "lr": "1.19712e-05", "gnorm": "132.062", "loss_scale": "8", "train_wall": "63", "gb_free": "33.3", "wall": "25794"}
[2024-07-10 04:26:46,390][train_inner][INFO] - {"epoch": 45, "update": 44.883, "loss": "89.738", "ntokens": "14568.3", "nsentences": "85.24", "nll_loss": "0.525", "wps": "45569.3", "ups": "3.13", "wpb": "14568.3", "bsz": "85.2", "num_updates": "78600", "lr": "1.18523e-05", "gnorm": "129.752", "loss_scale": "8", "train_wall": "63", "gb_free": "33.3", "wall": "25858"}
[2024-07-10 04:27:50,310][train_inner][INFO] - {"epoch": 45, "update": 44.997, "loss": "95.596", "ntokens": "14584.4", "nsentences": "83.2", "nll_loss": "0.545", "wps": "45682.6", "ups": "3.13", "wpb": "14584.4", "bsz": "83.2", "num_updates": "78800", "lr": "1.17345e-05", "gnorm": "132.56", "loss_scale": "8", "train_wall": "63", "gb_free": "31.2", "wall": "25922"}
[2024-07-10 04:27:51,747][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 04:27:51,748][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 04:28:02,476][dev-other][INFO] - {"epoch": 45, "dev-other_loss": "23.618", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.251", "dev-other_uer": "4.051", "dev-other_wer": "10.778", "dev-other_raw_wer": "10.778", "dev-other_wps": "27627.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "78805", "dev-other_best_wer": "10.778"}
[2024-07-10 04:28:02,478][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 45 @ 78805 updates
[2024-07-10 04:28:02,479][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-10 04:28:03,782][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-10 04:28:04,395][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 45 @ 78805 updates, score 10.778) (writing took 1.917568165808916 seconds)
[2024-07-10 04:28:04,396][fairseq_cli.train][INFO] - end of epoch 45 (average epoch stats below)
[2024-07-10 04:28:04,400][train][INFO] - {"epoch": 45, "train_loss": "90.486", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.527", "train_wps": "44442.1", "train_ups": "3.05", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "78805", "train_lr": "1.17316e-05", "train_gnorm": "130.079", "train_loss_scale": "8", "train_train_wall": "557", "train_gb_free": "32.7", "train_wall": "25936"}
[2024-07-10 04:28:04,401][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 04:28:04,654][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 04:28:04,658][fairseq.trainer][INFO] - begin training epoch 46
[2024-07-10 04:28:04,658][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 04:29:07,672][train_inner][INFO] - {"epoch": 46, "update": 45.111, "loss": "87.657", "ntokens": "14532.5", "nsentences": "86.12", "nll_loss": "0.519", "wps": "37572.2", "ups": "2.59", "wpb": "14532.5", "bsz": "86.1", "num_updates": "79000", "lr": "1.16179e-05", "gnorm": "128.51", "loss_scale": "16", "train_wall": "64", "gb_free": "33.1", "wall": "26000"}
[2024-07-10 04:30:12,103][train_inner][INFO] - {"epoch": 46, "update": 45.225, "loss": "86.297", "ntokens": "14573.4", "nsentences": "85.92", "nll_loss": "0.509", "wps": "45284.7", "ups": "3.11", "wpb": "14573.4", "bsz": "85.9", "num_updates": "79200", "lr": "1.15025e-05", "gnorm": "128.318", "loss_scale": "16", "train_wall": "64", "gb_free": "33.6", "wall": "26064"}
[2024-07-10 04:31:16,161][train_inner][INFO] - {"epoch": 46, "update": 45.34, "loss": "90.404", "ntokens": "14665", "nsentences": "86.435", "nll_loss": "0.533", "wps": "45791.9", "ups": "3.12", "wpb": "14665", "bsz": "86.4", "num_updates": "79400", "lr": "1.13882e-05", "gnorm": "128.183", "loss_scale": "16", "train_wall": "64", "gb_free": "30.2", "wall": "26128"}
[2024-07-10 04:32:20,517][train_inner][INFO] - {"epoch": 46, "update": 45.454, "loss": "90.766", "ntokens": "14642.7", "nsentences": "84.48", "nll_loss": "0.524", "wps": "45557.4", "ups": "3.11", "wpb": "14642.7", "bsz": "84.5", "num_updates": "79600", "lr": "1.1275e-05", "gnorm": "130.167", "loss_scale": "16", "train_wall": "64", "gb_free": "31.7", "wall": "26192"}
[2024-07-10 04:33:24,441][train_inner][INFO] - {"epoch": 46, "update": 45.568, "loss": "91.364", "ntokens": "14511.7", "nsentences": "84.52", "nll_loss": "0.532", "wps": "45408.1", "ups": "3.13", "wpb": "14511.7", "bsz": "84.5", "num_updates": "79800", "lr": "1.1163e-05", "gnorm": "130.625", "loss_scale": "16", "train_wall": "63", "gb_free": "32.5", "wall": "26256"}
[2024-07-10 04:34:28,063][train_inner][INFO] - {"epoch": 46, "update": 45.682, "loss": "93.131", "ntokens": "14497.9", "nsentences": "82.44", "nll_loss": "0.53", "wps": "45579.1", "ups": "3.14", "wpb": "14497.9", "bsz": "82.4", "num_updates": "80000", "lr": "1.10521e-05", "gnorm": "133.302", "loss_scale": "16", "train_wall": "63", "gb_free": "33.3", "wall": "26320"}
[2024-07-10 04:35:31,646][train_inner][INFO] - {"epoch": 46, "update": 45.796, "loss": "90.688", "ntokens": "14490.4", "nsentences": "82.88", "nll_loss": "0.519", "wps": "45582.6", "ups": "3.15", "wpb": "14490.4", "bsz": "82.9", "num_updates": "80200", "lr": "1.09423e-05", "gnorm": "132.313", "loss_scale": "16", "train_wall": "63", "gb_free": "31.9", "wall": "26384"}
[2024-07-10 04:36:35,721][train_inner][INFO] - {"epoch": 46, "update": 45.91, "loss": "92.612", "ntokens": "14610.2", "nsentences": "84.52", "nll_loss": "0.536", "wps": "45632.2", "ups": "3.12", "wpb": "14610.2", "bsz": "84.5", "num_updates": "80400", "lr": "1.08336e-05", "gnorm": "131.051", "loss_scale": "16", "train_wall": "64", "gb_free": "32", "wall": "26448"}
[2024-07-10 04:37:26,079][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 04:37:26,080][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 04:37:36,835][dev-other][INFO] - {"epoch": 46, "dev-other_loss": "23.444", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.249", "dev-other_uer": "3.957", "dev-other_wer": "10.595", "dev-other_raw_wer": "10.595", "dev-other_wps": "27788", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "80557", "dev-other_best_wer": "10.595"}
[2024-07-10 04:37:36,836][fairseq_cli.train][INFO] - end of epoch 46 (average epoch stats below)
[2024-07-10 04:37:36,839][train][INFO] - {"epoch": 46, "train_loss": "90.153", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.525", "train_wps": "44616", "train_ups": "3.06", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "80557", "train_lr": "1.0749e-05", "train_gnorm": "130.194", "train_loss_scale": "16", "train_train_wall": "557", "train_gb_free": "34.4", "train_wall": "26509"}
[2024-07-10 04:37:36,841][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 04:37:37,530][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 04:37:37,536][fairseq.trainer][INFO] - begin training epoch 47
[2024-07-10 04:37:37,537][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 04:37:51,843][train_inner][INFO] - {"epoch": 47, "update": 46.025, "loss": "86.825", "ntokens": "14624.3", "nsentences": "86.64", "nll_loss": "0.514", "wps": "38490.1", "ups": "2.63", "wpb": "14624.3", "bsz": "86.6", "num_updates": "80600", "lr": "1.07259e-05", "gnorm": "128.251", "loss_scale": "16", "train_wall": "64", "gb_free": "32", "wall": "26524"}
[2024-07-10 04:38:13,175][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 04:38:56,337][train_inner][INFO] - {"epoch": 47, "update": 46.139, "loss": "88.912", "ntokens": "14614.3", "nsentences": "85.8", "nll_loss": "0.522", "wps": "45543.8", "ups": "3.12", "wpb": "14614.3", "bsz": "85.8", "num_updates": "80800", "lr": "1.06193e-05", "gnorm": "130.918", "loss_scale": "8", "train_wall": "64", "gb_free": "31.8", "wall": "26588"}
[2024-07-10 04:40:00,356][train_inner][INFO] - {"epoch": 47, "update": 46.253, "loss": "87.389", "ntokens": "14501.8", "nsentences": "85.2", "nll_loss": "0.513", "wps": "45308.3", "ups": "3.12", "wpb": "14501.8", "bsz": "85.2", "num_updates": "81000", "lr": "1.05138e-05", "gnorm": "128.322", "loss_scale": "8", "train_wall": "64", "gb_free": "30.6", "wall": "26652"}
[2024-07-10 04:41:03,727][train_inner][INFO] - {"epoch": 47, "update": 46.368, "loss": "88.677", "ntokens": "14592.9", "nsentences": "86.2", "nll_loss": "0.524", "wps": "46073.8", "ups": "3.16", "wpb": "14592.9", "bsz": "86.2", "num_updates": "81200", "lr": "1.04094e-05", "gnorm": "128.371", "loss_scale": "8", "train_wall": "63", "gb_free": "32.3", "wall": "26716"}
[2024-07-10 04:42:08,011][train_inner][INFO] - {"epoch": 47, "update": 46.482, "loss": "89.046", "ntokens": "14556.6", "nsentences": "84.76", "nll_loss": "0.518", "wps": "45341.5", "ups": "3.11", "wpb": "14556.6", "bsz": "84.8", "num_updates": "81400", "lr": "1.03059e-05", "gnorm": "131.278", "loss_scale": "8", "train_wall": "64", "gb_free": "31.5", "wall": "26780"}
[2024-07-10 04:43:12,390][train_inner][INFO] - {"epoch": 47, "update": 46.596, "loss": "88.718", "ntokens": "14625.3", "nsentences": "84.32", "nll_loss": "0.511", "wps": "45441.9", "ups": "3.11", "wpb": "14625.3", "bsz": "84.3", "num_updates": "81600", "lr": "1.02035e-05", "gnorm": "130.264", "loss_scale": "8", "train_wall": "64", "gb_free": "32.7", "wall": "26844"}
[2024-07-10 04:44:16,564][train_inner][INFO] - {"epoch": 47, "update": 46.71, "loss": "90.891", "ntokens": "14567.8", "nsentences": "83.36", "nll_loss": "0.52", "wps": "45406.7", "ups": "3.12", "wpb": "14567.8", "bsz": "83.4", "num_updates": "81800", "lr": "1.01021e-05", "gnorm": "130.983", "loss_scale": "8", "train_wall": "64", "gb_free": "32.1", "wall": "26909"}
[2024-07-10 04:45:20,466][train_inner][INFO] - {"epoch": 47, "update": 46.824, "loss": "91.602", "ntokens": "14567.6", "nsentences": "83.6", "nll_loss": "0.526", "wps": "45598.7", "ups": "3.13", "wpb": "14567.6", "bsz": "83.6", "num_updates": "82000", "lr": "1.00018e-05", "gnorm": "129.261", "loss_scale": "8", "train_wall": "63", "gb_free": "32.3", "wall": "26972"}
[2024-07-10 04:46:24,429][train_inner][INFO] - {"epoch": 47, "update": 46.938, "loss": "89.587", "ntokens": "14624.3", "nsentences": "84.88", "nll_loss": "0.52", "wps": "45731.5", "ups": "3.13", "wpb": "14624.3", "bsz": "84.9", "num_updates": "82200", "lr": "9.90239e-06", "gnorm": "129.502", "loss_scale": "8", "train_wall": "63", "gb_free": "31.5", "wall": "27036"}
[2024-07-10 04:46:58,704][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 04:46:58,705][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 04:47:09,418][dev-other][INFO] - {"epoch": 47, "dev-other_loss": "23.588", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.251", "dev-other_uer": "3.953", "dev-other_wer": "10.568", "dev-other_raw_wer": "10.568", "dev-other_wps": "27646.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "82308", "dev-other_best_wer": "10.568"}
[2024-07-10 04:47:09,419][fairseq_cli.train][INFO] - end of epoch 47 (average epoch stats below)
[2024-07-10 04:47:09,421][train][INFO] - {"epoch": 47, "train_loss": "89.157", "train_ntokens": "14577.2", "train_nsentences": "84.8744", "train_nll_loss": "0.519", "train_wps": "44578.4", "train_ups": "3.06", "train_wpb": "14577.2", "train_bsz": "84.9", "train_num_updates": "82308", "train_lr": "9.84914e-06", "train_gnorm": "129.74", "train_loss_scale": "8", "train_train_wall": "556", "train_gb_free": "33.1", "train_wall": "27081"}
[2024-07-10 04:47:09,422][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 04:47:10,144][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 04:47:10,148][fairseq.trainer][INFO] - begin training epoch 48
[2024-07-10 04:47:10,148][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 04:47:40,318][train_inner][INFO] - {"epoch": 48, "update": 47.053, "loss": "89.341", "ntokens": "14502.6", "nsentences": "84.595", "nll_loss": "0.521", "wps": "38222.6", "ups": "2.64", "wpb": "14502.6", "bsz": "84.6", "num_updates": "82400", "lr": "9.804e-06", "gnorm": "130.689", "loss_scale": "8", "train_wall": "64", "gb_free": "31.6", "wall": "27112"}
[2024-07-10 04:48:44,799][train_inner][INFO] - {"epoch": 48, "update": 47.167, "loss": "89.67", "ntokens": "14550.1", "nsentences": "84.04", "nll_loss": "0.518", "wps": "45180.7", "ups": "3.11", "wpb": "14550.1", "bsz": "84", "num_updates": "82600", "lr": "9.70659e-06", "gnorm": "130.545", "loss_scale": "8", "train_wall": "64", "gb_free": "30.6", "wall": "27177"}
[2024-07-10 04:49:48,947][train_inner][INFO] - {"epoch": 48, "update": 47.281, "loss": "86.924", "ntokens": "14491.3", "nsentences": "84.355", "nll_loss": "0.506", "wps": "45185.1", "ups": "3.12", "wpb": "14491.3", "bsz": "84.4", "num_updates": "82800", "lr": "9.61014e-06", "gnorm": "131.722", "loss_scale": "16", "train_wall": "64", "gb_free": "32.1", "wall": "27241"}
[2024-07-10 04:50:52,769][train_inner][INFO] - {"epoch": 48, "update": 47.395, "loss": "88.39", "ntokens": "14581.7", "nsentences": "86.36", "nll_loss": "0.523", "wps": "45745.5", "ups": "3.14", "wpb": "14581.7", "bsz": "86.4", "num_updates": "83000", "lr": "9.51466e-06", "gnorm": "129.088", "loss_scale": "16", "train_wall": "63", "gb_free": "33.5", "wall": "27305"}
[2024-07-10 04:51:30,104][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 04:51:56,753][train_inner][INFO] - {"epoch": 48, "update": 47.51, "loss": "89.563", "ntokens": "14564.5", "nsentences": "83.76", "nll_loss": "0.515", "wps": "45527.9", "ups": "3.13", "wpb": "14564.5", "bsz": "83.8", "num_updates": "83200", "lr": "9.42012e-06", "gnorm": "131.383", "loss_scale": "8", "train_wall": "64", "gb_free": "31.9", "wall": "27369"}
[2024-07-10 04:53:00,852][train_inner][INFO] - {"epoch": 48, "update": 47.624, "loss": "90.56", "ntokens": "14557.8", "nsentences": "84.56", "nll_loss": "0.526", "wps": "45469.1", "ups": "3.12", "wpb": "14557.8", "bsz": "84.6", "num_updates": "83400", "lr": "9.32652e-06", "gnorm": "129.034", "loss_scale": "8", "train_wall": "64", "gb_free": "33", "wall": "27433"}
[2024-07-10 04:54:04,955][train_inner][INFO] - {"epoch": 48, "update": 47.738, "loss": "89.099", "ntokens": "14589.1", "nsentences": "84.48", "nll_loss": "0.516", "wps": "45524.1", "ups": "3.12", "wpb": "14589.1", "bsz": "84.5", "num_updates": "83600", "lr": "9.23385e-06", "gnorm": "130.062", "loss_scale": "8", "train_wall": "64", "gb_free": "33.2", "wall": "27497"}
[2024-07-10 04:55:09,131][train_inner][INFO] - {"epoch": 48, "update": 47.852, "loss": "88.459", "ntokens": "14701.2", "nsentences": "85.4", "nll_loss": "0.514", "wps": "45862.3", "ups": "3.12", "wpb": "14701.2", "bsz": "85.4", "num_updates": "83800", "lr": "9.1421e-06", "gnorm": "130.109", "loss_scale": "8", "train_wall": "64", "gb_free": "30.8", "wall": "27561"}
[2024-07-10 04:56:13,183][train_inner][INFO] - {"epoch": 48, "update": 47.966, "loss": "91.077", "ntokens": "14613.4", "nsentences": "85.04", "nll_loss": "0.53", "wps": "45676", "ups": "3.13", "wpb": "14613.4", "bsz": "85", "num_updates": "84000", "lr": "9.05126e-06", "gnorm": "130.396", "loss_scale": "8", "train_wall": "64", "gb_free": "31.8", "wall": "27625"}
[2024-07-10 04:56:31,784][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 04:56:31,785][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 04:56:42,479][dev-other][INFO] - {"epoch": 48, "dev-other_loss": "23.205", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.247", "dev-other_uer": "3.985", "dev-other_wer": "10.683", "dev-other_raw_wer": "10.683", "dev-other_wps": "27736.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "84059", "dev-other_best_wer": "10.683"}
[2024-07-10 04:56:42,480][fairseq_cli.train][INFO] - end of epoch 48 (average epoch stats below)
[2024-07-10 04:56:42,483][train][INFO] - {"epoch": 48, "train_loss": "89.268", "train_ntokens": "14578.4", "train_nsentences": "84.8195", "train_nll_loss": "0.519", "train_wps": "44544.8", "train_ups": "3.06", "train_wpb": "14578.4", "train_bsz": "84.8", "train_num_updates": "84059", "train_lr": "9.02464e-06", "train_gnorm": "130.164", "train_loss_scale": "8", "train_train_wall": "557", "train_gb_free": "32.8", "train_wall": "27654"}
[2024-07-10 04:56:42,484][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 04:56:43,235][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 04:56:43,239][fairseq.trainer][INFO] - begin training epoch 49
[2024-07-10 04:56:43,239][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 04:57:28,742][train_inner][INFO] - {"epoch": 49, "update": 48.08, "loss": "90.129", "ntokens": "14495.3", "nsentences": "84.2", "nll_loss": "0.524", "wps": "38401.6", "ups": "2.65", "wpb": "14495.3", "bsz": "84.2", "num_updates": "84200", "lr": "8.96133e-06", "gnorm": "130.775", "loss_scale": "8", "train_wall": "63", "gb_free": "31.9", "wall": "27701"}
[2024-07-10 04:58:32,954][train_inner][INFO] - {"epoch": 49, "update": 48.195, "loss": "87.687", "ntokens": "14561.3", "nsentences": "86.56", "nll_loss": "0.521", "wps": "45358.7", "ups": "3.12", "wpb": "14561.3", "bsz": "86.6", "num_updates": "84400", "lr": "8.87229e-06", "gnorm": "128.368", "loss_scale": "8", "train_wall": "64", "gb_free": "31.2", "wall": "27765"}
[2024-07-10 04:59:36,835][train_inner][INFO] - {"epoch": 49, "update": 48.309, "loss": "89.528", "ntokens": "14486.5", "nsentences": "83.8", "nll_loss": "0.518", "wps": "45361", "ups": "3.13", "wpb": "14486.5", "bsz": "83.8", "num_updates": "84600", "lr": "8.78413e-06", "gnorm": "130.645", "loss_scale": "8", "train_wall": "63", "gb_free": "33.2", "wall": "27829"}
[2024-07-10 05:00:41,372][train_inner][INFO] - {"epoch": 49, "update": 48.423, "loss": "88.961", "ntokens": "14531.8", "nsentences": "85.355", "nll_loss": "0.523", "wps": "45249.7", "ups": "3.11", "wpb": "14531.8", "bsz": "85.4", "num_updates": "84800", "lr": "8.69685e-06", "gnorm": "127.378", "loss_scale": "8", "train_wall": "64", "gb_free": "31.9", "wall": "27893"}
[2024-07-10 05:01:45,531][train_inner][INFO] - {"epoch": 49, "update": 48.537, "loss": "90.638", "ntokens": "14613.6", "nsentences": "85", "nll_loss": "0.527", "wps": "45619.2", "ups": "3.12", "wpb": "14613.6", "bsz": "85", "num_updates": "85000", "lr": "8.61044e-06", "gnorm": "132.426", "loss_scale": "8", "train_wall": "64", "gb_free": "31.9", "wall": "27957"}
[2024-07-10 05:02:49,309][train_inner][INFO] - {"epoch": 49, "update": 48.651, "loss": "90.363", "ntokens": "14678.7", "nsentences": "86.12", "nll_loss": "0.53", "wps": "46034", "ups": "3.14", "wpb": "14678.7", "bsz": "86.1", "num_updates": "85200", "lr": "8.52489e-06", "gnorm": "127.38", "loss_scale": "16", "train_wall": "63", "gb_free": "32.2", "wall": "28021"}
[2024-07-10 05:03:53,227][train_inner][INFO] - {"epoch": 49, "update": 48.765, "loss": "86.853", "ntokens": "14588.8", "nsentences": "84.48", "nll_loss": "0.503", "wps": "45651", "ups": "3.13", "wpb": "14588.8", "bsz": "84.5", "num_updates": "85400", "lr": "8.44018e-06", "gnorm": "129.229", "loss_scale": "16", "train_wall": "63", "gb_free": "32.9", "wall": "28085"}
[2024-07-10 05:04:56,538][train_inner][INFO] - {"epoch": 49, "update": 48.88, "loss": "90.103", "ntokens": "14557.8", "nsentences": "83.24", "nll_loss": "0.515", "wps": "45993.1", "ups": "3.16", "wpb": "14557.8", "bsz": "83.2", "num_updates": "85600", "lr": "8.35632e-06", "gnorm": "130.677", "loss_scale": "16", "train_wall": "63", "gb_free": "31.8", "wall": "28149"}
[2024-07-10 05:05:59,956][train_inner][INFO] - {"epoch": 49, "update": 48.994, "loss": "89.503", "ntokens": "14696.5", "nsentences": "85.64", "nll_loss": "0.522", "wps": "46352.8", "ups": "3.15", "wpb": "14696.5", "bsz": "85.6", "num_updates": "85800", "lr": "8.27329e-06", "gnorm": "128.08", "loss_scale": "16", "train_wall": "63", "gb_free": "33.5", "wall": "28212"}
[2024-07-10 05:06:03,448][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 05:06:03,449][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 05:06:14,162][dev-other][INFO] - {"epoch": 49, "dev-other_loss": "23.812", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.253", "dev-other_uer": "3.967", "dev-other_wer": "10.575", "dev-other_raw_wer": "10.575", "dev-other_wps": "27671.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "85811", "dev-other_best_wer": "10.575"}
[2024-07-10 05:06:14,163][fairseq_cli.train][INFO] - end of epoch 49 (average epoch stats below)
[2024-07-10 05:06:14,165][train][INFO] - {"epoch": 49, "train_loss": "89.165", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.519", "train_wps": "44675", "train_ups": "3.06", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "85811", "train_lr": "8.26875e-06", "train_gnorm": "129.593", "train_loss_scale": "16", "train_train_wall": "556", "train_gb_free": "33.8", "train_wall": "28226"}
[2024-07-10 05:06:14,167][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 05:06:14,878][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 05:06:14,882][fairseq.trainer][INFO] - begin training epoch 50
[2024-07-10 05:06:14,882][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 05:07:16,084][train_inner][INFO] - {"epoch": 50, "update": 49.108, "loss": "90.839", "ntokens": "14558.8", "nsentences": "82.56", "nll_loss": "0.515", "wps": "38261.7", "ups": "2.63", "wpb": "14558.8", "bsz": "82.6", "num_updates": "86000", "lr": "8.19109e-06", "gnorm": "133.45", "loss_scale": "16", "train_wall": "64", "gb_free": "30", "wall": "28288"}
[2024-07-10 05:08:19,357][train_inner][INFO] - {"epoch": 50, "update": 49.222, "loss": "92.133", "ntokens": "14569.9", "nsentences": "82.52", "nll_loss": "0.522", "wps": "46059", "ups": "3.16", "wpb": "14569.9", "bsz": "82.5", "num_updates": "86200", "lr": "8.1097e-06", "gnorm": "132.84", "loss_scale": "16", "train_wall": "63", "gb_free": "31.4", "wall": "28351"}
[2024-07-10 05:08:19,977][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 05:09:23,268][train_inner][INFO] - {"epoch": 50, "update": 49.337, "loss": "92.545", "ntokens": "14600.5", "nsentences": "86.16", "nll_loss": "0.546", "wps": "45692.9", "ups": "3.13", "wpb": "14600.5", "bsz": "86.2", "num_updates": "86400", "lr": "8.02912e-06", "gnorm": "128.201", "loss_scale": "8", "train_wall": "63", "gb_free": "32.7", "wall": "28415"}
[2024-07-10 05:10:27,273][train_inner][INFO] - {"epoch": 50, "update": 49.451, "loss": "88.132", "ntokens": "14665", "nsentences": "85.08", "nll_loss": "0.511", "wps": "45829.2", "ups": "3.13", "wpb": "14665", "bsz": "85.1", "num_updates": "86600", "lr": "7.94934e-06", "gnorm": "129.17", "loss_scale": "8", "train_wall": "64", "gb_free": "32.9", "wall": "28479"}
[2024-07-10 05:11:31,371][train_inner][INFO] - {"epoch": 50, "update": 49.565, "loss": "87.331", "ntokens": "14689.3", "nsentences": "87.635", "nll_loss": "0.521", "wps": "45839.1", "ups": "3.12", "wpb": "14689.3", "bsz": "87.6", "num_updates": "86800", "lr": "7.87036e-06", "gnorm": "127.225", "loss_scale": "8", "train_wall": "64", "gb_free": "31.5", "wall": "28543"}
[2024-07-10 05:12:35,420][train_inner][INFO] - {"epoch": 50, "update": 49.679, "loss": "83.839", "ntokens": "14645.8", "nsentences": "89.24", "nll_loss": "0.511", "wps": "45737.3", "ups": "3.12", "wpb": "14645.8", "bsz": "89.2", "num_updates": "87000", "lr": "7.79216e-06", "gnorm": "127.227", "loss_scale": "8", "train_wall": "64", "gb_free": "31.8", "wall": "28607"}
[2024-07-10 05:13:39,111][train_inner][INFO] - {"epoch": 50, "update": 49.793, "loss": "91.085", "ntokens": "14490.1", "nsentences": "82.8", "nll_loss": "0.52", "wps": "45506.2", "ups": "3.14", "wpb": "14490.1", "bsz": "82.8", "num_updates": "87200", "lr": "7.71473e-06", "gnorm": "132.833", "loss_scale": "8", "train_wall": "63", "gb_free": "33", "wall": "28671"}
[2024-07-10 05:14:42,821][train_inner][INFO] - {"epoch": 50, "update": 49.908, "loss": "86.046", "ntokens": "14428.9", "nsentences": "84.04", "nll_loss": "0.501", "wps": "45340.6", "ups": "3.14", "wpb": "14428.9", "bsz": "84", "num_updates": "87400", "lr": "7.63808e-06", "gnorm": "130.667", "loss_scale": "8", "train_wall": "63", "gb_free": "31.2", "wall": "28735"}
[2024-07-10 05:15:34,394][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 05:15:34,395][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 05:15:45,134][dev-other][INFO] - {"epoch": 50, "dev-other_loss": "23.697", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.252", "dev-other_uer": "3.978", "dev-other_wer": "10.623", "dev-other_raw_wer": "10.623", "dev-other_wps": "27807.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "87562", "dev-other_best_wer": "10.623"}
[2024-07-10 05:15:45,136][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 50 @ 87562 updates
[2024-07-10 05:15:45,137][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-10 05:15:46,432][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-10 05:15:47,041][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 50 @ 87562 updates, score 10.623) (writing took 1.9054525345563889 seconds)
[2024-07-10 05:15:47,042][fairseq_cli.train][INFO] - end of epoch 50 (average epoch stats below)
[2024-07-10 05:15:47,045][train][INFO] - {"epoch": 50, "train_loss": "89.228", "train_ntokens": "14578.1", "train_nsentences": "84.8744", "train_nll_loss": "0.519", "train_wps": "44558.1", "train_ups": "3.06", "train_wpb": "14578.1", "train_bsz": "84.9", "train_num_updates": "87562", "train_lr": "7.57655e-06", "train_gnorm": "130.338", "train_loss_scale": "8", "train_train_wall": "555", "train_gb_free": "33.9", "train_wall": "28799"}
[2024-07-10 05:15:47,047][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 05:15:47,296][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 05:15:47,299][fairseq.trainer][INFO] - begin training epoch 51
[2024-07-10 05:15:47,299][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 05:16:00,037][train_inner][INFO] - {"epoch": 51, "update": 50.022, "loss": "89.504", "ntokens": "14620.7", "nsentences": "85.48", "nll_loss": "0.523", "wps": "37904", "ups": "2.59", "wpb": "14620.7", "bsz": "85.5", "num_updates": "87600", "lr": "7.56219e-06", "gnorm": "130.717", "loss_scale": "8", "train_wall": "64", "gb_free": "32.3", "wall": "28812"}
[2024-07-10 05:17:04,574][train_inner][INFO] - {"epoch": 51, "update": 50.136, "loss": "88.784", "ntokens": "14591.9", "nsentences": "84.56", "nll_loss": "0.514", "wps": "45223.3", "ups": "3.1", "wpb": "14591.9", "bsz": "84.6", "num_updates": "87800", "lr": "7.48705e-06", "gnorm": "129.885", "loss_scale": "8", "train_wall": "64", "gb_free": "33.6", "wall": "28877"}
[2024-07-10 05:18:08,932][train_inner][INFO] - {"epoch": 51, "update": 50.25, "loss": "90.713", "ntokens": "14548", "nsentences": "84.36", "nll_loss": "0.526", "wps": "45256.2", "ups": "3.11", "wpb": "14548", "bsz": "84.4", "num_updates": "88000", "lr": "7.41266e-06", "gnorm": "133.101", "loss_scale": "8", "train_wall": "64", "gb_free": "31.9", "wall": "28941"}
[2024-07-10 05:19:12,532][train_inner][INFO] - {"epoch": 51, "update": 50.364, "loss": "90.499", "ntokens": "14436.6", "nsentences": "82.795", "nll_loss": "0.519", "wps": "45445.1", "ups": "3.15", "wpb": "14436.6", "bsz": "82.8", "num_updates": "88200", "lr": "7.339e-06", "gnorm": "132.613", "loss_scale": "8", "train_wall": "63", "gb_free": "29.8", "wall": "29004"}
[2024-07-10 05:20:16,333][train_inner][INFO] - {"epoch": 51, "update": 50.478, "loss": "88.987", "ntokens": "14589.6", "nsentences": "85.92", "nll_loss": "0.524", "wps": "45739.8", "ups": "3.14", "wpb": "14589.6", "bsz": "85.9", "num_updates": "88400", "lr": "7.26608e-06", "gnorm": "130.15", "loss_scale": "16", "train_wall": "63", "gb_free": "31.9", "wall": "29068"}
[2024-07-10 05:21:20,555][train_inner][INFO] - {"epoch": 51, "update": 50.592, "loss": "84.559", "ntokens": "14597.9", "nsentences": "87.88", "nll_loss": "0.509", "wps": "45505.1", "ups": "3.12", "wpb": "14597.9", "bsz": "87.9", "num_updates": "88600", "lr": "7.19389e-06", "gnorm": "126.773", "loss_scale": "16", "train_wall": "64", "gb_free": "32.8", "wall": "29132"}
[2024-07-10 05:22:24,568][train_inner][INFO] - {"epoch": 51, "update": 50.707, "loss": "91.868", "ntokens": "14631.5", "nsentences": "84.28", "nll_loss": "0.529", "wps": "45717.6", "ups": "3.12", "wpb": "14631.5", "bsz": "84.3", "num_updates": "88800", "lr": "7.12241e-06", "gnorm": "130.4", "loss_scale": "16", "train_wall": "64", "gb_free": "30.1", "wall": "29197"}
[2024-07-10 05:23:28,954][train_inner][INFO] - {"epoch": 51, "update": 50.821, "loss": "88.392", "ntokens": "14654.8", "nsentences": "85.8", "nll_loss": "0.518", "wps": "45525.2", "ups": "3.11", "wpb": "14654.8", "bsz": "85.8", "num_updates": "89000", "lr": "7.05164e-06", "gnorm": "126.548", "loss_scale": "16", "train_wall": "64", "gb_free": "32.7", "wall": "29261"}
[2024-07-10 05:24:33,791][train_inner][INFO] - {"epoch": 51, "update": 50.935, "loss": "88.033", "ntokens": "14578.2", "nsentences": "82.76", "nll_loss": "0.5", "wps": "44972.6", "ups": "3.08", "wpb": "14578.2", "bsz": "82.8", "num_updates": "89200", "lr": "6.98157e-06", "gnorm": "131.931", "loss_scale": "16", "train_wall": "64", "gb_free": "33.3", "wall": "29326"}
[2024-07-10 05:25:09,973][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 05:25:09,975][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 05:25:20,728][dev-other][INFO] - {"epoch": 51, "dev-other_loss": "23.146", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.246", "dev-other_uer": "3.968", "dev-other_wer": "10.587", "dev-other_raw_wer": "10.587", "dev-other_wps": "27636.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "89314", "dev-other_best_wer": "10.587"}
[2024-07-10 05:25:20,729][fairseq_cli.train][INFO] - end of epoch 51 (average epoch stats below)
[2024-07-10 05:25:20,731][train][INFO] - {"epoch": 51, "train_loss": "88.687", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.516", "train_wps": "44519", "train_ups": "3.05", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "89314", "train_lr": "6.94195e-06", "train_gnorm": "129.978", "train_loss_scale": "16", "train_train_wall": "558", "train_gb_free": "33", "train_wall": "29373"}
[2024-07-10 05:25:20,733][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 05:25:21,484][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 05:25:21,494][fairseq.trainer][INFO] - begin training epoch 52
[2024-07-10 05:25:21,494][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 05:25:49,503][train_inner][INFO] - {"epoch": 52, "update": 51.049, "loss": "87.214", "ntokens": "14521", "nsentences": "84.08", "nll_loss": "0.505", "wps": "38362.3", "ups": "2.64", "wpb": "14521", "bsz": "84.1", "num_updates": "89400", "lr": "6.9122e-06", "gnorm": "128.814", "loss_scale": "16", "train_wall": "63", "gb_free": "33.2", "wall": "29401"}
[2024-07-10 05:25:51,682][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 05:26:53,903][train_inner][INFO] - {"epoch": 52, "update": 51.164, "loss": "88.554", "ntokens": "14512.3", "nsentences": "84.12", "nll_loss": "0.513", "wps": "45120.2", "ups": "3.11", "wpb": "14512.3", "bsz": "84.1", "num_updates": "89600", "lr": "6.84352e-06", "gnorm": "130.823", "loss_scale": "8", "train_wall": "64", "gb_free": "33.5", "wall": "29466"}
[2024-07-10 05:27:58,193][train_inner][INFO] - {"epoch": 52, "update": 51.278, "loss": "91.34", "ntokens": "14623.7", "nsentences": "83.64", "nll_loss": "0.522", "wps": "45497.1", "ups": "3.11", "wpb": "14623.7", "bsz": "83.6", "num_updates": "89800", "lr": "6.77553e-06", "gnorm": "134.613", "loss_scale": "8", "train_wall": "64", "gb_free": "31.5", "wall": "29530"}
[2024-07-10 05:29:02,354][train_inner][INFO] - {"epoch": 52, "update": 51.392, "loss": "87.586", "ntokens": "14560.4", "nsentences": "84.755", "nll_loss": "0.51", "wps": "45392.2", "ups": "3.12", "wpb": "14560.4", "bsz": "84.8", "num_updates": "90000", "lr": "6.7082e-06", "gnorm": "130.817", "loss_scale": "8", "train_wall": "64", "gb_free": "32.6", "wall": "29594"}
[2024-07-10 05:30:06,989][train_inner][INFO] - {"epoch": 52, "update": 51.506, "loss": "87.583", "ntokens": "14676.2", "nsentences": "85.4", "nll_loss": "0.51", "wps": "45417.1", "ups": "3.09", "wpb": "14676.2", "bsz": "85.4", "num_updates": "90200", "lr": "6.64155e-06", "gnorm": "128.922", "loss_scale": "8", "train_wall": "64", "gb_free": "31.8", "wall": "29659"}
[2024-07-10 05:31:10,733][train_inner][INFO] - {"epoch": 52, "update": 51.62, "loss": "90.132", "ntokens": "14560.7", "nsentences": "84.16", "nll_loss": "0.521", "wps": "45689.8", "ups": "3.14", "wpb": "14560.7", "bsz": "84.2", "num_updates": "90400", "lr": "6.57556e-06", "gnorm": "130.571", "loss_scale": "8", "train_wall": "63", "gb_free": "32", "wall": "29723"}
[2024-07-10 05:32:14,734][train_inner][INFO] - {"epoch": 52, "update": 51.735, "loss": "86.79", "ntokens": "14592.6", "nsentences": "87.64", "nll_loss": "0.521", "wps": "45649.3", "ups": "3.13", "wpb": "14592.6", "bsz": "87.6", "num_updates": "90600", "lr": "6.51022e-06", "gnorm": "127.81", "loss_scale": "8", "train_wall": "63", "gb_free": "32.9", "wall": "29787"}
[2024-07-10 05:33:18,836][train_inner][INFO] - {"epoch": 52, "update": 51.849, "loss": "86.627", "ntokens": "14603.5", "nsentences": "85.84", "nll_loss": "0.509", "wps": "45567.1", "ups": "3.12", "wpb": "14603.5", "bsz": "85.8", "num_updates": "90800", "lr": "6.44554e-06", "gnorm": "129.494", "loss_scale": "8", "train_wall": "64", "gb_free": "33.2", "wall": "29851"}
[2024-07-10 05:34:23,024][train_inner][INFO] - {"epoch": 52, "update": 51.963, "loss": "90.29", "ntokens": "14528.6", "nsentences": "83.92", "nll_loss": "0.522", "wps": "45319.8", "ups": "3.12", "wpb": "14528.6", "bsz": "83.9", "num_updates": "91000", "lr": "6.38149e-06", "gnorm": "130.452", "loss_scale": "8", "train_wall": "64", "gb_free": "32.5", "wall": "29915"}
[2024-07-10 05:34:43,661][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 05:34:43,662][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 05:34:54,399][dev-other][INFO] - {"epoch": 52, "dev-other_loss": "23.179", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.246", "dev-other_uer": "3.938", "dev-other_wer": "10.536", "dev-other_raw_wer": "10.536", "dev-other_wps": "27644.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "91065", "dev-other_best_wer": "10.536"}
[2024-07-10 05:34:54,399][fairseq_cli.train][INFO] - end of epoch 52 (average epoch stats below)
[2024-07-10 05:34:54,402][train][INFO] - {"epoch": 52, "train_loss": "88.576", "train_ntokens": "14578.4", "train_nsentences": "84.8241", "train_nll_loss": "0.515", "train_wps": "44497.4", "train_ups": "3.05", "train_wpb": "14578.4", "train_bsz": "84.8", "train_num_updates": "91065", "train_lr": "6.36082e-06", "train_gnorm": "130.616", "train_loss_scale": "8", "train_train_wall": "558", "train_gb_free": "33.5", "train_wall": "29946"}
[2024-07-10 05:34:54,404][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 05:34:55,088][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 05:34:55,092][fairseq.trainer][INFO] - begin training epoch 53
[2024-07-10 05:34:55,092][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 05:35:38,561][train_inner][INFO] - {"epoch": 53, "update": 52.077, "loss": "89.155", "ntokens": "14513.3", "nsentences": "83.76", "nll_loss": "0.515", "wps": "38462.3", "ups": "2.65", "wpb": "14513.3", "bsz": "83.8", "num_updates": "91200", "lr": "6.31809e-06", "gnorm": "132.466", "loss_scale": "8", "train_wall": "63", "gb_free": "31.6", "wall": "29990"}
[2024-07-10 05:36:41,764][train_inner][INFO] - {"epoch": 53, "update": 52.191, "loss": "89.134", "ntokens": "14515.7", "nsentences": "84.44", "nll_loss": "0.519", "wps": "45981.9", "ups": "3.17", "wpb": "14515.7", "bsz": "84.4", "num_updates": "91400", "lr": "6.25531e-06", "gnorm": "130.322", "loss_scale": "8", "train_wall": "63", "gb_free": "32.2", "wall": "30054"}
[2024-07-10 05:37:45,421][train_inner][INFO] - {"epoch": 53, "update": 52.305, "loss": "87.592", "ntokens": "14688.8", "nsentences": "86.995", "nll_loss": "0.519", "wps": "46154.6", "ups": "3.14", "wpb": "14688.8", "bsz": "87", "num_updates": "91600", "lr": "6.19316e-06", "gnorm": "129.379", "loss_scale": "16", "train_wall": "63", "gb_free": "32", "wall": "30117"}
[2024-07-10 05:38:49,095][train_inner][INFO] - {"epoch": 53, "update": 52.42, "loss": "87.918", "ntokens": "14506.6", "nsentences": "84.52", "nll_loss": "0.512", "wps": "45614.8", "ups": "3.14", "wpb": "14506.6", "bsz": "84.5", "num_updates": "91800", "lr": "6.13162e-06", "gnorm": "129.706", "loss_scale": "16", "train_wall": "63", "gb_free": "32.8", "wall": "30181"}
[2024-07-10 05:39:52,957][train_inner][INFO] - {"epoch": 53, "update": 52.534, "loss": "90.81", "ntokens": "14616.7", "nsentences": "84.36", "nll_loss": "0.524", "wps": "45781.9", "ups": "3.13", "wpb": "14616.7", "bsz": "84.4", "num_updates": "92000", "lr": "6.0707e-06", "gnorm": "129.56", "loss_scale": "16", "train_wall": "63", "gb_free": "32.5", "wall": "30245"}
[2024-07-10 05:40:57,365][train_inner][INFO] - {"epoch": 53, "update": 52.648, "loss": "87.806", "ntokens": "14640.4", "nsentences": "84.56", "nll_loss": "0.507", "wps": "45498.3", "ups": "3.11", "wpb": "14640.4", "bsz": "84.6", "num_updates": "92200", "lr": "6.01038e-06", "gnorm": "129.833", "loss_scale": "16", "train_wall": "64", "gb_free": "31.9", "wall": "30309"}
[2024-07-10 05:41:53,256][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 05:42:02,360][train_inner][INFO] - {"epoch": 53, "update": 52.763, "loss": "88.174", "ntokens": "14580.4", "nsentences": "84.56", "nll_loss": "0.511", "wps": "44916.5", "ups": "3.08", "wpb": "14580.4", "bsz": "84.6", "num_updates": "92400", "lr": "5.95066e-06", "gnorm": "129.809", "loss_scale": "8", "train_wall": "64", "gb_free": "33.3", "wall": "30374"}
[2024-07-10 05:43:06,350][train_inner][INFO] - {"epoch": 53, "update": 52.877, "loss": "90.091", "ntokens": "14586.1", "nsentences": "84.68", "nll_loss": "0.523", "wps": "45607.6", "ups": "3.13", "wpb": "14586.1", "bsz": "84.7", "num_updates": "92600", "lr": "5.89153e-06", "gnorm": "130.663", "loss_scale": "8", "train_wall": "63", "gb_free": "31.9", "wall": "30438"}
[2024-07-10 05:44:10,363][train_inner][INFO] - {"epoch": 53, "update": 52.991, "loss": "86.602", "ntokens": "14530.4", "nsentences": "84.6", "nll_loss": "0.504", "wps": "45412.1", "ups": "3.13", "wpb": "14530.4", "bsz": "84.6", "num_updates": "92800", "lr": "5.83299e-06", "gnorm": "129.908", "loss_scale": "8", "train_wall": "64", "gb_free": "32", "wall": "30502"}
[2024-07-10 05:44:15,423][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 05:44:15,424][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 05:44:26,275][dev-other][INFO] - {"epoch": 53, "dev-other_loss": "23.065", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.245", "dev-other_uer": "3.945", "dev-other_wer": "10.593", "dev-other_raw_wer": "10.593", "dev-other_wps": "27580.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "92816", "dev-other_best_wer": "10.593"}
[2024-07-10 05:44:26,276][fairseq_cli.train][INFO] - end of epoch 53 (average epoch stats below)
[2024-07-10 05:44:26,349][train][INFO] - {"epoch": 53, "train_loss": "88.518", "train_ntokens": "14577.5", "train_nsentences": "84.8058", "train_nll_loss": "0.515", "train_wps": "44634.2", "train_ups": "3.06", "train_wpb": "14577.5", "train_bsz": "84.8", "train_num_updates": "92816", "train_lr": "5.82834e-06", "train_gnorm": "129.959", "train_loss_scale": "8", "train_train_wall": "556", "train_gb_free": "32.7", "train_wall": "30518"}
[2024-07-10 05:44:26,351][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 05:44:26,981][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 05:44:26,985][fairseq.trainer][INFO] - begin training epoch 54
[2024-07-10 05:44:26,985][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 05:45:26,728][train_inner][INFO] - {"epoch": 54, "update": 53.105, "loss": "87.578", "ntokens": "14624.1", "nsentences": "86.64", "nll_loss": "0.519", "wps": "38311.4", "ups": "2.62", "wpb": "14624.1", "bsz": "86.6", "num_updates": "93000", "lr": "5.77504e-06", "gnorm": "126.477", "loss_scale": "8", "train_wall": "64", "gb_free": "32.7", "wall": "30579"}
[2024-07-10 05:46:30,628][train_inner][INFO] - {"epoch": 54, "update": 53.219, "loss": "89.017", "ntokens": "14563.5", "nsentences": "85", "nll_loss": "0.52", "wps": "45585.8", "ups": "3.13", "wpb": "14563.5", "bsz": "85", "num_updates": "93200", "lr": "5.71766e-06", "gnorm": "131.322", "loss_scale": "8", "train_wall": "63", "gb_free": "33.2", "wall": "30643"}
[2024-07-10 05:47:34,206][train_inner][INFO] - {"epoch": 54, "update": 53.333, "loss": "92.438", "ntokens": "14512", "nsentences": "81.08", "nll_loss": "0.516", "wps": "45702.9", "ups": "3.15", "wpb": "14512", "bsz": "81.1", "num_updates": "93400", "lr": "5.66084e-06", "gnorm": "133.823", "loss_scale": "8", "train_wall": "63", "gb_free": "32.5", "wall": "30706"}
[2024-07-10 05:48:37,780][train_inner][INFO] - {"epoch": 54, "update": 53.447, "loss": "89.283", "ntokens": "14586.6", "nsentences": "85.115", "nll_loss": "0.521", "wps": "45892.1", "ups": "3.15", "wpb": "14586.6", "bsz": "85.1", "num_updates": "93600", "lr": "5.6046e-06", "gnorm": "128.848", "loss_scale": "8", "train_wall": "63", "gb_free": "33.4", "wall": "30770"}
[2024-07-10 05:49:41,661][train_inner][INFO] - {"epoch": 54, "update": 53.562, "loss": "89.934", "ntokens": "14581.6", "nsentences": "85.64", "nll_loss": "0.528", "wps": "45711", "ups": "3.13", "wpb": "14581.6", "bsz": "85.6", "num_updates": "93800", "lr": "5.54891e-06", "gnorm": "129.875", "loss_scale": "8", "train_wall": "63", "gb_free": "32", "wall": "30834"}
[2024-07-10 05:50:45,123][train_inner][INFO] - {"epoch": 54, "update": 53.676, "loss": "88.556", "ntokens": "14502.7", "nsentences": "85.2", "nll_loss": "0.52", "wps": "45751.8", "ups": "3.15", "wpb": "14502.7", "bsz": "85.2", "num_updates": "94000", "lr": "5.49378e-06", "gnorm": "129.978", "loss_scale": "8", "train_wall": "63", "gb_free": "30.1", "wall": "30897"}
[2024-07-10 05:51:49,051][train_inner][INFO] - {"epoch": 54, "update": 53.79, "loss": "90.471", "ntokens": "14677.2", "nsentences": "84.24", "nll_loss": "0.519", "wps": "45923.4", "ups": "3.13", "wpb": "14677.2", "bsz": "84.2", "num_updates": "94200", "lr": "5.43919e-06", "gnorm": "129.998", "loss_scale": "8", "train_wall": "63", "gb_free": "30.7", "wall": "30961"}
[2024-07-10 05:52:52,637][train_inner][INFO] - {"epoch": 54, "update": 53.904, "loss": "89.066", "ntokens": "14524.8", "nsentences": "86.36", "nll_loss": "0.53", "wps": "45688.6", "ups": "3.15", "wpb": "14524.8", "bsz": "86.4", "num_updates": "94400", "lr": "5.38514e-06", "gnorm": "130.751", "loss_scale": "8", "train_wall": "63", "gb_free": "31.7", "wall": "31025"}
[2024-07-10 05:53:46,089][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 05:53:46,091][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 05:53:56,864][dev-other][INFO] - {"epoch": 54, "dev-other_loss": "23.406", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.249", "dev-other_uer": "3.977", "dev-other_wer": "10.646", "dev-other_raw_wer": "10.646", "dev-other_wps": "27669.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "94568", "dev-other_best_wer": "10.623"}
[2024-07-10 05:53:56,864][fairseq_cli.train][INFO] - end of epoch 54 (average epoch stats below)
[2024-07-10 05:53:56,867][train][INFO] - {"epoch": 54, "train_loss": "89.893", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.523", "train_wps": "44766.3", "train_ups": "3.07", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "94568", "train_lr": "5.34016e-06", "train_gnorm": "130.334", "train_loss_scale": "16", "train_train_wall": "555", "train_gb_free": "32.1", "train_wall": "31089"}
[2024-07-10 05:53:56,868][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 05:53:57,565][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 05:53:57,584][fairseq.trainer][INFO] - begin training epoch 55
[2024-07-10 05:53:57,584][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 05:54:08,360][train_inner][INFO] - {"epoch": 55, "update": 54.018, "loss": "91.18", "ntokens": "14603.8", "nsentences": "84.96", "nll_loss": "0.53", "wps": "38608.4", "ups": "2.64", "wpb": "14603.8", "bsz": "85", "num_updates": "94600", "lr": "5.33164e-06", "gnorm": "131.555", "loss_scale": "16", "train_wall": "64", "gb_free": "30.1", "wall": "31100"}
[2024-07-10 05:54:23,767][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 05:55:13,111][train_inner][INFO] - {"epoch": 55, "update": 54.133, "loss": "87.342", "ntokens": "14627", "nsentences": "85.64", "nll_loss": "0.511", "wps": "45183.3", "ups": "3.09", "wpb": "14627", "bsz": "85.6", "num_updates": "94800", "lr": "5.27866e-06", "gnorm": "127.347", "loss_scale": "8", "train_wall": "64", "gb_free": "32", "wall": "31165"}
[2024-07-10 05:56:16,732][train_inner][INFO] - {"epoch": 55, "update": 54.247, "loss": "90.201", "ntokens": "14585.9", "nsentences": "84.28", "nll_loss": "0.521", "wps": "45855.3", "ups": "3.14", "wpb": "14585.9", "bsz": "84.3", "num_updates": "95000", "lr": "5.22621e-06", "gnorm": "130.432", "loss_scale": "8", "train_wall": "63", "gb_free": "32", "wall": "31229"}
[2024-07-10 05:57:20,633][train_inner][INFO] - {"epoch": 55, "update": 54.361, "loss": "86.885", "ntokens": "14643.9", "nsentences": "86.075", "nll_loss": "0.511", "wps": "45838.7", "ups": "3.13", "wpb": "14643.9", "bsz": "86.1", "num_updates": "95200", "lr": "5.17428e-06", "gnorm": "127.758", "loss_scale": "8", "train_wall": "63", "gb_free": "32.4", "wall": "31293"}
[2024-07-10 05:58:24,938][train_inner][INFO] - {"epoch": 55, "update": 54.475, "loss": "85.383", "ntokens": "14643.7", "nsentences": "87.04", "nll_loss": "0.508", "wps": "45550.4", "ups": "3.11", "wpb": "14643.7", "bsz": "87", "num_updates": "95400", "lr": "5.12287e-06", "gnorm": "128.049", "loss_scale": "8", "train_wall": "64", "gb_free": "32.6", "wall": "31357"}
[2024-07-10 05:59:28,691][train_inner][INFO] - {"epoch": 55, "update": 54.59, "loss": "88.765", "ntokens": "14418.9", "nsentences": "83.48", "nll_loss": "0.514", "wps": "45286.5", "ups": "3.14", "wpb": "14418.9", "bsz": "83.5", "num_updates": "95600", "lr": "5.07197e-06", "gnorm": "131.544", "loss_scale": "8", "train_wall": "63", "gb_free": "32.1", "wall": "31421"}
[2024-07-10 06:00:32,345][train_inner][INFO] - {"epoch": 55, "update": 54.704, "loss": "89.06", "ntokens": "14664.9", "nsentences": "84.88", "nll_loss": "0.515", "wps": "46080.9", "ups": "3.14", "wpb": "14664.9", "bsz": "84.9", "num_updates": "95800", "lr": "5.02158e-06", "gnorm": "129.74", "loss_scale": "8", "train_wall": "63", "gb_free": "31.6", "wall": "31484"}
[2024-07-10 06:01:36,351][train_inner][INFO] - {"epoch": 55, "update": 54.818, "loss": "89.431", "ntokens": "14555.1", "nsentences": "84.48", "nll_loss": "0.519", "wps": "45530.5", "ups": "3.13", "wpb": "14555.1", "bsz": "84.5", "num_updates": "96000", "lr": "4.97168e-06", "gnorm": "130.08", "loss_scale": "8", "train_wall": "63", "gb_free": "32", "wall": "31548"}
[2024-07-10 06:02:38,675][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-07-10 06:02:40,955][train_inner][INFO] - {"epoch": 55, "update": 54.933, "loss": "90.769", "ntokens": "14570.3", "nsentences": "83.2", "nll_loss": "0.518", "wps": "45158.4", "ups": "3.1", "wpb": "14570.3", "bsz": "83.2", "num_updates": "96200", "lr": "4.92228e-06", "gnorm": "130.43", "loss_scale": "4", "train_wall": "64", "gb_free": "32.1", "wall": "31613"}
[2024-07-10 06:03:18,449][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 06:03:18,450][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 06:03:29,493][dev-other][INFO] - {"epoch": 55, "dev-other_loss": "23.47", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.249", "dev-other_uer": "3.97", "dev-other_wer": "10.599", "dev-other_raw_wer": "10.599", "dev-other_wps": "27665.3", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "96318", "dev-other_best_wer": "10.599"}
[2024-07-10 06:03:29,494][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 55 @ 96318 updates
[2024-07-10 06:03:29,495][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-10 06:03:30,708][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-10 06:03:31,311][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 55 @ 96318 updates, score 10.599) (writing took 1.816565241664648 seconds)
[2024-07-10 06:03:31,311][fairseq_cli.train][INFO] - end of epoch 55 (average epoch stats below)
[2024-07-10 06:03:31,315][train][INFO] - {"epoch": 55, "train_loss": "88.346", "train_ntokens": "14577.9", "train_nsentences": "84.8223", "train_nll_loss": "0.514", "train_wps": "44410.3", "train_ups": "3.05", "train_wpb": "14577.9", "train_bsz": "84.8", "train_num_updates": "96318", "train_lr": "4.89337e-06", "train_gnorm": "129.591", "train_loss_scale": "4", "train_train_wall": "556", "train_gb_free": "33.2", "train_wall": "31663"}
[2024-07-10 06:03:31,317][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 06:03:31,580][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 06:03:31,583][fairseq.trainer][INFO] - begin training epoch 56
[2024-07-10 06:03:31,583][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 06:03:58,309][train_inner][INFO] - {"epoch": 56, "update": 55.047, "loss": "89.518", "ntokens": "14590.6", "nsentences": "84.24", "nll_loss": "0.517", "wps": "37725.4", "ups": "2.59", "wpb": "14590.6", "bsz": "84.2", "num_updates": "96400", "lr": "4.87337e-06", "gnorm": "131.814", "loss_scale": "4", "train_wall": "64", "gb_free": "32.7", "wall": "31690"}
[2024-07-10 06:05:02,807][train_inner][INFO] - {"epoch": 56, "update": 55.161, "loss": "88.44", "ntokens": "14504.3", "nsentences": "82.8", "nll_loss": "0.505", "wps": "45023.8", "ups": "3.1", "wpb": "14504.3", "bsz": "82.8", "num_updates": "96600", "lr": "4.82495e-06", "gnorm": "132.252", "loss_scale": "4", "train_wall": "64", "gb_free": "32.2", "wall": "31755"}
[2024-07-10 06:06:07,463][train_inner][INFO] - {"epoch": 56, "update": 55.275, "loss": "86.227", "ntokens": "14744.1", "nsentences": "88.36", "nll_loss": "0.517", "wps": "45699.3", "ups": "3.1", "wpb": "14744.1", "bsz": "88.4", "num_updates": "96800", "lr": "4.77701e-06", "gnorm": "125.512", "loss_scale": "4", "train_wall": "64", "gb_free": "32.7", "wall": "31819"}
[2024-07-10 06:07:11,337][train_inner][INFO] - {"epoch": 56, "update": 55.389, "loss": "89.875", "ntokens": "14498.2", "nsentences": "82.68", "nll_loss": "0.513", "wps": "45419", "ups": "3.13", "wpb": "14498.2", "bsz": "82.7", "num_updates": "97000", "lr": "4.72955e-06", "gnorm": "132.35", "loss_scale": "4", "train_wall": "63", "gb_free": "31.9", "wall": "31883"}
[2024-07-10 06:08:15,919][train_inner][INFO] - {"epoch": 56, "update": 55.503, "loss": "86.761", "ntokens": "14708.4", "nsentences": "86.88", "nll_loss": "0.512", "wps": "45595", "ups": "3.1", "wpb": "14708.4", "bsz": "86.9", "num_updates": "97200", "lr": "4.68255e-06", "gnorm": "127.546", "loss_scale": "4", "train_wall": "64", "gb_free": "32.1", "wall": "31948"}
[2024-07-10 06:09:19,668][train_inner][INFO] - {"epoch": 56, "update": 55.618, "loss": "90.503", "ntokens": "14548.3", "nsentences": "83.6", "nll_loss": "0.52", "wps": "45693.5", "ups": "3.14", "wpb": "14548.3", "bsz": "83.6", "num_updates": "97400", "lr": "4.63603e-06", "gnorm": "131.378", "loss_scale": "4", "train_wall": "63", "gb_free": "32.2", "wall": "32012"}
[2024-07-10 06:10:23,560][train_inner][INFO] - {"epoch": 56, "update": 55.732, "loss": "88.806", "ntokens": "14450", "nsentences": "84.12", "nll_loss": "0.517", "wps": "45238.8", "ups": "3.13", "wpb": "14450", "bsz": "84.1", "num_updates": "97600", "lr": "4.58996e-06", "gnorm": "130.572", "loss_scale": "4", "train_wall": "63", "gb_free": "32.8", "wall": "32076"}
[2024-07-10 06:11:27,810][train_inner][INFO] - {"epoch": 56, "update": 55.846, "loss": "84.952", "ntokens": "14571.3", "nsentences": "87.12", "nll_loss": "0.508", "wps": "45404.7", "ups": "3.12", "wpb": "14571.3", "bsz": "87.1", "num_updates": "97800", "lr": "4.54436e-06", "gnorm": "128.49", "loss_scale": "4", "train_wall": "64", "gb_free": "31.8", "wall": "32140"}
[2024-07-10 06:12:31,449][train_inner][INFO] - {"epoch": 56, "update": 55.96, "loss": "88.718", "ntokens": "14528.8", "nsentences": "84.675", "nll_loss": "0.517", "wps": "45713", "ups": "3.15", "wpb": "14528.8", "bsz": "84.7", "num_updates": "98000", "lr": "4.4992e-06", "gnorm": "131.064", "loss_scale": "4", "train_wall": "63", "gb_free": "32.9", "wall": "32203"}
[2024-07-10 06:12:53,708][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 06:12:53,710][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 06:13:04,473][dev-other][INFO] - {"epoch": 56, "dev-other_loss": "23.397", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.249", "dev-other_uer": "3.937", "dev-other_wer": "10.577", "dev-other_raw_wer": "10.577", "dev-other_wps": "27658", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "98070", "dev-other_best_wer": "10.577"}
[2024-07-10 06:13:04,474][fairseq_cli.train][INFO] - end of epoch 56 (average epoch stats below)
[2024-07-10 06:13:04,506][train][INFO] - {"epoch": 56, "train_loss": "88.297", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.514", "train_wps": "44559.8", "train_ups": "3.06", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "98070", "train_lr": "4.48351e-06", "train_gnorm": "130.181", "train_loss_scale": "4", "train_train_wall": "557", "train_gb_free": "33", "train_wall": "32236"}
[2024-07-10 06:13:04,508][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 06:13:05,221][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 06:13:05,225][fairseq.trainer][INFO] - begin training epoch 57
[2024-07-10 06:13:05,226][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 06:13:47,207][train_inner][INFO] - {"epoch": 57, "update": 56.074, "loss": "89.135", "ntokens": "14505.2", "nsentences": "83.96", "nll_loss": "0.516", "wps": "38328.8", "ups": "2.64", "wpb": "14505.2", "bsz": "84", "num_updates": "98200", "lr": "4.4545e-06", "gnorm": "134.004", "loss_scale": "4", "train_wall": "64", "gb_free": "32.2", "wall": "32279"}
[2024-07-10 06:14:50,986][train_inner][INFO] - {"epoch": 57, "update": 56.188, "loss": "89.632", "ntokens": "14536.1", "nsentences": "83.84", "nll_loss": "0.517", "wps": "45587.1", "ups": "3.14", "wpb": "14536.1", "bsz": "83.8", "num_updates": "98400", "lr": "4.41024e-06", "gnorm": "129.901", "loss_scale": "8", "train_wall": "63", "gb_free": "30.4", "wall": "32343"}
[2024-07-10 06:15:54,883][train_inner][INFO] - {"epoch": 57, "update": 56.303, "loss": "88.624", "ntokens": "14595.6", "nsentences": "84.24", "nll_loss": "0.512", "wps": "45732.5", "ups": "3.13", "wpb": "14595.6", "bsz": "84.2", "num_updates": "98600", "lr": "4.36642e-06", "gnorm": "130.156", "loss_scale": "8", "train_wall": "63", "gb_free": "32", "wall": "32407"}
[2024-07-10 06:16:58,250][train_inner][INFO] - {"epoch": 57, "update": 56.417, "loss": "89.89", "ntokens": "14558.3", "nsentences": "85.56", "nll_loss": "0.528", "wps": "45954.9", "ups": "3.16", "wpb": "14558.3", "bsz": "85.6", "num_updates": "98800", "lr": "4.32303e-06", "gnorm": "129.823", "loss_scale": "8", "train_wall": "63", "gb_free": "30.5", "wall": "32470"}
[2024-07-10 06:18:02,049][train_inner][INFO] - {"epoch": 57, "update": 56.531, "loss": "89.609", "ntokens": "14536.3", "nsentences": "83.035", "nll_loss": "0.512", "wps": "45620.2", "ups": "3.14", "wpb": "14536.3", "bsz": "83", "num_updates": "99000", "lr": "4.28008e-06", "gnorm": "132.735", "loss_scale": "8", "train_wall": "63", "gb_free": "31.6", "wall": "32534"}
[2024-07-10 06:19:06,991][train_inner][INFO] - {"epoch": 57, "update": 56.645, "loss": "87.111", "ntokens": "14762", "nsentences": "88.28", "nll_loss": "0.521", "wps": "45466.5", "ups": "3.08", "wpb": "14762", "bsz": "88.3", "num_updates": "99200", "lr": "4.23755e-06", "gnorm": "126.631", "loss_scale": "8", "train_wall": "64", "gb_free": "32.2", "wall": "32599"}
[2024-07-10 06:20:10,475][train_inner][INFO] - {"epoch": 57, "update": 56.759, "loss": "85.16", "ntokens": "14567.3", "nsentences": "87.52", "nll_loss": "0.512", "wps": "45897.1", "ups": "3.15", "wpb": "14567.3", "bsz": "87.5", "num_updates": "99400", "lr": "4.19545e-06", "gnorm": "126.77", "loss_scale": "8", "train_wall": "63", "gb_free": "32.8", "wall": "32662"}
[2024-07-10 06:21:14,017][train_inner][INFO] - {"epoch": 57, "update": 56.873, "loss": "90.434", "ntokens": "14589.6", "nsentences": "83.76", "nll_loss": "0.519", "wps": "45924.1", "ups": "3.15", "wpb": "14589.6", "bsz": "83.8", "num_updates": "99600", "lr": "4.15376e-06", "gnorm": "132.351", "loss_scale": "8", "train_wall": "63", "gb_free": "29.8", "wall": "32726"}
[2024-07-10 06:22:17,773][train_inner][INFO] - {"epoch": 57, "update": 56.987, "loss": "90.226", "ntokens": "14535.6", "nsentences": "82.64", "nll_loss": "0.513", "wps": "45601.6", "ups": "3.14", "wpb": "14535.6", "bsz": "82.6", "num_updates": "99800", "lr": "4.11249e-06", "gnorm": "132.207", "loss_scale": "8", "train_wall": "63", "gb_free": "32.1", "wall": "32790"}
[2024-07-10 06:22:24,654][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 06:22:24,655][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 06:22:35,356][dev-other][INFO] - {"epoch": 57, "dev-other_loss": "22.621", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.24", "dev-other_uer": "3.9", "dev-other_wer": "10.46", "dev-other_raw_wer": "10.46", "dev-other_wps": "27779.3", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "99822", "dev-other_best_wer": "10.46"}
[2024-07-10 06:22:35,357][fairseq_cli.train][INFO] - end of epoch 57 (average epoch stats below)
[2024-07-10 06:22:35,360][train][INFO] - {"epoch": 57, "train_loss": "88.809", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.517", "train_wps": "44739.9", "train_ups": "3.07", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "99822", "train_lr": "4.10797e-06", "train_gnorm": "130.364", "train_loss_scale": "8", "train_train_wall": "555", "train_gb_free": "31.7", "train_wall": "32807"}
[2024-07-10 06:22:35,361][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 06:22:36,109][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 06:22:36,112][fairseq.trainer][INFO] - begin training epoch 58
[2024-07-10 06:22:36,112][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 06:23:33,603][train_inner][INFO] - {"epoch": 58, "update": 57.102, "loss": "87.204", "ntokens": "14631.9", "nsentences": "86", "nll_loss": "0.513", "wps": "38594.5", "ups": "2.64", "wpb": "14631.9", "bsz": "86", "num_updates": "100000", "lr": "4.07163e-06", "gnorm": "129.845", "loss_scale": "8", "train_wall": "64", "gb_free": "32.5", "wall": "32866"}
[2024-07-10 06:24:37,299][train_inner][INFO] - {"epoch": 58, "update": 57.216, "loss": "92.899", "ntokens": "14505.1", "nsentences": "81.84", "nll_loss": "0.524", "wps": "45548.2", "ups": "3.14", "wpb": "14505.1", "bsz": "81.8", "num_updates": "100200", "lr": "4.03117e-06", "gnorm": "133.971", "loss_scale": "8", "train_wall": "63", "gb_free": "31.7", "wall": "32929"}
[2024-07-10 06:25:40,910][train_inner][INFO] - {"epoch": 58, "update": 57.33, "loss": "89.868", "ntokens": "14440.6", "nsentences": "82.24", "nll_loss": "0.512", "wps": "45454", "ups": "3.15", "wpb": "14440.6", "bsz": "82.2", "num_updates": "100400", "lr": "3.99112e-06", "gnorm": "134.177", "loss_scale": "16", "train_wall": "63", "gb_free": "34.2", "wall": "32993"}
[2024-07-10 06:26:44,662][train_inner][INFO] - {"epoch": 58, "update": 57.444, "loss": "87.66", "ntokens": "14580.6", "nsentences": "85.04", "nll_loss": "0.511", "wps": "45744.4", "ups": "3.14", "wpb": "14580.6", "bsz": "85", "num_updates": "100600", "lr": "3.95146e-06", "gnorm": "130.188", "loss_scale": "16", "train_wall": "63", "gb_free": "32.8", "wall": "33057"}
[2024-07-10 06:27:48,100][train_inner][INFO] - {"epoch": 58, "update": 57.558, "loss": "87.03", "ntokens": "14610.1", "nsentences": "85.8", "nll_loss": "0.511", "wps": "46066.2", "ups": "3.15", "wpb": "14610.1", "bsz": "85.8", "num_updates": "100800", "lr": "3.9122e-06", "gnorm": "129.745", "loss_scale": "16", "train_wall": "63", "gb_free": "32", "wall": "33120"}
[2024-07-10 06:28:22,256][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 06:28:52,064][train_inner][INFO] - {"epoch": 58, "update": 57.673, "loss": "88.9", "ntokens": "14536.8", "nsentences": "84.44", "nll_loss": "0.516", "wps": "45456.6", "ups": "3.13", "wpb": "14536.8", "bsz": "84.4", "num_updates": "101000", "lr": "3.87333e-06", "gnorm": "131.255", "loss_scale": "8", "train_wall": "63", "gb_free": "33.4", "wall": "33184"}
[2024-07-10 06:29:56,480][train_inner][INFO] - {"epoch": 58, "update": 57.787, "loss": "89.226", "ntokens": "14679", "nsentences": "86.2", "nll_loss": "0.524", "wps": "45578.8", "ups": "3.11", "wpb": "14679", "bsz": "86.2", "num_updates": "101200", "lr": "3.83484e-06", "gnorm": "128.023", "loss_scale": "8", "train_wall": "64", "gb_free": "33", "wall": "33248"}
[2024-07-10 06:31:00,585][train_inner][INFO] - {"epoch": 58, "update": 57.901, "loss": "88.089", "ntokens": "14652.7", "nsentences": "86.6", "nll_loss": "0.521", "wps": "45720.3", "ups": "3.12", "wpb": "14652.7", "bsz": "86.6", "num_updates": "101400", "lr": "3.79674e-06", "gnorm": "128.934", "loss_scale": "8", "train_wall": "64", "gb_free": "33.1", "wall": "33313"}
[2024-07-10 06:31:55,963][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 06:31:55,964][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 06:32:06,716][dev-other][INFO] - {"epoch": 58, "dev-other_loss": "23.043", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.245", "dev-other_uer": "3.931", "dev-other_wer": "10.52", "dev-other_raw_wer": "10.52", "dev-other_wps": "27667.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "101573", "dev-other_best_wer": "10.52"}
[2024-07-10 06:32:06,716][fairseq_cli.train][INFO] - end of epoch 58 (average epoch stats below)
[2024-07-10 06:32:06,745][train][INFO] - {"epoch": 58, "train_loss": "88.617", "train_ntokens": "14578.7", "train_nsentences": "84.8241", "train_nll_loss": "0.516", "train_wps": "44678.5", "train_ups": "3.06", "train_wpb": "14578.7", "train_bsz": "84.8", "train_num_updates": "101573", "train_lr": "3.76408e-06", "train_gnorm": "130.698", "train_loss_scale": "8", "train_train_wall": "555", "train_gb_free": "32.4", "train_wall": "33379"}
[2024-07-10 06:32:06,747][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 06:32:07,454][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 06:32:07,460][fairseq.trainer][INFO] - begin training epoch 59
[2024-07-10 06:32:07,461][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 06:32:16,360][train_inner][INFO] - {"epoch": 59, "update": 58.015, "loss": "86.87", "ntokens": "14532.4", "nsentences": "84.715", "nll_loss": "0.506", "wps": "38359.3", "ups": "2.64", "wpb": "14532.4", "bsz": "84.7", "num_updates": "101600", "lr": "3.75901e-06", "gnorm": "130.394", "loss_scale": "8", "train_wall": "64", "gb_free": "32.2", "wall": "33388"}
[2024-07-10 06:33:19,170][train_inner][INFO] - {"epoch": 59, "update": 58.13, "loss": "91.221", "ntokens": "14451.3", "nsentences": "82.2", "nll_loss": "0.519", "wps": "46018.7", "ups": "3.18", "wpb": "14451.3", "bsz": "82.2", "num_updates": "101800", "lr": "3.72166e-06", "gnorm": "133.991", "loss_scale": "8", "train_wall": "62", "gb_free": "31.3", "wall": "33451"}
[2024-07-10 06:34:22,356][train_inner][INFO] - {"epoch": 59, "update": 58.244, "loss": "86.929", "ntokens": "14473.7", "nsentences": "85.08", "nll_loss": "0.511", "wps": "45815.9", "ups": "3.17", "wpb": "14473.7", "bsz": "85.1", "num_updates": "102000", "lr": "3.68468e-06", "gnorm": "129.204", "loss_scale": "8", "train_wall": "63", "gb_free": "32.1", "wall": "33514"}
[2024-07-10 06:35:26,213][train_inner][INFO] - {"epoch": 59, "update": 58.358, "loss": "90.487", "ntokens": "14574.6", "nsentences": "82.92", "nll_loss": "0.515", "wps": "45651.9", "ups": "3.13", "wpb": "14574.6", "bsz": "82.9", "num_updates": "102200", "lr": "3.64807e-06", "gnorm": "131.485", "loss_scale": "8", "train_wall": "63", "gb_free": "33.2", "wall": "33578"}
[2024-07-10 06:36:30,633][train_inner][INFO] - {"epoch": 59, "update": 58.472, "loss": "87.302", "ntokens": "14636.6", "nsentences": "86.12", "nll_loss": "0.514", "wps": "45444.6", "ups": "3.1", "wpb": "14636.6", "bsz": "86.1", "num_updates": "102400", "lr": "3.61183e-06", "gnorm": "128.633", "loss_scale": "8", "train_wall": "64", "gb_free": "32.7", "wall": "33643"}
[2024-07-10 06:37:34,953][train_inner][INFO] - {"epoch": 59, "update": 58.586, "loss": "84.375", "ntokens": "14670.9", "nsentences": "87.2", "nll_loss": "0.502", "wps": "45622.3", "ups": "3.11", "wpb": "14670.9", "bsz": "87.2", "num_updates": "102600", "lr": "3.57594e-06", "gnorm": "127.612", "loss_scale": "8", "train_wall": "64", "gb_free": "30.3", "wall": "33707"}
[2024-07-10 06:38:38,677][train_inner][INFO] - {"epoch": 59, "update": 58.7, "loss": "88.926", "ntokens": "14552.9", "nsentences": "85.035", "nll_loss": "0.52", "wps": "45678.1", "ups": "3.14", "wpb": "14552.9", "bsz": "85", "num_updates": "102800", "lr": "3.54041e-06", "gnorm": "129.167", "loss_scale": "8", "train_wall": "63", "gb_free": "32.5", "wall": "33771"}
[2024-07-10 06:39:43,213][train_inner][INFO] - {"epoch": 59, "update": 58.814, "loss": "90.733", "ntokens": "14665.5", "nsentences": "84.44", "nll_loss": "0.522", "wps": "45452.2", "ups": "3.1", "wpb": "14665.6", "bsz": "84.4", "num_updates": "103000", "lr": "3.50523e-06", "gnorm": "129.807", "loss_scale": "16", "train_wall": "64", "gb_free": "32.3", "wall": "33835"}
[2024-07-10 06:40:47,446][train_inner][INFO] - {"epoch": 59, "update": 58.929, "loss": "84.852", "ntokens": "14644.6", "nsentences": "86.88", "nll_loss": "0.503", "wps": "45603.1", "ups": "3.11", "wpb": "14644.6", "bsz": "86.9", "num_updates": "103200", "lr": "3.4704e-06", "gnorm": "128.72", "loss_scale": "16", "train_wall": "64", "gb_free": "30.3", "wall": "33899"}
[2024-07-10 06:41:27,254][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 06:41:27,255][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 06:41:38,080][dev-other][INFO] - {"epoch": 59, "dev-other_loss": "23.852", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.254", "dev-other_uer": "3.956", "dev-other_wer": "10.556", "dev-other_raw_wer": "10.556", "dev-other_wps": "27580.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "103325", "dev-other_best_wer": "10.556"}
[2024-07-10 06:41:38,081][fairseq_cli.train][INFO] - end of epoch 59 (average epoch stats below)
[2024-07-10 06:41:38,087][train][INFO] - {"epoch": 59, "train_loss": "88.099", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.513", "train_wps": "44702", "train_ups": "3.07", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "103325", "train_lr": "3.44881e-06", "train_gnorm": "129.832", "train_loss_scale": "16", "train_train_wall": "556", "train_gb_free": "33.1", "train_wall": "33950"}
[2024-07-10 06:41:38,089][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 06:41:38,765][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 06:41:38,768][fairseq.trainer][INFO] - begin training epoch 60
[2024-07-10 06:41:38,769][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 06:42:03,306][train_inner][INFO] - {"epoch": 60, "update": 59.043, "loss": "89.286", "ntokens": "14592.8", "nsentences": "83.8", "nll_loss": "0.513", "wps": "38509.8", "ups": "2.64", "wpb": "14592.8", "bsz": "83.8", "num_updates": "103400", "lr": "3.43592e-06", "gnorm": "130.908", "loss_scale": "16", "train_wall": "64", "gb_free": "31.4", "wall": "33975"}
[2024-07-10 06:43:07,823][train_inner][INFO] - {"epoch": 60, "update": 59.157, "loss": "89.073", "ntokens": "14657.7", "nsentences": "85.84", "nll_loss": "0.522", "wps": "45487.6", "ups": "3.1", "wpb": "14657.7", "bsz": "85.8", "num_updates": "103600", "lr": "3.40178e-06", "gnorm": "128.641", "loss_scale": "16", "train_wall": "64", "gb_free": "32.7", "wall": "34040"}
[2024-07-10 06:44:12,424][train_inner][INFO] - {"epoch": 60, "update": 59.271, "loss": "84.32", "ntokens": "14707", "nsentences": "87.28", "nll_loss": "0.5", "wps": "45537.9", "ups": "3.1", "wpb": "14707", "bsz": "87.3", "num_updates": "103800", "lr": "3.36798e-06", "gnorm": "126.864", "loss_scale": "16", "train_wall": "64", "gb_free": "31.9", "wall": "34104"}
[2024-07-10 06:45:16,933][train_inner][INFO] - {"epoch": 60, "update": 59.385, "loss": "84.831", "ntokens": "14583.5", "nsentences": "85.64", "nll_loss": "0.498", "wps": "45218.8", "ups": "3.1", "wpb": "14583.5", "bsz": "85.6", "num_updates": "104000", "lr": "3.33451e-06", "gnorm": "129.78", "loss_scale": "16", "train_wall": "64", "gb_free": "31.9", "wall": "34169"}
[2024-07-10 06:46:21,129][train_inner][INFO] - {"epoch": 60, "update": 59.499, "loss": "86.384", "ntokens": "14569.7", "nsentences": "85.92", "nll_loss": "0.509", "wps": "45439.9", "ups": "3.12", "wpb": "14569.7", "bsz": "85.9", "num_updates": "104200", "lr": "3.30138e-06", "gnorm": "129.403", "loss_scale": "16", "train_wall": "64", "gb_free": "31.8", "wall": "34233"}
[2024-07-10 06:46:59,377][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 06:47:25,197][train_inner][INFO] - {"epoch": 60, "update": 59.614, "loss": "84.544", "ntokens": "14535.6", "nsentences": "86.075", "nll_loss": "0.501", "wps": "45379.2", "ups": "3.12", "wpb": "14535.6", "bsz": "86.1", "num_updates": "104400", "lr": "3.26858e-06", "gnorm": "130.755", "loss_scale": "8", "train_wall": "64", "gb_free": "31.9", "wall": "34297"}
[2024-07-10 06:48:29,387][train_inner][INFO] - {"epoch": 60, "update": 59.728, "loss": "90.165", "ntokens": "14572.2", "nsentences": "83", "nll_loss": "0.514", "wps": "45410.9", "ups": "3.12", "wpb": "14572.2", "bsz": "83", "num_updates": "104600", "lr": "3.2361e-06", "gnorm": "130.344", "loss_scale": "8", "train_wall": "64", "gb_free": "32.1", "wall": "34361"}
[2024-07-10 06:49:32,944][train_inner][INFO] - {"epoch": 60, "update": 59.842, "loss": "89.772", "ntokens": "14516.3", "nsentences": "82.6", "nll_loss": "0.511", "wps": "45687.2", "ups": "3.15", "wpb": "14516.3", "bsz": "82.6", "num_updates": "104800", "lr": "3.20395e-06", "gnorm": "133.079", "loss_scale": "8", "train_wall": "63", "gb_free": "30.7", "wall": "34425"}
[2024-07-10 06:50:36,510][train_inner][INFO] - {"epoch": 60, "update": 59.957, "loss": "91.441", "ntokens": "14545.8", "nsentences": "84.92", "nll_loss": "0.534", "wps": "45770", "ups": "3.15", "wpb": "14545.8", "bsz": "84.9", "num_updates": "105000", "lr": "3.17211e-06", "gnorm": "132.261", "loss_scale": "8", "train_wall": "63", "gb_free": "32.1", "wall": "34488"}
[2024-07-10 06:51:00,428][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 06:51:00,429][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 06:51:11,155][dev-other][INFO] - {"epoch": 60, "dev-other_loss": "22.823", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.243", "dev-other_uer": "3.913", "dev-other_wer": "10.471", "dev-other_raw_wer": "10.471", "dev-other_wps": "27858", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "105076", "dev-other_best_wer": "10.471"}
[2024-07-10 06:51:11,156][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 60 @ 105076 updates
[2024-07-10 06:51:11,157][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-10 06:51:12,405][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt
[2024-07-10 06:51:13,048][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_best.pt (epoch 60 @ 105076 updates, score 10.471) (writing took 1.8923881985247135 seconds)
[2024-07-10 06:51:13,049][fairseq_cli.train][INFO] - end of epoch 60 (average epoch stats below)
[2024-07-10 06:51:13,052][train][INFO] - {"epoch": 60, "train_loss": "87.823", "train_ntokens": "14577.6", "train_nsentences": "84.8195", "train_nll_loss": "0.511", "train_wps": "44394.8", "train_ups": "3.05", "train_wpb": "14577.6", "train_bsz": "84.8", "train_num_updates": "105076", "train_lr": "3.1601e-06", "train_gnorm": "130.613", "train_loss_scale": "8", "train_train_wall": "557", "train_gb_free": "32", "train_wall": "34525"}
[2024-07-10 06:51:13,053][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 06:51:13,308][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 06:51:13,312][fairseq.trainer][INFO] - begin training epoch 61
[2024-07-10 06:51:13,312][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 06:51:53,129][train_inner][INFO] - {"epoch": 61, "update": 60.071, "loss": "90.025", "ntokens": "14422.7", "nsentences": "82.04", "nll_loss": "0.512", "wps": "37681.6", "ups": "2.61", "wpb": "14422.7", "bsz": "82", "num_updates": "105200", "lr": "3.1406e-06", "gnorm": "133.452", "loss_scale": "8", "train_wall": "63", "gb_free": "31.6", "wall": "34565"}
[2024-07-10 06:52:57,253][train_inner][INFO] - {"epoch": 61, "update": 60.185, "loss": "87.06", "ntokens": "14502", "nsentences": "84.48", "nll_loss": "0.507", "wps": "45234.5", "ups": "3.12", "wpb": "14502", "bsz": "84.5", "num_updates": "105400", "lr": "3.10939e-06", "gnorm": "130.29", "loss_scale": "8", "train_wall": "64", "gb_free": "31.8", "wall": "34629"}
[2024-07-10 06:54:01,319][train_inner][INFO] - {"epoch": 61, "update": 60.299, "loss": "85.839", "ntokens": "14433.3", "nsentences": "85.72", "nll_loss": "0.51", "wps": "45108.4", "ups": "3.13", "wpb": "14433.3", "bsz": "85.7", "num_updates": "105600", "lr": "3.0785e-06", "gnorm": "129.651", "loss_scale": "8", "train_wall": "64", "gb_free": "32.9", "wall": "34693"}
[2024-07-10 06:55:05,890][train_inner][INFO] - {"epoch": 61, "update": 60.413, "loss": "89.268", "ntokens": "14708", "nsentences": "84.88", "nll_loss": "0.515", "wps": "45606", "ups": "3.1", "wpb": "14708", "bsz": "84.9", "num_updates": "105800", "lr": "3.04791e-06", "gnorm": "128.924", "loss_scale": "8", "train_wall": "64", "gb_free": "32.1", "wall": "34758"}
[2024-07-10 06:56:09,895][train_inner][INFO] - {"epoch": 61, "update": 60.527, "loss": "88.967", "ntokens": "14515.6", "nsentences": "83.84", "nll_loss": "0.514", "wps": "45363.2", "ups": "3.13", "wpb": "14515.6", "bsz": "83.8", "num_updates": "106000", "lr": "3.01762e-06", "gnorm": "130.514", "loss_scale": "8", "train_wall": "64", "gb_free": "31.8", "wall": "34822"}
[2024-07-10 06:57:14,130][train_inner][INFO] - {"epoch": 61, "update": 60.642, "loss": "89.25", "ntokens": "14708.5", "nsentences": "84.64", "nll_loss": "0.514", "wps": "45798.2", "ups": "3.11", "wpb": "14708.5", "bsz": "84.6", "num_updates": "106200", "lr": "2.98764e-06", "gnorm": "133.268", "loss_scale": "8", "train_wall": "64", "gb_free": "33", "wall": "34886"}
[2024-07-10 06:58:18,241][train_inner][INFO] - {"epoch": 61, "update": 60.756, "loss": "88.066", "ntokens": "14586.8", "nsentences": "85.6", "nll_loss": "0.517", "wps": "45574.8", "ups": "3.12", "wpb": "14586.8", "bsz": "85.6", "num_updates": "106400", "lr": "2.95795e-06", "gnorm": "130.369", "loss_scale": "16", "train_wall": "64", "gb_free": "31.6", "wall": "34950"}
[2024-07-10 06:59:22,489][train_inner][INFO] - {"epoch": 61, "update": 60.87, "loss": "86.685", "ntokens": "14642.7", "nsentences": "86.435", "nll_loss": "0.512", "wps": "45630.8", "ups": "3.12", "wpb": "14642.7", "bsz": "86.4", "num_updates": "106600", "lr": "2.92856e-06", "gnorm": "126.86", "loss_scale": "16", "train_wall": "64", "gb_free": "32.6", "wall": "35014"}
[2024-07-10 07:00:26,438][train_inner][INFO] - {"epoch": 61, "update": 60.984, "loss": "89.683", "ntokens": "14609.8", "nsentences": "83.64", "nll_loss": "0.513", "wps": "45696.9", "ups": "3.13", "wpb": "14609.8", "bsz": "83.6", "num_updates": "106800", "lr": "2.89946e-06", "gnorm": "130.73", "loss_scale": "16", "train_wall": "64", "gb_free": "31.5", "wall": "35078"}
[2024-07-10 07:00:35,328][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 07:00:35,329][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 07:00:46,071][dev-other][INFO] - {"epoch": 61, "dev-other_loss": "23.128", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.246", "dev-other_uer": "3.919", "dev-other_wer": "10.526", "dev-other_raw_wer": "10.526", "dev-other_wps": "27844.6", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "106828", "dev-other_best_wer": "10.471"}
[2024-07-10 07:00:46,072][fairseq_cli.train][INFO] - end of epoch 61 (average epoch stats below)
[2024-07-10 07:00:46,077][train][INFO] - {"epoch": 61, "train_loss": "87.958", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.512", "train_wps": "44570.6", "train_ups": "3.06", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "106828", "train_lr": "2.89541e-06", "train_gnorm": "130.09", "train_loss_scale": "16", "train_train_wall": "557", "train_gb_free": "32.6", "train_wall": "35098"}
[2024-07-10 07:00:46,079][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 07:00:46,777][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 07:00:46,781][fairseq.trainer][INFO] - begin training epoch 62
[2024-07-10 07:00:46,781][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 07:01:42,767][train_inner][INFO] - {"epoch": 62, "update": 61.098, "loss": "85.833", "ntokens": "14531.6", "nsentences": "83.56", "nll_loss": "0.494", "wps": "38096.2", "ups": "2.62", "wpb": "14531.6", "bsz": "83.6", "num_updates": "107000", "lr": "2.87066e-06", "gnorm": "130.767", "loss_scale": "16", "train_wall": "64", "gb_free": "32.3", "wall": "35155"}
[2024-07-10 07:02:46,364][train_inner][INFO] - {"epoch": 62, "update": 61.212, "loss": "87.892", "ntokens": "14474.5", "nsentences": "83.96", "nll_loss": "0.51", "wps": "45523.1", "ups": "3.15", "wpb": "14474.5", "bsz": "84", "num_updates": "107200", "lr": "2.84213e-06", "gnorm": "131.14", "loss_scale": "16", "train_wall": "63", "gb_free": "31.9", "wall": "35218"}
[2024-07-10 07:03:50,169][train_inner][INFO] - {"epoch": 62, "update": 61.326, "loss": "87.273", "ntokens": "14577.8", "nsentences": "86.28", "nll_loss": "0.517", "wps": "45703", "ups": "3.14", "wpb": "14577.8", "bsz": "86.3", "num_updates": "107400", "lr": "2.81389e-06", "gnorm": "128.414", "loss_scale": "16", "train_wall": "63", "gb_free": "32.8", "wall": "35282"}
[2024-07-10 07:04:54,390][train_inner][INFO] - {"epoch": 62, "update": 61.441, "loss": "87.322", "ntokens": "14633.2", "nsentences": "84.84", "nll_loss": "0.506", "wps": "45577.5", "ups": "3.11", "wpb": "14633.2", "bsz": "84.8", "num_updates": "107600", "lr": "2.78593e-06", "gnorm": "129.499", "loss_scale": "16", "train_wall": "64", "gb_free": "31.5", "wall": "35346"}
[2024-07-10 07:05:22,455][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 07:05:58,939][train_inner][INFO] - {"epoch": 62, "update": 61.555, "loss": "89.678", "ntokens": "14488.4", "nsentences": "82.6", "nll_loss": "0.511", "wps": "44915.8", "ups": "3.1", "wpb": "14488.4", "bsz": "82.6", "num_updates": "107800", "lr": "2.75825e-06", "gnorm": "134.454", "loss_scale": "8", "train_wall": "64", "gb_free": "31.8", "wall": "35411"}
[2024-07-10 07:07:03,521][train_inner][INFO] - {"epoch": 62, "update": 61.67, "loss": "86.442", "ntokens": "14655.4", "nsentences": "85.72", "nll_loss": "0.506", "wps": "45388.6", "ups": "3.1", "wpb": "14655.4", "bsz": "85.7", "num_updates": "108000", "lr": "2.73085e-06", "gnorm": "128.977", "loss_scale": "8", "train_wall": "64", "gb_free": "29.7", "wall": "35475"}
[2024-07-10 07:08:07,473][train_inner][INFO] - {"epoch": 62, "update": 61.784, "loss": "87.01", "ntokens": "14568.5", "nsentences": "85.6", "nll_loss": "0.511", "wps": "45565.4", "ups": "3.13", "wpb": "14568.5", "bsz": "85.6", "num_updates": "108200", "lr": "2.70371e-06", "gnorm": "127.663", "loss_scale": "8", "train_wall": "63", "gb_free": "31.9", "wall": "35539"}
[2024-07-10 07:09:11,832][train_inner][INFO] - {"epoch": 62, "update": 61.898, "loss": "85.453", "ntokens": "14647.4", "nsentences": "86.675", "nll_loss": "0.506", "wps": "45569.4", "ups": "3.11", "wpb": "14647.4", "bsz": "86.7", "num_updates": "108400", "lr": "2.67685e-06", "gnorm": "128.253", "loss_scale": "8", "train_wall": "64", "gb_free": "32", "wall": "35604"}
[2024-07-10 07:10:08,964][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 07:10:08,965][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 07:10:19,731][dev-other][INFO] - {"epoch": 62, "dev-other_loss": "22.96", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.244", "dev-other_uer": "3.926", "dev-other_wer": "10.499", "dev-other_raw_wer": "10.499", "dev-other_wps": "27629.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "108579", "dev-other_best_wer": "10.471"}
[2024-07-10 07:10:19,731][fairseq_cli.train][INFO] - end of epoch 62 (average epoch stats below)
[2024-07-10 07:10:19,734][train][INFO] - {"epoch": 62, "train_loss": "87.359", "train_ntokens": "14577.5", "train_nsentences": "84.815", "train_nll_loss": "0.508", "train_wps": "44495.9", "train_ups": "3.05", "train_wpb": "14577.5", "train_bsz": "84.8", "train_num_updates": "108579", "train_lr": "2.65303e-06", "train_gnorm": "129.93", "train_loss_scale": "8", "train_train_wall": "558", "train_gb_free": "33.6", "train_wall": "35672"}
[2024-07-10 07:10:19,735][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 07:10:20,478][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 07:10:20,485][fairseq.trainer][INFO] - begin training epoch 63
[2024-07-10 07:10:20,486][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 07:10:27,474][train_inner][INFO] - {"epoch": 63, "update": 62.012, "loss": "88.615", "ntokens": "14581.8", "nsentences": "83.76", "nll_loss": "0.509", "wps": "38558.8", "ups": "2.64", "wpb": "14581.8", "bsz": "83.8", "num_updates": "108600", "lr": "2.65025e-06", "gnorm": "130.764", "loss_scale": "8", "train_wall": "63", "gb_free": "32.6", "wall": "35679"}
[2024-07-10 07:11:31,298][train_inner][INFO] - {"epoch": 63, "update": 62.126, "loss": "89.517", "ntokens": "14528.4", "nsentences": "83.04", "nll_loss": "0.512", "wps": "45573.7", "ups": "3.14", "wpb": "14528.4", "bsz": "83", "num_updates": "108800", "lr": "2.62392e-06", "gnorm": "131.651", "loss_scale": "8", "train_wall": "63", "gb_free": "30.2", "wall": "35743"}
[2024-07-10 07:12:35,103][train_inner][INFO] - {"epoch": 63, "update": 62.24, "loss": "91.325", "ntokens": "14574.4", "nsentences": "81.64", "nll_loss": "0.512", "wps": "45687.6", "ups": "3.13", "wpb": "14574.4", "bsz": "81.6", "num_updates": "109000", "lr": "2.59785e-06", "gnorm": "133.819", "loss_scale": "8", "train_wall": "63", "gb_free": "33", "wall": "35807"}
[2024-07-10 07:13:39,900][train_inner][INFO] - {"epoch": 63, "update": 62.354, "loss": "84.289", "ntokens": "14688.7", "nsentences": "87.96", "nll_loss": "0.505", "wps": "45389.6", "ups": "3.09", "wpb": "14688.7", "bsz": "88", "num_updates": "109200", "lr": "2.57203e-06", "gnorm": "126.809", "loss_scale": "8", "train_wall": "64", "gb_free": "31.7", "wall": "35872"}
[2024-07-10 07:14:44,409][train_inner][INFO] - {"epoch": 63, "update": 62.469, "loss": "88.856", "ntokens": "14686.1", "nsentences": "84.84", "nll_loss": "0.513", "wps": "45535.5", "ups": "3.1", "wpb": "14686.1", "bsz": "84.8", "num_updates": "109400", "lr": "2.54648e-06", "gnorm": "130.388", "loss_scale": "8", "train_wall": "64", "gb_free": "33.4", "wall": "35936"}
[2024-07-10 07:15:49,071][train_inner][INFO] - {"epoch": 63, "update": 62.583, "loss": "86.483", "ntokens": "14521.1", "nsentences": "85.08", "nll_loss": "0.507", "wps": "44988.3", "ups": "3.1", "wpb": "14521.1", "bsz": "85.1", "num_updates": "109600", "lr": "2.52118e-06", "gnorm": "129.979", "loss_scale": "8", "train_wall": "64", "gb_free": "32.6", "wall": "36001"}
[2024-07-10 07:16:53,301][train_inner][INFO] - {"epoch": 63, "update": 62.697, "loss": "84.89", "ntokens": "14611.5", "nsentences": "88.12", "nll_loss": "0.512", "wps": "45505.4", "ups": "3.11", "wpb": "14611.5", "bsz": "88.1", "num_updates": "109800", "lr": "2.49613e-06", "gnorm": "126.562", "loss_scale": "16", "train_wall": "64", "gb_free": "33.3", "wall": "36065"}
[2024-07-10 07:17:57,721][train_inner][INFO] - {"epoch": 63, "update": 62.811, "loss": "87.458", "ntokens": "14555.7", "nsentences": "83.6", "nll_loss": "0.502", "wps": "45193.6", "ups": "3.1", "wpb": "14555.7", "bsz": "83.6", "num_updates": "110000", "lr": "2.47132e-06", "gnorm": "131.203", "loss_scale": "16", "train_wall": "64", "gb_free": "31.5", "wall": "36130"}
[2024-07-10 07:19:01,085][train_inner][INFO] - {"epoch": 63, "update": 62.925, "loss": "89.104", "ntokens": "14485", "nsentences": "84.68", "nll_loss": "0.521", "wps": "45725.6", "ups": "3.16", "wpb": "14485", "bsz": "84.7", "num_updates": "110200", "lr": "2.44677e-06", "gnorm": "129.144", "loss_scale": "16", "train_wall": "63", "gb_free": "29.4", "wall": "36193"}
[2024-07-10 07:19:42,934][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 07:19:42,936][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 07:19:53,689][dev-other][INFO] - {"epoch": 63, "dev-other_loss": "23.314", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.248", "dev-other_uer": "3.915", "dev-other_wer": "10.501", "dev-other_raw_wer": "10.501", "dev-other_wps": "27873", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "110331", "dev-other_best_wer": "10.471"}
[2024-07-10 07:19:53,690][fairseq_cli.train][INFO] - end of epoch 63 (average epoch stats below)
[2024-07-10 07:19:53,693][train][INFO] - {"epoch": 63, "train_loss": "87.517", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.51", "train_wps": "44497.9", "train_ups": "3.05", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "110331", "train_lr": "2.43082e-06", "train_gnorm": "129.862", "train_loss_scale": "16", "train_train_wall": "558", "train_gb_free": "32.6", "train_wall": "36246"}
[2024-07-10 07:19:53,694][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 07:19:54,382][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 07:19:54,388][fairseq.trainer][INFO] - begin training epoch 64
[2024-07-10 07:19:54,388][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 07:20:16,861][train_inner][INFO] - {"epoch": 64, "update": 63.039, "loss": "86.065", "ntokens": "14538.6", "nsentences": "84.555", "nll_loss": "0.501", "wps": "38376.1", "ups": "2.64", "wpb": "14538.6", "bsz": "84.6", "num_updates": "110400", "lr": "2.42246e-06", "gnorm": "129.048", "loss_scale": "16", "train_wall": "64", "gb_free": "30.1", "wall": "36269"}
[2024-07-10 07:21:21,055][train_inner][INFO] - {"epoch": 64, "update": 63.154, "loss": "84.699", "ntokens": "14670.1", "nsentences": "86.88", "nll_loss": "0.502", "wps": "45708.7", "ups": "3.12", "wpb": "14670.1", "bsz": "86.9", "num_updates": "110600", "lr": "2.39839e-06", "gnorm": "127.665", "loss_scale": "16", "train_wall": "64", "gb_free": "29.7", "wall": "36333"}
[2024-07-10 07:22:25,131][train_inner][INFO] - {"epoch": 64, "update": 63.268, "loss": "88.053", "ntokens": "14577.1", "nsentences": "83.92", "nll_loss": "0.507", "wps": "45549.3", "ups": "3.12", "wpb": "14577.1", "bsz": "83.9", "num_updates": "110800", "lr": "2.37456e-06", "gnorm": "130.702", "loss_scale": "16", "train_wall": "64", "gb_free": "32.7", "wall": "36397"}
[2024-07-10 07:23:28,441][train_inner][INFO] - {"epoch": 64, "update": 63.382, "loss": "87.641", "ntokens": "14526.5", "nsentences": "85.4", "nll_loss": "0.515", "wps": "45942.2", "ups": "3.16", "wpb": "14526.5", "bsz": "85.4", "num_updates": "111000", "lr": "2.35096e-06", "gnorm": "129.857", "loss_scale": "16", "train_wall": "63", "gb_free": "33.3", "wall": "36460"}
[2024-07-10 07:24:32,076][train_inner][INFO] - {"epoch": 64, "update": 63.496, "loss": "89.148", "ntokens": "14594.5", "nsentences": "83.76", "nll_loss": "0.512", "wps": "45873.1", "ups": "3.14", "wpb": "14594.5", "bsz": "83.8", "num_updates": "111200", "lr": "2.3276e-06", "gnorm": "129.958", "loss_scale": "16", "train_wall": "63", "gb_free": "31.9", "wall": "36524"}
[2024-07-10 07:25:36,650][train_inner][INFO] - {"epoch": 64, "update": 63.61, "loss": "88.096", "ntokens": "14685.2", "nsentences": "86.075", "nll_loss": "0.516", "wps": "45528.7", "ups": "3.1", "wpb": "14685.2", "bsz": "86.1", "num_updates": "111400", "lr": "2.30448e-06", "gnorm": "131.981", "loss_scale": "16", "train_wall": "64", "gb_free": "31.8", "wall": "36589"}
[2024-07-10 07:26:40,580][train_inner][INFO] - {"epoch": 64, "update": 63.724, "loss": "87.382", "ntokens": "14606.2", "nsentences": "84.88", "nll_loss": "0.508", "wps": "45699.2", "ups": "3.13", "wpb": "14606.2", "bsz": "84.9", "num_updates": "111600", "lr": "2.28158e-06", "gnorm": "129.69", "loss_scale": "16", "train_wall": "63", "gb_free": "31.9", "wall": "36653"}
[2024-07-10 07:27:43,347][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-10 07:27:44,946][train_inner][INFO] - {"epoch": 64, "update": 63.839, "loss": "88.054", "ntokens": "14615", "nsentences": "86.4", "nll_loss": "0.521", "wps": "45461.2", "ups": "3.11", "wpb": "14615", "bsz": "86.4", "num_updates": "111800", "lr": "2.25891e-06", "gnorm": "128.876", "loss_scale": "16", "train_wall": "64", "gb_free": "33", "wall": "36717"}
[2024-07-10 07:28:35,256][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 07:28:48,811][train_inner][INFO] - {"epoch": 64, "update": 63.954, "loss": "90.244", "ntokens": "14387.1", "nsentences": "81.52", "nll_loss": "0.511", "wps": "45055.8", "ups": "3.13", "wpb": "14387.1", "bsz": "81.5", "num_updates": "112000", "lr": "2.23646e-06", "gnorm": "134.793", "loss_scale": "8", "train_wall": "63", "gb_free": "31.8", "wall": "36781"}
[2024-07-10 07:29:14,362][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 07:29:14,363][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 07:29:25,108][dev-other][INFO] - {"epoch": 64, "dev-other_loss": "23.142", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.246", "dev-other_uer": "3.92", "dev-other_wer": "10.485", "dev-other_raw_wer": "10.485", "dev-other_wps": "27597.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "112081", "dev-other_best_wer": "10.471"}
[2024-07-10 07:29:25,109][fairseq_cli.train][INFO] - end of epoch 64 (average epoch stats below)
[2024-07-10 07:29:25,111][train][INFO] - {"epoch": 64, "train_loss": "87.907", "train_ntokens": "14577.1", "train_nsentences": "84.7903", "train_nll_loss": "0.511", "train_wps": "44643.5", "train_ups": "3.06", "train_wpb": "14577.1", "train_bsz": "84.8", "train_num_updates": "112081", "train_lr": "2.22744e-06", "train_gnorm": "130.448", "train_loss_scale": "8", "train_train_wall": "555", "train_gb_free": "32", "train_wall": "36817"}
[2024-07-10 07:29:25,113][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 07:29:25,851][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 07:29:25,861][fairseq.trainer][INFO] - begin training epoch 65
[2024-07-10 07:29:25,861][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 07:30:04,409][train_inner][INFO] - {"epoch": 65, "update": 64.068, "loss": "88.751", "ntokens": "14466.4", "nsentences": "84.64", "nll_loss": "0.519", "wps": "38274.6", "ups": "2.65", "wpb": "14466.4", "bsz": "84.6", "num_updates": "112200", "lr": "2.21424e-06", "gnorm": "132.662", "loss_scale": "8", "train_wall": "64", "gb_free": "32.9", "wall": "36856"}
[2024-07-10 07:31:08,914][train_inner][INFO] - {"epoch": 65, "update": 64.182, "loss": "85.889", "ntokens": "14714.7", "nsentences": "87.28", "nll_loss": "0.509", "wps": "45626.4", "ups": "3.1", "wpb": "14714.7", "bsz": "87.3", "num_updates": "112400", "lr": "2.19224e-06", "gnorm": "127.654", "loss_scale": "8", "train_wall": "64", "gb_free": "31.9", "wall": "36921"}
[2024-07-10 07:32:12,560][train_inner][INFO] - {"epoch": 65, "update": 64.296, "loss": "86.697", "ntokens": "14502.9", "nsentences": "84.16", "nll_loss": "0.503", "wps": "45580.2", "ups": "3.14", "wpb": "14502.9", "bsz": "84.2", "num_updates": "112600", "lr": "2.17046e-06", "gnorm": "131.116", "loss_scale": "8", "train_wall": "63", "gb_free": "31.3", "wall": "36985"}
[2024-07-10 07:33:16,030][train_inner][INFO] - {"epoch": 65, "update": 64.41, "loss": "90.47", "ntokens": "14496.3", "nsentences": "82.88", "nll_loss": "0.517", "wps": "45683.4", "ups": "3.15", "wpb": "14496.3", "bsz": "82.9", "num_updates": "112800", "lr": "2.14889e-06", "gnorm": "133.887", "loss_scale": "8", "train_wall": "63", "gb_free": "32.3", "wall": "37048"}
[2024-07-10 07:33:53,770][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-07-10 07:34:20,194][train_inner][INFO] - {"epoch": 65, "update": 64.525, "loss": "84.422", "ntokens": "14640.9", "nsentences": "88.16", "nll_loss": "0.508", "wps": "45640.6", "ups": "3.12", "wpb": "14640.9", "bsz": "88.2", "num_updates": "113000", "lr": "2.12754e-06", "gnorm": "126.882", "loss_scale": "4", "train_wall": "64", "gb_free": "30", "wall": "37112"}
[2024-07-10 07:35:24,865][train_inner][INFO] - {"epoch": 65, "update": 64.639, "loss": "87.661", "ntokens": "14595.6", "nsentences": "83.56", "nll_loss": "0.502", "wps": "45142", "ups": "3.09", "wpb": "14595.6", "bsz": "83.6", "num_updates": "113200", "lr": "2.1064e-06", "gnorm": "130.06", "loss_scale": "4", "train_wall": "64", "gb_free": "33.6", "wall": "37177"}
[2024-07-10 07:36:29,081][train_inner][INFO] - {"epoch": 65, "update": 64.753, "loss": "87.891", "ntokens": "14498.1", "nsentences": "82.44", "nll_loss": "0.5", "wps": "45161.5", "ups": "3.11", "wpb": "14498.1", "bsz": "82.4", "num_updates": "113400", "lr": "2.08547e-06", "gnorm": "132.932", "loss_scale": "4", "train_wall": "64", "gb_free": "31.4", "wall": "37241"}
[2024-07-10 07:37:33,765][train_inner][INFO] - {"epoch": 65, "update": 64.868, "loss": "84.67", "ntokens": "14689.2", "nsentences": "87.715", "nll_loss": "0.506", "wps": "45425.6", "ups": "3.09", "wpb": "14689.2", "bsz": "87.7", "num_updates": "113600", "lr": "2.06475e-06", "gnorm": "126.838", "loss_scale": "4", "train_wall": "64", "gb_free": "30.2", "wall": "37306"}
[2024-07-10 07:38:38,088][train_inner][INFO] - {"epoch": 65, "update": 64.982, "loss": "87.409", "ntokens": "14572.1", "nsentences": "82.56", "nll_loss": "0.495", "wps": "45360.3", "ups": "3.11", "wpb": "14572.1", "bsz": "82.6", "num_updates": "113800", "lr": "2.04424e-06", "gnorm": "131.183", "loss_scale": "4", "train_wall": "64", "gb_free": "32", "wall": "37370"}
[2024-07-10 07:38:48,061][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 07:38:48,062][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 07:38:58,842][dev-other][INFO] - {"epoch": 65, "dev-other_loss": "22.917", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.244", "dev-other_uer": "3.927", "dev-other_wer": "10.577", "dev-other_raw_wer": "10.577", "dev-other_wps": "27588.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "113832", "dev-other_best_wer": "10.471"}
[2024-07-10 07:38:58,860][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 65 @ 113832 updates
[2024-07-10 07:38:58,861][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_last.pt
[2024-07-10 07:39:00,243][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_last.pt
[2024-07-10 07:39:00,255][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_last.pt (epoch 65 @ 113832 updates, score 10.577) (writing took 1.394464511424303 seconds)
[2024-07-10 07:39:00,255][fairseq_cli.train][INFO] - end of epoch 65 (average epoch stats below)
[2024-07-10 07:39:00,336][train][INFO] - {"epoch": 65, "train_loss": "87.045", "train_ntokens": "14578.3", "train_nsentences": "84.8241", "train_nll_loss": "0.506", "train_wps": "44382.9", "train_ups": "3.04", "train_wpb": "14578.3", "train_bsz": "84.8", "train_num_updates": "113832", "train_lr": "2.04097e-06", "train_gnorm": "130.411", "train_loss_scale": "4", "train_train_wall": "558", "train_gb_free": "31.2", "train_wall": "37392"}
[2024-07-10 07:39:00,337][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 07:39:00,599][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 07:39:00,602][fairseq.trainer][INFO] - begin training epoch 66
[2024-07-10 07:39:00,602][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 07:39:54,942][train_inner][INFO] - {"epoch": 66, "update": 65.096, "loss": "86.85", "ntokens": "14588.2", "nsentences": "86.56", "nll_loss": "0.515", "wps": "37997.6", "ups": "2.6", "wpb": "14588.2", "bsz": "86.6", "num_updates": "114000", "lr": "2.02392e-06", "gnorm": "131.172", "loss_scale": "4", "train_wall": "64", "gb_free": "31.4", "wall": "37447"}
[2024-07-10 07:40:58,681][train_inner][INFO] - {"epoch": 66, "update": 65.21, "loss": "85.465", "ntokens": "14585.1", "nsentences": "86", "nll_loss": "0.504", "wps": "45812.6", "ups": "3.14", "wpb": "14585.1", "bsz": "86", "num_updates": "114200", "lr": "2.00381e-06", "gnorm": "129.707", "loss_scale": "4", "train_wall": "63", "gb_free": "33.2", "wall": "37511"}
[2024-07-10 07:42:02,322][train_inner][INFO] - {"epoch": 66, "update": 65.324, "loss": "89.603", "ntokens": "14520.8", "nsentences": "82.72", "nll_loss": "0.51", "wps": "45636.6", "ups": "3.14", "wpb": "14520.8", "bsz": "82.7", "num_updates": "114400", "lr": "1.9839e-06", "gnorm": "133.275", "loss_scale": "4", "train_wall": "63", "gb_free": "32.5", "wall": "37574"}
[2024-07-10 07:43:05,928][train_inner][INFO] - {"epoch": 66, "update": 65.438, "loss": "87.249", "ntokens": "14606.4", "nsentences": "85.6", "nll_loss": "0.511", "wps": "45946.4", "ups": "3.15", "wpb": "14606.4", "bsz": "85.6", "num_updates": "114600", "lr": "1.96419e-06", "gnorm": "129.325", "loss_scale": "4", "train_wall": "63", "gb_free": "32.6", "wall": "37638"}
[2024-07-10 07:44:09,842][train_inner][INFO] - {"epoch": 66, "update": 65.553, "loss": "88.825", "ntokens": "14558.5", "nsentences": "85.04", "nll_loss": "0.519", "wps": "45605.2", "ups": "3.13", "wpb": "14558.5", "bsz": "85", "num_updates": "114800", "lr": "1.94468e-06", "gnorm": "129.73", "loss_scale": "4", "train_wall": "63", "gb_free": "33.2", "wall": "37702"}
[2024-07-10 07:45:14,231][train_inner][INFO] - {"epoch": 66, "update": 65.667, "loss": "90.44", "ntokens": "14575.7", "nsentences": "82.92", "nll_loss": "0.515", "wps": "45318.3", "ups": "3.11", "wpb": "14575.7", "bsz": "82.9", "num_updates": "115000", "lr": "1.92535e-06", "gnorm": "131.948", "loss_scale": "8", "train_wall": "64", "gb_free": "29.9", "wall": "37766"}
[2024-07-10 07:46:18,480][train_inner][INFO] - {"epoch": 66, "update": 65.781, "loss": "90.012", "ntokens": "14537", "nsentences": "83.475", "nll_loss": "0.517", "wps": "45317.7", "ups": "3.12", "wpb": "14537", "bsz": "83.5", "num_updates": "115200", "lr": "1.90622e-06", "gnorm": "130.94", "loss_scale": "8", "train_wall": "64", "gb_free": "33", "wall": "37830"}
[2024-07-10 07:47:22,214][train_inner][INFO] - {"epoch": 66, "update": 65.895, "loss": "88.797", "ntokens": "14613.2", "nsentences": "85.88", "nll_loss": "0.522", "wps": "45860", "ups": "3.14", "wpb": "14613.2", "bsz": "85.9", "num_updates": "115400", "lr": "1.88728e-06", "gnorm": "129.18", "loss_scale": "8", "train_wall": "63", "gb_free": "32", "wall": "37894"}
[2024-07-10 07:48:20,643][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 07:48:20,644][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 07:48:31,396][dev-other][INFO] - {"epoch": 66, "dev-other_loss": "23.127", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.246", "dev-other_uer": "3.895", "dev-other_wer": "10.454", "dev-other_raw_wer": "10.454", "dev-other_wps": "27703.8", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "115584", "dev-other_best_wer": "10.454"}
[2024-07-10 07:48:31,396][fairseq_cli.train][INFO] - end of epoch 66 (average epoch stats below)
[2024-07-10 07:48:31,399][train][INFO] - {"epoch": 66, "train_loss": "88.646", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.516", "train_wps": "44723.5", "train_ups": "3.07", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "115584", "train_lr": "1.87002e-06", "train_gnorm": "130.626", "train_loss_scale": "8", "train_train_wall": "556", "train_gb_free": "33", "train_wall": "37963"}
[2024-07-10 07:48:31,400][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 07:48:32,148][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 07:48:32,153][fairseq.trainer][INFO] - begin training epoch 67
[2024-07-10 07:48:32,153][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 07:48:37,570][train_inner][INFO] - {"epoch": 67, "update": 66.009, "loss": "90.248", "ntokens": "14583.3", "nsentences": "85.96", "nll_loss": "0.532", "wps": "38707.9", "ups": "2.65", "wpb": "14583.3", "bsz": "86", "num_updates": "115600", "lr": "1.86853e-06", "gnorm": "130.121", "loss_scale": "8", "train_wall": "63", "gb_free": "33", "wall": "37970"}
[2024-07-10 07:49:41,786][train_inner][INFO] - {"epoch": 67, "update": 66.123, "loss": "88.876", "ntokens": "14613.4", "nsentences": "85.16", "nll_loss": "0.518", "wps": "45560.4", "ups": "3.12", "wpb": "14613.4", "bsz": "85.2", "num_updates": "115800", "lr": "1.84996e-06", "gnorm": "129.082", "loss_scale": "8", "train_wall": "64", "gb_free": "33", "wall": "38034"}
[2024-07-10 07:50:45,672][train_inner][INFO] - {"epoch": 67, "update": 66.237, "loss": "89.12", "ntokens": "14587.3", "nsentences": "84.68", "nll_loss": "0.517", "wps": "45716.4", "ups": "3.13", "wpb": "14587.3", "bsz": "84.7", "num_updates": "116000", "lr": "1.83158e-06", "gnorm": "130.493", "loss_scale": "8", "train_wall": "63", "gb_free": "31.6", "wall": "38098"}
[2024-07-10 07:51:49,413][train_inner][INFO] - {"epoch": 67, "update": 66.352, "loss": "87.902", "ntokens": "14508.8", "nsentences": "84.035", "nll_loss": "0.509", "wps": "45527.5", "ups": "3.14", "wpb": "14508.8", "bsz": "84", "num_updates": "116200", "lr": "1.81338e-06", "gnorm": "131.621", "loss_scale": "8", "train_wall": "63", "gb_free": "31.4", "wall": "38161"}
[2024-07-10 07:52:53,290][train_inner][INFO] - {"epoch": 67, "update": 66.466, "loss": "87.528", "ntokens": "14587.1", "nsentences": "85.68", "nll_loss": "0.514", "wps": "45713.7", "ups": "3.13", "wpb": "14587.1", "bsz": "85.7", "num_updates": "116400", "lr": "1.79537e-06", "gnorm": "130.89", "loss_scale": "8", "train_wall": "63", "gb_free": "32.7", "wall": "38225"}
[2024-07-10 07:53:56,657][train_inner][INFO] - {"epoch": 67, "update": 66.58, "loss": "89.538", "ntokens": "14553.1", "nsentences": "83.52", "nll_loss": "0.514", "wps": "45939.5", "ups": "3.16", "wpb": "14553.1", "bsz": "83.5", "num_updates": "116600", "lr": "1.77753e-06", "gnorm": "130.358", "loss_scale": "8", "train_wall": "63", "gb_free": "31.8", "wall": "38289"}
[2024-07-10 07:55:00,595][train_inner][INFO] - {"epoch": 67, "update": 66.694, "loss": "85.91", "ntokens": "14616.7", "nsentences": "86.04", "nll_loss": "0.506", "wps": "45770.2", "ups": "3.13", "wpb": "14616.7", "bsz": "86", "num_updates": "116800", "lr": "1.75987e-06", "gnorm": "128.67", "loss_scale": "8", "train_wall": "63", "gb_free": "30.2", "wall": "38353"}
[2024-07-10 07:56:04,300][train_inner][INFO] - {"epoch": 67, "update": 66.808, "loss": "85.942", "ntokens": "14560.7", "nsentences": "84.12", "nll_loss": "0.497", "wps": "45720", "ups": "3.14", "wpb": "14560.7", "bsz": "84.1", "num_updates": "117000", "lr": "1.74238e-06", "gnorm": "130.77", "loss_scale": "8", "train_wall": "63", "gb_free": "32.5", "wall": "38416"}
[2024-07-10 07:57:08,257][train_inner][INFO] - {"epoch": 67, "update": 66.922, "loss": "85.395", "ntokens": "14647.5", "nsentences": "85.64", "nll_loss": "0.499", "wps": "45848", "ups": "3.13", "wpb": "14647.5", "bsz": "85.6", "num_updates": "117200", "lr": "1.72507e-06", "gnorm": "128.807", "loss_scale": "16", "train_wall": "63", "gb_free": "32.3", "wall": "38480"}
[2024-07-10 07:57:51,011][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 07:57:51,012][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 07:58:01,954][dev-other][INFO] - {"epoch": 67, "dev-other_loss": "23.158", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.246", "dev-other_uer": "3.9", "dev-other_wer": "10.45", "dev-other_raw_wer": "10.45", "dev-other_wps": "27236.9", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "117336", "dev-other_best_wer": "10.45"}
[2024-07-10 07:58:01,954][fairseq_cli.train][INFO] - end of epoch 67 (average epoch stats below)
[2024-07-10 07:58:01,958][train][INFO] - {"epoch": 67, "train_loss": "87.643", "train_ntokens": "14577.5", "train_nsentences": "84.867", "train_nll_loss": "0.51", "train_wps": "44763.1", "train_ups": "3.07", "train_wpb": "14577.5", "train_bsz": "84.9", "train_num_updates": "117336", "train_lr": "1.71339e-06", "train_gnorm": "129.971", "train_loss_scale": "16", "train_train_wall": "554", "train_gb_free": "33.8", "train_wall": "38534"}
[2024-07-10 07:58:01,960][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 07:58:02,647][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 07:58:02,651][fairseq.trainer][INFO] - begin training epoch 68
[2024-07-10 07:58:02,651][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 07:58:23,395][train_inner][INFO] - {"epoch": 68, "update": 67.037, "loss": "89.898", "ntokens": "14493.6", "nsentences": "83.835", "nll_loss": "0.52", "wps": "38615", "ups": "2.66", "wpb": "14493.6", "bsz": "83.8", "num_updates": "117400", "lr": "1.70793e-06", "gnorm": "130.778", "loss_scale": "16", "train_wall": "63", "gb_free": "32.6", "wall": "38555"}
[2024-07-10 07:59:27,749][train_inner][INFO] - {"epoch": 68, "update": 67.151, "loss": "86.907", "ntokens": "14646.7", "nsentences": "85.24", "nll_loss": "0.506", "wps": "45522.6", "ups": "3.11", "wpb": "14646.7", "bsz": "85.2", "num_updates": "117600", "lr": "1.69096e-06", "gnorm": "131.619", "loss_scale": "16", "train_wall": "64", "gb_free": "32.8", "wall": "38620"}
[2024-07-10 08:00:31,849][train_inner][INFO] - {"epoch": 68, "update": 67.265, "loss": "86.806", "ntokens": "14664.7", "nsentences": "85.52", "nll_loss": "0.506", "wps": "45760.6", "ups": "3.12", "wpb": "14664.7", "bsz": "85.5", "num_updates": "117800", "lr": "1.67416e-06", "gnorm": "129.768", "loss_scale": "16", "train_wall": "64", "gb_free": "32.9", "wall": "38684"}
[2024-07-10 08:01:35,540][train_inner][INFO] - {"epoch": 68, "update": 67.379, "loss": "84.552", "ntokens": "14634.5", "nsentences": "88", "nll_loss": "0.508", "wps": "45958.3", "ups": "3.14", "wpb": "14634.5", "bsz": "88", "num_updates": "118000", "lr": "1.65752e-06", "gnorm": "126.386", "loss_scale": "16", "train_wall": "63", "gb_free": "31.7", "wall": "38748"}
[2024-07-10 08:02:39,173][train_inner][INFO] - {"epoch": 68, "update": 67.493, "loss": "88.191", "ntokens": "14510.6", "nsentences": "83.24", "nll_loss": "0.506", "wps": "45612", "ups": "3.14", "wpb": "14510.6", "bsz": "83.2", "num_updates": "118200", "lr": "1.64105e-06", "gnorm": "129.99", "loss_scale": "16", "train_wall": "63", "gb_free": "33.2", "wall": "38811"}
[2024-07-10 08:03:42,704][train_inner][INFO] - {"epoch": 68, "update": 67.607, "loss": "88.206", "ntokens": "14523.8", "nsentences": "84.6", "nll_loss": "0.514", "wps": "45726.6", "ups": "3.15", "wpb": "14523.8", "bsz": "84.6", "num_updates": "118400", "lr": "1.62475e-06", "gnorm": "130.843", "loss_scale": "16", "train_wall": "63", "gb_free": "32.1", "wall": "38875"}
[2024-07-10 08:04:47,136][train_inner][INFO] - {"epoch": 68, "update": 67.721, "loss": "87.294", "ntokens": "14573.3", "nsentences": "84", "nll_loss": "0.503", "wps": "45285.5", "ups": "3.11", "wpb": "14573.3", "bsz": "84", "num_updates": "118600", "lr": "1.6086e-06", "gnorm": "130.851", "loss_scale": "16", "train_wall": "64", "gb_free": "29.4", "wall": "38939"}
[2024-07-10 08:05:13,028][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 08:05:51,498][train_inner][INFO] - {"epoch": 68, "update": 67.836, "loss": "88.109", "ntokens": "14534.7", "nsentences": "83.64", "nll_loss": "0.507", "wps": "45214.4", "ups": "3.11", "wpb": "14534.7", "bsz": "83.6", "num_updates": "118800", "lr": "1.59262e-06", "gnorm": "131.471", "loss_scale": "8", "train_wall": "64", "gb_free": "33.3", "wall": "39003"}
[2024-07-10 08:06:55,758][train_inner][INFO] - {"epoch": 68, "update": 67.95, "loss": "86.808", "ntokens": "14595.5", "nsentences": "85.24", "nll_loss": "0.507", "wps": "45429.9", "ups": "3.11", "wpb": "14595.5", "bsz": "85.2", "num_updates": "119000", "lr": "1.57679e-06", "gnorm": "129.036", "loss_scale": "8", "train_wall": "64", "gb_free": "31.9", "wall": "39068"}
[2024-07-10 08:07:23,419][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 08:07:23,420][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 08:07:34,117][dev-other][INFO] - {"epoch": 68, "dev-other_loss": "23.345", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.248", "dev-other_uer": "3.928", "dev-other_wer": "10.524", "dev-other_raw_wer": "10.524", "dev-other_wps": "27746.1", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "119087", "dev-other_best_wer": "10.471"}
[2024-07-10 08:07:34,118][fairseq_cli.train][INFO] - end of epoch 68 (average epoch stats below)
[2024-07-10 08:07:34,121][train][INFO] - {"epoch": 68, "train_loss": "87.197", "train_ntokens": "14578", "train_nsentences": "84.8195", "train_nll_loss": "0.507", "train_wps": "44613.4", "train_ups": "3.06", "train_wpb": "14578", "train_bsz": "84.8", "train_num_updates": "119087", "train_lr": "1.56996e-06", "train_gnorm": "130.116", "train_loss_scale": "8", "train_train_wall": "556", "train_gb_free": "30.8", "train_wall": "39106"}
[2024-07-10 08:07:34,122][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 08:07:34,871][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1752
[2024-07-10 08:07:34,874][fairseq.trainer][INFO] - begin training epoch 69
[2024-07-10 08:07:34,875][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 08:08:10,725][train_inner][INFO] - {"epoch": 69, "update": 68.064, "loss": "88.955", "ntokens": "14478.7", "nsentences": "84.04", "nll_loss": "0.516", "wps": "38664.2", "ups": "2.67", "wpb": "14478.7", "bsz": "84", "num_updates": "119200", "lr": "1.56113e-06", "gnorm": "131.771", "loss_scale": "8", "train_wall": "63", "gb_free": "32.8", "wall": "39143"}
[2024-07-10 08:09:14,426][train_inner][INFO] - {"epoch": 69, "update": 68.179, "loss": "89.394", "ntokens": "14465.8", "nsentences": "82.88", "nll_loss": "0.512", "wps": "45470.5", "ups": "3.14", "wpb": "14465.8", "bsz": "82.9", "num_updates": "119400", "lr": "1.54562e-06", "gnorm": "134.526", "loss_scale": "8", "train_wall": "63", "gb_free": "31.6", "wall": "39206"}
[2024-07-10 08:10:19,149][train_inner][INFO] - {"epoch": 69, "update": 68.293, "loss": "87.194", "ntokens": "14738.9", "nsentences": "86.92", "nll_loss": "0.514", "wps": "45595", "ups": "3.09", "wpb": "14738.9", "bsz": "86.9", "num_updates": "119600", "lr": "1.53026e-06", "gnorm": "128.748", "loss_scale": "8", "train_wall": "64", "gb_free": "32.1", "wall": "39271"}
[2024-07-10 08:11:22,927][train_inner][INFO] - {"epoch": 69, "update": 68.407, "loss": "90.02", "ntokens": "14529.2", "nsentences": "83.24", "nll_loss": "0.516", "wps": "45611.7", "ups": "3.14", "wpb": "14529.2", "bsz": "83.2", "num_updates": "119800", "lr": "1.51505e-06", "gnorm": "132.749", "loss_scale": "8", "train_wall": "63", "gb_free": "33.5", "wall": "39335"}
[2024-07-10 08:12:27,363][train_inner][INFO] - {"epoch": 69, "update": 68.521, "loss": "83", "ntokens": "14754.9", "nsentences": "88.395", "nll_loss": "0.497", "wps": "45819.2", "ups": "3.11", "wpb": "14754.9", "bsz": "88.4", "num_updates": "120000", "lr": "1.5e-06", "gnorm": "124.951", "loss_scale": "8", "train_wall": "64", "gb_free": "33", "wall": "39399"}
[2024-07-10 08:12:27,401][fairseq_cli.train][INFO] - Stopping training due to num_updates: 120000 >= max_update: 120000
[2024-07-10 08:12:27,401][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 08:12:27,402][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 08:12:38,146][dev-other][INFO] - {"epoch": 69, "dev-other_loss": "23.133", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.246", "dev-other_uer": "3.921", "dev-other_wer": "10.507", "dev-other_raw_wer": "10.507", "dev-other_wps": "27807.3", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "120000", "dev-other_best_wer": "10.471"}
[2024-07-10 08:12:38,147][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 69 @ 120000 updates
[2024-07-10 08:12:38,148][fairseq.trainer][INFO] - Saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_last.pt
[2024-07-10 08:12:39,146][fairseq.trainer][INFO] - Finished saving checkpoint to /mntcephfs/lab_data/maduo/exp/finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_last.pt
[2024-07-10 08:12:39,159][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mntcephfs/lab_data/maduo/exp//finetune/hubert_base_librispeech_offical_no_finetune_500h_asr_finetune_12ksteps/checkpoint_last.pt (epoch 69 @ 120000 updates, score 10.507) (writing took 1.0114026479423046 seconds)
[2024-07-10 08:12:39,162][fairseq_cli.train][INFO] - end of epoch 69 (average epoch stats below)
[2024-07-10 08:12:39,239][train][INFO] - {"epoch": 69, "train_loss": "87.687", "train_ntokens": "14602.3", "train_nsentences": "85.1599", "train_nll_loss": "0.511", "train_wps": "43705", "train_ups": "2.99", "train_wpb": "14602.3", "train_bsz": "85.2", "train_num_updates": "120000", "train_lr": "1.5e-06", "train_gnorm": "130.56", "train_loss_scale": "8", "train_train_wall": "290", "train_gb_free": "33", "train_wall": "39411"}
[2024-07-10 08:12:39,239][fairseq_cli.train][INFO] - done training in 39385.9 seconds
/mntnfs/lee_data1/maduo/anaconda3/envs/fairseq_speechtext/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
fine tune base offical hubert model  using train-clean-360 supervision data
[2024-07-10 08:12:51,254][fairseq.distributed.utils][INFO] - Rank 0, device_id: 0
2024-07-10 08:12:55 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:28610
2024-07-10 08:12:55 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:28610
2024-07-10 08:12:55 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:28610
2024-07-10 08:12:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2024-07-10 08:12:55 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:28610
2024-07-10 08:12:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2024-07-10 08:12:56 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2024-07-10 08:12:56 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2024-07-10 08:12:56 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-07-10 08:12:56 | INFO | fairseq.distributed.utils | initialized host pgpu13 as rank 0
2024-07-10 08:12:56 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-07-10 08:12:56 | INFO | fairseq.distributed.utils | initialized host pgpu13 as rank 2
2024-07-10 08:12:56 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-07-10 08:12:56 | INFO | fairseq.distributed.utils | initialized host pgpu13 as rank 3
2024-07-10 08:12:56 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-07-10 08:12:56 | INFO | fairseq.distributed.utils | initialized host pgpu13 as rank 1
[2024-07-10 08:12:58,813][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/mntcephfs/lab_data/maduo/exp//finetune/hubert_base_librispeech_offical_no_finetune_360h_asr_finetune_10ksteps', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/t-hubert', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:28610', 'distributed_port': 28610, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3200000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train-clean-360', 'valid_subset': 'dev-other', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3200000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 100000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [2], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/mntcephfs/lab_data/maduo/exp//finetune/hubert_base_librispeech_offical_no_finetune_360h_asr_finetune_10ksteps', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'wer', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'hubert_ctc', 'w2v_path': '/mntcephfs/lab_data/maduo/model_hub/librispeech/hubert_base_librispeech_offical_no_finetune//hubert_base_ls960.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.1, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_embed_dim': 768, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 0, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'normalize': False, 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'w2v_args': None, 'autoregressive': False}, 'task': {'_name': 'hubert_pretraining', 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'fine_tuning': True, 'labels': ['ltr'], 'label_dir': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'label_rate': -1.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': None, 'min_sample_size': None, 'single_target': True, 'random_crop': True, 'pad_audio': False}, 'criterion': {'_name': 'ctc', 'zero_infinity': True, 'sentence_avg': True, 'post_process': 'letter', 'wer_kenlm_model': None, 'wer_lexicon': None, 'wer_lm_weight': 2.0, 'wer_word_score': -1.0, 'wer_sil_weight': 0.0, 'wer_args': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05], 'amsgrad': False}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 10000, 'hold_steps': 40000, 'decay_steps': 50000, 'phase_ratio': None, 'init_lr_scale': 0.01, 'final_lr_scale': 0.05, 'max_update': 100000.0, 'lr': [3e-05]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': '/mntcephfs/lab_data/maduo/model_hub/librispeech/hubert_base_librispeech_offical_no_finetune//finetune.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-07-10 08:12:58,817][fairseq.tasks.hubert_pretraining][INFO] - current directory is /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/t-hubert
[2024-07-10 08:12:58,817][fairseq.tasks.hubert_pretraining][INFO] - HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'fine_tuning': True, 'labels': ['ltr'], 'label_dir': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'label_rate': -1.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': None, 'min_sample_size': None, 'single_target': True, 'random_crop': True, 'pad_audio': False}
[2024-07-10 08:12:58,820][fairseq.models.hubert.hubert_asr][INFO] - cfg: {'_name': 'hubert_ctc', 'w2v_path': '/mntcephfs/lab_data/maduo/model_hub/librispeech/hubert_base_librispeech_offical_no_finetune//hubert_base_ls960.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.1, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_embed_dim': 768, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 0, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'normalize': False, 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'w2v_args': None, 'autoregressive': False}, task: <fairseq.tasks.hubert_pretraining.HubertPretrainingTask object at 0x1554074f30d0>
[2024-07-10 08:12:58,821][fairseq.models.hubert.hubert_asr][INFO] - mdddd:::/mntcephfs/lab_data/maduo/model_hub/librispeech/hubert_base_librispeech_offical_no_finetune//hubert_base_ls960.pt
[2024-07-10 08:13:04,389][fairseq.tasks.hubert_pretraining][INFO] - current directory is /mntnfs/lee_data1/maduo/codebase/fairseq_speechtext/examples/t-hubert
[2024-07-10 08:13:04,389][fairseq.tasks.hubert_pretraining][INFO] - HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': '/mntcephfs/lab_data/maduo/datasets/format/librispeech/', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
[2024-07-10 08:13:04,397][fairseq.models.hubert.hubert][INFO] - HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
[2024-07-10 08:13:08,601][fairseq_cli.train][INFO] - HubertCtc(
  (w2v_encoder): HubertEncoder(
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (proj): Linear(in_features=768, out_features=32, bias=True)
  )
)
[2024-07-10 08:13:08,603][fairseq_cli.train][INFO] - task: HubertPretrainingTask
[2024-07-10 08:13:08,603][fairseq_cli.train][INFO] - model: HubertCtc
[2024-07-10 08:13:08,603][fairseq_cli.train][INFO] - criterion: CtcCriterion
[2024-07-10 08:13:08,604][fairseq_cli.train][INFO] - num. shared model params: 94,525,344 (num. trained: 94,525,344)
[2024-07-10 08:13:08,605][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-07-10 08:13:08,611][fairseq.data.audio.hubert_dataset][INFO] - max_keep=None, min_keep=None, loaded 2864, skipped 0 short and 0 long, longest-loaded=562480, shortest-loaded=17040
[2024-07-10 08:13:08,613][fairseq.data.audio.hubert_dataset][INFO] - /mntcephfs/lab_data/maduo/datasets/format/librispeech//dev-other.ltr is sequence label. skipped
[2024-07-10 08:13:08,614][fairseq.data.audio.hubert_dataset][INFO] - pad_audio=False, random_crop=True, normalize=False, max_sample_size=9223372036854775807
[2024-07-10 08:13:11,203][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:2 to store for rank: 0
[2024-07-10 08:13:11,285][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
[2024-07-10 08:13:11,285][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias <- w2v_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
[2024-07-10 08:13:11,285][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias <- w2v_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
[2024-07-10 08:13:11,285][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias <- w2v_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
[2024-07-10 08:13:11,286][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias <- w2v_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
[2024-07-10 08:13:11,286][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias <- w2v_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
[2024-07-10 08:13:11,286][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias <- w2v_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
[2024-07-10 08:13:11,900][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2024-07-10 08:13:11,900][fairseq.utils][INFO] - rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
[2024-07-10 08:13:11,900][fairseq.utils][INFO] - rank   1: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
[2024-07-10 08:13:11,901][fairseq.utils][INFO] - rank   2: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
[2024-07-10 08:13:11,901][fairseq.utils][INFO] - rank   3: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   
[2024-07-10 08:13:11,901][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2024-07-10 08:13:11,901][fairseq_cli.train][INFO] - training on 4 devices (GPUs/TPUs)
[2024-07-10 08:13:11,901][fairseq_cli.train][INFO] - max tokens per device = 3200000 and max sentences per device = None
[2024-07-10 08:13:11,902][fairseq.trainer][INFO] - Preparing to load checkpoint /mntcephfs/lab_data/maduo/exp//finetune/hubert_base_librispeech_offical_no_finetune_360h_asr_finetune_10ksteps/checkpoint_last.pt
[2024-07-10 08:13:11,902][fairseq.trainer][INFO] - No existing checkpoint found /mntcephfs/lab_data/maduo/exp//finetune/hubert_base_librispeech_offical_no_finetune_360h_asr_finetune_10ksteps/checkpoint_last.pt
[2024-07-10 08:13:11,902][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-07-10 08:13:11,970][fairseq.data.audio.hubert_dataset][INFO] - max_keep=None, min_keep=None, loaded 104014, skipped 0 short and 0 long, longest-loaded=475760, shortest-loaded=17040
[2024-07-10 08:13:12,076][fairseq.data.audio.hubert_dataset][INFO] - /mntcephfs/lab_data/maduo/datasets/format/librispeech//train-clean-360.ltr is sequence label. skipped
[2024-07-10 08:13:12,076][fairseq.data.audio.hubert_dataset][INFO] - pad_audio=False, random_crop=True, normalize=False, max_sample_size=9223372036854775807
[2024-07-10 08:13:12,124][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 08:13:12,124][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2024-07-10 08:13:12,124][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = False
[2024-07-10 08:13:12,124][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2024-07-10 08:13:12,950][fairseq_cli.train][INFO] - begin dry-run validation on "dev-other" subset
[2024-07-10 08:13:12,951][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 08:13:12,951][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2024-07-10 08:13:12,951][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = False
[2024-07-10 08:13:12,951][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2024-07-10 08:13:38,826][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-10 08:13:38,829][fairseq.trainer][INFO] - begin training epoch 1
[2024-07-10 08:13:38,829][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 08:14:08,447][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2024-07-10 08:14:08,886][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2024-07-10 08:14:09,317][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-07-10 08:14:09,676][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-07-10 08:14:30,758][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-07-10 08:15:03,425][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-07-10 08:15:21,975][train_inner][INFO] - {"epoch": 1, "update": 0.159, "loss": "2181.81", "ntokens": "14768.5", "nsentences": "80.04", "nll_loss": "11.825", "wps": "40887.2", "ups": "2.77", "wpb": "14768.5", "bsz": "80", "num_updates": "200", "lr": "8.94e-07", "gnorm": "1631.94", "loss_scale": "2", "train_wall": "79", "gb_free": "32.6", "wall": "130"}
[2024-07-10 08:15:32,265][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-07-10 08:16:32,350][train_inner][INFO] - {"epoch": 1, "update": 0.314, "loss": "1233.17", "ntokens": "14833.8", "nsentences": "80.04", "nll_loss": "6.654", "wps": "42161.3", "ups": "2.84", "wpb": "14833.8", "bsz": "80", "num_updates": "400", "lr": "1.488e-06", "gnorm": "2057.93", "loss_scale": "1", "train_wall": "70", "gb_free": "32.5", "wall": "200"}
[2024-07-10 08:17:41,393][train_inner][INFO] - {"epoch": 1, "update": 0.468, "loss": "819.274", "ntokens": "14865.8", "nsentences": "80.75", "nll_loss": "4.45", "wps": "43064.9", "ups": "2.9", "wpb": "14865.8", "bsz": "80.8", "num_updates": "600", "lr": "2.082e-06", "gnorm": "527.64", "loss_scale": "1", "train_wall": "69", "gb_free": "32.5", "wall": "269"}
[2024-07-10 08:18:50,252][train_inner][INFO] - {"epoch": 1, "update": 0.622, "loss": "780.662", "ntokens": "14855.9", "nsentences": "80.08", "nll_loss": "4.208", "wps": "43189.4", "ups": "2.91", "wpb": "14855.9", "bsz": "80.1", "num_updates": "800", "lr": "2.676e-06", "gnorm": "233.318", "loss_scale": "1", "train_wall": "68", "gb_free": "32.2", "wall": "338"}
[2024-07-10 08:19:58,234][train_inner][INFO] - {"epoch": 1, "update": 0.776, "loss": "765.05", "ntokens": "14801.2", "nsentences": "80.6", "nll_loss": "4.166", "wps": "43590.2", "ups": "2.95", "wpb": "14801.2", "bsz": "80.6", "num_updates": "1000", "lr": "3.27e-06", "gnorm": "190.342", "loss_scale": "1", "train_wall": "67", "gb_free": "29.5", "wall": "406"}
[2024-07-10 08:21:05,520][train_inner][INFO] - {"epoch": 1, "update": 0.931, "loss": "764.615", "ntokens": "14834.5", "nsentences": "80.4", "nll_loss": "4.144", "wps": "44099.7", "ups": "2.97", "wpb": "14834.5", "bsz": "80.4", "num_updates": "1200", "lr": "3.864e-06", "gnorm": "185.058", "loss_scale": "1", "train_wall": "67", "gb_free": "32.4", "wall": "474"}
[2024-07-10 08:21:35,697][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 08:21:35,886][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 08:21:47,259][dev-other][INFO] - {"epoch": 1, "dev-other_loss": "392.39", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "4.171", "dev-other_uer": "100", "dev-other_wer": "100", "dev-other_raw_wer": "100", "dev-other_wps": "26541.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "1290"}
[2024-07-10 08:21:47,260][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2024-07-10 08:21:47,263][train][INFO] - {"epoch": 1, "train_loss": "1067.96", "train_ntokens": "14823", "train_nsentences": "80.2217", "train_nll_loss": "5.78", "train_wps": "41792.2", "train_ups": "2.82", "train_wpb": "14823", "train_bsz": "80.2", "train_num_updates": "1290", "train_lr": "4.1313e-06", "train_gnorm": "761.436", "train_loss_scale": "1", "train_train_wall": "450", "train_gb_free": "31.6", "train_wall": "515"}
[2024-07-10 08:21:47,264][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 08:21:47,921][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-10 08:21:47,926][fairseq.trainer][INFO] - begin training epoch 2
[2024-07-10 08:21:47,926][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 08:22:24,544][train_inner][INFO] - {"epoch": 2, "update": 1.085, "loss": "757.402", "ntokens": "14770.5", "nsentences": "80.56", "nll_loss": "4.131", "wps": "37385.5", "ups": "2.53", "wpb": "14770.5", "bsz": "80.6", "num_updates": "1400", "lr": "4.458e-06", "gnorm": "199.252", "loss_scale": "1", "train_wall": "66", "gb_free": "30.8", "wall": "553"}
[2024-07-10 08:23:30,584][train_inner][INFO] - {"epoch": 2, "update": 1.239, "loss": "758.669", "ntokens": "14787.5", "nsentences": "80.28", "nll_loss": "4.119", "wps": "44804.1", "ups": "3.03", "wpb": "14787.5", "bsz": "80.3", "num_updates": "1600", "lr": "5.052e-06", "gnorm": "193.177", "loss_scale": "1", "train_wall": "66", "gb_free": "32.9", "wall": "619"}
[2024-07-10 08:24:36,629][train_inner][INFO] - {"epoch": 2, "update": 1.393, "loss": "783.374", "ntokens": "14761.8", "nsentences": "77.48", "nll_loss": "4.112", "wps": "44745.5", "ups": "3.03", "wpb": "14761.8", "bsz": "77.5", "num_updates": "1800", "lr": "5.646e-06", "gnorm": "176.965", "loss_scale": "1", "train_wall": "66", "gb_free": "31.2", "wall": "685"}
[2024-07-10 08:25:43,050][train_inner][INFO] - {"epoch": 2, "update": 1.547, "loss": "760.043", "ntokens": "14901.5", "nsentences": "80.68", "nll_loss": "4.115", "wps": "44872.7", "ups": "3.01", "wpb": "14901.5", "bsz": "80.7", "num_updates": "2000", "lr": "6.24e-06", "gnorm": "191.996", "loss_scale": "1", "train_wall": "66", "gb_free": "32.1", "wall": "751"}
[2024-07-10 08:26:48,547][train_inner][INFO] - {"epoch": 2, "update": 1.702, "loss": "757.864", "ntokens": "14728.1", "nsentences": "79.92", "nll_loss": "4.112", "wps": "45020.1", "ups": "3.06", "wpb": "14728.1", "bsz": "79.9", "num_updates": "2200", "lr": "6.834e-06", "gnorm": "180.344", "loss_scale": "1", "train_wall": "65", "gb_free": "32.2", "wall": "817"}
[2024-07-10 08:27:54,241][train_inner][INFO] - {"epoch": 2, "update": 1.856, "loss": "748.47", "ntokens": "14923.5", "nsentences": "81.87", "nll_loss": "4.106", "wps": "45436.7", "ups": "3.04", "wpb": "14923.5", "bsz": "81.9", "num_updates": "2400", "lr": "7.428e-06", "gnorm": "159.994", "loss_scale": "2", "train_wall": "65", "gb_free": "32.3", "wall": "882"}
[2024-07-10 08:28:55,400][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 08:28:55,402][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 08:29:06,178][dev-other][INFO] - {"epoch": 2, "dev-other_loss": "374.41", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "3.98", "dev-other_uer": "99.832", "dev-other_wer": "100", "dev-other_raw_wer": "100", "dev-other_wps": "27717.4", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "2587"}
[2024-07-10 08:29:06,178][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2024-07-10 08:29:06,185][train][INFO] - {"epoch": 2, "train_loss": "759.527", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "4.109", "train_wps": "43801.8", "train_ups": "2.96", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "2587", "train_lr": "7.98339e-06", "train_gnorm": "179.235", "train_loss_scale": "2", "train_train_wall": "424", "train_gb_free": "32.4", "train_wall": "954"}
[2024-07-10 08:29:06,187][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 08:29:06,792][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-10 08:29:06,796][fairseq.trainer][INFO] - begin training epoch 3
[2024-07-10 08:29:06,796][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 08:29:11,291][train_inner][INFO] - {"epoch": 3, "update": 2.01, "loss": "753.063", "ntokens": "14874.8", "nsentences": "80.4", "nll_loss": "4.07", "wps": "38614.5", "ups": "2.6", "wpb": "14874.8", "bsz": "80.4", "num_updates": "2600", "lr": "8.022e-06", "gnorm": "162.024", "loss_scale": "2", "train_wall": "65", "gb_free": "33", "wall": "959"}
[2024-07-10 08:30:17,096][train_inner][INFO] - {"epoch": 3, "update": 2.164, "loss": "700.474", "ntokens": "14751.4", "nsentences": "79.71", "nll_loss": "3.785", "wps": "44879.6", "ups": "3.04", "wpb": "14751.4", "bsz": "79.7", "num_updates": "2800", "lr": "8.616e-06", "gnorm": "194.391", "loss_scale": "2", "train_wall": "65", "gb_free": "30.6", "wall": "1025"}
[2024-07-10 08:31:22,483][train_inner][INFO] - {"epoch": 3, "update": 2.318, "loss": "607.494", "ntokens": "14897", "nsentences": "79.88", "nll_loss": "3.257", "wps": "45621.6", "ups": "3.06", "wpb": "14897", "bsz": "79.9", "num_updates": "3000", "lr": "9.21e-06", "gnorm": "184.906", "loss_scale": "2", "train_wall": "65", "gb_free": "32.6", "wall": "1091"}
[2024-07-10 08:32:27,649][train_inner][INFO] - {"epoch": 3, "update": 2.473, "loss": "485.814", "ntokens": "14898.8", "nsentences": "82.6", "nll_loss": "2.693", "wps": "45756.8", "ups": "3.07", "wpb": "14898.8", "bsz": "82.6", "num_updates": "3200", "lr": "9.804e-06", "gnorm": "210.439", "loss_scale": "2", "train_wall": "65", "gb_free": "32.1", "wall": "1156"}
[2024-07-10 08:33:32,733][train_inner][INFO] - {"epoch": 3, "update": 2.627, "loss": "404.343", "ntokens": "14861.5", "nsentences": "80.48", "nll_loss": "2.19", "wps": "45673.4", "ups": "3.07", "wpb": "14861.5", "bsz": "80.5", "num_updates": "3400", "lr": "1.0398e-05", "gnorm": "166.976", "loss_scale": "2", "train_wall": "65", "gb_free": "32", "wall": "1221"}
[2024-07-10 08:34:37,842][train_inner][INFO] - {"epoch": 3, "update": 2.781, "loss": "331.023", "ntokens": "14787.6", "nsentences": "80.12", "nll_loss": "1.793", "wps": "45427.8", "ups": "3.07", "wpb": "14787.6", "bsz": "80.1", "num_updates": "3600", "lr": "1.0992e-05", "gnorm": "163.462", "loss_scale": "2", "train_wall": "65", "gb_free": "32.7", "wall": "1286"}
[2024-07-10 08:35:43,079][train_inner][INFO] - {"epoch": 3, "update": 2.935, "loss": "285.829", "ntokens": "14784.5", "nsentences": "79.44", "nll_loss": "1.536", "wps": "45377.1", "ups": "3.07", "wpb": "14784.5", "bsz": "79.4", "num_updates": "3800", "lr": "1.1586e-05", "gnorm": "148.543", "loss_scale": "2", "train_wall": "65", "gb_free": "33", "wall": "1351"}
[2024-07-10 08:36:10,288][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 08:36:10,289][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 08:36:21,093][dev-other][INFO] - {"epoch": 3, "dev-other_loss": "82.33", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.875", "dev-other_uer": "15.927", "dev-other_wer": "48.401", "dev-other_raw_wer": "48.401", "dev-other_wps": "27546.2", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "3884"}
[2024-07-10 08:36:21,094][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)
[2024-07-10 08:36:21,097][train][INFO] - {"epoch": 3, "train_loss": "459.97", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "2.489", "train_wps": "44205.3", "train_ups": "2.98", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "3884", "train_lr": "1.18355e-05", "train_gnorm": "177.472", "train_loss_scale": "2", "train_train_wall": "420", "train_gb_free": "32.1", "train_wall": "1389"}
[2024-07-10 08:36:21,098][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 08:36:21,720][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-10 08:36:21,724][fairseq.trainer][INFO] - begin training epoch 4
[2024-07-10 08:36:21,725][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 08:36:59,975][train_inner][INFO] - {"epoch": 4, "update": 3.089, "loss": "258.88", "ntokens": "14797.2", "nsentences": "81.12", "nll_loss": "1.419", "wps": "38491.1", "ups": "2.6", "wpb": "14797.2", "bsz": "81.1", "num_updates": "4000", "lr": "1.218e-05", "gnorm": "153.299", "loss_scale": "2", "train_wall": "65", "gb_free": "34", "wall": "1428"}
[2024-07-10 08:38:04,863][train_inner][INFO] - {"epoch": 4, "update": 3.244, "loss": "235.937", "ntokens": "14838.9", "nsentences": "80.75", "nll_loss": "1.284", "wps": "45786.4", "ups": "3.09", "wpb": "14838.9", "bsz": "80.8", "num_updates": "4200", "lr": "1.2774e-05", "gnorm": "150.731", "loss_scale": "2", "train_wall": "64", "gb_free": "32.5", "wall": "1493"}
[2024-07-10 08:39:09,617][train_inner][INFO] - {"epoch": 4, "update": 3.398, "loss": "230.575", "ntokens": "14834.6", "nsentences": "81.92", "nll_loss": "1.273", "wps": "45824.4", "ups": "3.09", "wpb": "14834.6", "bsz": "81.9", "num_updates": "4400", "lr": "1.3368e-05", "gnorm": "163.402", "loss_scale": "4", "train_wall": "64", "gb_free": "32.9", "wall": "1558"}
[2024-07-10 08:40:14,543][train_inner][INFO] - {"epoch": 4, "update": 3.552, "loss": "218.82", "ntokens": "14831", "nsentences": "79.52", "nll_loss": "1.173", "wps": "45690.9", "ups": "3.08", "wpb": "14831", "bsz": "79.5", "num_updates": "4600", "lr": "1.3962e-05", "gnorm": "161.065", "loss_scale": "4", "train_wall": "64", "gb_free": "32.1", "wall": "1623"}
[2024-07-10 08:41:19,335][train_inner][INFO] - {"epoch": 4, "update": 3.706, "loss": "204.251", "ntokens": "14743.8", "nsentences": "78.32", "nll_loss": "1.085", "wps": "45556.1", "ups": "3.09", "wpb": "14743.8", "bsz": "78.3", "num_updates": "4800", "lr": "1.4556e-05", "gnorm": "146.294", "loss_scale": "4", "train_wall": "64", "gb_free": "33.4", "wall": "1687"}
[2024-07-10 08:42:23,921][train_inner][INFO] - {"epoch": 4, "update": 3.86, "loss": "207.132", "ntokens": "14780.2", "nsentences": "77.2", "nll_loss": "1.082", "wps": "45831.4", "ups": "3.1", "wpb": "14780.2", "bsz": "77.2", "num_updates": "5000", "lr": "1.515e-05", "gnorm": "152.104", "loss_scale": "4", "train_wall": "64", "gb_free": "32", "wall": "1752"}
[2024-07-10 08:43:22,782][fairseq_cli.train][INFO] - begin validation on "dev-other" subset
[2024-07-10 08:43:22,783][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 08:43:33,769][dev-other][INFO] - {"epoch": 4, "dev-other_loss": "50.039", "dev-other_ntokens": "9267.86", "dev-other_nsentences": "98.5172", "dev-other_nll_loss": "0.532", "dev-other_uer": "9.57", "dev-other_wer": "30.762", "dev-other_raw_wer": "30.762", "dev-other_wps": "27739.5", "dev-other_wpb": "9267.9", "dev-other_bsz": "98.5", "dev-other_num_updates": "5181"}
[2024-07-10 08:43:33,769][fairseq_cli.train][INFO] - end of epoch 4 (average epoch stats below)
[2024-07-10 08:43:33,778][train][INFO] - {"epoch": 4, "train_loss": "217.195", "train_ntokens": "14822.9", "train_nsentences": "80.1958", "train_nll_loss": "1.175", "train_wps": "44433.8", "train_ups": "3", "train_wpb": "14822.9", "train_bsz": "80.2", "train_num_updates": "5181", "train_lr": "1.56876e-05", "train_gnorm": "152.815", "train_loss_scale": "4", "train_train_wall": "418", "train_gb_free": "32.1", "train_wall": "1822"}
[2024-07-10 08:43:33,779][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-07-10 08:43:34,215][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1297
[2024-07-10 08:43:34,219][fairseq.trainer][INFO] - begin training epoch 5
[2024-07-10 08:43:34,225][fairseq_cli.train][INFO] - Start iterating over samples
[2024-07-10 08:43:40,889][train_inner][INFO] - {"epoch": 5, "update": 4.015, "loss": "185.469", "ntokens": "14876.4", "nsentences": "80.68", "nll_loss": "1.006", "wps": "38794", "ups": "2.61", "wpb": "14876.4", "bsz": "80.7", "num_updates": "5200", "lr": "1.5744e-05", "gnorm": "143.23", "loss_scale": "4", "train_wall": "65", "gb_free": "32.3", "wall": "1829"}
[2024-07-10 08:44:45,248][train_inner][INFO] - {"epoch": 5, "update": 4.169, "loss": "181.806", "ntokens": "14798", "nsentences": "79.36", "nll_loss": "0.975", "wps": "46007.7", "ups": "3.11", "wpb": "14798", "bsz": "79.4", "num_updates": "5400", "lr": "1.6338e-05", "gnorm": "147.382", "loss_scale": "4", "train_wall": "64", "gb_free": "31.8", "wall": "1893"}
[2024-07-10 08:45:49,761][train_inner][INFO] - {"epoch": 5, "update": 4.323, "loss": "174.908", "ntokens": "14805", "nsentences": "79.84", "nll_loss": "0.943", "wps": "45952.4", "ups": "3.1", "wpb": "14805", "bsz": "79.8", "num_updates": "5600", "lr": "1.6932e-05", "gnorm": "143.305", "loss_scale": "4", "train_wall": "64", "gb_free": "32.3", "wall": "1958"}
[2024-07-10 08:46:54,446][train_inner][INFO] - {"epoch": 5, "update": 4.477, "loss": "160.915", "ntokens": "14860.8", "nsentences": "82.08", "nll_loss": "0.889", "wps": "45953.7", "ups": "3.09", "wpb": "14860.8", "bsz": "82.1", "num_updates": "5800", "lr": "1.7526e-05", "gnorm": "134.613", "loss_scale": "4", "train_wall": "64", "gb_free": "33.1", "wall": "2023"}
[2024-07-10 08:47:58,678][train_inner][INFO] - {"epoch": 5, "update": 4.631, "loss": "162.316", "ntokens": "14875.5", "nsentences": "80.04", "nll_loss": "0.873", "wps": "46366.7", "ups": "3.12", "wpb": "14875.6", "bsz": "80", "num_updates": "6000", "lr": "1.812e-05", "gnorm": "137.533", "loss_scale": "4", "train_wall": "64", "gb_free": "32.8", "wall": "2087"}
[2024-07-10 08:49:02,838][train_inner][INFO] - {"epoch": 5, "update": 4.786, "loss": "158.099", "ntokens": "14863.6", "nsentences": "80.64", "nll_loss": "0.858", "wps": "46338.9", "ups": "3.12", "wpb": "14863.6", "bsz": "80.6", "num_updates": "6200", "lr": "1.8714e-05", "gnorm": "136.478", "loss_scale": "4", "train_wall": "64", "gb_free": "32.4", "wall": "2151"}
slurmstepd: error: *** JOB 167757 ON pgpu13 CANCELLED AT 2024-07-10T08:49:33 DUE TO TIME LIMIT ***
